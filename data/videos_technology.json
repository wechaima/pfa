[
    {
        "id": "ea2c856c-c626-4a32-b741-108c1a18535e",
        "type": "video",
        "domaine": "technology",
        "titre": "Crash Course Computer Science ",
        "url": "https://www.youtube.com/watch?v=tpIctyqH29Q",
        "description": "Starting February 22nd, Carrie Anne Philbin will be hosting Crash Course ",
        "chaine": "CrashCourse",
        "durée": "2:45",
        "keywords": [
           
            "computers",
           
            "computing",
           
            "Computer Science",
           
            "Computer"
           
        ],
        "transcription": "Hello world! I’m Carrie Anne Philbin and welcome to Crash\nCourse Computer Science! So, computers really have allowed us to do\nsome pretty amazing things - think global telecommunications, international commerce,\nglobal transportation, breakthroughs in medicine, distributed education, online shopping, online\ndating, just the Internet in general. Computers are allowing us to explore our own\nworld and other worlds, and of course some seemingly mundane things like permitting us\nto spy on our pets from work or communicate with our friends in a nearly indecipherable\nstream of emoji! But don’t call computers magical. They are not, I repeat ARE NOT, magical. So before we get into what we are going to\ntalk about in this course, it might be useful to tell you what we aren’t going to talk\nabout. We aren’t going to teach you how to program. Programming is a really crucial aspect of\ncomputer software, and we will get to the rules that guide the logic of hardware and\nsoftware design. But we aren’t going to teach you how to\nprogram an Arduino Uno to water your plant or how to change the CSS on your grandma’s\nsewing blog so visitors’ cursors turn into kittens. This also isn’t a computing course. Or at least how computing is thought of in\nthe U.S. Computing here is a goal - it’s what computers do. And we’ll talk about some of that for sure,\nbut OUR goal for this course is much broader. But computing means other things in other\ncountries. It’s all pretty confusing. But what we are going to look are the history\nof computers… even before we had electricity. We’re going retrace the design decisions\nthat have given us our president-day components. We’re going to talk about how Operating\nSystems work… or don’t work… how the YouTubes get to you over the Internet, how\nour smartphones and other smart devices are... well getting smarter, and of course mysterious\nfuturistic stuff like quantum computing and frustrating present-day stuff like hacking! It’s a lot to cover, but I suppose before\nwe get started I should introduce myself. I’m Carrie Anne Philbin! Hello! I'm an award winning secondary Computing teacher,\nauthor of 'Adventures in Raspberry Pi' and the creator of a YouTube video series for\nteenagers called the Geek Gurl Diaries, which includes stuff like interviews with women\nworking in technology, computer science based tutorials, and hands on digital maker style\nprojects. In my day job, I help people learn about technology\nand how to make things with computers as Director of Education for the Raspberry Pi Foundation,\nwhich is a charity based in Cambridge in the UK. Needless to say, I am passionate about this\nstuff, but not because computers are these amazing devices that are always making our\nlives easier (sometimes that’s debatable) but because computers inarguably have become\npivotal in our society. From our cars and thermostats to pacemakers\nand cellphones, computers are everywhere, and it’s my hope that by the end of this\ncourse you’ll have a better understanding and appreciation for how far we’ve come\nand how far they may take us. I’ll see you next week."
    },
    {
        "id": "3aadb89d-371f-4057-a886-d8f6082d0993",
        "type": "video",
        "domaine": "technology",
        "titre": "100+ Computer Science Concepts Explained",
        "url": "https://www.youtube.com/watch?v=-uleG_Vecis",
        "description": "Learn the fundamentals of ",
        "chaine": "Fireship",
        "durée": "13:08",
        "keywords": [
            "data points data",
            "multiple data points",
            "points data structures",
            "organizes multiple data",
            "built-in data types",
            "iterable data type",
            "char data type",
            "boolean data type",
            "iterable data structure",
            "run code simultaneously"
        ],
        "transcription": "what's the first thing you should do when your code throws an error obviously you should change nothing and try to run it again a few times if that doesn't work you're gonna need a computer science degree the awesome thing about software engineering is that you can learn to code and get a high paying job while literally having no idea how anything actually works it all just feels like magic like a pilot driving a giant metal tube in the sky while knowing nothing about aerodynamics [Music] welcome to computer science 101 in today's video you'll learn the science behind the garbage code you've been writing by learning 101 different computer science terms and concepts this is a computer it's just a piece of tape that holds ones and zeros along with a device that can read and write to it it's called a turing machine and in theory it can compute anything like the graphics in this video or the algorithm that recommended that you watch it at the core of modern computers we have the central processing unit if we crack it open we find a piece of silicon that contains billions of tiny transistors which are like microscopic on off switches the value at one of these switches is called a bit and is the smallest piece of information a computer can use however one bit by itself is not very useful so they come in a package of eight called a byte one byte can represent 256 different values like all the characters that you type on your keyboard in fact when you type into your keyboard the character produced is actually mapped to a binary value in a character encoding like ascii or utf-8 binary is just a system for counting like the base 10 system you normally use when counting on your fingers but it only has two characters one and zero humans have a hard time reading binary so most often it's represented in a hexadecimal base 16 format where ten numbers and six letters can represent a four bit group called a nibble as a developer when you write code in a programming language it will eventually be converted into machine code which is a binary format that can be decoded and executed by the cpu what it doesn't do though is store data for your applications for that computers have random access memory or ram it's like a neighborhood and inside of every house lives a byte every location has a memory address which the cpu can read and write to you can think of the cpu and ram as the brain of the computer but in order for a computer to be useful it needs to handle input and output an input device might be the keyboard and mouse while an output device might be your monitor luckily most developers don't need to worry about how this hardware fits together because we have operating system kernels like linux mac and windows that control all hardware resources via device drivers now to start hacking on the operating system your first entry point is the shell which is a program that exposes the operating system to the end user it's called a shell because it wraps the kernel it takes a line of text as input and produces an output this is called a command line interface not only can it connect to your own computer but with the secure shell protocol it can also connect to remote computers over a network now that you have access to the mainframe it's time to pick a programming language which is a tool that uses the abstraction principle to make computers practical to work with for humans by simplifying different systems layer by layer some languages like python are interpreted that means there's a program called an interpreter that will execute each line of code one by one other languages like c plus are compiled they use a compiler to convert the entire program into machine code in advance before the cpu attempts to execute it this results in an executable file that can be run by the operating system without any extra dependencies now every programming language has a variety of built-in data types to represent the data we're working with in our code instead of bytes we work with more human-friendly things like characters and numbers now the most fundamental way to use data in your application is to declare a variable this attaches a name to a data point allowing you to reuse it somewhere else in your code python is a dynamically typed language which means we don't need to tell the program exactly which data type is assigned to a variable it just figures it out automatically however other languages like c are statically typed and that means you need to specify the data type of a variable in your code when you define a variable its value is stored somewhere in memory on the hardware and you may need to allocate and free up memory throughout the program a pointer is a variable whose value is the memory address of another variable which can be used for low-level memory control many languages don't want to deal with low-level memory management and instead implement a garbage collector which automatically allocates and de-allocates memory when an object is no longer referenced in the program [Music] now the data types available are different in every programming language but typically you'll find int to represent whole numbers which may or may not be signed or unsigned to represent negative numbers as well when numbers require a decimal point they typically use the floating point type it's called a float because there's only enough memory to represent a certain range of numbers at a certain precision and is basically a form of scientific notation to make computers faster if you need more range or precision many languages also have a double that doubles the amount of memory used for the number now when it comes to characters you'll typically find the char data type to represent a single character or more commonly a string to represent multiple characters together ultimately these characters get stored in a memory address somewhere but they need to be stored in a certain order when the order starts with the most significant byte and the smallest memory address it's called big endian or vice versa if the least significant byte is stored in the smallest address it's called little endian when it comes to practical software engineering one of the most fundamental things we do is organize data into data structures the most useful data structure is probably the array or list just like a shopping list it organizes multiple data points in order however it also maintains an index of integers that starts at zero and goes up for every new item in the list that can be useful but you don't actually need an index to create a list of items another option is a linked list where each item has a pointer to the next item in front of it another option is a stack that follows the last in first out principle it's like stacking a set of plates then when you want to access the data you pop the last one off the top the inverse option is a queue which is first in first out just like when you get into the red line the first person there is the first one to be fed now another extremely useful data structure is the hash which might also be called a map or dictionary it's like an array but instead of an index of integers you define the keys that point to each individual item giving you a collection of key value pairs in many cases though it's not efficient to organize data in a linear way to address that problem we have trees which organize nodes together in a hierarchy that can often be traversed more quickly this can sometimes be too rigid of a data structure though so instead a graph can be created to connect multiple nodes together in a virtually unlimited number of ways a graph has a node for the data and an edge for the relationship between the data points data structures are essential but they don't do anything by themselves to do something useful you'll need to code up an algorithm which is just code that solves a problem i took the initiative in creating the internet in our code we have several mechanisms for implementing algorithms the most fundamental of which is a function which is a block of code that takes an input then does something and returns an output like a variable a function has a name and it can be called from other parts of your code with different input parameters called arguments one thing you might do in the function body is compare one value to another every language has a variety of built-in operators like equality greater than and less than that you can use to compare two values if a is greater than b then it forms a value of true but if b is greater than a then the value is false true false is what's known as a boolean data type and whenever your code produces a value like this it's known as an expression but not all code will produce a value sometimes your code will simply do something which is known as a statement a good example is the if statement which handles conditional logic for example if the condition is true it will execute this code otherwise it will short circuit and run the code inside of the else block another very common type of statement is a loop a while loop will run this block of code over and over again until the condition in the parentheses becomes false that can be useful but more often than not you'll want to loop over an iterable data type like an array most languages have a for loop that can run some code for every object in the array or iterable data structure now in some cases a function may not have an output which is generally called a void function an interesting thing about functions is that they can call themselves when a function calls itself it's called recursion because when done like this by default it will recurse forever creating an infinite loop that happens because when you call a function the programming language will put it into memory on what's known as the call stack which is a short-term chunk of memory for executing your code when a function keeps calling itself the language will keep pushing frames onto the call stack until you get a stack overflow error to avoid this your algorithm needs a base condition so it knows when to terminate the loop now when you write an algorithm you'll need to determine if it's any good and the system for doing that is called big-o notation it's a standard format for approximating the performance of an algorithm at scale it may reference time complexity which is how fast your algorithm will run and space complexity which deals with how much memory is required to run it developers have many different algorithm types at their disposal the most crude option is brute force where you might loop over every possible combination to hack somebody's credit card pin a more sophisticated approach might be divide and conquer like binary search where you cut the problem in half multiple times until you find what you're looking for another option is dynamic programming algorithms where a problem is broken down into multiple smaller sub-problems and the result of each computation is stored for later use using a technique called memoization that means if a function has already been called it will use the existing value instead of recomputing it again from scratch then we have greedy algorithms that will make the choice that is most beneficial in the short term without considering the problem as a whole one example of this is dijkstra's shortest path algorithm on the flip side we have backtracking algorithms which take a more incremental approach by looking at all the possible options like a rat and a maze exploring all the different potential paths now when it comes to implementing your code there are always multiple ways to get the job done one programming paradigm is declarative where your code describes what the program does and the outcome but doesn't care about things like control flow this style of programming is often associated with functional languages like haskell the other paradigm is imperative programming where your code uses statements like if and while providing explicit instructions about how to produce an outcome it's associated with procedural languages like c today most general purpose languages like python javascript kotlin swift and so on are multi-paradigm which means they support all these options at the same time in addition to object-oriented programming the idea behind oop is that you use classes to write a blueprint for the data or objects in your code a class can encapsulate variables which are commonly called properties as well as functions which are usually called methods in this context it's a common way to organize and reuse code because classes can share behaviors between each other through inheritance where a subclass can extend and override the behaviors of the parent class and it opens the door to all kinds of other ideas called design patterns now a class by itself doesn't actually do anything instead it's used to instantiate objects which are actual chunks of data that live in your computer's memory often you'll want to reference the same object over and over again in your code when data is long-lived it can't go in the call stack instead most languages have a separate area of memory called the heap which unlike the call stack can grow and shrink based on how your application is used it also allows you to pass objects by reference which means you can use the same object in multiple variables without increasing the memory footprint because it always points to the same chunk of memory in the heap now what's interesting is that if we go back to the cpu that we talked about in the beginning you'll notice that it contains multiple threads a thread takes the physical cpu core and breaks it into virtual cores that allow it to run code simultaneously there are some programming languages that support parallelism where you can write code that literally executes on two different threads at the same time however many languages out there are only single threaded but that doesn't mean they can't do two things at the same time instead they implement concurrency models like an event loop or co-routines that can pause or delay the normal execution of code to handle multiple jobs on a single thread at the same time now in modern computing we're rarely working with the bare metal cpu and ram instead we work in the cloud with a virtual machine which is just a piece of software that simulates hardware that allows us to take really big computers and split them up into a bunch of smaller virtual computers these machines are the backbone of the internet and are connected via the internet protocol each machine has a unique ip address to identify it on the network that ip address is usually alias to a url that is registered in a global database called the domain name service now to establish a connection the two computers will perform a tcp handshake which will allow them to exchange messages called packets on top of that there's usually a security layer like ssl to encrypt and decrypt the messages over the network now the two computers can securely share data with the hypertext transfer protocol the client may request a web page then the server will respond with some html modern servers provide a standardized way for a client to request data which is called an application programming interface or api the most common architecture is rest where urls are mapped to different data entities available on the server and that brings us to our final topic mother effin printers you're gonna need to learn how these things work inside and out because every time you go to grandma's house she's going to ask you to fix it which shouldn't be a problem for a computer scientist like you thanks for watching and i will see you in the next one"
    },
    {
        "id": "82f90e83-bea8-447f-bf16-181b9322e6ee",
        "type": "video",
        "domaine": "technology",
        "titre": "What is Computer Science?",
        "url": "https://www.youtube.com/watch?v=Tzl0ELY_TiM",
        "description": "In this part 1 video of \"What is ",
        "chaine": "Zach Star",
        "durée": "11:14",
        "keywords": [
            "greatest common factor",
            "computer science Time",
            "large prime number",
            "computer science students",
            "computer science final",
            "prime number key",
            "give computer science",
            "prime number word",
            "websites classes factors",
            "school computer science"
        ],
        "transcription": "computer science is typically thought of as becoming an expert programmer but it doesn't take many classes and undergrad to realize this isn't the entire story in this video I'm going to explain why this is the case and really just focus on what you will see in the undergraduate curriculum in computer science I'll include a few example problems and many real world applications so you have an idea of what's to come now I think people get this idea of the major being all programming because computer science does involve more programming than pretty much any other major Computer Engineering and software engineering are the other two at the top of that list in no particular order but programming isn't just what it's about so let's start with the beginning of the curriculum which is about learning how to program this is probably what you expecting so you'll learn the command to write something to the screen which involves a print F command and C then your phrase you learn how to declare an integer that you'll use for your program which you could call anything you'll learn how you can assign that integer a value and multiply or add to that variable you also learn you need a semicolon after nearly every line as you can see here you'll learn how to do loops for example if you wanted to write the numbers 1 through 1,000 you could write print f for every number individually and take up an hour or two of time and by the way back sln just means go to the next line or you could write a loop that starts at one increments by one after every Loop and prints to the screen the number you're at then stops at 1,000 coding this is so many less steps than writing every number for those who have never programmed before don't worry about what this means you'll learn it later just realize that you can print a thousand numbers with pretty much just these two lines of code you don't need much more and if you wanted to go to a million all you'd have to do is change this number so you can see how it's all the basics the syntax and just making your program run properly but now let's move on to the classes you may not totally be expecting exp in or just don't know much about the first is discret math which has no lab component just math so for everyone asking do I need to be good at math or computer science the answer is yes but it's a different kind of math than you're probably used to and I'll explain more on this later but I am going to go into a little depth on this class so you have an understanding of what's to come you're used to continuous math given a function of x x can be any value you have to know how to graph it Factor it solve for when equals something or whatever discrete math is where the variables can only assume discrete values typically denoted as n but not always and this class actually involves a lot of proofs and I'll show one real quick on probably your first week you could come across this problem prove that 1 + 2 + 3 all the way to n equals n * n + 1 / 2 so let's see if this is true for n = 3 we get 1 + 2 + 3 which equal 6 then if we plug in 3 for n we get 3 * 4 / 2 which is also 6 so that checks out it works for n = 2 and 1 as well but how do we prove it for all values well this involves proof by induction we know it works for Nal 2 and 3 normally you check for n equal 0 first and now we're going to prove it for n + 1 it works for one in this case so if it works for n + 1 then it will work for all n so I'll write this out again now for n + 1 we would say 1 + 2 + dot dot dot n + n + 1 equal n + 1 * n + 1 + 1 / 2 you just plug in n + 1 where there were n's but here we see that 1 + 2 all the way to n was what was given to us above so we can rewrite that then add on the N +1 and then I'm not going to simplify this cuz I'm sure you know how but these will equal each other and you have proved this to be true seems kind of weird but basically if you know this is true for n equals 0 or even n equal 1 then by proving it for n + 1 is kind of like knocking over dominoes to prove the next proving it for every next case for all n all the way to Infinity is what you just did and you'll have to know how to do proofs with that technique now that you know this you could prove something like 8 to the nus 3 to the N is divisible by 5 so now you may be thinking why would I need to understand this kind of math well let's look at a different kind of example that applies a little to encryption how would you find the greatest common factor of 288 and 160 the biggest number that goes into both of them well I would divide by two cuz they're both even and get two more numbers then those are both even so divide by two again and just keep going conveniently two works every time so we just multiply them at the end and see the greatest common factor is 32 but there's actually a faster method or algorithm to do this that most likely you haven't seen before so to find the greatest factor of the two you could find the remainder of dividing 288 by 160 which would just be their difference of 128 now you have to find the greatest common factor of that and 160 the smaller of the two numbers above then just do the same thing the remainder if you divided 160 by 128 is again their difference which is 32 then what's the greatest common factor of that and 128 if you divided those the remainder is actually zero it goes imperfectly and our smaller number is 32 then since we got down to zero we know our greatest common factor is 32 so look at that we accomplished this in less steps here than we did here and for bigger numbers the difference would be even more this kind of math allows computers to compute factors way faster so what does this have to do with encryption well if we have a word we want to encrypt like maybe you want to secretly send a friend the message we can change it into the numbers that represent its place in the alphabet you then have to calculate some number to add on here which would make it Prime so now we have a large prime number then you and your friend would exchange a secret key which is also a large prime number you multiply your prime number word by your prime number key so if someone intercepts the message and turns it into letters it won't make sense but your friend would just divide the received message by the key and then translate it so why is this hard to crack if someone intercepted the message because computers have trouble factoring large numbers into two prime factors there isn't a fast algorithm so that's why factoring quickly and efficiently has important applications now I do realize when it comes to encryption this method is wrong this isn't exactly how it's done there's a lot more to it and if you want more info there's plenty of videos out there but for this one I just wanted to give you the tiniest Glimpse as to what's going on it never made sense to me when people said encryption has to do with large prime numbers so I wanted to just show that then you will come across graph Theory and know not graphs like x s or S of X it's graphs that have a bunch of nodes or points and vertices that connect them this has a lot of applications in computer science because of how complicated connections can get think of how we are all connected on Facebook for example two people actually use graph Theory to become billionaires that I'll explain soon but first a basic example let's say we have five college classes so a really small school computer science one Biology one chemistry 1 physics one and calculus one some computer science students are in the physics class some others are in the bio class and some others are in the chem class then some bio students are in the chem class and some chem students are in the Calculus class so chem and physics don't have any of the same students same with Cal and bio and you get the idea now the question is how many time slots do we need for finals day so could we schedule one final time from I don't know maybe 9:00 a.m. to 11:00 a.m. no of course we can't because if there's a computer science final at time one and the biof final has to be at the same time those students who share both classes can't take both the finals so could we do it with two time slots one from 9: to 11:00 and one from 11:00 a.m. to 1:00 p.m. if we gave computer science Time 1 then bio would have to have time to but now chem would be out of luck because it shares with both those classes but turns out we can do it in three time slots if we make another time slot we could give computer science time one bio time two chem time 3 then physics could be time three cuz no one shares it with chem and calculus could be Time 1 but imagine what this is like for a university with hundreds of classes and thousands of students it gets complicated what if we have five chess players a through e and player a can beat player B B who can beat player C who beats player a then e beats a and so on based on all these connections and who beats who which player should be ranked the best or what if we looked at the 50 states really only the 48 that border each other so like California borders Arizona Nevada and Oregon then those border other states and this would go on for a while how many colors do we need to color a map of the United States so that no two bordering states have the same color believe it or not this was proven to be four you've probably never noticed but the maps of the United States only need four colors so that no two bordering states have the same color which allows us to distinguish the states easily and lastly what if the worldwide web contained four websites all on the same subject and website a had a link on its site to B and C which kind of means hey these websites are good check them out then B linked to D and a and so on which website should be ranked the best assuming they are all about the same topics well two guys studied this and created an algorithm for how to rank the sites and called their website Google so being good at graph Theory can pay off quite well there's more to discrete math but I'm going to move on I think you get the point how these are discrete math problems like amount of websites classes factors of large numbers and so on this class will lead into the design and Analysis of algorithms I'll go over the basics of this class and more in the next video"
    },
    {
        "id": "bdaa9bce-4e31-42d9-995a-c562f0d8bfbe",
        "type": "video",
        "domaine": "technology",
        "titre": "Map of Computer Science",
        "url": "https://www.youtube.com/watch?v=SzJ46YA_RaA",
        "description": "Computer science",
        "chaine": "Domain of Science",
        "durée": "10:58",
        "keywords": [
            "computer science computer",
            "theoretical computer science",
            "science computer engineering",
            "computer science research",
            "real world problems",
            "nintendos computer science",
            "computer science alan",
            "developing computer systems",
            "design computer systems",
            "computer science"
        ],
        "transcription": "[Music] we built computers to expand our brains originally scientists built computers to solve arithmetic but they turn out to be incredibly useful for many other things as well running the entire internet life like graphics artificial brains or simulating the universe but amazingly all of it boils down to just flipping zeros and ones computers have become smaller and more powerful and an incredible rate there's more computing power in your cell phone than there was in the entire world in the mid-1960s and the entire apollo moon landing could have been run on a couple of nintendos computer science is a subject that studies what computers can do it's a diverse and overlapping field but i'm gonna split it into three parts the fundamental theory of computer science computer engineering and applications we'll start with the father of theoretical computer science alan turing who formalized the concept of a turing machine which is a simple description of a general purpose computer people came up with other designs for computing machines but they're all equivalent to a turing machine which makes it the foundation of computer science a turing machine contains several parts an infinitely long tape that's split into cells containing symbols there's also a head that can read and write symbols to the tape a state register that stores the state of the head and a list of possible instructions in today's computers the tape is like the working memory or ram the head is the central processing unit and the list of instructions is held in the computer's memory even though a turing machine is a simple set of rules it's incredibly powerful and this is essentially what all computers do nowadays although our computers obviously have a few more parts like permanent storage and all the other components every problem that's computable by a turing machine is computable using lambda calculus which is the basis of research in programming languages computability theory attempts to classify what is and isn't computable there are some problems that due to their very nature can never be solved by a computer a famous example is the halting problem where you try and predict whether a program will stop running or carry on forever there are programs where this is impossible to answer by a computer or a human many problems are theoretically solvable but in practice take too much memory or more steps than the lifetime of the universe to solve and computational complexity attempts to categorize these problems according to how they scale there are many different classes of complexity and many classes of problem that fall into each type there are a lot of real world problems that fall into these impossible to solve categories but fortunately computer scientists have a bunch of sneaky tricks where you can fudge things and get pretty good answers but you'll never know if they're the best answer an algorithm is a set of instructions independent of the hardware or programming language designed to solve a particular problem it's kind of like a recipe of how to build a program and a lot of work is put into developing algorithms to get the best out of computers different algorithms can get to the same final result like sorting a random set of numbers into order but some algorithms are much more efficient than others this is studied in algorithmic complexity information theorist studies the properties of information and how it can be measured stored and communicated one application of this is how well you can compress data making it take up less memory while preserving all or most of the information but there are lots of other applications related to information theory is coding theory and cryptography is obviously very important for keeping information sent over the internet secret there are many different encryption schemes which scramble data and usually rely on some very complex mathematical problem to keep the information locked up these are the main branches of theoretical computer science although there are many more that i didn't have time to go into like logic graph theory computational geometry automata theory quantum computation parallel programming formal methods and data structures but let's move on to computer engineering designing computers is a challenge because they have to do so many different things designers need to try and make sure that they're capable of solving many different kinds of problems as optimally as possible every single task that runs on a computer goes through the core of the computer the cpu when you're doing lots of different things at the same time the cpu needs to switch back and forth between these jobs to make sure everything gets done in a reasonable time this is controlled by a scheduler which chooses what to do and when and tries to get through the tasks in the most efficient way which can be a very difficult problem multi-processing helps speed things up because the cpu has several cores that can execute multiple jobs in parallel but this makes the job of the scheduler even more complex computer architecture is how a processor is designed to perform tasks and different architectures are good at different things cpus are general purpose gpus are optimized for graphics and fpgas can be programmed to be very fast at a very narrow range of task on top of the raw hardware there are many layers of software written by programmers using many different programming languages a programming language is how humans tell a computer what to do and they vary greatly depending on the job at hand from low-level languages like assembly through to high-level languages like python or javascript for coding websites and apps in general the closer language is to the hardware the more difficult it is for humans to use at all stages of this hierarchy the code that programmers write needs to be turned into raw cpu instructions and this is done by one or several programs called compilers designing programming languages and compilers is a big deal because they are the tool that software engineers use to make everything so they need to be as easy to use as possible but also versatile enough to allow programmers to build their crazy ideas the operating system is the most important piece of software on the computer is it's what we interact with and it controls how all of the other programs are run on the hardware and engineering a good operating system is a huge challenge this brings us to software engineering writing bundles of instructions telling the computer what to do building good software is an art form because you have to translate your creative ideas into these logical instructions in a specific language make it as efficient as possible to run and as free of errors as you can so there are many best practices and design philosophies that people follow some other important areas are getting many computers to communicate and work together to solve problems storing and retrieving large amounts of data determining how well computer systems are performing at specific tasks and creating highly detailed and realistic graphics now we get to a really cool part of computer science getting computers to solve real world problems these technologies underlie a lot of the programs apps and websites we use when you're going on vacation you want to get the best trip for the money you're solving an optimization problem optimization problems appear everywhere and finding the best path or most efficient combination of parts can save businesses millions of dollars this is related to boolean satisfiability where you attempt to work out if a logic formula can be satisfied or not this was the first problem proved to be np complete and so widely considered to be impossible to solve but amazing development of new sat solvers means that huge sap problems are solved routinely today especially in artificial intelligence computers extend our brains and multiply our cognitive abilities the forefront of computer science research is developing computer systems that can think for themselves artificial intelligence there are many avenues that ai research takes the most prominent of which is machine learning which aims to develop algorithms and techniques to enable computers to learn from large amounts of data and then use what they've learned to do something useful like make decisions or classify things and there are many different types of machine learning closely related are fields like computer vision trying to make computers able to see objects in images like we do which uses image processing techniques natural language processing aims to get computers to understand and communicate using human language or to process large amounts of data in the form of words for analysis this commonly uses another field called knowledge representation where data is organized according to their relationships like words with similar meanings are clustered together machine learning algorithms have improved because of the large amount of data we give them big data looks at how to manage and analyze large amounts of data and get value from it and we'll get even more data from the internet of things adding data collection and communications to everyday objects hacking is not a traditional academic discipline but definitely worth mentioning trying to find weaknesses and computer systems and take advantage of them without being noticed computational science uses computers to help answer scientific questions from fundamental physics to neuroscience and often makes use of super computing which throws the way to the world's most powerful computers of very large problems often in the area of simulation then there is human computer interaction which looks at how to design computer systems to be easy and intuitive to use virtual reality augmented reality and telepresence enhancing or replacing our experience of reality and finally robotics which gives computers a physical embodiment from a roomba to trying to make intelligent human-like machines so that is my map of computer science a field that's still developing as fast as it ever has despite the fact that the underlying hardware is hitting some hard limits as we struggle to miniaturize transistors anymore so lots of people are working on other kinds of computers to try and overcome this problem computers have had an absolutely huge impact on human society so it's going to be interesting to see where this technology goes in the next hundred years who knows perhaps one day we'll all be computers as per usual if you want to get hold of this map as a poster i've made it available so check in the description below for some links and also if you want to find out more about computer science i recommend you check out the sponsor for this video brilliant.org people often ask me how to go about learning more about the kind of subjects i cover in these videos and as well as watching videos a really great way is to get down and solve some real problems and brilliant does an excellent job at this it's a really cool website and also an app which helps you learn by getting you to solve interesting problems in science mathematics and computer science and each of the courses starts off kind of easy and fun and then gets more and more challenging as you master the concepts if you want to learn specifically about computer science they've got whole courses built around topics in this video like logic algorithms machine learning artificial intelligence so if you want to check that out just type in brilliant.org slash d o s or even better click the link in the description below because that lets them know that you've come from here so thanks again for watching and i'll be back soon with a new video"
    },
    {
        "id": "c1918c3f-e96d-4948-9016-7c7464def0a8",
        "type": "video",
        "domaine": "technology",
        "titre": "Early Computing: Crash Course Computer Science #1",
        "url": "https://www.youtube.com/watch?v=O5nskjZ_GoI",
        "description": "Hello, world! Welcome to Crash Course ",
        "chaine": "CrashCourse",
        "durée": "11:53",
        "keywords": [
            "Difference Engine",
            "machine",
            "Step Reckoner",
            "computing",
            "Computer",
            "Engine",
            "row",
            "Analytical Engine",
            "Computers"
        ],
        "transcription": "Hello world, I’m Carrie Anne, and welcome\nto CrashCourse Computer Science! Over the course of this series, we’re going\nto go from bits, bytes, transistors and logic gates, all the way to Operating Systems, Virtual\nReality and Robots! We’re going to cover a lot, but just to\nclear things up - we ARE NOT going to teach you how to program. Instead, we’re going to explore a range\nof computing topics as a discipline and a technology. Computers are the lifeblood of today’s world. If they were to suddenly turn off, all at\nonce, the power grid would shut down, cars would crash, planes would fall, water treatment\nplants would stop, stock markets would freeze, trucks with food wouldn’t know where to\ndeliver, and employees wouldn’t get paid. Even many non-computer objects - like DFTBA\nshirts and the chair I’m sitting on – are made in factories run by computers. Computing really has transformed nearly every\naspect of our lives. And this isn’t the first time we’ve seen\nthis sort of technology-driven global change. Advances in manufacturing during the Industrial\nRevolution brought a new scale to human civilization - in agriculture, industry and domestic life. Mechanization meant superior harvests and\nmore food, mass produced goods, cheaper and faster travel and communication, and usually\na better quality of life. And computing technology is doing the same\nright now – from automated farming and medical equipment, to global telecommunications and\neducational opportunities, and new frontiers like Virtual Reality and Self Driving Cars. We are living in a time likely to be remembered\nas the Electronic Age. With billions of transistors in just your\nsmartphones, computers can seem pretty complicated, but really, they’re just simple machines\nthat perform complex actions through many layers of abstraction. So in this series, we’re going break down\nthose layers, and build up from simple 1’s and 0’s, to logic units, CPUs, operating\nsystems, the entire internet and beyond. And don’t worry, in the same way someone\nbuying t-shirts on a webpage doesn’t need to know how that webpage was programmed, or\nthe web designer doesn’t need to know how all the packets are routed, or router engineers\ndon’t need to know about transistor logic, this series will build on previous episodes\nbut not be dependent on them. By the end of this series, I hope that you\ncan better contextualize computing’s role both in your own life and society, and how\nhumanity's (arguably) greatest invention is just in its infancy, with its biggest impacts\nyet to come. But before we get into all that, we should\nstart at computing’s origins, because although electronic computers are relatively new, the\nneed for computation is not. INTRO The earliest recognized device for computing was the abacus, invented in Mesopotamia around\n2500 BCE. It’s essentially a hand operated calculator,\nthat helps add and subtract many numbers. It also stores the current state of the computation,\nmuch like your hard drive does today. The abacus was created because, the scale\nof society had become greater than what a single person could keep and manipulate in\ntheir mind. There might be thousands of people in a village\nor tens of thousands of cattle. There are many variants of the abacus, but\nlet’s look at a really basic version with each row representing a different power of\nten. So each bead on the bottom row represents\na single unit, in the next row they represent 10, the row above 100, and so on. Let’s say we have 3 heads of cattle represented\nby 3 beads on the bottom row on the right side. If we were to buy 4 more cattle we would just\nslide 4 more beads to the right for a total of 7. But if we were to add 5 more after the first\n3 we would run out of beads, so we would slide everything back to the left, slide one bead\non the second row to the right, representing ten, and then add the final 2 beads on the\nbottom row for a total of 12. This is particularly useful with large numbers. So if we were to add 1,251 we would just add\n1 to the bottom row, 5 to the second row, 2 to the third row, and 1 to the fourth row\n- we don’t have to add in our head and the abacus stores the total for us. Over the next 4000 years, humans developed\nall sorts of clever computing devices, like the astrolabe, which enabled ships to calculate\ntheir latitude at sea. Or the slide rule, for assisting with multiplication\nand division. And there are literally hundred of types of\nclocks created that could be used to calculate sunrise, tides, positions of celestial bodies,\nand even just the time. Each one of these devices made something that\nwas previously laborious to calculate much faster, easier, and often more accurate –– it\nlowered the barrier to entry, and at the same time, amplified our mental abilities –– take\nnote, this is a theme we’re going to touch on a lot in this series. As early computer pioneer Charles Babbage\nsaid: “At each increase of knowledge, as well as on the contrivance of every new tool,\nhuman labour becomes abridged.” However, none of these devices were called\n“computers”. The earliest documented use of the word “computer”\nis from 1613, in a book by Richard Braithwait. And it wasn’t a machine at all - it was\na job title. Braithwait said,\n“I have read the truest computer of times, and the best arithmetician that ever breathed,\nand he reduceth thy dayes into a short number”. In those days, computer was a person who did\ncalculations, sometimes with the help of machines, but often not. This job title persisted until the late 1800s,\nwhen the meaning of computer started shifting to refer to devices. Notable among these devices was the Step Reckoner,\nbuilt by German polymath Gottfried Leibniz in 1694. Leibniz said “... it is beneath the dignity\nof excellent men to waste their time in calculation when any peasant could do the work just as\naccurately with the aid of a machine.” It worked kind of like the odometer in your\ncar, which is really just a machine for adding up the number of miles your car has driven. The device had a series of gears that turned;\neach gear had ten teeth, to represent the digits from 0 to 9. Whenever a gear bypassed nine, it rotated\nback to 0 and advanced the adjacent gear by one tooth. Kind of like when hitting 10 on\nthat basic abacus. This worked in reverse when doing subtraction,\ntoo. With some clever mechanical tricks, the Step\nReckoner was also able to multiply and divide numbers. Multiplications and divisions are really just\nmany additions and subtractions. For example, if we want to divide 17 by 5,\nwe just subtract 5, then 5, then 5 again, and then we can’t subtract any more 5’s…\nso we know 5 goes into 17 three times, with 2 left over. The Step Reckoner was able to do this in an\nautomated way, and was the first machine that could do all four of these operations. And this design was so successful it was used\nfor the next three centuries of calculator design. Unfortunately, even with mechanical calculators,\nmost real world problems required many steps of computation before an answer was determined. It could take hours or days to generate a\nsingle result. Also, these hand-crafted machines were expensive,\nand not accessible to most of the population. So, before 20th century, most people experienced\ncomputing through pre-computed tables assembled by those amazing “human computers” we\ntalked about. So if you needed to know the square root of\n8 million 6 hundred and 75 thousand 3 hundred and 9, instead of spending all day hand-cranking\nyour step reckoner, you could look it up in a huge book full of square root tables in\na minute or so. Speed and accuracy is particularly important\non the battlefield, and so militaries were among the first to apply computing to complex\nproblems. A particularly difficult problem is accurately\nfiring artillery shells, which by the 1800s could travel well over a kilometer (or a bit\nmore than half a mile). Add to this varying wind conditions, temperature,\nand atmospheric pressure, and even hitting something as large as a ship was difficult. Range Tables were created that allowed gunners\nto look up environmental conditions and the distance they wanted to fire, and the table\nwould tell them the angle to set the canon. These Range Tables worked so well, they were\nused well into World War Two. The problem was, if you changed the design\nof the cannon or of the shell, a whole new table had to be computed, which was massively\ntime consuming and inevitably led to errors. Charles Babbage acknowledged this problem\nin 1822 in a paper to the Royal Astronomical Society entitled: “Note on the application\nof machinery to the computation of astronomical and mathematical tables\". Let’s go to the thought bubble. Charles Babbage proposed a new mechanical\ndevice called the Difference Engine, a much more complex machine that could approximate\npolynomials. Polynomials describe the relationship between\nseveral variables - like range and air pressure, or amount of pizza Carrie Anne eats and happiness. Polynomials could also be used to approximate\nlogarithmic and trigonometric functions, which are a real hassle to calculate by hand. Babbage started construction in 1823, and\nover the next two decades, tried to fabricate and assemble the 25,000 components, collectively\nweighing around 15 tons. Unfortunately, the project was ultimately abandoned. But, in 1991, historians finished constructing\na Difference Engine based on Babbage's drawings and writings - and it worked! But more importantly, during construction\nof the Difference Engine, Babbage imagined an even more complex machine - the Analytical\nEngine. Unlike the Difference Engine, Step Reckoner\nand all other computational devices before it - the Analytical Engine was a “general\npurpose computer”. It could be used for many things, not just\none particular computation; it could be given data and run operations in sequence; it had\nmemory and even a primitive printer. Like the Difference Engine, it was ahead of\nits time, and was never fully constructed. However, the idea of an “automatic computer”\n– one that could guide itself through a series of operations automatically, was a\nhuge deal, and would foreshadow computer programs. English mathematician Ada Lovelace wrote hypothetical\nprograms for the Analytical Engine, saying, “A new, a vast, and a powerful language\nis developed for the future use of analysis.” For her work, Ada is often considered the\nworld’s first programmer. The Analytical Engine would inspire, arguably,\nthe first generation of computer scientists, who incorporated many of Babbage’s ideas\nin their machines. This is why Babbage is often considered the\n\"father of computing\". Thanks Thought Bubble! So by the end of the 19th century, computing\ndevices were used for special purpose tasks in the sciences and engineering, but rarely\nseen in business, government or domestic life. However, the US government faced a serious\nproblem for its 1890 census that demanded the kind of efficiency that only computers\ncould provide. The US Constitution requires that a census\nbe conducted every ten years, for the purposes of distributing federal funds, representation\nin congress, and good stuff like that. And by 1880, the US population was booming,\nmostly due to immigration. That census took seven years to manually compile\nand by the time it was completed, it was already out of date – and it was predicted that\nthe 1890 census would take 13 years to compute. That’s a little problematic when it’s\nrequired every decade! The Census bureau turned to Herman Hollerith,\nwho had built a tabulating machine. His machine was “electro-mechanical” – it\nused traditional mechanical systems for keeping count, like Leibniz’s Step Reckoner –– but\ncoupled them with electrically-powered components. Hollerith’s machine used punch cards which\nwere paper cards with a grid of locations that can be punched out to represent data. For example, there was a series of holes for\nmarital status. If you were married, you would punch out the\nmarried spot, then when the card was inserted into Hollerith’s machine, little metal pins\nwould come down over the card – if a spot was punched out, the pin would pass through\nthe hole in the paper and into a little vial of mercury, which completed the circuit. This now completed circuit powered an electric\nmotor, which turned a gear to add one, in this case, to the “married” total. Hollerith’s machine was roughly 10x faster\nthan manual tabulations, and the Census was completed in just two and a half years - saving\nthe census office millions of dollars. Businesses began recognizing the value of\ncomputing, and saw its potential to boost profits by improving labor- and data-intensive\ntasks, like accounting, insurance appraisals, and inventory management. To meet this demand, Hollerith founded The\nTabulating Machine Company, which later merged with other machine makers in 1924 to become\nThe International Business Machines Corporation or IBM - which you’ve probably heard of. These electro-mechanical “business machines”\nwere a huge success, transforming commerce and government, and by the mid-1900s, the\nexplosion in world population and the rise of globalized trade demanded even faster and\nmore flexible tools for processing data, setting the stage for digital computers, which we’ll\ntalk about next week."
    },
    {
        "id": "f8543099-6e5a-4207-9b13-a265fbc84ea7",
        "type": "video",
        "domaine": "technology",
        "titre": "Harvard CS50’s Artificial Intelligence with Python – Full University Course",
        "url": "https://www.youtube.com/watch?v=5NgNicANyqM",
        "description": "This course from Harvard University explores the concepts and algorithms at the foundation of modern ",
        "chaine": "freeCodeCamp.org",
        "durée": "11:51:22",
        "keywords": [
            "probability",
            "state",
            "data",
            "neural network",
            "network",
            "input",
            "time",
            "function",
            "Harry visited Hagrid"
        ],
        "transcription": "This course from Harvard University explores the concepts and algorithms at the foundation of modern artificial intelligence, diving into the ideas that give rise to technologies like game-playing engines, handwriting recognition, and machine translation. You'll gain exposure to the theory behind graph search algorithms, classification, optimization, reinforcement learning, and other topics in artificial intelligence and machine learning. Brian Yu teaches this course. Hello, world. This is CS50, and this is an introduction to artificial intelligence with Python with CS50's own Brian Yu. This course picks up where CS50 itself leaves off and explores the concepts and algorithms at the foundation of modern AI. We'll start with a look at how AI can search for solutions to problems, whether those problems are learning how to play a game or trying to find driving directions to a destination. We'll then look at how AI can represent information, both knowledge that our AI is certain about, but also information and events about which our AI might be uncertain, learning how to represent that information, but more importantly, how to use that information to draw inferences and new conclusions as well. We'll explore how AI can solve various types of optimization problems, trying to maximize profits or minimize costs or satisfy some other constraints before turning our attention to the fast-growing field of machine learning, where we won't tell our AI exactly how to solve a problem, but instead, give our AI access to data and experiences so that our AI can learn on its own how to perform these tasks. In particular, we'll look at neural networks, one of the most popular tools in modern machine learning, inspired by the way that human brains learn and reason as well before finally taking a look at the world of natural language processing so that it's not just us humans learning to learn how artificial intelligence is able to speak, but also AI learning how to understand and interpret human language as well. We'll explore these ideas and algorithms, and along the way, give you the opportunity to build your own AI programs to implement all of this and more. This is CS50. All right. Welcome, everyone, to an introduction to artificial intelligence with Python. My name is Brian Yu, and in this class, we'll explore some of the ideas and techniques and algorithms that are at the foundation of artificial intelligence. Now, artificial intelligence covers a wide variety of types of techniques. Anytime you see a computer do something that appears to be intelligent or rational in some way, like recognizing someone's face in a photo, or being able to play a game better than people can, or being able to understand human language when we talk to our phones and they understand what we mean and are able to respond back to us, these are all examples of AI, or artificial intelligence. And in this class, we'll explore some of the ideas that make that AI possible. So we'll begin our conversations with search, the problem of we have an AI, and we would like the AI to be able to search for solutions to some kind of problem, no matter what that problem might be. Whether it's trying to get driving directions from point A to point B, or trying to figure out how to play a game, given a tic-tac-toe game, for example, figuring out what move it ought to make. After that, we'll take a look at knowledge. Ideally, we want our AI to be able to know information, to be able to represent that information, and more importantly, to be able to draw inferences from that information, to be able to use the information it knows and draw additional conclusions. So we'll talk about how AI can be programmed in order to do just that. Then we'll explore the topic of uncertainty, talking about ideas of what happens if a computer isn't sure about a fact, but maybe is only sure with a certain probability. So we'll talk about some of the ideas behind probability, and how computers can begin to deal with uncertain events in order to be a little bit more intelligent in that sense as well. After that, we'll turn our attention to optimization, problems of when the computer is trying to optimize for some sort of goal, especially in a situation where there might be multiple ways that a computer might solve a problem, but we're looking for a better way, or potentially the best way, if that's at all possible. Then we'll take a look at machine learning, or learning more generally, and looking at how, when we have access to data, our computers can be programmed to be quite intelligent by learning from data and learning from experience, being able to perform a task better and better based on greater access to data. So your email, for example, where your email inbox somehow knows which of your emails are good emails and which of your emails are spam. These are all examples of computers being able to learn from past experiences and past data. We'll take a look, too, at how computers are able to draw inspiration from human intelligence, looking at the structure of the human brain, and how neural networks can be a computer analog to that sort of idea, and how, by taking advantage of a certain type of structure of a computer program, we can write neural networks that are able to perform tasks very, very effectively. And then finally, we'll turn our attention to language, not programming languages, but human languages that we speak every day. And taking a look at the challenges that come about as a computer tries to understand natural language, and how it is some of the natural language processing that occurs in modern artificial intelligence can actually work. But today, we'll begin our conversation with search, this problem of trying to figure out what to do when we have some sort of situation that the computer is in, some sort of environment that an agent is in, so to speak, and we would like for that agent to be able to somehow look for a solution to that problem. Now, these problems can come in any number of different types of formats. One example, for instance, might be something like this classic 15 puzzle with the sliding tiles that you might have seen. Where you're trying to slide the tiles in order to make sure that all the numbers line up in order. This is an example of what you might call a search problem. The 15 puzzle begins in an initially mixed up state, and we need some way of finding moves to make in order to return the puzzle to its solved state. But there are similar problems that you can frame in other ways. Trying to find your way through a maze, for example, is another example of a search problem. You begin in one place, you have some goal of where you're trying to get to, and you need to figure out the correct sequence of actions that will take you from that initial state to the goal. And while this is a little bit abstract, any time we talk about maze solving in this class, you can translate it to something a little more real world. Something like driving directions. If you ever wonder how Google Maps is able to figure out what is the best way for you to get from point A to point B, and what turns to make at what time, depending on traffic, for example, it's often some sort of search algorithm. You have an AI that is trying to get from an initial position to some sort of goal by taking some sequence of actions. So we'll start our conversations today by thinking about these types of search problems and what goes in to solving a search problem like this in order for an AI to be able to find a good solution. In order to do so, though, we're going to need to introduce a little bit of terminology, some of which I've already used. But the first term we'll need to think about is an agent. An agent is just some entity that perceives its environment. It somehow is able to perceive the things around it and act on that environment in some way. So in the case of the driving directions, your agent might be some representation of a car that is trying to figure out what actions to take in order to arrive at a destination. In the case of the 15 puzzle with the sliding tiles, the agent might be the AI or the person that is trying to solve that puzzle to try and figure out what tiles to move in order to get to that solution. Next, we introduce the idea of a state. A state is just some configuration of the agent in its environment. So in the 15 puzzle, for example, any state might be any one of these three, for example. A state is just some configuration of the tiles. And each of these states is different and is going to require a slightly different solution. A different sequence of actions will be needed in each one of these in order to get from this initial state to the goal, which is where we're trying to get. So the initial state, then, what is that? The initial state is just the state where the agent begins. It is one such state where we're going to start from. And this is going to be the starting point for our search algorithm, so to speak. We're going to begin with this initial state and then start to reason about it, to think about what actions might we apply to that initial state in order to figure out how to get from the beginning to the end, from the initial position to whatever our goal happens to be. And how do we make our way from that initial position to the goal? Well, ultimately, it's via taking actions. Actions are just choices that we can make in any given state. And in AI, we're always going to try to formalize these ideas a little bit more precisely, such that we could program them a little bit more mathematically, so to speak. So this will be a recurring theme. And we can more precisely define actions as a function. We're going to effectively define a function called actions that takes an input, s, where s is going to be some state that exists inside of our environment. And actions of s is going to take the state as input and return as output the set of all actions that can be executed in that state. And so it's possible that some actions are only valid in certain states and not in other states. And we'll see examples of that soon, too. So in the case of the 15 puzzle, for example, there are generally going to be four possible actions that we can do most of the time. We can slide a tile to the right, slide a tile to the left, slide a tile up, or slide a tile down, for example. And those are going to be the actions that are available to us. So somehow our AI, our program, needs some encoding of the state, which is often going to be in some numerical format, and some encoding of these actions. But it also needs some encoding of the relationship between these things. How do the states and actions relate to one another? And in order to do that, we'll introduce to our AI a transition model, which will be a description of what state we get after we perform some available action in some other state. And again, we can be a little bit more precise about this, define this transition model a little bit more formally, again, as a function. The function is going to be a function called result that this time takes two inputs. Input number one is s, some state. And input number two is a, some action. And the output of this function result is it is going to give us the state that we get after we perform action a in state s. So let's take a look at an example to see more precisely what this actually means. Here is an example of a state, of the 15 puzzle, for example. And here is an example of an action, sliding a tile to the right. What happens if we pass these as inputs to the result function? Again, the result function takes this board, this state, as its first input. And it takes an action as a second input. And of course, here, I'm describing things visually so that you can see visually what the state is and what the action is. In a computer, you might represent one of these actions as just some number that represents the action. Or if you're familiar with enums that allow you to enumerate multiple possibilities, it might be something like that. And this state might just be represented as an array or two-dimensional array of all of these numbers that exist. But here, we're going to show it visually just so you can see it. But when we take this state and this action, pass it into the result function, the output is a new state. The state we get after we take a tile and slide it to the right, and this is the state we get as a result. If we had a different action and a different state, for example, and pass that into the result function, we'd get a different answer altogether. So the result function needs to take care of figuring out how to take a state and take an action and get what results. And this is going to be our transition model that describes how it is that states and actions are related to each other. If we take this transition model and think about it more generally and across the entire problem, we can form what we might call a state space. The set of all of the states we can get from the initial state via any sequence of actions, by taking 0 or 1 or 2 or more actions in addition to that, so we could draw a diagram that looks something like this, where every state is represented here by a game board, and there are arrows that connect every state to every other state we can get to from that state. And the state space is much larger than what you see just here. This is just a sample of what the state space might actually look like. And in general, across many search problems, whether they're this particular 15 puzzle or driving directions or something else, the state space is going to look something like this. We have individual states and arrows that are connecting them. And oftentimes, just for simplicity, we'll simplify our representation of this entire thing as a graph, some sequence of nodes and edges that connect nodes. But you can think of this more abstract representation as the exact same idea. Each of these little circles or nodes is going to represent one of the states inside of our problem. And the arrows here represent the actions that we can take in any particular state, taking us from one particular state to another state, for example. All right. So now we have this idea of nodes that are representing these states, actions that can take us from one state to another, and a transition model that defines what happens after we take a particular action. So the next step we need to figure out is how we know when the AI is done solving the problem. The AI needs some way to know when it gets to the goal that it's found the goal. So the next thing we'll need to encode into our artificial intelligence is a goal test, some way to determine whether a given state is a goal state. In the case of something like driving directions, it might be pretty easy. If you're in a state that corresponds to whatever the user typed in as their intended destination, well, then you know you're in a goal state. In the 15 puzzle, it might be checking the numbers to make sure they're all in ascending order. But the AI needs some way to encode whether or not any state they happen to be in is a goal. And some problems might have one goal, like a maze where you have one initial position and one ending position, and that's the goal. In other more complex problems, you might imagine that there are multiple possible goals. That there are multiple ways to solve a problem, and we might not care which one the computer finds, as long as it does find a particular goal. However, sometimes the computer doesn't just care about finding a goal, but finding a goal well, or one with a low cost. And it's for that reason that the last piece of terminology that we'll use to define these search problems is something called a path cost. You might imagine that in the case of driving directions, it would be pretty annoying if I said I wanted directions from point A to point B, and the route that Google Maps gave me was a long route with lots of detours that were unnecessary that took longer than it should have for me to get to that destination. And it's for that reason that when we're formulating search problems, we'll often give every path some sort of numerical cost, some number telling us how expensive it is to take this particular option, and then tell our AI that instead of just finding a solution, some way of getting from the initial state to the goal, we'd really like to find one that minimizes this path cost. That is, less expensive, or takes less time, or minimizes some other numerical value. We can represent this graphically if we take a look at this graph again, and imagine that each of these arrows, each of these actions that we can take from one state to another state, has some sort of number associated with it. That number being the path cost of this particular action, where some of the costs for any particular action might be more expensive than the cost for some other action, for example. Although this will only happen in some sorts of problems. In other problems, we can simplify the diagram and just assume that the cost of any particular action is the same. And this is probably the case in something like the 15 puzzle, for example, where it doesn't really make a difference whether I'm moving right or moving left. The only thing that matters is the total number of steps that I have to take to get from point A to point B. And each of those steps is of equal cost. We can just assume it's of some constant cost like one. And so this now forms the basis for what we might consider to be a search problem. A search problem has some sort of initial state, some place where we begin, some sort of action that we can take or multiple actions that we can take in any given state. And it has a transition model. Some way of defining what happens when we go from one state and take one action, what state do we end up with as a result. In addition to that, we need some goal test to know whether or not we've reached a goal. And then we need a path cost function that tells us for any particular path, by following some sequence of actions, how expensive is that path. What does its cost in terms of money or time or some other resource that we are trying to minimize our usage of. And the goal ultimately is to find a solution. Where a solution in this case is just some sequence of actions that will take us from the initial state to the goal state. And ideally, we'd like to find not just any solution but the optimal solution, which is a solution that has the lowest path cost among all of the possible solutions. And in some cases, there might be multiple optimal solutions. But an optimal solution just means that there is no way that we could have done better in terms of finding that solution. So now we've defined the problem. And now we need to begin to figure out how it is that we're going to solve this kind of search problem. And in order to do so, you'll probably imagine that our computer is going to need to represent a whole bunch of data about this particular problem. We need to represent data about where we are in the problem. And we might need to be considering multiple different options at once. And oftentimes, when we're trying to package a whole bunch of data related to a state together, we'll do so using a data structure that we're going to call a node. A node is a data structure that is just going to keep track of a variety of different values. And specifically, in the case of a search problem, it's going to keep track of these four values in particular. Every node is going to keep track of a state, the state we're currently on. And every node is also going to keep track of a parent. A parent being the state before us or the node that we used in order to get to this current state. And this is going to be relevant because eventually, once we reach the goal node, once we get to the end, we want to know what sequence of actions we use in order to get to that goal. And the way we'll know that is by looking at these parents to keep track of what led us to the goal and what led us to that state and what led us to the state before that, so on and so forth, backtracking our way to the beginning so that we know the entire sequence of actions we needed in order to get from the beginning to the end. The node is also going to keep track of what action we took in order to get from the parent to the current state. And the node is also going to keep track of a path cost. In other words, it's going to keep track of the number that represents how long it took to get from the initial state to the state that we currently happen to be at. And we'll see why this is relevant as we start to talk about some of the optimizations that we can make in terms of these search problems more generally. So this is the data structure that we're going to use in order to solve the problem. And now let's talk about the approach. How might we actually begin to solve the problem? Well, as you might imagine, what we're going to do is we're going to start at one particular state, and we're just going to explore from there. The intuition is that from a given state, we have multiple options that we could take, and we're going to explore those options. And once we explore those options, we'll find that more options than that are going to make themselves available. And we're going to consider all of the available options to be stored inside of a single data structure that we'll call the frontier. The frontier is going to represent all of the things that we could explore next that we haven't yet explored or visited. So in our approach, we're going to begin the search algorithm by starting with a frontier that just contains one state. The frontier is going to contain the initial state, because at the beginning, that's the only state we know about. That is the only state that exists. And then our search algorithm is effectively going to follow a loop. We're going to repeat some process again and again and again. The first thing we're going to do is if the frontier is empty, then there's no solution. And we can report that there is no way to get to the goal. And that's certainly possible. There are certain types of problems that an AI might try to explore and realize that there is no way to solve that problem. And that's useful information for humans to know as well. So if ever the frontier is empty, that means there's nothing left to explore. And we haven't yet found a solution, so there is no solution. There's nothing left to explore. Otherwise, what we'll do is we'll remove a node from the frontier. So right now at the beginning, the frontier just contains one node representing the initial state. But over time, the frontier might grow. It might contain multiple states. And so here, we're just going to remove a single node from that frontier. If that node happens to be a goal, then we found a solution. So we remove a node from the frontier and ask ourselves, is this the goal? And we do that by applying the goal test that we talked about earlier, asking if we're at the destination. Or asking if all the numbers of the 15 puzzle happen to be in order. So if the node contains the goal, we found a solution. Great. We're done. And otherwise, what we'll need to do is we'll need to expand the node. And this is a term of art in artificial intelligence. To expand the node just means to look at all of the neighbors of that node. In other words, consider all of the possible actions that I could take from the state that this node is representing and what nodes could I get to from there. We're going to take all of those nodes, the next nodes that I can get to from this current one I'm looking at, and add those to the frontier. And then we'll repeat this process. So at a very high level, the idea is we start with a frontier that contains the initial state. And we're constantly removing a node from the frontier, looking at where we can get to next and adding those nodes to the frontier, repeating this process over and over until either we remove a node from the frontier and it contains a goal, meaning we've solved the problem, or we run into a situation where the frontier is empty, at which point we're left with no solution. So let's actually try and take the pseudocode, put it into practice by taking a look at an example of a sample search problem. So right here, I have a sample graph. A is connected to B via this action. B is connected to nodes C and D. C is connected to E. D is connected to F. And what I'd like to do is have my AI find a path from A to E. We want to get from this initial state to this goal state. So how are we going to do that? Well, we're going to start with a frontier that contains the initial state. This is going to represent our frontier. So our frontier initially will just contain A, that initial state where we're going to begin. And now we'll repeat this process. If the frontier is empty, no solution. That's not a problem, because the frontier is not empty. So we'll remove a node from the frontier as the one to consider next. There's only one node in the frontier. So we'll go ahead and remove it from the frontier. But now A, this initial node, this is the node we're currently considering. We follow the next step. We ask ourselves, is this node the goal? No, it's not. A is not the goal. E is the goal. So we don't return the solution. So instead, we go to this last step, expand the node, and add the resulting nodes to the frontier. What does that mean? Well, it means take this state A and consider where we could get to next. And after A, what we could get to next is only B. So that's what we get when we expand A. We find B. And we add B to the frontier. And now B is in the frontier. And we repeat the process again. We say, all right, the frontier is not empty. So let's remove B from the frontier. B is now the node that we're considering. We ask ourselves, is B the goal? No, it's not. So we go ahead and expand B and add its resulting nodes to the frontier. What happens when we expand B? In other words, what nodes can we get to from B? Well, we can get to C and D. So we'll go ahead and add C and D from the frontier. And now we have two nodes in the frontier, C and D. And we repeat the process again. We remove a node from the frontier. For now, I'll do so arbitrarily just by picking C. We'll see why later, how choosing which node you remove from the frontier is actually quite an important part of the algorithm. But for now, I'll arbitrarily remove C, say it's not the goal. So we'll add E, the next one, to the frontier. Then let's say I remove E from the frontier. And now I check I'm currently looking at state E. Is it a goal state? It is, because I'm trying to find a path from A to E. So I would return the goal. And that now would be the solution, that I'm now able to return the solution. And I have found a path from A to E. So this is the general idea, the general approach of this search algorithm, to follow these steps, constantly removing nodes from the frontier, until we're able to find a solution. So the next question you might reasonably ask is, what could go wrong here? What are the potential problems with an approach like this? And here's one example of a problem that could arise from this sort of approach. Imagine this same graph, same as before, with one change. The change being now, instead of just an arrow from A to B, we also have an arrow from B to A, meaning we can go in both directions. And this is true in something like the 15 puzzle, where when I slide a tile to the right, I could then slide a tile to the left to get back to the original position. I could go back and forth between A and B. And that's what these double arrows symbolize, the idea that from one state, I can get to another, and then I can get back. And that's true in many search problems. What's going to happen if I try to apply the same approach now? Well, I'll begin with A, same as before. And I'll remove A from the frontier. And then I'll consider where I can get to from A. And after A, the only place I can get to is B. So B goes into the frontier. Then I'll say, all right, let's take a look at B. That's the only thing left in the frontier. Where can I get to from B? Before, it was just C and D. But now, because of that reverse arrow, I can get to A or C or D. So all three, A, C, and D, all of those now go into the frontier. They are places I can get to from B. And now I remove one from the frontier. And maybe I'm unlucky, and maybe I pick A. And now I'm looking at A again. And I consider, where can I get to from A? And from A, well, I can get to B. And now we start to see the problem. But if I'm not careful, I go from A to B, and then back to A, and then to B again. And I could be going in this infinite loop, where I never make any progress, because I'm constantly just going back and forth between two states that I've already seen. So what is the solution to this? We need some way to deal with this problem. And the way that we can deal with this problem is by somehow keeping track of what we've already explored. And the logic is going to be, well, if we've already explored the state, there's no reason to go back to it. Once we've explored a state, don't go back to it. Don't bother adding it to the frontier. There's no need to. So here's going to be our revised approach, a better way to approach this sort of search problem. And it's going to look very similar, just with a couple of modifications. We'll start with a frontier that contains the initial state, same as before. But now we'll start with another data structure, which will just be a set of nodes that we've already explored. So what are the states we've explored? Initially, it's empty. We have an empty explored set. And now we repeat. If the frontier is empty, no solution, same as before. We remove a node from the frontier. We check to see if it's a goal state, return the solution. None of this is any different so far. But now what we're going to do is we're going to add the node to the explored state. So if it happens to be the case that we remove a node from the frontier and it's not the goal, we'll add it to the explored set so that we know we've already explored it. We don't need to go back to it again if it happens to come up later. And then the final step, we expand the node and we add the resulting nodes to the frontier. But before, we just always added the resulting nodes to the frontier. We're going to be a little clever about it this time. We're only going to add the nodes to the frontier if they aren't already in the frontier and if they aren't already in the explored set. So we'll check both the frontier and the explored set, make sure that the node isn't already in one of those two. And so long as it isn't, then we'll go ahead and add it to the frontier, but not otherwise. And so that revised approach is ultimately what's going to help make sure that we don't go back and forth between two nodes. Now, the one point that I've kind of glossed over here so far is this step here, removing a node from the frontier. Before, I just chose arbitrarily. Like, let's just remove a node and that's it. But it turns out it's actually quite important how we decide to structure our frontier, how we add and how we remove our nodes. The frontier is a data structure and we need to make a choice about in what order are we going to be removing elements. And one of the simplest data structures for adding and removing elements is something called a stack. And a stack is a data structure that is a last in, first out data type, which means the last thing that I add to the frontier is going to be the first thing that I remove from the frontier. So the most recent thing to go into the stack or the frontier in this case is going to be the node that I explore. So let's see what happens if I apply this stack-based approach to something like this problem, finding a path from A to E. What's going to happen? Well, again, we'll start with A and we'll say, all right, let's go ahead and look at A first. And then notice this time, we've added A to the explored set. A is something we've now explored. We have this data structure that's keeping track. We then say from A, we can get to B. And all right, from B, what can we do? Well, from B, we can explore B and get to both C and D. So we added C and then D. So now, when we explore a node, we're going to treat the frontier as a stack, last in, first out. D was the last one to come in. So we'll go ahead and explore that next and say, all right, where can we get to from D? Well, we can get to F. And so all right, we'll put F into the frontier. And now, because the frontier is a stack, F is the most recent thing that's gone in the stack. So F is what we'll explore next. We'll explore F and say, all right, where can we get to from F? Well, we can't get anywhere, so nothing gets added to the frontier. So now, what was the new most recent thing added to the frontier? Well, it's now C, the only thing left in the frontier. We'll explore that from which we can see, all right, from C, we can get to E. So E goes into the frontier. And then we say, all right, let's look at E. And E is now the solution. And now, we've solved the problem. So when we treat the frontier like a stack, a last in, first out data structure, that's the result we get. We go from A to B to D to F. And then we sort of backed up and went down to C and then E. And it's important to get a visual sense for how this algorithm is working. We went very deep in this search tree, so to speak, all the way until the bottom where we hit a dead end. And then we effectively backed up and explored this other route that we didn't try before. And it's this going very deep in the search tree idea, this way the algorithm ends up working when we use a stack that we call this version of the algorithm depth first search. Depth first search is the search algorithm where we always explore the deepest node in the frontier. We keep going deeper and deeper through our search tree. And then if we hit a dead end, we back up and we try something else instead. But depth first search is just one of the possible search options that we could use. It turns out that there's another algorithm called breadth first search, which behaves very similarly to depth first search with one difference. Instead of always exploring the deepest node in the search tree, the way the depth first search does, breadth first search is always going to explore the shallowest node in the frontier. So what does that mean? Well, it means that instead of using a stack which depth first search or DFS used, where the most recent item added to the frontier is the one we'll explore next, in breadth first search or BFS, we'll instead use a queue, where a queue is a first in first out data type, where the very first thing we add to the frontier is the first one we'll explore and they effectively form a line or a queue, where the earlier you arrive in the frontier, the earlier you get explored. So what would that mean for the same exact problem, finding a path from A to E? Well, we start with A, same as before, then we'll go ahead and have explored A and say, where can we get to from A? Well, from A, we can get to B, same as before. From B, same as before, we can get to C and D. So C and D get added to the frontier. This time, though, we added C to the frontier before D. So we'll explore C first. So C gets explored. And from C, where can we get to? Well, we can get to E. So E gets added to the frontier. But because D was explored before E, we'll look at D next. So we'll explore D and say, where can we get to from D? We can get to F. And only then will we say, all right, now we can get to E. And so what breadth first search or BFS did is we started here, we looked at both C and D, and then we looked at E. Effectively, we're looking at things one away from the initial state, then two away from the initial state, and only then, things that are three away from the initial state, unlike depth first search, which just went as deep as possible into the search tree until it hit a dead end and then ultimately had to back up. So these now are two different search algorithms that we could apply in order to try and solve a problem. And let's take a look at how these would actually work in practice with something like maze solving, for example. So here's an example of a maze. These empty cells represent places where our agent can move. These darkened gray cells represent walls that the agent can't pass through. And ultimately, our agent, our AI, is going to try to find a way to get from position A to position B via some sequence of actions, where those actions are left, right, up, and down. What will depth first search do in this case? Well, depth first search will just follow one path. If it reaches a fork in the road where it has multiple different options, depth first search is just, in this case, going to choose one. That doesn't a real preference. But it's going to keep following one until it hits a dead end. And when it hits a dead end, depth first search effectively goes back to the last decision point and tries the other path, fully exhausting this entire path. And when it realizes that, OK, the goal is not here, then it turns its attention to this path. It goes as deep as possible. When it hits a dead end, it backs up and then tries this other path, keeps going as deep as possible down one particular path. And when it realizes that that's a dead end, then it'll back up, and then ultimately find its way to the goal. And maybe you got lucky, and maybe you made a different choice earlier on. But ultimately, this is how depth first search is going to work. It's going to keep following until it hits a dead end. And when it hits a dead end, it backs up and looks for a different solution. And so one thing you might reasonably ask is, is this algorithm always going to work? Will it always actually find a way to get from the initial state? To the goal. And it turns out that as long as our maze is finite, as long as there are only finitely many spaces where we can travel, then, yes, depth first search is going to find a solution. Because eventually, it'll just explore everything. If the maze happens to be infinite and there's an infinite state space, which does exist in certain types of problems, then it's a slightly different story. But as long as our maze has finitely many squares, we're going to find a solution. The next question, though, that we want to ask is, is it going to be a good solution? Is it the optimal solution that we can find? And the answer there is not necessarily. And let's take a look at an example of that. In this maze, for example, we're again trying to find our way from A to B. And you notice here there are multiple possible solutions. We could go this way or we could go up in order to make our way from A to B. Now, if we're lucky, depth first search will choose this way and get to B. But there's no reason necessarily why depth first search would choose between going up or going to the right. It's sort of an arbitrary decision point because both are going to be added to the frontier. And ultimately, if we get unlucky, depth first search might choose to explore this path first because it's just a random choice at this point. It'll explore, explore, explore. And it'll eventually find the goal, this particular path, when in actuality there was a better path. There was a more optimal solution that used fewer steps, assuming we're measuring the cost of a solution based on the number of steps that we need to take. So depth first search, if we're unlucky, might end up not finding the best solution when a better solution is available. So that's DFS, depth first search. How does BFS, or breadth first search, compare? How would it work in this particular situation? Well, the algorithm is going to look very different visually in terms of how BFS explores. Because BFS looks at shallower nodes first, the idea is going to be, BFS will first look at all of the nodes that are one away from the initial state. Look here and look here, for example, just at the two nodes that are immediately next to this initial state. Then it'll explore nodes that are two away, looking at this state and that state, for example. Then it'll explore nodes that are three away, this state and that state. Whereas depth first search just picked one path and kept following it, breadth first search, on the other hand, is taking the option of exploring all of the possible paths as kind of at the same time bouncing back between them, looking deeper and deeper at each one, but making sure to explore the shallower ones or the ones that are closer to the initial state earlier. So we'll keep following this pattern, looking at things that are four away, looking at things that are five away, looking at things that are six away, until eventually we make our way to the goal. And in this case, it's true we had to explore some states that ultimately didn't lead us anywhere, but the path that we found to the goal was the optimal path. This is the shortest way that we could get to the goal. And so what might happen then in a larger maze? Well, let's take a look at something like this and how breadth first search is going to behave. Well, breadth first search, again, we'll just keep following the states until it receives a decision point. It could go either left or right. And while DFS just picked one and kept following that until it hit a dead end, BFS, on the other hand, will explore both. It'll say look at this node, then this node, and it'll look at this node, then that node. So on and so forth. And when it hits a decision point here, rather than pick one left or two right and explore that path, it'll again explore both, alternating between them, going deeper and deeper. We'll explore here, and then maybe here and here, and then keep going. Explore here and slowly make our way, you can visually see, further and further out. Once we get to this decision point, we'll explore both up and down until ultimately we make our way to the goal. And what you'll notice is, yes, breadth first search did find our way from A to B by following this particular path, but it needed to explore a lot of states in order to do so. And so we see some trade offs here between DFS and BFS, that in DFS, there may be some cases where there is some memory savings as compared to a breadth first approach, where breadth first search in this case had to explore a lot of states. But maybe that won't always be the case. So now let's actually turn our attention to some code and look at the code that we could actually write in order to implement something like depth first search or breadth first search in the context of solving a maze, for example. So I'll go ahead and go into my terminal. And what I have here inside of maze.py is an implementation of this same idea of maze solving. I've defined a class called node that in this case is keeping track of the state, the parent, in other words, the state before the state, and the action. In this case, we're not keeping track of the path cost because we can calculate the cost of the path at the end after we found our way from the initial state to the goal. In addition to this, I've defined a class called a stack frontier. And if unfamiliar with a class, a class is a way for me to define a way to generate objects in Python. It refers to an idea of object oriented programming, where the idea here is that I would like to create an object that is able to store all of my frontier data. And I would like to have functions, otherwise known as methods, on that object that I can use to manipulate the object. And so what's going on here, if unfamiliar with the syntax, is I have a function that initially creates a frontier that I'm going to represent using a list. And initially, my frontier is represented by the empty list. There's nothing in my frontier to begin with. I have an add function that adds something to the frontier as by appending it to the end of the list. I have a function that checks if the frontier contains a particular state. I have an empty function that checks if the frontier is empty. If the frontier is empty, that just means the length of the frontier is 0. And then I have a function for removing something from the frontier. I can't remove something from the frontier if the frontier is empty, so I check for that first. But otherwise, if the frontier isn't empty, recall that I'm implementing this frontier as a stack, a last in first out data structure, which means the last thing I add to the frontier, in other words, the last thing in the list, is the item that I should remove from this frontier. So what you'll see here is I have removed the last item of a list. And if you index into a Python list with negative 1, that gets you the last item in the list. Since 0 is the first item, negative 1 kind of wraps around and gets you to the last item in the list. So we give that the node. We call that node. We update the frontier here on line 28 to say, go ahead and remove that node that you just removed from the frontier. And then we return the node as a result. So this class here effectively implements the idea of a frontier. It gives me a way to add something to a frontier and a way to remove something from the frontier as a stack. I've also, just for good measure, implemented an alternative version of the same thing called a queue frontier, which in parentheses you'll see here, it inherits from a stack frontier, meaning it's going to do all the same things that the stack frontier did, except the way we remove a node from the frontier is going to be slightly different. Instead of removing from the end of the list the way we would in a stack, we're instead going to remove from the beginning of the list. Self.frontier 0 will get me the first node in the frontier, the first one that was added, and that is going to be the one that we return in the case of a queue. Then under here, I have a definition of a class called maze. This is going to handle the process of taking a sequence, a maze-like text file, and figuring out how to solve it. So it will take as input a text file that looks something like this, for example, where we see hash marks that are here representing walls, and I have the character A representing the starting position and the character B representing the ending position. And you can take a look at the code for parsing this text file right now. That's the less interesting part. The more interesting part is this solve function here, the solve function is going to figure out how to actually get from point A to point B. And here we see an implementation of the exact same idea we saw from a moment ago. We're going to keep track of how many states we've explored, just so we can report that data later. But I start with a node that represents just the start state. And I start with a frontier that, in this case, is a stack frontier. And given that I'm treating my frontier as a stack, you might imagine that the algorithm I'm using here is now depth-first search, because depth-first search, or DFS, uses a stack as its data structure. And initially, this frontier is just going to contain the start state. We initialize an explored set that initially is empty. There's nothing we've explored so far. And now here's our loop, that notion of repeating something again and again. First, we check if the frontier is empty by calling that empty function that we saw the implementation of a moment ago. And if the frontier is indeed empty, we'll go ahead and raise an exception, or a Python error, to say, sorry, there is no solution to this problem. Otherwise, we'll go ahead and remove a node from the frontier as by calling frontier.remove and update the number of states we've explored, because now we've explored one additional state. So we say self.numexplored plus equals 1, adding 1 to the number of states we've explored. Once we remove a node from the frontier, recall that the next step is to see whether or not it's the goal, the goal test. And in the case of the maze, the goal is pretty easy. I check to see whether the state of the node is equal to the goal. Initially, when I set up the maze, I set up this value called goal, which is a property of the maze, so I can just check to see if the node is actually the goal. And if it is the goal, then what I want to do is backtrack my way towards figuring out what actions I took in order to get to this goal. And how do I do that? We'll recall that every node stores its parent, the node that came before it that we used to get to this node, and also the action used in order to get there. So I can create this loop where I'm constantly just looking at the parent of every node and keeping track for all of the parents what action I took to get from the parent to this current node. So this loop is going to keep repeating this process of looking through all of the parent nodes until we get back to the initial state, which has no parent, where node.parent is going to be equal to none. As I do so, I'm going to be building up the list of all of the actions that I'm following and the list of all the cells that are part of the solution. But I'll reverse them because when I build it up, going from the goal back to the initial state and building the sequence of actions from the goal to the initial state, but I want to reverse them in order to get the sequence of actions from the initial state to the goal. And that is ultimately going to be the solution. So all of that happens if the current state is equal to the goal. And otherwise, if it's not the goal, well, then I'll go ahead and add this state to the explored set to say, I've explored this state now. No need to go back to it if I come across it in the future. And then this logic here implements the idea of adding neighbors to the frontier. I'm saying, look at all of my neighbors, and I implemented a function called neighbors that you can take a look at. And for each of those neighbors, I'm going to check, is the state already in the frontier? Is the state already in the explored set? And if it's not in either of those, then I'll go ahead and add this new child node, this new node, to the frontier. So there's a fair amount of syntax here, but the key here is not to understand all the nuances of the syntax. So feel free to take a closer look at this file on your own to get a sense for how it is working. But the key is to see how this is an implementation of the same pseudocode, the same idea that we were describing a moment ago on the screen when we were looking at the steps that we might follow in order to solve this kind of search problem. So now let's actually see this in action. I'll go ahead and run maze.py on maze1.txt, for example. And what we'll see is here, we have a printout of what the maze initially looked like. And then here down below is after we've solved it. We had to explore 11 states in order to do it, and we found a path from A to B. And in this program, I just happened to generate a graphical representation of this as well. So I can open up maze.png, which is generated by this program, that shows you where in the darker color here are the walls, red is the initial state, green is the goal, and yellow is the path that was followed. We found a path from the initial state to the goal. But now let's take a look at a more sophisticated maze to see what might happen instead. Let's look now at maze2.txt. We're now here. We have a much larger maze. Again, we're trying to find our way from point A to point B. But now you'll imagine that depth-first search might not be so lucky. It might not get the goal on the first try. It might have to follow one path, then backtrack and explore something else a little bit later. So let's try this. We'll run python maze.py of maze2.txt, this time trying on this other maze. And now, depth-first search is able to find a solution. Here, as indicated by the stars, is a way to get from A to B. And we can represent this visually by opening up this maze. Here's what that maze looks like, and highlighted in yellow is the path that was found from the initial state to the goal. But how many states did we have to explore before we found that path? Well, recall that in my program, I was keeping track of the number of states that we've explored so far. And so I can go back to the terminal and see that, all right, in order to solve this problem, we had to explore 399 different states. And in fact, if I make one small modification of the program and tell the program at the end when we output this image, I added an argument called show explored. And if I set show explored equal to true and rerun this program, python maze.py, running it on maze2, and then I open the maze, what you'll see here is highlighted in red are all of the states that had to be explored to get from the initial state to the goal. Depth-first search, or DFS, didn't find its way to the goal right away. It made a choice to first explore this direction. And when it explored this direction, it had to follow every conceivable path all the way to the very end, even this long and winding one, in order to realize that, you know what? That's a dead end. And instead, the program needed to backtrack. After going this direction, it must have gone this direction. It got lucky here by just not choosing this path, but it got unlucky here, exploring this direction, exploring a bunch of states it didn't need to, and then likewise exploring all of this top part of the graph when it probably didn't need to do that either. So all in all, depth-first search here really not performing optimally, or probably exploring more states than it needs to. It finds an optimal solution, the best path to the goal, but the number of states needed to explore in order to do so, the number of steps I had to take, that was much higher. So let's compare. How would breadth-first search, or BFS, do on this exact same maze instead? And in order to do so, it's a very easy change. The algorithm for DFS and BFS is identical with the exception of what data structure we use to represent the frontier, that in DFS, I used a stack frontier, last in, first out, whereas in BFS, I'm going to use a queue frontier, first in, first out, where the first thing I add to the frontier is the first thing that I remove. So I'll go back to the terminal, rerun this program on the same maze, and now you'll see that the number of states we had to explore was only 77 as compared to almost 400 when we used depth-first search. And we can see exactly why. We can see what happened if we open up maze.png now and take a look. Again, yellow highlight is the solution that breadth-first search found, which incidentally is the same solution that depth-first search found. They're both finding the best solution. But notice all the white unexplored cells. There was much fewer states that needed to be explored in order to make our way to the goal because breadth-first search operates a little more shallowly. It's exploring things that are close to the initial state without exploring things that are further away. So if the goal is not too far away, then breadth-first search can actually behave quite effectively on a maze that looks a little something like this. Now, in this case, both BFS and DFS ended up finding the same solution, but that won't always be the case. And in fact, let's take a look at one more example. For instance, maze3.txt. In maze3.txt, notice that here there are multiple ways that you could get from A to B. It's a relatively small maze, but let's look at what happens. If I use, and I'll go ahead and turn off show explored so we just see the solution. If I use BFS, breadth-first search, to solve maze3.txt, well, then we find a solution, and if I open up the maze, here is the solution that we found. It is the optimal one. With just four steps, we can get from the initial state to what the goal happens to be. But what happens if we tried to use depth-first search or DFS instead? Well, again, I'll go back up to my Q frontier, where Q frontier means that we're using breadth-first search, and I'll change it to a stack frontier, which means that now we'll be using depth-first search. I'll rerun pythonmaze.py, and now you'll see that we find the solution, but it is not the optimal solution. This instead is what our algorithm finds, and maybe depth-first search would have found the solution. It's possible, but it's not guaranteed that if we just happen to be unlucky, if we choose this state instead of that state, then depth-first search might find a longer route to get from the initial state to the goal. So we do see some trade-offs here, where depth-first search might not find the optimal solution. So at that point, it seems like breadth-first search is pretty good. Is that the best we can do, where it's going to find us the optimal solution, and we don't have to worry about situations where we might end up finding a longer path to the solution than what actually exists? Where the goal is far away from the initial state, and we might have to take lots of steps in order to get from the initial state to the goal, what ended up happening is that this algorithm, BFS, ended up exploring basically the entire graph, having to go through the entire maze in order to find its way from the initial state to the goal state. What we'd ultimately like is for our algorithm to be a little bit more intelligent. And now what would it mean for our algorithm to be a little bit more intelligent in this case? Well, let's look back to where breadth-first search might have been able to make a different decision and consider human intuition in this process as well. What might a human do when solving this maze that is different than what BFS ultimately chose to do? Well, the very first decision point that BFS made was right here, when it made five steps and ended up in a position where it had a fork in the row. It could either go left or it could go right. In these initial couple steps, there was no choice. There was only one action that could be taken from each of those states. And so the search algorithm did the only thing that any search algorithm could do, which is keep following that state after the next state. But this decision point is where things get a little bit interesting. Depth-first search, that very first search algorithm we looked at, chose to say, let's pick one path and exhaust that path. See if anything that way has the goal. And if not, then let's try the other way. Depth-first search took the alternative approach of saying, you know what, let's explore things that are shallow, close to us first. Look left and right, then back left and back right, so on and so forth, alternating between our options in the hopes of finding something nearby. But ultimately, what might a human do if confronted with a situation like this of go left or go right? Well, a human might visually see that, all right, I'm trying to get to state b, which is way up there, and going right just feels like it's closer to the goal. It feels like going right should be better than going left because I'm making progress towards getting to that goal. Now, of course, there are a couple of assumptions that I'm making here. I'm making the assumption that we can represent this grid as like a two-dimensional grid where I know the coordinates of everything. I know that a is in coordinate 0, 0, and b is in some other coordinate pair, and I know what coordinate I'm at now. So I can calculate that, yeah, going this way, that is closer to the goal. And that might be a reasonable assumption for some types of search problems, but maybe not in others. But for now, we'll go ahead and assume that, that I know what my current coordinate pair is, and I know the coordinate, x, y, of the goal that I'm trying to get to. And in this situation, I'd like an algorithm that is a little bit more intelligent, that somehow knows that I should be making progress towards the goal, and this is probably the way to do that because in a maze, moving in the coordinate direction of the goal is usually, though not always, a good thing. And so here we draw a distinction between two different types of search algorithms, uninformed search and informed search. Uninformed search algorithms are algorithms like DFS and BFS, the two algorithms that we just looked at, which are search strategies that don't use any problem-specific knowledge to be able to solve the problem. DFS and BFS didn't really care about the structure of the maze or anything about the way that a maze is in order to solve the problem. They just look at the actions available and choose from those actions, and it doesn't matter whether it's a maze or some other problem, the solution or the way that it tries to solve the problem is really fundamentally going to be the same. What we're going to take a look at now is an improvement upon uninformed search. We're going to take a look at informed search. Informed search are going to be search strategies that use knowledge specific to the problem to be able to better find a solution. And in the case of a maze, this problem-specific knowledge is something like if I'm in a square that is geographically closer to the goal, that is better than being in a square that is geographically further away. And this is something we can only know by thinking about this problem and reasoning about what knowledge might be helpful for our AI agent to know a little something about. There are a number of different types of informed search. Specifically, first, we're going to look at a particular type of search algorithm called greedy best-first search. Greedy best-first search, often abbreviated G-BFS, is a search algorithm that instead of expanding the deepest node like DFS or the shallowest node like BFS, this algorithm is always going to expand the node that it thinks is closest to the goal. Now, the search algorithm isn't going to know for sure whether it is the closest thing to the goal. Because if we knew what was closest to the goal all the time, then we would already have a solution. The knowledge of what is close to the goal, we could just follow those steps in order to get from the initial position to the solution. But if we don't know the solution, meaning we don't know exactly what's closest to the goal, instead we can use an estimate of what's closest to the goal, otherwise known as a heuristic, just some way of estimating whether or not we're close to the goal. And we'll do so using a heuristic function conventionally called h of n that takes a status input and returns our estimate of how close we are to the goal. So what might this heuristic function actually look like in the case of a maze solving algorithm? Where we're trying to solve a maze, what does the heuristic look like? Well, the heuristic needs to answer a question between these two cells, C and D, which one is better? Which one would I rather be in if I'm trying to find my way to the goal? Well, any human could probably look at this and tell you, you know what, D looks like it's better. Even if the maze is convoluted and you haven't thought about all the walls, D is probably better. And why is D better? Well, because if you ignore the wall, so let's just pretend the walls don't exist for a moment and relax the problem, so to speak, D, just in terms of coordinate pairs, is closer to this goal. It's fewer steps that I wouldn't take to get to the goal as compared to C, even if you ignore the walls. If you just know the xy-coordinate of C and the xy-coordinate of the goal, and likewise you know the xy-coordinate of D, you can calculate the D just geographically. Ignoring the walls looks like it's better. And so this is the heuristic function that we're going to use. And it's something called the Manhattan distance, one specific type of heuristic, where the heuristic is how many squares vertically and horizontally and then left to right, so not allowing myself to go diagonally, just either up or right or left or down. How many steps do I need to take to get from each of these cells to the goal? Well, as it turns out, D is much closer. There are fewer steps. It only needs to take six steps in order to get to that goal. Again, here, ignoring the walls. We've relaxed the problem a little bit. We're just concerned with if you do the math to subtract the x values from each other and the y values from each other, what is our estimate of how far we are away? We can estimate the D is closer to the goal than C is. And so now we have an approach. We have a way of picking which node to remove from the frontier. And at each stage in our algorithm, we're going to remove a node from the frontier. We're going to explore the node if it has the smallest value for this heuristic function, if it has the smallest Manhattan distance to the goal. And so what would this actually look like? Well, let me first label this graph, label this maze, with a number representing the value of this heuristic function, the value of the Manhattan distance from any of these cells. So from this cell, for example, we're one away from the goal. From this cell, we're two away from the goal, three away, four away. Here, we're five away because we have to go one to the right and then four up. From somewhere like here, the Manhattan distance is two. We're only two squares away from the goal geographically, even though in practice, we're going to have to take a longer path. But we don't know that yet. The heuristic is just some easy way to estimate how far we are away from the goal. And maybe our heuristic is overly optimistic. It thinks that, yeah, we're only two steps away. When in practice, when you consider the walls, it might be more steps. So the important thing here is that the heuristic isn't a guarantee of how many steps it's going to take. It is estimating. It's an attempt at trying to approximate. And it does seem generally the case that the squares that look closer to the goal have smaller values for the heuristic function than squares that are further away. So now, using greedy best-first search, what might this algorithm actually do? Well, again, for these first five steps, there's not much of a choice. We start at this initial state a, and we say, all right, we have to explore these five states. But now we have a decision point. Now we have a choice between going left and going right. And before, when DFS and BFS would just pick arbitrarily, because it just depends on the order you throw these two nodes into the frontier, and we didn't specify what order you put them into the frontier, only the order you take them out, here we can look at 13 and 11 and say that, all right, this square is a distance of 11 away from the goal according to our heuristic, according to our estimate. And this one, we estimate to be 13 away from the goal. So between those two options, between these two choices, I'd rather have the 11. I'd rather be 11 steps away from the goal, so I'll go to the right. We're able to make an informed decision, because we know a little something more about this problem. So then we keep following, 10, 9, 8. Between the two 7s, we don't really have much of a way to know between those. So then we do just have to make an arbitrary choice. And you know what, maybe we choose wrong. But that's OK, because now we can still say, all right, let's try this 7. We say 7, 6, we have to make this choice, even though it increases the value of the heuristic function. But now we have another decision point, between 6 and 8, and between those two. And really, we're also considering this 13, but that's much higher. Between 6, 8, and 13, well, the 6 is the smallest value, so we'd rather take the 6. We're able to make an informed decision that going this way to the right is probably better than going down. So we turn this way, we go to 5. And now we find a decision point where we'll actually make a decision that we might not want to make, but there's unfortunately not too much of a way around this. We see 4 and 6. 4 looks closer to the goal, right? It's going up, and the goal is further up. So we end up taking that route, which ultimately leads us to a dead end. But that's OK, because we can still say, all right, now let's try the 6. And now follow this route that will ultimately lead us to the goal. And so this now is how greedy best-for-search might try to approach this problem by saying, whenever we have a decision between multiple nodes that we could explore, let's explore the node that has the smallest value of h of n, this heuristic function that is estimating how far I have to go. And it just so happens that in this case, we end up doing better in terms of the number of states we needed to explore than BFS needed to. BFS explored all of this section and all of that section, but we were able to eliminate that by taking advantage of this heuristic, this knowledge about how close we are to the goal or some estimate of that idea. So this seems much better. So wouldn't we always prefer an algorithm like this over an algorithm like breadth-first search? Well, maybe one thing to take into consideration is that we need to come up with a good heuristic, how good the heuristic is, is going to affect how good this algorithm is. And coming up with a good heuristic can oftentimes be challenging. But the other thing to consider is to ask the question, just as we did with the prior two algorithms, is this algorithm optimal? Will it always find the shortest path from the initial state to the goal? And to answer that question, let's take a look at this example for a moment. Take a look at this example. Again, we're trying to get from A to B. And again, I've labeled each of the cells with their Manhattan distance from the goal. The number of squares up and to the right, you would need to travel in order to get from that square to the goal. And let's think about, would greedy best-first search that always picks the smallest number end up finding the optimal solution? What is the shortest solution? And would this algorithm find it? And the important thing to realize is that right here is the decision point. We're estimated to be 12 away from the goal. And we have two choices. We can go to the left, which we estimate to be 13 away from the goal. Or we can go up, where we estimate it to be 11 away from the goal. And between those two, greedy best-first search is going to say the 11 looks better than the 13. And in doing so, greedy best-first search will end up finding this path to the goal. But it turns out this path is not optimal. There is a way to get to the goal using fewer steps. And it's actually this way, this way that ultimately involved fewer steps, even though it meant at this moment choosing the worst option between the two or what we estimated to be the worst option based on the heuristics. And so this is what we mean by this is a greedy algorithm. It's making the best decision locally. At this decision point, it looks like it's better to go here than it is to go to the 13. But in the big picture, it's not necessarily optimal. That it might find a solution when in actuality, there was a better solution available. So we would like some way to solve this problem. We like the idea of this heuristic, of being able to estimate the path, the distance between us and the goal. And that helps us to be able to make better decisions and to eliminate having to search through entire parts of this state space. But we would like to modify the algorithm so that we can achieve optimality, so that it can be optimal. And what is the way to do this? What is the intuition here? Well, let's take a look at this problem. In this initial problem, greedy best research found us this solution here, this long path. And the reason why it wasn't great is because, yes, the heuristic numbers went down pretty low. But later on, they started to build back up. They built back 8, 9, 10, 11, all the way up to 12 in this case. And so how might we go about trying to improve this algorithm? Well, one thing that we might realize is that if we go all the way through this algorithm, through this path, and we end up going to the 12, and we've had to take this many steps, who knows how many steps that is, just to get to this 12, we could have also, as an alternative, taken much fewer steps, just six steps, and ended up at this 13 here. And yes, 13 is more than 12, so it looks like it's not as good. But it required far fewer steps. It only took six steps to get to this 13 versus many more steps to get to this 12. And while greedy best research says, oh, well, 12 is better than 13, so pick the 12, we might more intelligently say, I'd rather be somewhere that heuristically looks like it takes slightly longer if I can get there much more quickly. And we're going to encode that idea, this general idea, into a more formal algorithm known as A star search. A star search is going to solve this problem by instead of just considering the heuristic, also considering how long it took us to get to any particular state. So the distinction is greedy best for search. If I am in a state right now, the only thing I care about is, what is the estimated distance, the heuristic value, between me and the goal? Whereas A star search will take into consideration two pieces of information. It'll take into consideration, how far do I estimate I am from the goal? But also, how far did I have to travel in order to get here? Because that is relevant, too. So we'll search algorithms by expanding the node with the lowest value of g of n plus h of n. h of n is that same heuristic that we were talking about a moment ago that's going to vary based on the problem. But g of n is going to be the cost to reach the node, how many steps I had to take, in this case, to get to my current position. So what does that search algorithm look like in practice? Well, let's take a look. Again, we've got the same maze. And again, I've labeled them with their Manhattan distance. This value is the h of n value, the heuristic estimate of how far each of these squares is away from the goal. But now, as we begin to explore states, we care not just about this heuristic value, but also about g of n, the number of steps I had to take in order to get there. And I care about summing those two numbers together. So what does that look like? On this very first step, I have taken one step. And now I am estimated to be 16 steps away from the goal. So the total value here is 17. Then I take one more step. I've now taken two steps. And I estimate myself to be 15 away from the goal, again, a total value of 17. Now I've taken three steps. And I'm estimated to be 14 away from the goal, so on and so forth. Four steps, an estimate of 13. Five steps, estimate of 12. And now here's a decision point. I could either be six steps away from the goal with a heuristic of 13 for a total of 19, or I could be six steps away from the goal with a heuristic of 11 with an estimate of 17 for the total. So between 19 and 17, I'd rather take the 17, the 6 plus 11. So so far, no different than what we saw before. We're still taking this option because it appears to be better. And I keep taking this option because it appears to be better. But it's right about here that things get a little bit different. Now I could be 15 steps away from the goal with an estimated distance of 6. So 15 plus 6, total value of 21. Alternatively, I could be six steps away from the goal, because this is five steps away, so this is six steps away, with a total value of 13 as my estimate. So 6 plus 13, that's 19. So here, we would evaluate g of n plus h of n to be 19, 6 plus 13. Whereas here, we would be 15 plus 6, or 21. And so the intuition is 19 less than 21, pick here. But the idea is ultimately I'd rather be having taken fewer steps, get to a 13, than having taken 15 steps and be at a 6, because it means I've had to take more steps in order to get there. Maybe there's a better path this way. So instead, we'll explore this route. Now if we go one more, this is seven steps plus 14 is 21. So between those two, it's sort of a toss-up. We might end up exploring that one anyways. But after that, as these numbers start to get bigger in the heuristic values, and these heuristic values start to get smaller, you'll find that we'll actually keep exploring down this path. And you can do the math to see that at every decision point, A star search is going to make a choice based on the sum of how many steps it took me to get to my current position, and then how far I estimate I am from the goal. So while we did have to explore some of these states, the ultimate solution we found was, in fact, an optimal solution. It did find us the quickest possible way to get from the initial state to the goal. And it turns out that A star is an optimal search algorithm under certain conditions. So the conditions are H of n, my heuristic, needs to be admissible. What does it mean for a heuristic to be admissible? Well, a heuristic is admissible if it never overestimates the true cost. H of n always needs to either get it exactly right in terms of how far away I am, or it needs to underestimate. So we saw an example from before where the heuristic value was much smaller than the actual cost it would take. That's totally fine, but the heuristic value should never overestimate. It should never think that I'm further away from the goal than I actually am. And meanwhile, to make a stronger statement, H of n also needs to be consistent. And what does it mean for it to be consistent? Mathematically, it means that for every node, which we'll call n, and successor, the node after me, that I'll call n prime, where it takes a cost of C to make that step, the heuristic value of n needs to be less than or equal to the heuristic value of n prime plus the cost. So it's a lot of math, but in words what that ultimately means is that if I am here at this state right now, the heuristic value from me to the goal shouldn't be more than the heuristic value of my successor, the next place I could go to, plus however much it would cost me to just make that step from one step to the next step. And so this is just making sure that my heuristic is consistent between all of these steps that I might take. So as long as this is true, then A star search is going to find me an optimal solution. And this is where much of the challenge of solving these search problems can sometimes come in, that A star search is an algorithm that is known and you could write the code fairly easily, but it's choosing the heuristic. It can be the interesting challenge. The better the heuristic is, the better I'll be able to solve the problem in the fewer states that I'll have to explore. And I need to make sure that the heuristic satisfies these particular constraints. So all in all, these are some of the examples of search algorithms that might work, and certainly there are many more than just this. A star, for example, does have a tendency to use quite a bit of memory. So there are alternative approaches to A star that ultimately use less memory than this version of A star happens to use, and there are other search algorithms that are optimized for other cases as well. But now so far, we've only been looking at search algorithms where there is one agent. I am trying to find a solution to a problem. I am trying to navigate my way through a maze. I am trying to solve a 15 puzzle. I am trying to find driving directions from point A to point B. Sometimes in search situations, though, we'll enter an adversarial situation, where I am an agent trying to make intelligent decisions. And there's someone else who is fighting against me, so to speak, that has opposite objectives, someone where I am trying to succeed, someone else that wants me to fail. And this is most popular in something like a game, a game like Tic Tac Toe, where we've got this 3 by 3 grid, and x and o take turns, either writing an x or an o in any one of these squares. And the goal is to get three x's in a row if you're the x player, or three o's in a row if you're the o player. And computers have gotten quite good at playing games, Tic Tac Toe very easily, but even more complex games. And so you might imagine, what does an intelligent decision in a game look like? So maybe x makes an initial move in the middle, and o plays up here. What does an intelligent move for x now become? Where should you move if you were x? And it turns out there are a couple of possibilities. But if an AI is playing this game optimally, then the AI might play somewhere like the upper right, where in this situation, o has the opposite objective of x. x is trying to win the game to get three in a row diagonally here. And o is trying to stop that objective, opposite of the objective. And so o is going to place here to try to block. But now, x has a pretty clever move. x can make a move like this, where now x has two possible ways that x can win the game. x could win the game by getting three in a row across here. Or x could win the game by getting three in a row vertically this way. So it doesn't matter where o makes their next move. o could play here, for example, blocking the three in a row horizontally. But then x is going to win the game by getting a three in a row vertically. And so there's a fair amount of reasoning that's going on here in order for the computer to be able to solve a problem. And it's similar in spirit to the problems we've looked at so far. There are actions. There's some sort of state of the board and some transition from one action to the next. But it's different in the sense that this is now not just a classical search problem, but an adversarial search problem. That I am at the x player trying to find the best moves to make, but I know that there is some adversary that is trying to stop me. So we need some sort of algorithm to deal with these adversarial type of search situations. And the algorithm we're going to take a look at is an algorithm called Minimax, which works very well for these deterministic games where there are two players. It can work for other types of games as well. But we'll look right now at games where I make a move, then my opponent makes a move. And I am trying to win, and my opponent is trying to win also. Or in other words, my opponent is trying to get me to lose. And so what do we need in order to make this algorithm work? Well, any time we try and translate this human concept of playing a game, winning and losing to a computer, we want to translate it in terms that the computer can understand. And ultimately, the computer really just understands the numbers. And so we want some way of translating a game of x's and o's on a grid to something numerical, something the computer can understand. The computer doesn't normally understand notions of win or lose. But it does understand the concept of bigger and smaller. And so what we might do is we might take each of the possible ways that a tic-tac-toe game can unfold and assign a value or a utility to each one of those possible ways. And in a tic-tac-toe game, and in many types of games, there are three possible outcomes. The outcomes are o wins, x wins, or nobody wins. So player one wins, player two wins, or nobody wins. And for now, let's go ahead and assign each of these possible outcomes a different value. We'll say o winning, that'll have a value of negative 1. Nobody winning, that'll have a value of 0. And x winning, that will have a value of 1. So we've just assigned numbers to each of these three possible outcomes. And now we have two players, we have the x player and the o player. And we're going to go ahead and call the x player the max player. And we'll call the o player the min player. And the reason why is because in the min and max algorithm, the max player, which in this case is x, is aiming to maximize the score. These are the possible options for the score, negative 1, 0, and 1. x wants to maximize the score, meaning if at all possible, x would like this situation, where x wins the game, and we give it a score of 1. But if this isn't possible, if x needs to choose between these two options, negative 1, meaning o winning, or 0, meaning nobody winning, x would rather that nobody wins, score of 0, than a score of negative 1, o winning. So this notion of winning and losing and tying has been reduced mathematically to just this idea of try and maximize the score. The x player always wants the score to be bigger. And on the flip side, the min player, in this case o, is aiming to minimize the score. The o player wants the score to be as small as possible. So now we've taken this game of x's and o's and winning and losing and turned it into something mathematical, something where x is trying to maximize the score, o is trying to minimize the score. Let's now look at all of the parts of the game that we need in order to encode it in an AI so that an AI can play a game like tic-tac-toe. So the game is going to need a couple of things. We'll need some sort of initial state that will, in this case, call s0, which is how the game begins, like an empty tic-tac-toe board, for example. We'll also need a function called player, where the player function is going to take as input a state here represented by s. And the output of the player function is going to be which player's turn is it. We need to be able to give a tic-tac-toe board to the computer, run it through a function, and that function tells us whose turn it is. We'll need some notion of actions that we can take. We'll see examples of that in just a moment. We need some notion of a transition model, same as before. If I have a state and I take an action, I need to know what results as a consequence of it. I need some way of knowing when the game is over. So this is equivalent to kind of like a goal test, but I need some terminal test, some way to check to see if a state is a terminal state, where a terminal state means the game is over. In a classic game of tic-tac-toe, a terminal state means either someone has gotten three in a row or all of the squares of the tic-tac-toe board are filled. Either of those conditions make it a terminal state. In a game of chess, it might be something like when there is checkmate or if checkmate is no longer possible, that that becomes a terminal state. And then finally, we'll need a utility function, a function that takes a state and gives us a numerical value for that terminal state, some way of saying if x wins the game, that has a value of 1. If o is won the game, that has a value of negative 1. If nobody has won the game, that has a value of 0. So let's take a look at each of these in turn. The initial state, we can just represent in tic-tac-toe as the empty game board. This is where we begin. It's the place from which we begin this search. And again, I'll be representing these things visually, but you can imagine this really just being like an array or a two-dimensional array of all of these possible squares. Then we need the player function that, again, takes a state and tells us whose turn it is. Assuming x makes the first move, if I have an empty game board, then my player function is going to return x. And if I have a game board where x has made a move, then my player function is going to return o. The player function takes a tic-tac-toe game board and tells us whose turn it is. Next up, we'll consider the actions function. The actions function, much like it did in classical search, takes a state and gives us the set of all of the possible actions we can take in that state. So let's imagine it's o is turned to move in a game board that looks like this. What happens when we pass it into the actions function? So the actions function takes this state of the game as input, and the output is a set of possible actions. It's a set of I could move in the upper left or I could move in the bottom middle. So those are the two possible action choices that I have when I begin in this particular state. Now, just as before, when we had states and actions, we need some sort of transition model to tell us when we take this action in the state, what is the new state that we get. And here, we define that using the result function that takes a state as input as well as an action. And when we apply the result function to this state, saying that let's let o move in this upper left corner, the new state we get is this resulting state where o is in the upper left corner. And now, this seems obvious to someone who knows how to play tic-tac-toe. Of course, you play in the upper left corner. That's the board you get. But all of this information needs to be encoded into the AI. The AI doesn't know how to play tic-tac-toe until you tell the AI how the rules of tic-tac-toe work. And this function, defining this function here, allows us to tell the AI how this game actually works and how actions actually affect the outcome of the game. So the AI needs to know how the game works. The AI also needs to know when the game is over, as by defining a function called terminal that takes as input a state s, such that if we take a game that is not yet over, pass it into the terminal function, the output is false. The game is not over. But if we take a game that is over because x has gotten three in a row along that diagonal, pass that into the terminal function, then the output is going to be true because the game now is, in fact, over. And finally, we've told the AI how the game works in terms of what moves can be made and what happens when you make those moves. We've told the AI when the game is over. Now we need to tell the AI what the value of each of those states is. And we do that by defining this utility function that takes a state s and tells us the score or the utility of that state. So again, we said that if x wins the game, that utility is a value of 1, whereas if o wins the game, then the utility of that is negative 1. And the AI needs to know, for each of these terminal states where the game is over, what is the utility of that state? So if I give you a game board like this where the game is, in fact, over, and I ask the AI to tell me what the value of that state is, it could do so. The value of the state is 1. Where things get interesting, though, is if the game is not yet over. Let's imagine a game board like this, where in the middle of the game, it's o's turn to make a move. So how do we know it's o's turn to make a move? We can calculate that using the player function. We can say player of s, pass in the state, o is the answer. So we know it's o's turn to move. And now, what is the value of this board and what action should o take? Well, that's going to depend. We have to do some calculation here. And this is where the minimax algorithm really comes in. Recall that x is trying to maximize the score, which means that o is trying to minimize the score. So o would like to minimize the total value that we get at the end of the game. And because this game isn't over yet, we don't really know just yet what the value of this game board is. We have to do some calculation in order to figure that out. And so how do we do that kind of calculation? Well, in order to do so, we're going to consider, just as we might in a classical search situation, what actions could happen next and what states will that take us to. And it turns out that in this position, there are only two open squares, which means there are only two open places where o can make a move. o could either make a move in the upper left or o can make a move in the bottom middle. And minimax doesn't know right out of the box which of those moves is going to be better. So it's going to consider both. But now, we sort of run into the same situation. Now, I have two more game boards, neither of which is over. What happens next? And now, it's in this sense that minimax is what we'll call a recursive algorithm. It's going to now repeat the exact same process, although now considering it from the opposite perspective. It's as if I am now going to put myself, if I am the o player, I'm going to put myself in my opponent's shoes, my opponent as the x player, and consider what would my opponent do if they were in this position? What would my opponent do, the x player, if they were in that position? And what would then happen? Well, the other player, my opponent, the x player, is trying to maximize the score, whereas I am trying to minimize the score as the o player. So x is trying to find the maximum possible value that they can get. And so what's going to happen? Well, from this board position, x only has one choice. x is going to play here, and they're going to get three in a row. And we know that that board, x winning, that has a value of 1. If x wins the game, the value of that game board is 1. And so from this position, if this state can only ever lead to this state, it's the only possible option, and this state has a value of 1, then the maximum possible value that the x player can get from this game board is also 1. From here, the only place we can get is to a game with a value of 1, so this game board also has a value of 1. Now we consider this one over here. What's going to happen now? Well, x needs to make a move. The only move x can make is in the upper left, so x will go there. And in this game, no one wins the game. Nobody has three in a row. And so the value of that game board is 0. Nobody is 1. And so again, by the same logic, if from this board position the only place we can get to is a board where the value is 0, then this state must also have a value of 0. And now here comes the choice part, the idea of trying to minimize. I, as the o player, now know that if I make this choice moving in the upper left, that is going to result in a game with a value of 1, assuming everyone plays optimally. And if I instead play in the lower middle, choose this fork in the road, that is going to result in a game board with a value of 0. I have two options. I have a 1 and a 0 to choose from, and I need to pick. And as the min player, I would rather choose the option with the minimum value. So whenever a player has multiple choices, the min player will choose the option with the smallest value. The max player will choose the option with the largest value. Between the 1 and the 0, the 0 is smaller, meaning I'd rather tie the game than lose the game. And so this game board will say also has a value of 0, because if I am playing optimally, I will pick this fork in the road. I'll place my o here to block x's 3 in a row, x will move in the upper left, and the game will be over, and no one will have won the game. So this is now the logic of minimax, to consider all of the possible options that I can take, all of the actions that I can take, and then to put myself in my opponent's shoes. I decide what move I'm going to make now by considering what move my opponent will make on the next turn. And to do that, I consider what move I would make on the turn after that, so on and so forth, until I get all the way down to the end of the game, to one of these so-called terminal states. In fact, this very decision point, where I am trying to decide as the o player what to make a decision about, might have just been a part of the logic that the x player, my opponent, was using, the move before me. This might be part of some larger tree, where x is trying to make a move in this situation, and needs to pick between three different options in order to make a decision about what to happen. And the further and further away we are from the end of the game, the deeper this tree has to go. Because every level in this tree is going to correspond to one move, one move or action that I take, one move or action that my opponent takes, in order to decide what happens. And in fact, it turns out that if I am the x player in this position, and I recursively do the logic, and see I have a choice, three choices, in fact, one of which leads to a value of 0. If I play here, and if everyone plays optimally, the game will be a tie. If I play here, then o is going to win, and I'll lose playing optimally. Or here, where I, the x player, can win, well between a score of 0, and negative 1, and 1, I'd rather pick the board with a value of 1, because that's the maximum value I can get. And so this board would also have a maximum value of 1. And so this tree can get very, very deep, especially as the game starts to have more and more moves. And this logic works not just for tic-tac-toe, but any of these sorts of games, where I make a move, my opponent makes a move, and ultimately, we have these adversarial objectives. And we can simplify the diagram into a diagram that looks like this. This is a more abstract version of the minimax tree, where these are each states, but I'm no longer representing them as exactly like tic-tac-toe boards. This is just representing some generic game that might be tic-tac-toe, might be some other game altogether. Any of these green arrows that are pointing up, that represents a maximizing state. I would like the score to be as big as possible. And any of these red arrows pointing down, those are minimizing states, where the player is the min player, and they are trying to make the score as small as possible. So if you imagine in this situation, I am the maximizing player, this player here, and I have three choices. One choice gives me a score of 5, one choice gives me a score of 3, and one choice gives me a score of 9. Well, then between those three choices, my best option is to choose this 9 over here, the score that maximizes my options out of all the three options. And so I can give this state a value of 9, because among my three options, that is the best choice that I have available to me. So that's my decision now. You imagine it's like one move away from the end of the game. But then you could also ask a reasonable question, what might my opponent do two moves away from the end of the game? My opponent is the minimizing player. They are trying to make the score as small as possible. Imagine what would have happened if they had to pick which choice to make. One choice leads us to this state, where I, the maximizing player, am going to opt for 9, the biggest score that I can get. And 1 leads to this state, where I, the maximizing player, would choose 8, which is then the largest score that I can get. Now the minimizing player, forced to choose between a 9 or an 8, is going to choose the smallest possible score, which in this case is an 8. And that is then how this process would unfold, that the minimizing player in this case considers both of their options, and then all of the options that would happen as a result of that. So this now is a general picture of what the minimax algorithm looks like. Let's now try to formalize it using a little bit of pseudocode. So what exactly is happening in the minimax algorithm? Well, given a state s, we need to decide what to happen. The max player, if it's max's player's turn, then max is going to pick an action a in actions of s. Recall that actions is a function that takes a state and gives me back all of the possible actions that I can take. It tells me all of the moves that are possible. The max player is going to specifically pick an action a in this set of actions that gives me the highest value of min value of result of s and a. So what does that mean? Well, it means that I want to make the option that gives me the highest score of all of the actions a. But what score is that going to have? To calculate that, I need to know what my opponent, the min player, is going to do if they try to minimize the value of the state that results. So we say, what state results after I take this action? And what happens when the min player tries to minimize the value of that state? I consider that for all of my possible options. And after I've considered that for all of my possible options, I pick the action a that has the highest value. Likewise, the min player is going to do the same thing but backwards. They're also going to consider what are all of the possible actions they can take if it's their turn. And they're going to pick the action a that has the smallest possible value of all the options. And the way they know what the smallest possible value of all the options is is by considering what the max player is going to do by saying, what's the result of applying this action to the current state? And then what would the max player try to do? What value would the max player calculate for that particular state? So everyone makes their decision based on trying to estimate what the other person would do. And now we need to turn our attention to these two functions, max value and min value. How do you actually calculate the value of a state if you're trying to maximize its value? And how do you calculate the value of a state if you're trying to minimize the value? If you can do that, then we have an entire implementation of this min and max algorithm. So let's try it. Let's try and implement this max value function that takes a state and returns as output the value of that state if I'm trying to maximize the value of the state. Well, the first thing I can check for is to see if the game is over. Because if the game is over, in other words, if the state is a terminal state, then this is easy. I already have this utility function that tells me what the value of the board is. If the game is over, I just check, did x win, did o win, is it a tie? And this utility function just knows what the value of the state is. What's trickier is if the game isn't over. Because then I need to do this recursive reasoning about thinking, what is my opponent going to do on the next move? And I want to calculate the value of this state. And I want the value of the state to be as high as possible. And I'll keep track of that value in a variable called v. And if I want the value to be as high as possible, I need to give v an initial value. And initially, I'll just go ahead and set it to be as low as possible. Because I don't know what options are available to me yet. So initially, I'll set v equal to negative infinity, which seems a little bit strange. But the idea here is I want the value initially to be as low as possible. Because as I consider my actions, I'm always going to try and do better than v. And if I set v to negative infinity, I know I can always do better than that. So now I consider my actions. And this is going to be some kind of loop where for every action in actions of state, recall actions as a function that takes my state and gives me all the possible actions that I can use in that state. So for each one of those actions, I want to compare it to v and say, all right, v is going to be equal to the maximum of v and this expression. So what is this expression? Well, first it is get the result of taking the action in the state and then get the min value of that. In other words, let's say I want to find out from that state what is the best that the min player can do because they're going to try and minimize the score. So whatever the resulting score is of the min value of that state, compare it to my current best value and just pick the maximum of those two because I am trying to maximize the value. In short, what these three lines of code are doing are going through all of my possible actions and asking the question, how do I maximize the score given what my opponent is going to try to do? After this entire loop, I can just return v and that is now the value of that particular state. And for the min player, it's the exact opposite of this, the same logic just backwards. To calculate the minimum value of a state, first we check if it's a terminal state. If it is, we return its utility. Otherwise, we're going to now try to minimize the value of the state given all of my possible actions. So I need an initial value for v, the value of the state. And initially, I'll set it to infinity because I know I can always get something less than infinity. So by starting with v equals infinity, I make sure that the very first action I find, that will be less than this value of v. And then I do the same thing, loop over all of my possible actions. And for each of the results that we could get when the max player makes their decision, let's take the minimum of that and the current value of v. So after all is said and done, I get the smallest possible value of v that I then return back to the user. So that, in effect, is the pseudocode for Minimax. That is how we take a gain and figure out what the best move to make is by recursively using these max value and min value functions, where max value calls min value, min value calls max value back and forth, all the way until we reach a terminal state, at which point our algorithm can simply return the utility of that particular state. So what you might imagine is that this is going to start to be a long process, especially as games start to get more complex, as we start to add more moves and more possible options and games that might last quite a bit longer. So the next question to ask is, what sort of optimizations can we make here? How can we do better in order to use less space or take less time to be able to solve this kind of problem? And we'll take a look at a couple of possible optimizations. But for one, we'll take a look at this example. Again, returning to these up arrows and down arrows, let's imagine that I now am the max player, this green arrow. I am trying to make this score as high as possible. And this is an easy game where there are just two moves. I make a move, one of these three options. And then my opponent makes a move, one of these three options, based on what move I make. And as a result, we get some value. Let's look at the order in which I do these calculations and figure out if there are any optimizations I might be able to make to this calculation process. I'm going to have to look at these states one at a time. So let's say I start here on the left and say, all right, now I'm going to consider, what will the min player, my opponent, try to do here? Well, the min player is going to look at all three of their possible actions and look at their value, because these are terminal states. They're the end of the game. And so they'll see, all right, this node is a value of four, value of eight, value of five. And the min player is going to say, well, all right, between these three options, four, eight, and five, I'll take the smallest one. I'll take the four. So this state now has a value of four. Then I, as the max player, say, all right, if I take this action, it will have a value of four. That's the best that I can do, because min player is going to try and minimize my score. So now what if I take this option? We'll explore this next. And now explore what the min player would do if I choose this action. And the min player is going to say, all right, what are the three options? The min player has options between nine, three, and seven. And so three is the smallest among nine, three, and seven. So we'll go ahead and say this state has a value of three. So now I, as the max player, I have now explored two of my three options. I know that one of my options will guarantee me a score of four, at least. And one of my options will guarantee me a score of three. And now I consider my third option and say, all right, what happens here? Same exact logic. The min player is going to look at these three states, two, four, and six. I'll say the minimum possible option is two. So the min player wants the two. Now I, as the max player, have calculated all of the information by looking two layers deep, by looking at all of these nodes. And I can now say, between the four, the three, and the two, you know what? I'd rather take the four. Because if I choose this option, if my opponent plays optimally, they will try and get me to the four. But that's the best I can do. I can't guarantee a higher score. Because if I pick either of these two options, I might get a three or I might get a two. And it's true that down here is a nine. And that's the highest score out of any of the scores. So I might be tempted to say, you know what? Maybe I should take this option because I might get the nine. But if the min player is playing intelligently, if they're making the best moves at each possible option they have when they get to make a choice, I'll be left with a three. Whereas I could better, playing optimally, have guaranteed that I would get the four. So that is, in effect, the logic that I would use as a min and max player trying to maximize my score from that node there. But it turns out they took quite a bit of computation for me to figure that out. I had to reason through all of these nodes in order to draw this conclusion. And this is for a pretty simple game where I have three choices, my opponent has three choices, and then the game's over. So what I'd like to do is come up with some way to optimize this. Maybe I don't need to do all of this calculation to still reach the conclusion that, you know what, this action to the left, that's the best that I could do. Let's go ahead and try again and try to be a little more intelligent about how I go about doing this. So first, I start the exact same way. I don't know what to do initially, so I just have to consider one of the options and consider what the min player might do. Min has three options, four, eight, and five. And between those three options, min says four is the best they can do because they want to try to minimize the score. Now I, the max player, will consider my second option, making this move here, and considering what my opponent would do in response. What will the min player do? Well, the min player is going to, from that state, look at their options. And I would say, all right, nine is an option, three is an option. And if I am doing the math from this initial state, doing all this calculation, when I see a three, that should immediately be a red flag for me. Because when I see a three down here at this state, I know that the value of this state is going to be at most three. It's going to be three or something less than three, even though I haven't yet looked at this last action or even further actions if there were more actions that could be taken here. How do I know that? Well, I know that the min player is going to try to minimize my score. And if they see a three, the only way this could be something other than a three is if this remaining thing that I haven't yet looked at is less than three, which means there is no way for this value to be anything more than three because the min player can already guarantee a three and they are trying to minimize my score. So what does that tell me? Well, it tells me that if I choose this action, my score is going to be three or maybe even less than three if I'm unlucky. But I already know that this action will guarantee me a four. And so given that I know that this action guarantees me a score of four and this action means I can't do better than three, if I'm trying to maximize my options, there is no need for me to consider this triangle here. There is no value, no number that could go here that would change my mind between these two options. I'm always going to opt for this path that gets me a four as opposed to this path where the best I can do is a three if my opponent plays optimally. And this is going to be true for all the future states that I look at too. That if I look over here at what min player might do over here, if I see that this state is a two, I know that this state is at most a two because the only way this value could be something other than two is if one of these remaining states is less than a two and so the min player would opt for that instead. So even without looking at these remaining states, I as the maximizing player can know that choosing this path to the left is going to be better than choosing either of those two paths to the right because this one can't be better than three. This one can't be better than two. And so four in this case is the best that I can do. So in order to do this cut, and I can say now that this state has a value of four. So in order to do this type of calculation, I was doing a little bit more bookkeeping, keeping track of things, keeping track all the time of what is the best that I can do, what is the worst that I can do, and for each of these states saying, all right, well, if I already know that I can get a four, then if the best I can do at this state is a three, no reason for me to consider it, I can effectively prune this leaf and anything below it from the tree. And it's for that reason this approach, this optimization to minimax, is called alpha, beta pruning. Alpha and beta stand for these two values that you'll have to keep track of of the best you can do so far and the worst you can do so far. And pruning is the idea of if I have a big, long, deep search tree, I might be able to search it more efficiently if I don't need to search through everything, if I can remove some of the nodes to try and optimize the way that I look through this entire search space. So alpha, beta pruning can definitely save us a lot of time as we go about the search process by making our searches more efficient. But even then, it's still not great as games get more complex. Tic-tac-toe, fortunately, is a relatively simple game. And we might reasonably ask a question like, how many total possible tic-tac-toe games are there? You can think about it. You can try and estimate how many moves are there at any given point, how many moves long can the game last. It turns out there are about 255,000 possible tic-tac-toe games that can be played. But compare that to a more complex game, something like a game of chess, for example. Far more pieces, far more moves, games that last much longer. How many total possible chess games could there be? It turns out that after just four moves each, four moves by the white player, four moves by the black player, that there are 288 billion possible chess games that can result from that situation, after just four moves each. And going even further, if you look at entire chess games and how many possible chess games there could be as a result there, there are more than 10 to the 29,000 possible chess games, far more chess games than could ever be considered. And this is a pretty big problem for the Minimax algorithm, because the Minimax algorithm starts with an initial state, considers all the possible actions, and all the possible actions after that, all the way until we get to the end of the game. And that's going to be a problem if the computer is going to need to look through this many states, which is far more than any computer could ever do in any reasonable amount of time. So what do we do in order to solve this problem? Instead of looking through all these states which is totally intractable for a computer, we need some better approach. And it turns out that better approach generally takes the form of something called depth-limited Minimax, where normally Minimax is depth-unlimited. We just keep going layer after layer, move after move, until we get to the end of the game. Depth-limited Minimax is instead going to say, you know what, after a certain number of moves, maybe I'll look 10 moves ahead, maybe I'll look 12 moves ahead, but after that point, I'm going to stop and not consider additional moves that might come after that, just because it would be computationally intractable to consider all of those possible options. But what do we do after we get 10 or 12 moves deep when we arrive at a situation where the game's not over? Minimax still needs a way to assign a score to that game board or game state to figure out what its current value is, which is easy to do if the game is over, but not so easy to do if the game is not yet over. So in order to do that, we need to add one additional feature to depth-limited Minimax called an evaluation function, which is just some function that is going to estimate the expected utility of a game from a given state. So in a game like chess, if you imagine that a game value of 1 means white wins, negative 1 means black wins, 0 means it's a draw, then you might imagine that a score of 0.8 means white is very likely to win, though certainly not guaranteed. And you would have an evaluation function that estimates how good the game state happens to be. And depending on how good that evaluation function is, that is ultimately what's going to constrain how good the AI is. The better the AI is at estimating how good or how bad any particular game state is, the better the AI is going to be able to play that game. If the evaluation function is worse and not as good as it estimating what the expected utility is, then it's going to be a whole lot harder. And you can imagine trying to come up with these evaluation functions. In chess, for example, you might write an evaluation function based on how many pieces you have as compared to how many pieces your opponent has, because each one has a value. And your evaluation function probably needs to be a little bit more complicated than that to consider other possible situations that might arise as well. And there are many other variants on Minimax that add additional features in order to help it perform better under these larger, more computationally untractable situations where we couldn't possibly explore all of the possible moves. So we need to figure out how to use evaluation functions and other techniques to be able to play these games ultimately better. But this now was a look at this kind of adversarial search, these search problems where we have situations where I am trying to play against some sort of opponent. And these search problems show up all over the place throughout artificial intelligence. We've been talking a lot today about more classical search problems, like trying to find directions from one location to another. But any time an AI is faced with trying to make a decision, like what do I do now in order to do something that is rational, or do something that is intelligent, or trying to play a game, like figuring out what move to make, these sort of algorithms can really come in handy. It turns out that for tic-tac-toe, the solution is pretty simple because it's a small game. XKCD has famously put together a web comic where he will tell you exactly what move to make as the optimal move to make no matter what your opponent happens to do. This type of thing is not quite as possible for a much larger game like Checkers or Chess, for example, where chess is totally computationally untractable for most computers to be able to explore all the possible states. So we really need our AI to be far more intelligent about how they go about trying to deal with these problems and how they go about taking this environment that they find themselves in and ultimately searching for one of these solutions. So this, then, was a look at search in artificial intelligence. Next time, we'll take a look at knowledge, thinking about how it is that our AIs are able to know information, reason about that information, and draw conclusions, all in our look at AI and the principles behind it. We'll see you next time. [\"AIMS INTRO MUSIC\"] All right, welcome back, everyone, to an introduction to artificial intelligence with Python. Last time, we took a look at search problems, in particular, where we have AI agents that are trying to solve some sort of problem by taking actions in some sort of environment, whether that environment is trying to take actions by playing moves in a game or whether those actions are something like trying to figure out where to make turns in order to get driving directions from point A to point B. This time, we're going to turn our attention more generally to just this idea of knowledge, the idea that a lot of intelligence is based on knowledge, especially if we think about human intelligence. People know information. We know facts about the world. And using that information that we know, we're able to draw conclusions, reason about the information that we know in order to figure out how to do something or figure out some other piece of information that we conclude based on the information we already have available to us. What we'd like to focus on now is the ability to take this idea of knowledge and being able to reason based on knowledge and apply those ideas to artificial intelligence. In particular, we're going to be building what are known as knowledge-based agents, agents that are able to reason and act by representing knowledge internally. Somehow inside of our AI, they have some understanding of what it means to know something. And ideally, they have some algorithms or some techniques they can use based on that knowledge that they know in order to figure out the solution to a problem or figure out some additional piece of information that can be helpful in some sense. So what do we mean by reasoning based on knowledge to be able to draw conclusions? Well, let's look at a simple example drawn from the world of Harry Potter. We take one sentence that we know to be true. Imagine if it didn't rain, then Harry visited Hagrid today. So one fact that we might know about the world. And then we take another fact. Harry visited Hagrid or Dumbledore today, but not both. So it tells us something about the world, that Harry either visited Hagrid but not Dumbledore, or Harry visited Dumbledore but not Hagrid. And now we have a third piece of information about the world that Harry visited Dumbledore today. So we now have three pieces of information now, three facts. Inside of a knowledge base, so to speak, information that we know. And now we, as humans, can try and reason about this and figure out, based on this information, what additional information can we begin to conclude? And well, looking at these last two statements, Harry either visited Hagrid or Dumbledore but not both, and we know that Harry visited Dumbledore today, well, then it's pretty reasonable that we could draw the conclusion that, you know what, Harry must not have visited Hagrid today. Because based on a combination of these two statements, we can draw this inference, so to speak, a conclusion that Harry did not visit Hagrid today. But it turns out we can even do a little bit better than that, get some more information by taking a look at this first statement and reasoning about that. This first statement says, if it didn't rain, then Harry visited Hagrid today. So what does that mean? In all cases where it didn't rain, then we know that Harry visited Hagrid. But if we also know now that Harry did not visit Hagrid, then that tells us something about our initial premise that we were thinking about. In particular, it tells us that it did rain today, because we can reason, if it didn't rain, that Harry would have visited Hagrid. But we know for a fact that Harry did not visit Hagrid today. So it's this kind of reason, this sort of logical reasoning, where we use logic based on the information that we know in order to take information and reach conclusions that is going to be the focus of what we're going to be talking about today. How can we make our artificial intelligence logical so that they can perform the same kinds of deduction, the same kinds of reasoning that we've been doing so far? Of course, humans reason about logic generally in terms of human language. That I just now was speaking in English, talking in English about these sentences and trying to reason through how it is that they relate to one another. We're going to need to be a little bit more formal when we turn our attention to computers and being able to encode this notion of logic and truthhood and falsehood inside of a machine. So we're going to need to introduce a few more terms and a few symbols that will help us reason through this idea of logic inside of an artificial intelligence. And we'll begin with the idea of a sentence. Now, a sentence in a natural language like English is just something that I'm saying, like what I'm saying right now. In the context of AI, though, a sentence is just an assertion about the world in what we're going to call a knowledge representation language, some way of representing knowledge inside of our computers. And the way that we're going to spend most of today reasoning about knowledge is through a type of logic known as propositional logic. There are a number of different types of logic, some of which we'll touch on. But propositional logic is based on a logic of propositions, or just statements about the world. And so we begin in propositional logic with a notion of propositional symbols. We will have certain symbols that are oftentimes just letters, something like P or Q or R, where each of those symbols is going to represent some fact or sentence about the world. So P, for example, might represent the fact that it is raining. And so P is going to be a symbol that represents that idea. And Q, for example, might represent Harry visited Hagrid today. Each of these propositional symbols represents some sentence or some fact about the world. But in addition to just having individual facts about the world, we want some way to connect these propositional symbols together in order to reason more complexly about other facts that might exist inside of the world in which we're reasoning. So in order to do that, we'll need to introduce some additional symbols that are known as logical connectives. Now, there are a number of these logical connectives. But five of the most important, and the ones we're going to focus on today, are these five up here, each represented by a logical symbol. Not is represented by this symbol here, and is represented as sort of an upside down V, or is represented by a V shape. Implication, and we'll talk about what that means in just a moment, is represented by an arrow. And biconditional, again, we'll talk about what that means in a moment, is represented by these double arrows. But these five logical connectives are the main ones we're going to be focusing on in terms of thinking about how it is that a computer can reason about facts and draw conclusions based on the facts that it knows. But in order to get there, we need to take a look at each of these logical connectives and build up an understanding for what it is that they actually mean. So let's go ahead and begin with the not symbol, so this not symbol here. And what we're going to show for each of these logical connectives is what we're going to call a truth table, a table that demonstrates what this word not means when we attach it to a propositional symbol or any sentence inside of our logical language. And so the truth table for not is shown right here. If P, some propositional symbol, or some other sentence even, is false, then not P is true. And if P is true, then not P is false. So you can imagine that placing this not symbol in front of some sentence of propositional logic just says the opposite of that. So if, for example, P represented it is raining, then not P would represent the idea that it is not raining. And as you might expect, if P is false, meaning if the sentence, it is raining, is false, well then the sentence not P must be true. The sentence that it is not raining is therefore true. So not, you can imagine, just takes whatever is in P and it inverts it. It turns false into true and true into false, much analogously to what the English word not means, just taking whatever comes after it and inverting it to mean the opposite. Next up, and also very English-like, is this idea of and represented by this upside-down V shape or this point shape. And as opposed to just taking a single argument the way not does, we have P and we have not P. And is going to combine two different sentences in propositional logic together. So I might have one sentence P and another sentence Q, and I want to combine them together to say P and Q. And the general logic for what P and Q means is it means that both of its operands are true. P is true and also Q is true. And so here's what that truth table looks like. This time we have two variables, P and Q. And when we have two variables, each of which can be in two possible states, true or false, that leads to two squared or four possible combinations of truth and falsehood. So we have P is false and Q is false. We have P is false and Q is true. P is true and Q is false. And then P and Q both are true. And those are the only four possibilities for what P and Q could mean. And in each of those situations, this third column here, P and Q, is telling us a little bit about what it actually means for P and Q to be true. And we see that the only case where P and Q is true is in this fourth row here, where P happens to be true, Q also happens to be true. And in all other situations, P and Q is going to evaluate to false. So this, again, is much in line with what our intuition of and might mean. If I say P and Q, I probably mean that I expect both P and Q to be true. Next up, also potentially consistent with what we mean, is this word or, represented by this V shape, sort of an upside down and symbol. And or, as the name might suggest, is true if either of its arguments are true, as long as P is true or Q is true, then P or Q is going to be true. Which means the only time that P or Q is false is if both of its operands are false. If P is false and Q is false, then P or Q is going to be false. But in all other cases, at least one of the operands is true. Maybe they're both true, in which case P or Q is going to evaluate to true. Now, this is mostly consistent with the way that most people might use the word or, in the sense of speaking the word or in normal English, though there is sometimes when we might say or, where we mean P or Q, but not both, where we mean, sort of, it can only be one or the other. It's important to note that this symbol here, this or, means P or Q or both, that those are totally OK. As long as either or both of them are true, then the or is going to evaluate to be true, as well. It's only in the case where all of the operands are false that P or Q ultimately evaluates to false, as well. In logic, there's another symbol known as the exclusive or, which encodes this idea of exclusivity of one or the other, but not both. But we're not going to be focusing on that today. Whenever we talk about or, we're always talking about either or both, in this case, as represented by this truth table here. So that now is not an and an or. And next up is what we might call implication, as denoted by this arrow symbol. So we have P and Q. And this sentence here will generally read as P implies Q. And what P implies Q means is that if P is true, then Q is also true. So I might say something like, if it is raining, then I will be indoors. Meaning, it is raining implies I will be indoors, as the logical sentence that I'm saying there. And the truth table for this can sometimes be a little bit tricky. So obviously, if P is true and Q is true, then P implies Q. That's true. That definitely makes sense. And it should also stand to reason that when P is true and Q is false, then P implies Q is false. Because if I said to you, if it is raining, then I will be out indoors. And it is raining, but I'm not indoors? Well, then it would seem to be that my original statement was not true. P implies Q means that if P is true, then Q also needs to be true. And if it's not, well, then the statement is false. What's also worth noting, though, is what happens when P is false. When P is false, the implication makes no claim at all. If I say something like, if it is raining, then I will be indoors. And it turns out it's not raining. Then in that case, I am not making any statement as to whether or not I will be indoors or not. P implies Q just means that if P is true, Q must be true. But if P is not true, then we make no claim about whether or not Q is true at all. So in either case, if P is false, it doesn't matter what Q is. Whether it's false or true, we're not making any claim about Q whatsoever. We can still evaluate the implication to true. The only way that the implication is ever false is if our premise, P, is true, but the conclusion that we're drawing Q happens to be false. So in that case, we would say P does not imply Q in that case. Finally, the last connective that we'll discuss is this bi-conditional. You can think of a bi-conditional as a condition that goes in both directions. So originally, when I said something like, if it is raining, then I will be indoors. I didn't say what would happen if it wasn't raining. Maybe I'll be indoors, maybe I'll be outdoors. This bi-conditional, you can read as an if and only if. So I can say, I will be indoors if and only if it is raining, meaning if it is raining, then I will be indoors. And if I am indoors, it's reasonable to conclude that it is also raining. So this bi-conditional is only true when P and Q are the same. So if P is true and Q is true, then this bi-conditional is also true. P implies Q, but also the reverse is true. Q also implies P. So if P and Q both happen to be false, we would still say it's true. But in any of these other two situations, this P if and only if Q is going to ultimately evaluate to false. So a lot of trues and falses going on there, but these five basic logical connectives are going to form the core of the language of propositional logic, the language that we're going to use in order to describe ideas, and the language that we're going to use in order to reason about those ideas in order to draw conclusions. So let's now take a look at some of the additional terms that we'll need to know about in order to go about trying to form this language of propositional logic and writing AI that's actually able to understand this sort of logic. The next thing we're going to need is the notion of what is actually true about the world. We have a whole bunch of propositional symbols, P and Q and R and maybe others, but we need some way of knowing what actually is true in the world. Is P true or false? Is Q true or false? So on and so forth. And to do that, we'll introduce the notion of a model. A model just assigns a truth value, where a truth value is either true or false, to every propositional symbol. In other words, it's creating what we might call a possible world. So let me give an example. If, for example, I have two propositional symbols, P is it is raining and Q is it is a Tuesday, a model just takes each of these two symbols and assigns a truth value to them, either true or false. So here's a sample model. In this model, in other words, in this possible world, it is possible that P is true, meaning it is raining, and Q is false, meaning it is not a Tuesday. But there are other possible worlds or other models as well. There is some model where both of these variables are true, some model where both of these variables are false. In fact, if there are n variables that are propositional symbols like this that are either true or false, then the number of possible models is 2 to the n, because each of these possible models, possible variables within my model, could be set to either true or false if I don't know any information about it. So now that I have the symbols and the connectives that I'm going to need in order to construct these parts of knowledge, we need some way to represent that knowledge. And to do so, we're going to allow our AI access to what we'll call a knowledge base. And a knowledge base is really just a set of sentences that our AI knows to be true. Some set of sentences in propositional logic that are things that our AI knows about the world. And so we might tell our AI some information, information about a situation that it finds itself in, or a situation about a problem that it happens to be trying to solve. And we would give that information to the AI that the AI would store inside of its knowledge base. And what happens next is the AI would like to use that information in the knowledge base to be able to draw conclusions about the rest of the world. And what do those conclusions look like? Well, to understand those conclusions, we'll need to introduce one more idea, one more symbol. And that is the notion of entailment. So this sentence here, with this double turnstile in these Greek letters, this is the Greek letter alpha and the Greek letter beta. And we read this as alpha entails beta. And alpha and beta here are just sentences in propositional logic. And what this means is that alpha entails beta means that in every model, in other words, in every possible world in which sentence alpha is true, then sentence beta is also true. So if something entails something else, if alpha entails beta, it means that if I know alpha to be true, then beta must therefore also be true. So if my alpha is something like I know that it is a Tuesday in January, then a reasonable beta might be something like I know that it is January. Because in all worlds where it is a Tuesday in January, I know for sure that it must be January, just by definition. This first statement or sentence about the world entails the second statement. And we can reasonably use deduction based on that first sentence to figure out that the second sentence is, in fact, true as well. And ultimately, it's this idea of entailment that we're going to try and encode into our computer. We want our AI agent to be able to figure out what the possible entailments are. We want our AI to be able to take these three sentences, sentences like, if it didn't rain, Harry visited Hagrid. That Harry visited Hagrid or Dumbledore, but not both. And that Harry visited Dumbledore. And just using that information, we'd like our AI to be able to infer or figure out that using these three sentences inside of a knowledge base, we can draw some conclusions. In particular, we can draw the conclusions here that, one, Harry did not visit Hagrid today. And we can draw the entailment, too, that it did, in fact, rain today. And this process is known as inference. And that's what we're going to be focusing on today, this process of deriving new sentences from old ones, that I give you these three sentences, you put them in the knowledge base in, say, the AI. And the AI is able to use some sort of inference algorithm to figure out that these two sentences must also be true. And that is how we define inference. So let's take a look at an inference example to see how we might actually go about inferring things in a human sense before we take a more algorithmic approach to see how we could encode this idea of inference in AI. And we'll see there are a number of ways that we can actually achieve this. So again, we'll deal with a couple of propositional symbols. We'll deal with P, Q, and R. P is it is a Tuesday. Q is it is raining. And R is Harry will go for a run, three propositional symbols that we are just defining to mean this. We're not saying anything yet about whether they're true or false. We're just defining what they are. Now, we'll give ourselves or an AI access to a knowledge base, abbreviated to KB, the knowledge that we know about the world. We know this statement. All right. So let's try to parse it. The parentheses here are just used for precedent, so we can see what associates with what. But you would read this as P and not Q implies R. All right. So what does that mean? Let's put it piece by piece. P is it is a Tuesday. Q is it is raining, so not Q is it is not raining, and implies R is Harry will go for a run. So the way to read this entire sentence in human natural language at least is if it is a Tuesday and it is not raining, then Harry will go for a run. So if it is a Tuesday and it is not raining, then Harry will go for a run. And that is now inside of our knowledge base. And let's now imagine that our knowledge base has two other pieces of information as well. It has information that P is true, that it is a Tuesday. And we also have the information not Q, that it is not raining, that this sentence Q, it is raining, happens to be false. And those are the three sentences that we have access to. P and not Q implies R, P and not Q. Using that information, we should be able to draw some inferences. P and not Q is only true if both P and not Q are true. All right, we know that P is true and we know that not Q is true. So we know that this whole expression is true. And the definition of implication is if this whole thing on the left is true, then this thing on the right must also be true. So if we know that P and not Q is true, then R must be true as well. So the inference we should be able to draw from all of this is that R is true and we know that Harry will go for a run by taking this knowledge inside of our knowledge base and being able to reason based on that idea. And so this ultimately is the beginning of what we might consider to be some sort of inference algorithm, some process that we can use to try and figure out whether or not we can draw some conclusion. And ultimately, what these inference algorithms are going to answer is the central question about entailment. Given some query about the world, something we're wondering about the world, and we'll call that query alpha, the question we want to ask using these inference algorithms is does KB, our knowledge base, entail alpha? In other words, using only the information we know inside of our knowledge base, the knowledge that we have access to, can we conclude that this sentence alpha is true? And that's ultimately what we would like to do. So how can we do that? How can we go about writing an algorithm that can look at this knowledge base and figure out whether or not this query alpha is actually true? Well, it turns out there are a couple of different algorithms for doing so. And one of the simplest, perhaps, is known as model checking. Now, remember that a model is just some assignment of all of the propositional symbols inside of our language to a truth value, true or false. And you can think of a model as a possible world, that there are many possible worlds where different things might be true or false, and we can enumerate all of them. And the model checking algorithm does exactly that. So what does our model checking algorithm do? Well, if we wanted to determine if our knowledge base entails some query alpha, then we are going to enumerate all possible models. In other words, consider all possible values of true and false for our variables, all possible states in which our world can be in. And if in every model where our knowledge base is true, alpha is also true, then we know that the knowledge base entails alpha. So let's take a closer look at that sentence and try and figure out what it actually means. If we know that in every model, in other words, in every possible world, no matter what assignment of true and false to variables you give, if we know that whenever our knowledge is true, what we know to be true is true, that this query alpha is also true, well, then it stands to reason that as long as our knowledge base is true, then alpha must also be true. And so this is going to form the foundation of our model checking algorithm. We're going to enumerate all of the possible worlds and ask ourselves whenever the knowledge base is true, is alpha true? And if that's the case, then we know alpha to be true. And otherwise, there is no entailment. Our knowledge base does not entail alpha. All right. So this is a little bit abstract, but let's take a look at an example to try and put real propositional symbols to this idea. So again, we'll work with the same example. P is it is a Tuesday, Q is it is raining, R as Harry will go for a run. Our knowledge base contains these pieces of information. P and not Q implies R. We also know P. It is a Tuesday and not Q. It is not raining. And our query, our alpha in this case, the thing we want to ask is R. We want to know, is it guaranteed? Is it entailed that Harry will go for a run? So the first step is to enumerate all of the possible models. We have three propositional symbols here, P, Q, and R, which means we have 2 to the third power, or eight possible models. All false, false, false true, false true, false, false true, true, et cetera. Eight possible ways you could assign true and false to all of these models. And we might ask in each one of them, is the knowledge base true? Here are the set of things that we know. In which of these worlds could this knowledge base possibly apply to? In which world is this knowledge base true? Well, in the knowledge base, for example, we know P. We know it is a Tuesday, which means we know that these four first four rows where P is false, none of those are going to be true or are going to work for this particular knowledge base. Our knowledge base is not true in those worlds. Likewise, we also know not Q. We know that it is not raining. So any of these models where Q is true, like these two and these two here, those aren't going to work either because we know that Q is not true. And finally, we also know that P and not Q implies R, which means that when P is true or P is true here and Q is false, Q is false in these two, then R must be true. And if ever P is true, Q is false, but R is also false, well, that doesn't satisfy this implication here. That implication does not hold true under those situations. So we could say that for our knowledge base, we can conclude under which of these possible worlds is our knowledge base true and under which of the possible worlds is our knowledge base false. And it turns out there is only one possible world where our knowledge base is actually true. In some cases, there might be multiple possible worlds where the knowledge base is true. But in this case, it just so happens that there's only one, one possible world where we can definitively say something about our knowledge base. And in this case, we would look at the query. The query of R is R true, R is true, and so as a result, we can draw that conclusion. And so this is this idea of model check-in. Enumerate all the possible models and look in those possible models to see whether or not, if our knowledge base is true, is the query in question true as well. So let's now take a look at how we might actually go about writing this in a programming language like Python. Take a look at some actual code that would encode this notion of propositional symbols and logic and these connectives like and and or and not and implication and so forth and see what that code might actually look like. So I've written in advance a logic library that's more detailed than we need to worry about entirely today. But the important thing is that we have one class for every type of logical symbol or connective that we might have. So we just have one class for logical symbols, for example, where every symbol is going to represent and store some name for that particular symbol. And we also have a class for not that takes an operand. So we might say not one symbol to say something is not true or some other sentence is not true. We have one for and, one for or, so on and so forth. And I'll just demonstrate how this works. And you can take a look at the actual logic.py later on. But I'll go ahead and call this file harry.py. We're going to store information about this world of Harry Potter, for example. So I'll go ahead and import from my logic module. I'll import everything. And in this library, in order to create a symbol, you use capital S symbol. And I'll create a symbol for rain, to mean it is raining, for example. And I'll create a symbol for Hagrid, to mean Harry visited Hagrid, is what this symbol is going to mean. So this symbol means it is raining. This symbol means Harry visited Hagrid. And I'll add another symbol called Dumbledore for Harry visited Dumbledore. Now, I'd like to save these symbols so that I can use them later as I do some logical analysis. So I'll go ahead and save each one of them inside of a variable. So like rain, Hagrid, and Dumbledore, so you could call the variables anything. And now that I have these logical symbols, I can use logical connectives to combine them together. So for example, if I have a sentence like and rain and Hagrid, for example, which is not necessarily true, but just for demonstration, I can now try and print out sentence.formula, which is a function I wrote that takes a sentence in propositional logic and just prints it out so that we, the programmers, can now see this in order to get an understanding for how it actually works. So if I run python harry.py, what we'll see is this sentence in propositional logic, rain and Hagrid. This is the logical representation of what we have here in our Python program of saying and whose arguments are rain and Hagrid. So we're saying rain and Hagrid by encoding that idea. And this is quite common in Python object-oriented programming, where you have a number of different classes, and you pass arguments into them in order to create a new and object, for example, in order to represent this idea. But now what I'd like to do is somehow encode the knowledge that I have about the world in order to solve that problem from the beginning of class, where we talked about trying to figure out who Harry visited and trying to figure out if it's raining or if it's not raining. And so what knowledge do I have? I'll go ahead and create a new variable called knowledge. And what do I know? Well, I know the very first sentence that we talked about was the idea that if it is not raining, then Harry will visit Hagrid. So all right, how do I encode the idea that it is not raining? Well, I can use not and then the rain symbol. So here's me saying that it is not raining. And now the implication is that if it is not raining, then Harry visited Hagrid. So I'll wrap this inside of an implication to say, if it is not raining, this first argument to the implication will then Harry visited Hagrid. So I'm saying implication, the premise is that it's not raining. And if it is not raining, then Harry visited Hagrid. And I can print out knowledge.formula to see the logical formula equivalent of that same idea. So I run Python of harry.py. And this is the logical formula that we see as a result, which is a text-based version of what we were looking at before, that if it is not raining, then that implies that Harry visited Hagrid. But there was additional information that we had access to as well. In this case, we had access to the fact that Harry visited either Hagrid or Dumbledore. So how do I encode that? Well, this means that in my knowledge, I've really got multiple pieces of knowledge going on. I know one thing and another thing and another thing. So I'll go ahead and wrap all of my knowledge inside of an and. And I'll move things on to new lines just for good measure. But I know multiple things. So I'm saying knowledge is an and of multiple different sentences. I know multiple different sentences to be true. One such sentence that I know to be true is this implication, that if it is not raining, then Harry visited Hagrid. Another such sentence that I know to be true is or Hagrid Dumbledore. In other words, Hagrid or Dumbledore is true, because I know that Harry visited Hagrid or Dumbledore. But I know more than that, actually. That initial sentence from before said that Harry visited Hagrid or Dumbledore, but not both. So now I want a sentence that will encode the idea that Harry didn't visit both Hagrid and Dumbledore. Well, the notion of Harry visiting Hagrid and Dumbledore would be represented like this, and of Hagrid and Dumbledore. And if that is not true, if I want to say not that, then I'll just wrap this whole thing inside of a not. So now these three lines, line 8 says that if it is not raining, then Harry visited Hagrid. Line 9 says Harry visited Hagrid or Dumbledore. And line 10 says Harry didn't visit both Hagrid and Dumbledore, that it is not true that both the Hagrid symbol and the Dumbledore symbol are true. Only one of them can be true. And finally, the last piece of information that I knew was the fact that Harry visited Dumbledore. So these now are the pieces of knowledge that I know, one sentence and another sentence and another and another. And I can print out what I know just to see it a little bit more visually. And here now is a logical representation of the information that my computer is now internally representing using these various different Python objects. And again, take a look at logic.py if you want to take a look at how exactly it's implementing this, but no need to worry too much about all of the details there. We're here saying that if it is not raining, then Harry visited Hagrid. We're saying that Hagrid or Dumbledore is true. And we're saying it is not the case that Hagrid and Dumbledore is true, that they're not both true. And we also know that Dumbledore is true. So this long logical sentence represents our knowledge base. It is the thing that we know. And now what we'd like to do is we'd like to use model checking to ask a query, to ask a question like, based on this information, do I know whether or not it's raining? And we as humans were able to logic our way through it and figure out that, all right, based on these sentences, we can conclude this and that to figure out that, yes, it must have been raining. But now we'd like for the computer to do that as well. So let's take a look at the model checking algorithm that is going to follow that same pattern that we drew out in pseudocode a moment ago. So I've defined a function here in logic.py that you can take a look at called model check. Model check takes two arguments, the knowledge that I already know, and the query. And the idea is, in order to do model checking, I need to enumerate all of the possible models. And for each of the possible models, I need to ask myself, is the knowledge base true? And is the query true? So the first thing I need to do is somehow enumerate all of the possible models, meaning for all possible symbols that exist, I need to assign true and false to each one of them and see whether or not it's still true. And so here is the way we're going to do that. We're going to start. So I've defined another helper function internally that we'll get to in just a moment. But this function starts by getting all of the symbols in both the knowledge and the query, by figuring out what symbols am I dealing with. In this case, the symbols I'm dealing with are rain and Hagrid and Dumbledore, but there might be other symbols depending on the problem. And we'll take a look soon at some examples of situations where ultimately we're going to need some additional symbols in order to represent the problem. And then we're going to run this check all function, which is a helper function that's basically going to recursively call itself checking every possible configuration of propositional symbols. So we start out by looking at this check all function. And what do we do? So if not symbols means if we finish assigning all of the symbols. We've assigned every symbol a value. So far we haven't done that, but if we ever do, then we check. In this model, is the knowledge true? That's what this line is saying. If we evaluate the knowledge propositional logic formula using the model's assignment of truth values, is the knowledge true? If the knowledge is true, then we should return true only if the query is true. Because if the knowledge is true, we want the query to be true as well in order for there to be entailment. Otherwise, we don't know that there otherwise there won't be an entailment if there's ever a situation where what we know in our knowledge is true, but the query, the thing we're asking, happens to be false. So this line here is checking that same idea that in all worlds where the knowledge is true, the query must also be true. Otherwise, we can just return true because if the knowledge isn't true, then we don't care. This is equivalent to when we were enumerating this table from a moment ago. In all situations where the knowledge base wasn't true, all of these seven rows here, we didn't care whether or not our query was true or not. We only care to check whether the query is true when the knowledge base is actually true, which was just this green highlighted row right there. So that logic is encoded using that statement there. And otherwise, if we haven't assigned symbols yet, which we haven't seen anything yet, then the first thing we do is pop one of the symbols. I make a copy of the symbols first just to save an existing copy. But I pop one symbol off of the remaining symbols so that I just pick one symbol at random. And I create one copy of the model where that symbol is true. And I create a second copy of the model where that symbol is false. So I now have two copies of the model, one where the symbol is true and one where the symbol is false. And I need to make sure that this entailment holds in both of those models. So I recursively check all on the model where the statement is true and check all on the model where the statement is false. So again, you can take a look at that function to try to get a sense for how exactly this logic is working. But in effect, what it's doing is recursively calling this check all function again and again and again. And on every level of the recursion, we're saying let's pick a new symbol that we haven't yet assigned, assign it to true and assign it to false, and then check to make sure that the entailment holds in both cases. Because ultimately, I need to check every possible world. I need to take every combination of symbols and try every combination of true and false in order to figure out whether the entailment relation actually holds. So that function we've written for you. But in order to use that function inside of harry.py, what I'll write is something like this. I would like to model check based on the knowledge. And then I provide as a second argument what the query is, what the thing I want to ask is. And what I want to ask in this case is, is it raining? So model check again takes two arguments. The first argument is the information that I know, this knowledge, which in this case is this information that was given to me at the beginning. And the second argument, rain, is encoding the idea of the query. What am I asking? I would like to ask, based on this knowledge, do I know for sure that it is raining? And I can try and print out the result of that. And when I run this program, I see that the answer is true. That based on this information, I can conclusively say that it is raining, because using this model checking algorithm, we were able to check that in every world where this knowledge is true, it is raining. In other words, there is no world where this knowledge is true, and it is not raining. So you can conclude that it is, in fact, raining. And this sort of logic can be applied to a number of different types of problems, that if confronted with a problem where some sort of logical deduction can be used in order to try to solve it, you might try thinking about what propositional symbols you might need in order to represent that information, and what statements and propositional logic you might use in order to encode that information which you know. And this process of trying to take a problem and figure out what propositional symbols to use in order to encode that idea, or how to represent it logically, is known as knowledge engineering. That software engineers and AI engineers will take a problem and try and figure out how to distill it down into knowledge that is representable by a computer. And if we can take any general purpose problem, some problem that we find in the human world, and turn it into a problem that computers know how to solve as by using any number of different variables, well, then we can take a computer that is able to do something like model checking or some other inference algorithm and actually figure out how to solve that problem. So now we'll take a look at two or three examples of knowledge engineering and practice, of taking some problem and figuring out how we can apply logical symbols and use logical formulas to be able to encode that idea. And we'll start with a very popular board game in the US and the UK known as Clue. Now, in the game of Clue, there's a number of different factors that are going on. But the basic premise of the game, if you've never played it before, is that there are a number of different people. For now, we'll just use three, Colonel Mustard, Professor Plumb, and Miss Scarlet. There are a number of different rooms, like a ballroom, a kitchen, and a library. And there are a number of different weapons, a knife, a revolver, and a wrench. And three of these, one person, one room, and one weapon, is the solution to the mystery, the murderer and what room they were in and what weapon they happened to use. And what happens at the beginning of the game is that all these cards are randomly shuffled together. And three of them, one person, one room, and one weapon, are placed into a sealed envelope that we don't know. And we would like to figure out, using some sort of logical process, what's inside the envelope, which person, which room, and which weapon. And we do so by looking at some, but not all, of these cards here, by looking at these cards to try and figure out what might be going on. And so this is a very popular game. But let's now try and formalize it and see if we could train a computer to be able to play this game by reasoning through it logically. So in order to do this, we'll begin by thinking about what propositional symbols we're ultimately going to need. Remember, again, that propositional symbols are just some symbol, some variable, that can be either true or false in the world. And so in this case, the propositional symbols are really just going to correspond to each of the possible things that could be inside the envelope. Mustard is a propositional symbol that, in this case, will just be true if Colonel Mustard is inside the envelope, if he is the murderer, and false otherwise. And likewise for Plum, for Professor Plum, and Scarlet, for Miss Scarlet. And likewise for each of the rooms and for each of the weapons. We have one propositional symbol for each of these ideas. Then using those propositional symbols, we can begin to create logical sentences, create knowledge that we know about the world. So for example, we know that someone is the murderer, that one of the three people is, in fact, the murderer. And how would we encode that? Well, we don't know for sure who the murderer is. But we know it is one person or the second person or the third person. So I could say something like this. Mustard or Plum or Scarlet. And this piece of knowledge encodes that one of these three people is the murderer. We don't know which, but one of these three things must be true. What other information do we know? Well, we know that, for example, one of the rooms must have been the room in the envelope. The crime was committed either in the ballroom or the kitchen or the library. Again, right now, we don't know which. But this is knowledge we know at the outset, knowledge that one of these three must be inside the envelope. And likewise, we can say the same thing about the weapon, that it was either the knife or the revolver or the wrench, that one of those weapons must have been the weapon of choice and therefore the weapon in the envelope. And then as the game progresses, the gameplay works by people get various different cards. And using those cards, you can deduce information. That if someone gives you a card, for example, I have the Professor Plum card in my hand, then I know the Professor Plum card can't be inside the envelope. I know that Professor Plum is not the criminal, so I know a piece of information like not Plum, for example. I know that Professor Plum has to be false. This propositional symbol is not true. And sometimes I might not know for sure that a particular card is not in the middle, but sometimes someone will make a guess and I'll know that one of three possibilities is not true. Someone will guess Colonel Mustard in the library with the revolver or something to that effect. And in that case, a card might be revealed that I don't see. But if it is a card and it is either Colonel Mustard or the revolver or the library, then I know that at least one of them can't be in the middle. So I know something like it is either not Mustard or it is not the library or it is not the revolver. Now maybe multiple of these are not true, but I know that at least one of Mustard, Library, and Revolver must, in fact, be false. And so this now is a propositional logic representation of this game of Clue, a way of encoding the knowledge that we know inside this game using propositional logic that a computer algorithm, something like model checking that we saw a moment ago, can actually look at and understand. So let's now take a look at some code to see how this algorithm might actually work in practice. All right, so I'm now going to open up a file called Clue.py, which I've started already. And what we'll see here is I've defined a couple of things. To find some symbols initially, notice I have a symbol for Colonel Mustard, a symbol for Professor Plum, a symbol for Miss Scarlett, all of which I've put inside of this list of characters. I have a symbol for Ballroom and Kitchen and Library inside of a list of rooms. And then I have symbols for Knife and Revolver and Wrench. These are my weapons. And so all of these characters and rooms and weapons altogether, those are my symbols. And now I also have this check knowledge function. And what the check knowledge function does is it takes my knowledge and it's going to try and draw conclusions about what I know. So for example, we'll loop over all of the possible symbols and we'll check, do I know that that symbol is true? And a symbol is going to be something like Professor Plum or the Knife or the Library. And if I know that it is true, in other words, I know that it must be the card in the envelope, then I'm going to print out using a function called cprint, which prints things in color. I'm going to print out the word yes, and I'm going to print that in green, just to make it very clear to us. If we're not sure that the symbol is true, maybe I can check to see if I'm sure that the symbol is not true. Like if I know for sure that it is not Professor Plum, for example. And I do that by running model check again, this time checking if my knowledge is not the symbol, if I know for sure that the symbol is not true. And if I don't know for sure that the symbol is not true, because I say if not model check, meaning I'm not sure that the symbol is false, well, then I'll go ahead and print out maybe next to the symbol. Because maybe the symbol is true, maybe it's not, I don't actually know. So what knowledge do I actually have? Well, let's try and represent my knowledge now. So my knowledge is, I know a couple of things, so I'll put them in an and. And I know that one of the three people must be the criminal. So I know or mustard, plum, scarlet. This is my way of encoding that it is either Colonel Mustard or Professor Plum or Miss Scarlet. I know that it must have happened in one of the rooms. So I know or ballroom, kitchen, library, for example. And I know that one of the weapons must have been used as well. So I know or knife, revolver, wrench. So that might be my initial knowledge, that I know that it must have been one of the people, I know it must have been in one of the rooms, and I know that it must have been one of the weapons. And I can see what that knowledge looks like as a formula by printing out knowledge.formula. So I'll run python clue.py. And here now is the information that I know in logical format. I know that it is Colonel Mustard or Professor Plum or Miss Scarlet. And I know that it is the ballroom, the kitchen, or the library. And I know that it is the knife, the revolver, or the wrench. But I don't know much more than that. I can't really draw any firm conclusions. And in fact, we can see that if I try and do, let me go ahead and run my knowledge check function on my knowledge. Knowledge check is this function that I, or check knowledge rather, is this function that I just wrote that looks over all of the symbols and tries to see what conclusions I can actually draw about any of the symbols. So I'll go ahead and run clue.py and see what it is that I know. And it seems that I don't really know anything for sure. I have all three people are maybes, all three of the rooms are maybes, all three of the weapons are maybes. I don't really know anything for certain just yet. But now let me try and add some additional information and see if additional information, additional knowledge, can help us to logically reason our way through this process. And we are just going to provide the information. Our AI is going to take care of doing the inference and figuring out what conclusions it's able to draw. So I start with some cards. And those cards tell me something. So if I have the kernel mustard card, for example, I know that the mustard symbol must be false. In other words, mustard is not the one in the envelope, is not the criminal. So I can say, knowledge supports something called, every and in this library supports dot add, which is a way of adding knowledge or adding an additional logical sentence to an and clause. So I can say, knowledge dot add, not mustard. I happen to know, because I have the mustard card, that kernel mustard is not the suspect. And maybe I have a couple of other cards too. Maybe I also have a card for the kitchen. So I know it's not the kitchen. And maybe I have another card that says that it is not the revolver. So I have three cards, kernel mustard, the kitchen, and the revolver. And I encode that into my AI this way by saying, it's not kernel mustard, it's not the kitchen, and it's not the revolver. And I know those to be true. So now, when I rerun clue.py, we'll see that I've been able to eliminate some possibilities. Before, I wasn't sure if it was the knife or the revolver or the wrench. If a knife was maybe, a revolver was maybe, wrench is maybe. Now I'm down to just the knife and the wrench. Between those two, I don't know which one it is. They're both maybes. But I've been able to eliminate the revolver, which is one that I know to be false, because I have the revolver card. And so additional information might be acquired over the course of this game. And we would represent that just by adding knowledge to our knowledge set or knowledge base that we've been building here. So if, for example, we additionally got the information that someone made a guess, someone guessed like Miss Scarlet in the library with the wrench. And we know that a card was revealed, which means that one of those three cards, either Miss Scarlet or the library or the wrench, one of those at minimum must not be inside of the envelope. So I could add some knowledge, say knowledge.add. And I'm going to add an or clause, because I don't know for sure which one it's not, but I know one of them is not in the envelope. So it's either not Scarlet, or it's not the library, and or supports multiple arguments. I can say it's also or not the wrench. So at least one of those needs a Scarlet library and wrench. At least one of those needs to be false. I don't know which, though. Maybe it's multiple. Maybe it's just one, but at least one I know needs to hold. And so now if I rerun clue.py, I don't actually have any additional information just yet. Nothing I can say conclusively. I still know that maybe it's Professor Plum, maybe it's Miss Scarlet. I haven't eliminated any options. But let's imagine that I get some more information, that someone shows me the Professor Plum card, for example. So I say, all right, let's go back here, knowledge.add, not Plum. So I have the Professor Plum card. I know the Professor Plum is not in the middle. I rerun clue.py. And right now, I'm able to draw some conclusions. Now I've been able to eliminate Professor Plum, and the only person it could left remaining be is Miss Scarlet. So I know, yes, Miss Scarlet, this variable must be true. And I've been able to infer that based on the information I already had. Now between the ballroom and the library and the knife and the wrench, for those two, I'm still not sure. So let's add one more piece of information. Let's say that I know that it's not the ballroom. Someone has shown me the ballroom card, so I know it's not the ballroom. Which means at this point, I should be able to conclude that it's the library. Let's see. I'll say knowledge.add, not the ballroom. And we'll go ahead and run that. And it turns out that after all of this, not only can I conclude that I know that it's the library, but I also know that the weapon was the knife. And that might have been an inference that was a little bit trickier, something I wouldn't have realized immediately, but the AI, via this model checking algorithm, is able to draw that conclusion, that we know for sure that it must be Miss Scarlet in the library with the knife. And how did we know that? Well, we know it from this or clause up here, that we know that it's either not Scarlet, or it's not the library, or it's not the wrench. And given that we know that it is Miss Scarlet, and we know that it is the library, then the only remaining option for the weapon is that it is not the wrench, which means that it must be the knife. So we as humans now can go back and reason through that, even though it might not have been immediately clear. And that's one of the advantages of using an AI or some sort of algorithm in order to do this, is that the computer can exhaust all of these possibilities and try and figure out what the solution actually should be. And so for that reason, it's often helpful to be able to represent knowledge in this way. Knowledge engineering, some situation where we can use a computer to be able to represent knowledge and draw conclusions based on that knowledge. And any time we can translate something into propositional logic symbols like this, this type of approach can be useful. So you might be familiar with logic puzzles, where you have to puzzle your way through trying to figure something out. This is what a classic logic puzzle might look like. Something like Gilderoy, Minerva, Pomona, and Horace each belong to a different one of the four houses, Gryffindor, Hufflepuff, Ravenclaw, and Slytherin. And then we have some information. The Gilderoy belongs to Gryffindor or Ravenclaw, Pomona does not belong in Slytherin, and Minerva does belong to Gryffindor. So we have a couple pieces of information. And using that information, we need to be able to draw some conclusions about which person should be assigned to which house. And again, we can use the exact same idea to try and implement this notion. So we need some propositional symbols. And in this case, the propositional symbols are going to get a little more complex, although we'll see ways to make this a little bit cleaner later on. But we'll need 16 propositional symbols, one for each person and house. So we need to say, remember, every propositional symbol is either true or false. So Gilderoy Gryffindor is either true or false. Either he's in Gryffindor or he is not. Likewise, Gilderoy Hufflepuff also true or false. Either it is true or it's false. And that's true for every combination of person and house that we could come up with. We have some sort of propositional symbol for each one of those. Using this type of knowledge, we can then begin to think about what types of logical sentences we can say about the puzzle. That if we know what will before even think about the information we were given, we can think about the premise of the problem, that every person is assigned to a different house. So what does that tell us? Well, it tells us sentences like this. It tells us like Pomona Slytherin implies not Pomona Hufflepuff. Something like if Pomona is in Slytherin, then we know that Pomona is not in Hufflepuff. And we know this for all four people and for all combinations of houses, that no matter what person you pick, if they're in one house, then they're not in some other house. So I'll probably have a whole bunch of knowledge statements that are of this form, that if we know Pomona is in Slytherin, then we know Pomona is not in Hufflepuff. We were also given the information that each person is in a different house. So I also have pieces of knowledge that look something like this. Minerva Ravenclaw implies not Gilderoy Ravenclaw. If they're all in different houses, then if Minerva is in Ravenclaw, then we know the Gilderoy is not in Ravenclaw as well. And I have a whole bunch of similar sentences like this that are expressing that idea for other people and other houses as well. And so in addition to sentences of these form, I also have the knowledge that was given to me. Information like Gilderoy was in Gryffindor or in Ravenclaw that would be represented like this, Gilderoy Gryffindor or Gilderoy Ravenclaw. And then using these sorts of sentences, I can begin to draw some conclusions about the world. So let's see an example of this. We'll go ahead and actually try and implement this logic puzzle to see if we can figure out what the answer is. I'll go ahead and open up puzzle.py, where I've already started to implement this sort of idea. I've defined a list of people and a list of houses. And I've so far created one symbol for every person and for every house. That's what this double four loop is doing, looping over all people, looping over all houses, creating a new symbol for each of them. And then I've added some information. I know that every person belongs to a house, so I've added the information for every person that person Gryffindor or person Hufflepuff or person Ravenclaw or person Slytherin, that one of those four things must be true. Every person belongs to a house. What other information do I know? I also know that only one house per person, so no person belongs to multiple houses. So how does this work? Well, this is going to be true for all people. So I'll loop over every person. And then I need to loop over all different pairs of houses. The idea is I want to encode the idea that if Minerva is in Gryffindor, then Minerva can't be in Ravenclaw. So I'll loop over all houses, each one. And I'll loop over all houses again, h2. And as long as they're different, h1 not equal to h2, then I'll add to my knowledge base this piece of information. That implication, in other words, an if then, if the person is in h1, then I know that they are not in house h2. So these lines here are encoding the notion that for every person, if they belong to house one, then they are not in house two. And the other piece of logic we need to encode is the idea that every house can only have one person. In other words, if Pomona is in Hufflepuff, then nobody else is allowed to be in Hufflepuff either. And that's the same logic, but sort of backwards. I loop over all of the houses and loop over all different pairs of people. So I loop over people once, loop over people again, and only do this when the people are different, p1 not equal to p2. And I add the knowledge that if, as given by the implication, if person one belongs to the house, then it is not the case that person two belongs to the same house. So here I'm just encoding the knowledge that represents the problem's constraints. I know that everyone's in a different house. I know that any person can only belong to one house. And I can now take my knowledge and try and print out the information that I happen to know. So I'll go ahead and print out knowledge.formula, just to see this in action, and I'll go ahead and skip this for now. But we'll come back to this in a second. Let's print out the knowledge that I know by running Python puzzle.py. It's a lot of information, a lot that I have to scroll through, because there are 16 different variables all going on. But the basic idea, if we scroll up to the very top, is I see my initial information. Gilderoy is either in Gryffindor, or Gilderoy is in Hufflepuff, or Gilderoy is in Ravenclaw, or Gilderoy is in Slytherin, and then way more information as well. So this is quite messy, more than we really want to be looking at. And soon, too, we'll see ways of representing this a little bit more nicely using logic. But for now, we can just say these are the variables that we're dealing with. And now we'd like to add some information. So the information we're going to add is Gilderoy is in Gryffindor, or he is in Ravenclaw. So that knowledge was given to us. So I'll go ahead and say knowledge.add. And I know that either or Gilderoy Gryffindor or Gilderoy Ravenclaw. One of those two things must be true. I also know that Pomona was not in Slytherin, so I can say knowledge.add not this symbol, not the Pomona-Slytherin symbol. And then I can add the knowledge that Minerva is in Gryffindor by adding the symbol Minerva Gryffindor. So those are the pieces of knowledge that I know. And this loop here at the bottom just loops over all of my symbols, checks to see if the knowledge entails that symbol by calling this model check function again. And if it does, if we know the symbol is true, we print out the symbol. So now I can run Python, puzzle.py, and Python is going to solve this puzzle for me. We're able to conclude that Gilderoy belongs to Ravenclaw, Pomona belongs to Hufflepuff, Minerva to Gryffindor, and Horace to Slytherin just by encoding this knowledge inside the computer, although it was quite tedious to do in this case. And as a result, we were able to get the conclusion from that as well. And you can imagine this being applied to many sorts of different deductive situations. So not only these situations where we're trying to deal with Harry Potter characters in this puzzle, but if you've ever played games like Mastermind, where you're trying to figure out which order different colors go in and trying to make predictions about it, I could tell you, for example, let's play a simplified version of Mastermind where there are four colors, red, blue, green, and yellow, and they're in some order, but I'm not telling you what order. You just have to make a guess, and I'll tell you of red, blue, green, and yellow how many of the four you got in the right position. So a simplified version of this game, you might make a guess like red, blue, green, yellow, and I would tell you something like two of those four are in the correct position, but the other two are not. And then you could reasonably make a guess and say, all right, look at this, blue, red, green, yellow. Try switching two of them around, and this time maybe I tell you, you know what, none of those are in the correct position. And the question then is, all right, what is the correct order of these four colors? And we as humans could begin to reason this through. All right, well, if none of these were correct, but two of these were correct, well, it must have been because I switched the red and the blue, which means red and blue here must be correct, which means green and yellow are probably not correct. You can begin to do this sort of deductive reasoning. And we can also equivalently try and take this and encode it inside of our computer as well. And it's going to be very similar to the logic puzzle that we just did a moment ago. So I won't spend too much time on this code because it is fairly similar. But again, we have a whole bunch of colors and four different positions in which those colors can be. And then we have some additional knowledge. And I encode all of that knowledge. And you can take a look at this code on your own time. But I just want to demonstrate that when we run this code, run python mastermind.py and run and see what we get, we ultimately are able to compute red 0 in the 0 position, blue in the 1 position, yellow in the 2 position, and green in the 3 position as the ordering of those symbols. Now, ultimately, what you might have noticed is this process was taking quite a long time. And in fact, model checking is not a particularly efficient algorithm, right? What I need to do in order to model check is take all of my possible different variables and enumerate all of the possibilities that they could be in. If I have n variables, I have 2 to the n possible worlds that I need to be looking through in order to perform this model checking algorithm. And this is probably not tractable, especially as we start to get to much larger and larger sets of data where you have many, many more variables that are at play. Right here, we only have a relatively small number of variables. So this sort of approach can actually work. But as the number of variables increases, model checking becomes less and less good of a way of trying to solve these sorts of problems. So while it might have been OK for something like Mastermind to conclude that this is indeed the correct sequence where all four are in the correct position, what we'd like to do is come up with some better ways to be able to make inferences rather than just enumerate all of the possibilities. And to do so, what we'll transition to next is the idea of inference rules, some sort of rules that we can apply to take knowledge that already exists and translate it into new forms of knowledge. And the general way we'll structure an inference rule is by having a horizontal line here. Anything above the line is going to represent a premise, something that we know to be true. And then anything below the line will be the conclusion that we can arrive at after we apply the logic from the inference rule that we're going to demonstrate. So we'll do some of these inference rules by demonstrating them in English first, but then translating them into the world of propositional logic so you can see what those inference rules actually look like. So for example, let's imagine that I have access to two pieces of information. I know, for example, that if it is raining, then Harry is inside, for example. And let's say I also know it is raining. Then most of us could reasonably then look at this information and conclude that, all right, Harry must be inside. This inference rule is known as modus ponens, and it's phrased more formally in logic as this. If we know that alpha implies beta, in other words, if alpha, then beta, and we also know that alpha is true, then we should be able to conclude that beta is also true. We can apply this inference rule to take these two pieces of information and generate this new piece of information. Notice that this is a totally different approach from the model checking approach, where the approach was look at all of the possible worlds and see what's true in each of these worlds. Here, we're not dealing with any specific world. We're just dealing with the knowledge that we know and what conclusions we can arrive at based on that knowledge. That I know that A implies B, and I know A, and the conclusion is B. And this should seem like a relatively obvious rule. But of course, if alpha, then beta, and we know alpha, then we should be able to conclude that beta is also true. And that's going to be true for many, but maybe even all of the inference rules that we'll take a look at. You should be able to look at them and say, yeah, of course that's going to be true. But it's putting these all together, figuring out the right combination of inference rules that can be applied that ultimately is going to allow us to generate interesting knowledge inside of our AI. So that's modus ponensis application of implication, that if we know alpha and we know that alpha implies beta, then we can conclude beta. Let's take a look at another example. Fairly straightforward, something like Harry is friends with Ron and Hermione. Based on that information, we can reasonably conclude Harry is friends with Hermione. That must also be true. And this inference rule is known as and elimination. And what and elimination says is that if we have a situation where alpha and beta are both true, I have information alpha and beta, well then, just alpha is true. Or likewise, just beta is true. That if I know that both parts are true, then one of those parts must also be true. Again, something obvious from the point of view of human intuition, but a computer needs to be told this kind of information. To be able to apply the inference rule, we need to tell the computer that this is an inference rule that you can apply, so the computer has access to it and is able to use it in order to translate information from one form to another. In addition to that, let's take a look at another example of an inference rule, something like it is not true that Harry did not pass the test. Bit of a tricky sentence to parse. I'll read it again. It is not true, or it is false, that Harry did not pass the test. Well, if it is false that Harry did not pass the test, then the only reasonable conclusion is that Harry did pass the test. And so this, instead of being and elimination, is what we call double negation elimination. That if we have two negatives inside of our premise, then we can just remove them altogether. They cancel each other out. One turns true to false, and the other one turns false back into true. Phrased a little bit more formally, we say that if the premise is not alpha, then the conclusion we can draw is just alpha. We can say that alpha is true. We'll take a look at a couple more of these. If I have it is raining, then Harry is inside. How do I reframe this? Well, this one is a little bit trickier. But if I know if it is raining, then Harry is inside, then I conclude one of two things must be true. Either it is not raining, or Harry is inside. Now, this one's trickier. So let's think about it a little bit. This first premise here, if it is raining, then Harry is inside, is saying that if I know that it is raining, then Harry must be inside. So what is the other possible case? Well, if Harry is not inside, then I know that it must not be raining. So one of those two situations must be true. Either it's not raining, or it is raining, in which case Harry is inside. So the conclusion I can draw is either it is not raining, or it is raining, so therefore, Harry is inside. And so this is a way to translate if-then statements into or statements. And this is known as implication elimination. And this is similar to what we actually did in the beginning when we were first looking at those very first sentences about Harry and Hagrid and Dumbledore. And phrased a little bit more formally, this says that if I have the implication, alpha implies beta, that I can draw the conclusion that either not alpha or beta, because there are only two possibilities. Either alpha is true or alpha is not true. So one of those possibilities is alpha is not true. But if alpha is true, well, then we can draw the conclusion that beta must be true. So either alpha is not true or alpha is true, in which case beta is also true. So this is one way to turn an implication into just a statement about or. In addition to eliminating implications, we can also eliminate biconditionals as well. So let's take an English example, something like, it is raining if and only if Harry is inside. And this if and only if really sounds like that biconditional, that double arrow sign that we saw in propositional logic not too long ago. And what does this actually mean if we were to translate this? Well, this means that if it is raining, then Harry is inside. And if Harry is inside, then it is raining, that this implication goes both ways. And this is what we would call biconditional elimination, that I can take a biconditional, a if and only if b, and translate that into something like this, a implies b, and b implies a. So many of these inference rules are taking logic that uses certain symbols and turning them into different symbols, taking an implication and turning it into an or, or taking a biconditional and turning it into implication. And another example of it would be something like this. It is not true that both Harry and Ron passed the test. Well, all right, how do we translate that? What does that mean? Well, if it is not true that both of them passed the test, well, then the reasonable conclusion we might draw is that at least one of them didn't pass the test. So the conclusion is either Harry did not pass the test or Ron did not pass the test, or both. This is not an exclusive or. But if it is true that it is not true that both Harry and Ron passed the test, well, then either Harry didn't pass the test or Ron didn't pass the test. And this type of law is one of De Morgan's laws. Quite famous in logic where the idea is that we can turn an and into an or. We can say we can take this and that both Harry and Ron passed the test and turn it into an or by moving the nots around. So if it is not true that Harry and Ron passed the test, well, then either Harry did not pass the test or Ron did not pass the test either. And the way we frame that more formally using logic is to say this. If it is not true that alpha and beta, well, then either not alpha or not beta. The way I like to think about this is that if you have a negation in front of an and expression, you move the negation inwards, so to speak, moving the negation into each of these individual sentences and then flip the and into an or. So the negation moves inwards and the and flips into an or. So I go from not a and b to not a or not b. And there's actually a reverse of De Morgan's law that goes in the other direction for something like this. If I say it is not true that Harry or Ron passed the test, meaning neither of them passed the test, well, then the conclusion I can draw is that Harry did not pass the test and Ron did not pass the test. So in this case, instead of turning an and into an or, we're turning an or into an and. But the idea is the same. And this, again, is another example of De Morgan's laws. And the way that works is that if I have not a or b this time, the same logic is going to apply. I'm going to move the negation inwards. And I'm going to flip this time, flip the or into an and. So if not a or b, meaning it is not true that a or b or alpha or beta, then I can say not alpha and not beta, moving the negation inwards in order to make that conclusion. So those are De Morgan's laws and a couple other inference rules that are worth just taking a look at. One is the distributive law that works this way. So if I have alpha and beta or gamma, well, then much in the same way that you can use in math, use distributive laws to distribute operands like addition and multiplication, I can do a similar thing here, where I can say if alpha and beta or gamma, then I can say something like alpha and beta or alpha and gamma, that I've been able to distribute this and sign throughout this expression. So this is an example of the distributive property or the distributive law as applied to logic in much the same way that you would distribute a multiplication over the addition of something, for example. This works the other way too. So if, for example, I have alpha or beta and gamma, I can distribute the or throughout the expression. I can say alpha or beta and alpha or gamma. So the distributive law works in that way too. And it's helpful if I want to take an or and move it into the expression. And we'll see an example soon of why it is that we might actually care to do something like that. All right, so now we've seen a lot of different inference rules. And the question now is, how can we use those inference rules to actually try and draw some conclusions, to actually try and prove something about entailment, proving that given some initial knowledge base, we would like to find some way to prove that a query is true? Well, one way to think about it is actually to think back to what we talked about last time when we talked about search problems. Recall again that search problems have some sort of initial state. They have actions that you can take from one state to another as defined by a transition model that tells you how to get from one state to another. We talked about testing to see if you were at a goal. And then some path cost function to see how many steps did you have to take or how costly was the solution that you found. Now that we have these inference rules that take some set of sentences in propositional logic and get us some new set of sentences in propositional logic, we can actually treat those sentences or those sets of sentences as states inside of a search problem. So if we want to prove that some query is true, prove that some logical theorem is true, we can treat theorem proving as a form of a search problem. I can say that we begin in some initial state, where that initial state is the knowledge base that I begin with, the set of all of the sentences that I know to be true. What actions are available to me? Well, the actions are any of the inference rules that I can apply at any given time. The transition model just tells me after I apply the inference rule, here is the new set of all of the knowledge that I have, which will be the old set of knowledge, plus some additional inference that I've been able to draw, much as in the same way we saw what we got when we applied those inference rules and got some sort of conclusion. That conclusion gets added to our knowledge base, and our transition model will encode that. What is the goal test? Well, our goal test is checking to see if we have proved the statement we're trying to prove, if the thing we're trying to prove is inside of our knowledge base. And the path cost function, the thing we're trying to minimize, is maybe the number of inference rules that we needed to use, the number of steps, so to speak, inside of our proof. And so here we've been able to apply the same types of ideas that we saw last time with search problems to something like trying to prove something about knowledge by taking our knowledge and framing it in terms that we can understand as a search problem with an initial state, with actions, with a transition model. So this shows a couple of things, one being how versatile search problems are, that they can be the same types of algorithms that we use to solve a maze or figure out how to get from point A to point B inside of driving directions, for example, can also be used as a theorem proving method of taking some sort of starting knowledge base and trying to prove something about that knowledge. So this, yet again, is a second way, in addition to model checking, to try and prove that certain statements are true. But it turns out there's yet another way that we can try and apply inference. And we'll talk about this now, which is not the only way, but certainly one of the most common, which is known as resolution. And resolution is based on another inference rule that we'll take a look at now, quite a powerful inference rule that will let us prove anything that can be proven about a knowledge base. And it's based on this basic idea. Let's say I know that either Ron is in the Great Hall or Hermione is in the library. And let's say I also know that Ron is not in the Great Hall. Based on those two pieces of information, what can I conclude? Well, I could pretty reasonably conclude that Hermione must be in the library. How do I know that? Well, it's because these two statements, these two what we'll call complementary literals, literals that complement each other, they're opposites of each other, seem to conflict with each other. This sentence tells us that either Ron is in the Great Hall or Hermione is in the library. So if we know that Ron is not in the Great Hall, that conflicts with this one, which means Hermione must be in the library. And this we can frame as a more general rule known as the unit resolution rule, a rule that says that if we have p or q and we also know not p, well then from that we can reasonably conclude q. That if p or q are true and we know that p is not true, the only possibility is for q to then be true. And this, it turns out, is quite a powerful inference rule in terms of what it can do, in part because we can quickly start to generalize this rule. This q right here doesn't need to just be a single propositional symbol. It could be multiple, all chained together in a single clause, as we'll call it. So if I had something like p or q1 or q2 or q3, so on and so forth, up until qn, so I had n different other variables, and I have not p, well then what happens when these two complement each other is that these two clauses resolve, so to speak, to produce a new clause that is just q1 or q2 all the way up to qn. And in an or, the order of the arguments in the or doesn't actually matter. The p doesn't need to be the first thing. It could have been in the middle. But the idea here is that if I have p in one clause and not p in the other clause, well then I know that one of these remaining things must be true. I've resolved them in order to produce a new clause. But it turns out we can generalize this idea even further, in fact, and display even more power that we can have with this resolution rule. So let's take another example. Let's say, for instance, that I know the same piece of information that either Ron is in the Great Hall or Hermione is in the library. And the second piece of information I know is that Ron is not in the Great Hall or Harry is sleeping. So it's not just a single piece of information. I have two different clauses. And we'll define clauses more precisely in just a moment. What do I know here? Well again, for any propositional symbol like Ron is in the Great Hall, there are only two possibilities. Either Ron is in the Great Hall, in which case, based on resolution, we know that Harry must be sleeping, or Ron is not in the Great Hall, in which case we know based on the same rule that Hermione must be in the library. Based on those two things in combination, I can say based on these two premises that I can conclude that either Hermione is in the library or Harry is sleeping. So again, because these two conflict with each other, I know that one of these two must be true. And you can take a closer look and try and reason through that logic. Make sure you convince yourself that you believe this conclusion. Stated more generally, we can name this resolution rule by saying that if we know p or q is true, and we also know that not p or r is true, we resolve these two clauses together to get a new clause, q or r, that either q or r must be true. And again, much as in the last case, q and r don't need to just be single propositional symbols. It could be multiple symbols. So if I had a rule that had p or q1 or q2 or q3, so on and so forth, up until qn, where n is just some number. And likewise, I had not p or r1 or r2, so on and so forth, up until rm, where m, again, is just some other number. I can resolve these two clauses together to get one of these must be true, q1 or q2 up until qn or r1 or r2 up until rm. And this is just a generalization of that same rule we saw before. Each of these things here are what we're going to call a clause, where a clause is formally defined as a disjunction of literals, where a disjunction means it's a bunch of things that are connected with or. Disjunction means things connected with or. Conjunction, meanwhile, is things connected with and. And a literal is either a propositional symbol or the opposite of a propositional symbol. So it's something like p or q or not p or not q. Those are all propositional symbols or not of the propositional symbols. And we call those literals. And so a clause is just something like this, p or q or r, for example. Meanwhile, what this gives us an ability to do is it gives us an ability to turn logic, any logical sentence, into something called conjunctive normal form. A conjunctive normal form sentence is a logical sentence that is a conjunction of clauses. Recall, again, conjunction means things are connected to one another using and. And so a conjunction of clauses means it is an and of individual clauses, each of which has ors in it. So something like this, a or b or c, and d or not e, and f or g. Everything in parentheses is one clause. All of the clauses are connected to each other using an and. And everything in the clause is separated using an or. And this is just a standard form that we can translate a logical sentence into that just makes it easy to work with and easy to manipulate. And it turns out that we can take any sentence in logic and turn it into conjunctive normal form just by applying some inference rules and transformations to it. So we'll take a look at how we can actually do that. So what is the process for taking a logical formula and converting it into conjunctive normal form, otherwise known as c and f? Well, the process looks a little something like this. We need to take all of the symbols that are not part of conjunctive normal form. The bi-conditionals and the implications and so forth, and turn them into something that is more closely like conjunctive normal form. So the first step will be to eliminate bi-conditionals, those if and only if double arrows. And we know how to eliminate bi-conditionals because we saw there was an inference rule to do just that. Any time I have an expression like alpha if and only if beta, I can turn that into alpha implies beta and beta implies alpha based on that inference rule we saw before. Likewise, in addition to eliminating bi-conditionals, I can eliminate implications as well, the if then arrows. And I can do that using the same inference rule we saw before too, taking alpha implies beta and turning that into not alpha or beta because that is logically equivalent to this first thing here. Then we can move knots inwards because we don't want knots on the outsides of our expressions. Conjunctive normal form requires that it's just claws and claws and claws and claws. Any knots need to be immediately next to propositional symbols. But we can move those knots around using De Morgan's laws by taking something like not A and B and turn it into not A or not B, for example, using De Morgan's laws to manipulate that. And after that, all we'll be left with are ands and ors. And those are easy to deal with. We can use the distributive law to distribute the ors so that the ors end up on the inside of the expression, so to speak, and the ands end up on the outside. So this is the general pattern for how we'll take a formula and convert it into conjunctive normal form. And let's now take a look at an example of how we would do this and explore then why it is that we would want to do something like this. Here's how we can do it. Let's take this formula, for example. P or Q implies R. And I'd like to convert this into conjunctive normal form, where it's all ands of clauses, and every clause is a disjunctive clause. It's ors together. So what's the first thing I need to do? Well, this is an implication. So let me go ahead and remove that implication. Using the implication inference rule, I can turn P or Q into P or Q implies R into not P or Q or R. So that's the first step. I've gotten rid of the implication. And next, I can get rid of the not on the outside of this expression, too. I can move the nots inwards so they're closer to the literals themselves by using De Morgan's laws. And De Morgan's law says that not P or Q is equivalent to not P and not Q. Again, here, just applying the inference rules that we've already seen in order to translate these statements. And now, I have two things that are separated by an or, where this thing on the inside is an and. What I'd really like to move the ors so the ors are on the inside, because conjunctive normal form means I need clause and clause and clause and clause. And so to do that, I can use the distributive law. If I have not P and not Q or R, I can distribute the or R to both of these to get not P or R and not Q or R using the distributive law. And this now here at the bottom is in conjunctive normal form. It is a conjunction and and of disjunctions of clauses that just are separated by ors. So this process can be used by any formula to take a logical sentence and turn it into this conjunctive normal form, where I have clause and clause and clause and clause and clause and so on. So why is this helpful? Why do we even care about taking all these sentences and converting them into this form? It's because once they're in this form where we have these clauses, these clauses are the inputs to the resolution inference rule that we saw a moment ago, that if I have two clauses where there's something that conflicts or something complementary between those two clauses, I can resolve them to get a new clause, to draw a new conclusion. And we call this process inference by resolution, using the resolution rule to draw some sort of inference. And it's based on the same idea, that if I have P or Q, this clause, and I have not P or R, that I can resolve these two clauses together to get Q or R as the resulting clause, a new piece of information that I didn't have before. Now, a couple of key points that are worth noting about this before we talk about the actual algorithm. One thing is that, let's imagine we have P or Q or S, and I also have not P or R or S. The resolution rule says that because this P conflicts with this not P, we would resolve to put everything else together to get Q or S or R or S. But it turns out that this double S is redundant, or S here and or S there. It doesn't change the meaning of the sentence. So in resolution, when we do this resolution process, we'll usually also do a process known as factoring, where we take any duplicate variables that show up and just eliminate them. So Q or S or R or S just becomes Q or R or S. The S only needs to appear once, no need to include it multiple times. Now, one final question worth considering is what happens if I try to resolve P and not P together? If I know that P is true and I know that not P is true, well, resolution says I can merge these clauses together and look at everything else. Well, in this case, there is nothing else, so I'm left with what we might call the empty clause. I'm left with nothing. And the empty clause is always false. The empty clause is equivalent to just being false. And that's pretty reasonable because it's impossible for both P and not P to both hold at the same time. P is either true or it's not true, which means that if P is true, then this must be false. And if this is true, then this must be false. There is no way for both of these to hold at the same time. So if ever I try and resolve these two, it's a contradiction, and I'll end up getting this empty clause where the empty clause I can call equivalent to false. And this idea that if I resolve these two contradictory terms, I get the empty clause, this is the basis for our inference by resolution algorithm. Here's how we're going to perform inference by resolution at a very high level. We want to prove that our knowledge base entails some query alpha, that based on the knowledge we have, we can prove conclusively that alpha is going to be true. How are we going to do that? Well, in order to do that, we're going to try to prove that if we know the knowledge and not alpha, that that would be a contradiction. And this is a common technique in computer science more generally, this idea of proving something by contradiction. If I want to prove that something is true, I can do so by first assuming that it is false and showing that it would be contradictory, showing that it leads to some contradiction. And if the thing I'm trying to prove, if when I assume it's false, leads to a contradiction, then it must be true. And that's the logical approach or the idea behind a proof by contradiction. And that's what we're going to do here. We want to prove that this query alpha is true. So we're going to assume that it's not true. We're going to assume not alpha. And we're going to try and prove that it's a contradiction. If we do get a contradiction, well, then we know that our knowledge entails the query alpha. If we don't get a contradiction, there is no entailment. This is this idea of a proof by contradiction of assuming the opposite of what you're trying to prove. And if you can demonstrate that that's a contradiction, then what you're proving must be true. But more formally, how do we actually do this? How do we check that knowledge base and not alpha is going to lead to a contradiction? Well, here is where resolution comes into play. To determine if our knowledge base entails some query alpha, we're going to convert knowledge base and not alpha to conjunctive normal form, that form where we have a whole bunch of clauses that are all anded together. And when we have these individual clauses, now we can keep checking to see if we can use resolution to produce a new clause. We can take any pair of clauses and check, is there some literal that is the opposite of each other or complementary to each other in both of them? For example, I have a p in one clause and a not p in another clause. Or an r in one clause and a not r in another clause. If ever I have that situation where once I convert to conjunctive normal form and I have a whole bunch of clauses, I see two clauses that I can resolve to produce a new clause, then I'll do so. This process occurs in a loop. I'm going to keep checking to see if I can use resolution to produce a new clause and keep using those new clauses to try to generate more new clauses after that. Now, it just so may happen that eventually we may produce the empty clause, the clause we were talking about before. If I resolve p and not p together, that produces the empty clause and the empty clause we know to be false. Because we know that there's no way for both p and not p to both simultaneously be true. So if ever we produce the empty clause, then we have a contradiction. And if we have a contradiction, that's exactly what we were trying to do in a fruit by contradiction. If we have a contradiction, then we know that our knowledge base must entail this query alpha. And we know that alpha must be true. And it turns out, and we won't go into the proof here, but you can show that otherwise, if you don't produce the empty clause, then there is no entailment. If we run into a situation where there are no more new clauses to add, we've done all the resolution that we can do, and yet we still haven't produced the empty clause, then there is no entailment in this case. And this now is the resolution algorithm. And it's very abstract looking, especially this idea of like, what does it even mean to have the empty clause? So let's take a look at an example, actually try and prove some entailment by using this inference by resolution process. So here's our question. We have this knowledge base. Here is the knowledge that we know, A or B, and not B or C, and not C. And we want to know if all of this entails A. So this is our knowledge base here, this whole log thing. And our query alpha is just this propositional symbol, A. So what do we do? Well, first, we want to prove by contradiction. So we want to first assume that A is false, and see if that leads to some sort of contradiction. So here is what we're going to start with, A or B, and not B or C, and not C. This is our knowledge base. And we're going to assume not A. We're going to assume that the thing we're trying to prove is, in fact, false. And so this is now in conjunctive normal form, and I have four different clauses. I have A or B. I have not B or C. I have not C, and I have not A. And now, I can begin to just pick two clauses that I can resolve, and apply the resolution rule to them. And so looking at these four clauses, I see, all right, these two clauses are ones I can resolve. I can resolve them because there are complementary literals that show up in them. There's a C here, and a not C here. So just looking at these two clauses, if I know that not B or C is true, and I know that C is not true, well, then I can resolve these two clauses to say, all right, not B, that must be true. I can generate this new clause as a new piece of information that I now know to be true. And all right, now I can repeat this process, do the process again. Can I use resolution again to get some new conclusion? Well, it turns out I can. I can use that new clause I just generated, along with this one here. There are complementary literals. This B is complementary to, or conflicts with, this not B over here. And so if I know that A or B is true, and I know that B is not true, well, then the only remaining possibility is that A must be true. So now we have A. That is a new clause that I've been able to generate. And now, I can do this one more time. I'm looking for two clauses that can be resolved, and you might programmatically do this by just looping over all possible pairs of clauses and checking for complementary literals in each. And here, I can say, all right, I found two clauses, not A and A, that conflict with each other. And when I resolve these two together, well, this is the same as when we were resolving P and not P from before. When I resolve these two clauses together, I get rid of the As, and I'm left with the empty clause. And the empty clause we know to be false, which means we have a contradiction, which means we can safely say that this whole knowledge base does entail A. That if this sentence is true, that we know that A for sure is also true. So this now, using inference by resolution, is an entirely different way to take some statement and try and prove that it is, in fact, true. Instead of enumerating all of the possible worlds that we might be in in order to try to figure out in which cases is the knowledge base true and in which cases are query true, instead we use this resolution algorithm to say, let's keep trying to figure out what conclusions we can draw and see if we reach a contradiction. And if we reach a contradiction, then that tells us something about whether our knowledge actually entails the query or not. And it turns out there are many different algorithms that can be used for inference. What we've just looked at here are just a couple of them. And in fact, all of this is just based on one particular type of logic. It's based on propositional logic, where we have these individual symbols and we connect them using and and or and not and implies and by conditionals. But propositional logic is not the only kind of logic that exists. And in fact, we see that there are limitations that exist in propositional logic, especially as we saw in examples like with the mastermind example or with the example with the logic puzzle where we had different Hogwarts house people that belong to different houses and we were trying to figure out who belonged to which houses. There were a lot of different propositional symbols that we needed in order to represent some fairly basic ideas. So now is the final topic that we'll take a look at just before we end class today is one final type of logic different from propositional logic known as first order logic, which is a little bit more powerful than propositional logic and is going to make it easier for us to express certain types of ideas. In propositional logic, if we think back to that puzzle with the people in the Hogwarts houses, we had a whole bunch of symbols. And every symbol could only be true or false. We had a symbol for Minerva Gryffindor, which was either true of Minerva within Gryffindor and false otherwise, and likewise for Minerva Hufflepuff and Minerva Ravenclaw and Minerva Slytherin and so forth. But this was starting to get quite redundant. We wanted some way to be able to express that there is a relationship between these propositional symbols, that Minerva shows up in all of them. And also, I would have liked to have not have had so many different symbols to represent what really was a fairly straightforward problem. So first order logic will give us a different way of trying to deal with this idea by giving us two different types of symbols. We're going to have constant symbols that are going to represent objects like people or houses. And then predicate symbols, which you can think of as relations or functions that take an input and evaluate them to true or false, for example, that tell us whether or not some property of some constant or some pair of constants or multiple constants actually holds. So we'll see an example of that in just a moment. For now, in this same problem, our constant symbols might be objects, things like people or houses. So Minerva, Pomona, Horace, Gilderoy, those are all constant symbols, as are my four houses, Gryffindor, Hufflepuff, Ravenclaw, and Slytherin. Predicates, meanwhile, these predicate symbols are going to be properties that might hold true or false of these individual constants. So person might hold true of Minerva, but it would be false for Gryffindor because Gryffindor is not a person. And house is going to hold true for Ravenclaw, but it's not going to hold true for Horace, for example, because Horace is a person. And belongs to, meanwhile, is going to be some relation that is going to relate people to their houses. And it's going to only tell me when someone belongs to a house or does not. So let's take a look at some examples of what a sentence in first order logic might actually look like. A sentence might look like something like this. Person Minerva, with Minerva in parentheses, and person being a predicate symbol, Minerva being a constant symbol. This sentence in first order logic effectively means Minerva is a person, or the person property applies to the Minerva object. So if I want to say something like Minerva is a person, here is how I express that idea using first order logic. Meanwhile, I can say something like, house Gryffindor, to likewise express the idea that Gryffindor is a house. I can do that this way. And all of the same logical connectives that we saw in propositional logic, those are going to work here too. And or implication by conditional not. In fact, I can use not to say something like, not house Minerva. And this sentence in first order logic means something like, Minerva is not a house. It is not true that the house property applies to Minerva. Meanwhile, in addition to some of these predicate symbols that just take a single argument, some of our predicate symbols are going to express binary relations, relations between two of its arguments. So I could say something like, belongs to, and then two inputs, Minerva and Gryffindor, to express the idea that Minerva belongs to Gryffindor. And so now here's the key difference, or one of the key differences, between this and propositional logic. In propositional logic, I needed one symbol for Minerva Gryffindor, and one symbol for Minerva Hufflepuff, and one symbol for all the other people's Gryffindor and Hufflepuff variables. In this case, I just need one symbol for each of my people, and one symbol for each of my houses. And then I can express as a predicate something like, belongs to, and say, belongs to Minerva Gryffindor, to express the idea that Minerva belongs to Gryffindor House. So already we can see that first order logic is quite expressive in being able to express these sorts of sentences using the existing constant symbols and predicates that already exist, while minimizing the number of new symbols that I need to create. I can just use eight symbols for people for houses, instead of 16 symbols for every possible combination of each. But first order logic gives us a couple of additional features that we can use to express even more complex ideas. And these more additional features are generally known as quantifiers. And there are two main quantifiers in first order logic, the first of which is universal quantification. Universal quantification lets me express an idea like something is going to be true for all values of a variable. Like for all values of x, some statement is going to hold true. So what might a sentence in universal quantification look like? Well, we're going to use this upside down a to mean for all. So upside down ax means for all values of x, where x is any object, this is going to hold true. Belongs to x Gryffindor implies not belongs to x Hufflepuff. So let's try and parse this out. This means that for all values of x, if this holds true, if x belongs to Gryffindor, then this does not hold true. x does not belong to Hufflepuff. So translated into English, this sentence is saying something like for all objects x, if x belongs to Gryffindor, then x does not belong to Hufflepuff, for example. Or a phrase even more simply, anyone in Gryffindor is not in Hufflepuff, simplified way of saying the same thing. So this universal quantification lets us express an idea like something is going to hold true for all values of a particular variable. In addition to universal quantification though, we also have existential quantification. Whereas universal quantification said that something is going to be true for all values of a variable, existential quantification says that some expression is going to be true for some value of a variable, at least one value of the variable. So let's take a look at a sample sentence using existential quantification. One such sentence looks like this. There exists an x. This backwards e stands for exists. And here we're saying there exists an x such that house x and belongs to Minerva x. In other words, there exists some object x where x is a house and Minerva belongs to x. Or phrased a little more succinctly in English, I'm here just saying Minerva belongs to a house. There's some object that is a house and Minerva belongs to a house. And combining this universal and existential quantification, we can create far more sophisticated logical statements than we were able to just using propositional logic. I could combine these to say something like this. For all x, person x implies there exists a y such that house y and belongs to xy. All right. So a lot of stuff going on there, a lot of symbols. Let's try and parse it out and just understand what it's saying. Here we're saying that for all values of x, if x is a person, then this is true. So in other words, I'm saying for all people, and we call that person x, this statement is going to be true. What statement is true of all people? Well, there exists a y that is a house, so there exists some house, and x belongs to y. In other words, I'm saying that for all people out there, there exists some house such that x, the person, belongs to y, the house. This is phrased more succinctly. I'm saying that every person belongs to a house, that for all x, if x is a person, then there exists a house that x belongs to. And so we can now express a lot more powerful ideas using this idea now of first order logic. And it turns out there are many other kinds of logic out there. There's second order logic and other higher order logic, each of which allows us to express more and more complex ideas. But all of it, in this case, is really in pursuit of the same goal, which is the representation of knowledge. We want our AI agents to be able to know information, to represent that information, whether that's using propositional logic or first order logic or some other logic, and then be able to reason based on that, to be able to draw conclusions, make inferences, figure out whether there's some sort of entailment relationship, as by using some sort of inference algorithm, something like inference by resolution or model checking or any number of these other algorithms that we can use in order to take information that we know and translate it to additional conclusions. So all of this has helped us to create AI that is able to represent information about what it knows and what it doesn't know. Next time, though, we'll take a look at how we can make our AI even more powerful by not just encoding information that we know for sure to be true and not to be true, but also to take a look at uncertainty, to look at what happens if AI thinks that something might be probable or maybe not very probable or somewhere in between those two extremes, all in the pursuit of trying to build our intelligent systems to be even more intelligent. We'll see you next time. Thank you. All right, welcome back, everyone, to an introduction to artificial intelligence with Python. And last time, we took a look at how it is that AI inside of our computers can represent knowledge. We represented that knowledge in the form of logical sentences in a variety of different logical languages. And the idea was we wanted our AI to be able to represent knowledge or information and somehow use those pieces of information to be able to derive new pieces of information by inference, to be able to take some information and deduce some additional conclusions based on the information that it already knew for sure. But in reality, when we think about computers and we think about AI, very rarely are our machines going to be able to know things for sure. Oftentimes, there's going to be some amount of uncertainty in the information that our AIs or our computers are dealing with, where it might believe something with some probability, as we'll soon discuss what probability is all about and what it means, but not entirely for certain. And we want to use the information that it has some knowledge about, even if it doesn't have perfect knowledge, to still be able to make inferences, still be able to draw conclusions. So you might imagine, for example, in the context of a robot that has some sensors and is exploring some environment, it might not know exactly where it is or exactly what's around it, but it does have access to some data that can allow it to draw inferences with some probability. There's some likelihood that one thing is true or another. Or you can imagine in context where there is a little bit more randomness and uncertainty, something like predicting the weather, where you might not be able to know for sure what tomorrow's weather is with 100% certainty, but you can probably infer with some probability what tomorrow's weather is going to be based on maybe today's weather and yesterday's weather and other data that you might have access to as well. And so oftentimes, we can distill this in terms of just possible events that might happen and what the likelihood of those events are. This comes a lot in games, for example, where there is an element of chance inside of those games. So you imagine rolling a dice. You're not sure exactly what the die roll is going to be, but you know it's going to be one of these possibilities from 1 to 6, for example. And so here now, we introduce the idea of probability theory. And what we'll take a look at today is beginning by looking at the mathematical foundations of probability theory, getting an understanding for some of the key concepts within probability, and then diving into how we can use probability and the ideas that we look at mathematically to represent some ideas in terms of models that we can put into our computers in order to program an AI that is able to use information about probability to draw inferences, to make some judgments about the world with some probability or likelihood of being true. So probability ultimately boils down to this idea that there are possible worlds that we're here representing using this little Greek letter omega. And the idea of a possible world is that when I roll a die, there are six possible worlds that could result from it. I could roll a 1, or a 2, or a 3, or a 4, or a 5, or a 6. And each of those are a possible world. And each of those possible worlds has some probability of being true, the probability that I do roll a 1, or a 2, or a 3, or something else. And we represent that probability like this, using the capital letter P. And then in parentheses, what it is that we want the probability of. So this right here would be the probability of some possible world as represented by the little letter omega. Now, there are a couple of basic axioms of probability that become relevant as we consider how we deal with probability and how we think about it. First and foremost, every probability value must range between 0 and 1 inclusive. So the smallest value any probability can have is the number 0, which is an impossible event. Something like I roll a die, and the die is a 7 is the roll that I get. If the die only has numbers 1 through 6, the event that I roll a 7 is impossible, so it would have probability 0. And on the other end of the spectrum, probability can range all the way up to the positive number 1, meaning an event is certain to happen, that I roll a die and the number is less than 10, for example. That is an event that is guaranteed to happen if the only sides on my die are 1 through 6, for instance. And then they can range through any real number in between these two values. Where, generally speaking, a higher value for the probability means an event is more likely to take place, and a lower value for the probability means the event is less likely to take place. And the other key rule for probability looks a little bit like this. This sigma notation, if you haven't seen it before, refers to summation, the idea that we're going to be adding up a whole sequence of values. And this sigma notation is going to come up a couple of times today, because as we deal with probability, oftentimes we're adding up a whole bunch of individual values or individual probabilities to get some other value. So we'll see this come up a couple of times. But what this notation means is that if I sum up all of the possible worlds omega that are in big omega, which represents the set of all the possible worlds, meaning I take for all of the worlds in the set of possible worlds and add up all of their probabilities, what I ultimately get is the number 1. So if I take all the possible worlds, add up what each of their probabilities is, I should get the number 1 at the end, meaning all probabilities just need to sum to 1. So for example, if I take dice, for example, and if you imagine I have a fair die with numbers 1 through 6 and I roll the die, each one of these rolls has an equal probability of taking place. And the probability is 1 over 6, for example. So each of these probabilities is between 0 and 1, 0 meaning impossible and 1 meaning for certain. And if you add up all of these probabilities for all of the possible worlds, you get the number 1. And we can represent any one of those probabilities like this. The probability that we roll the number 2, for example, is just 1 over 6. Every six times we roll the die, we'd expect that one time, for instance, the die might come up as a 2. Its probability is not certain, but it's a little more than nothing, for instance. And so this is all fairly straightforward for just a single die. But things get more interesting as our models of the world get a little bit more complex. Let's imagine now that we're not just dealing with a single die, but we have two dice, for example. I have a red die here and a blue die there, and I care not just about what the individual roll is, but I care about the sum of the two rolls. In this case, the sum of the two rolls is the number 3. How do I begin to now reason about what does the probability look like if instead of having one die, I now have two dice? Well, what we might imagine is that we could first consider what are all of the possible worlds. And in this case, all of the possible worlds are just every combination of the red and blue die that I could come up with. For the red die, it could be a 1 or a 2 or a 3 or a 4 or a 5 or a 6. And for each of those possibilities, the blue die, likewise, could also be either 1 or 2 or 3 or 4 or 5 or 6. And it just so happens that in this particular case, each of these possible combinations is equally likely. Equally likely are all of these various different possible worlds. That's not always going to be the case. If you imagine more complex models that we could try to build and things that we could try to represent in the real world, it's probably not going to be the case that every single possible world is always equally likely. But in the case of fair dice, where in any given die roll, any one number has just as good a chance of coming up as any other number, we can consider all of these possible worlds to be equally likely. But even though all of the possible worlds are equally likely, that doesn't necessarily mean that their sums are equally likely. So if we consider what the sum is of all of these two, so 1 plus 1, that's a 2. 2 plus 1 is a 3. And consider for each of these possible pairs of numbers what their sum ultimately is, we can notice that there are some patterns here, where it's not entirely the case that every number comes up equally likely. If you consider 7, for example, what's the probability that when I roll two dice, their sum is 7? There are several ways this can happen. There are six possible worlds where the sum is 7. It could be a 1 and a 6, or a 2 and a 5, or a 3 and a 4, a 4 and a 3, and so forth. But if you instead consider what's the probability that I roll two dice, and the sum of those two die rolls is 12, for example, we're looking at this diagram, there's only one possible world in which that can happen. And that's the possible world where both the red die and the blue die both come up as sixes to give us a sum total of 12. So based on just taking a look at this diagram, we see that some of these probabilities are likely different. The probability that the sum is a 7 must be greater than the probability that the sum is a 12. And we can represent that even more formally by saying, OK, the probability that we sum to 12 is 1 out of 36. Out of the 36 equally likely possible worlds, 6 squared because we have six options for the red die and six options for the blue die, out of those 36 options, only one of them sums to 12. Whereas on the other hand, the probability that if we take two dice rolls and they sum up to the number 7, well, out of those 36 possible worlds, there were six worlds where the sum was 7. And so we get 6 over 36, which we can simplify as a fraction to just 1 over 6. So here now, we're able to represent these different ideas of probability, representing some events that might be more likely and then other events that are less likely as well. And these sorts of judgments, where we're figuring out just in the abstract what is the probability that this thing takes place, are generally known as unconditional probabilities. Some degree of belief we have in some proposition, some fact about the world, in the absence of any other evidence. Without knowing any additional information, if I roll a die, what's the chance it comes up as a 2? Or if I roll two dice, what's the chance that the sum of those two die rolls is a 7? But usually when we're thinking about probability, especially when we're thinking about training in AI to intelligently be able to know something about the world and make predictions based on that information, it's not unconditional probability that our AI is dealing with, but rather conditional probability, probability where rather than having no original knowledge, we have some initial knowledge about the world and how the world actually works. So conditional probability is the degree of belief in a proposition given some evidence that has already been revealed to us. So what does this look like? Well, it looks like this in terms of notation. We're going to represent conditional probability as probability of A and then this vertical bar and then B. And the way to read this is the thing on the left-hand side of the vertical bar is what we want the probability of. Here now, I want the probability that A is true, that it is the real world, that it is the event that actually does take place. And then on the right side of the vertical bar is our evidence, the information that we already know for certain about the world. For example, that B is true. So the way to read this entire expression is what is the probability of A given B, the probability that A is true, given that we already know that B is true. And this type of judgment, conditional probability, the probability of one thing given some other fact, comes up quite a lot when we think about the types of calculations we might want our AI to be able to do. For example, we might care about the probability of rain today given that we know that it rained yesterday. We could think about the probability of rain today just in the abstract. What is the chance that today it rains? But usually, we have some additional evidence. I know for certain that it rained yesterday. And so I would like to calculate the probability that it rains today given that I know that it rained yesterday. Or you might imagine that I want to know the probability that my optimal route to my destination changes given the current traffic condition. So whether or not traffic conditions change, that might change the probability that this route is actually the optimal route. Or you might imagine in a medical context, I want to know the probability that a patient has a particular disease given some results of some tests that have been performed on that patient. And I have some evidence, the results of that test, and I would like to know the probability that a patient has a particular disease. So this notion of conditional probability comes up everywhere. So we begin to think about what we would like to reason about, but being able to reason a little more intelligently by taking into account evidence that we already have. We're more able to get an accurate result for what is the likelihood that someone has this disease if we know this evidence, the results of the test, as opposed to if we were just calculating the unconditional probability of saying, what is the probability they have the disease without any evidence to try and back up our result one way or the other. So now that we've got this idea of what conditional probability is, the next question we have to ask is, all right, how do we calculate conditional probability? How do we figure out mathematically, if I have an expression like this, how do I get a number from that? What does conditional probability actually mean? Well, the formula for conditional probability looks a little something like this. The probability of a given b, the probability that a is true, given that we know that b is true, is equal to this fraction, the probability that a and b are true, divided by just the probability that b is true. And the way to intuitively try to think about this is that if I want to know the probability that a is true, given that b is true, well, I want to consider all the ways they could both be true out of the only worlds that I care about are the worlds where b is already true. I can sort of ignore all the cases where b isn't true, because those aren't relevant to my ultimate computation. They're not relevant to what it is that I want to get information about. So let's take a look at an example. Let's go back to that example of rolling two dice and the idea that those two dice might sum up to the number 12. We discussed earlier that the unconditional probability that if I roll two dice and they sum to 12 is 1 out of 36, because out of the 36 possible worlds that I might care about, in only one of them is the sum of those two dice 12. It's only when red is 6 and blue is also 6. But let's say now that I have some additional information. I now want to know what is the probability that the two dice sum to 12, given that I know that the red die was a 6. So I already have some evidence. I already know the red die is a 6. I don't know what the blue die is. That information isn't given to me in this expression. But given the fact that I know that the red die rolled a 6, what is the probability that we sum to 12? And so we can begin to do the math using that expression from before. Here, again, are all of the possibilities, all of the possible combinations of red die being 1 through 6 and blue die being 1 through 6. And I might consider first, all right, what is the probability of my evidence, my B variable, where I want to know, what is the probability that the red die is a 6? Well, the probability that the red die is a 6 is just 1 out of 6. So these 1 out of 6 options are really the only worlds that I care about here now. All the rest of them are irrelevant to my calculation, because I already have this evidence that the red die was a 6, so I don't need to care about all of the other possibilities that could result. So now, in addition to the fact that the red die rolled as a 6 and the probability of that, the other piece of information I need to know in order to calculate this conditional probability is the probability that both of my variables, A and B, are true. The probability that both the red die is a 6, and they all sum to 12. So what is the probability that both of these things happen? Well, it only happens in one possible case in 1 out of these 36 cases, and it's the case where both the red and the blue die are equal to 6. This is a piece of information that we already knew. And so this probability is equal to 1 over 36. And so to get the conditional probability that the sum is 12, given that I know that the red dice is equal to 6, well, I just divide these two values together, and 1 over 36 divided by 1 over 6 gives us this probability of 1 over 6. Given that I know that the red die rolled a value of 6, the probability that the sum of the two dice is 12 is also 1 over 6. And that probably makes intuitive sense to you, too, because if the red die is a 6, the only way for me to get to a 12 is if the blue die also rolls a 6, and we know that the probability of the blue die rolling a 6 is 1 over 6. So in this case, the conditional probability seems fairly straightforward. But this idea of calculating a conditional probability by looking at the probability that both of these events take place is an idea that's going to come up again and again. This is the definition now of conditional probability. And we're going to use that definition as we think about probability more generally to be able to draw conclusions about the world. This, again, is that formula. The probability of A given B is equal to the probability that A and B take place divided by the probability of B. And you'll see this formula sometimes written in a couple of different ways. You could imagine algebraically multiplying both sides of this equation by probability of B to get rid of the fraction, and you'll get an expression like this. The probability of A and B, which is this expression over here, is just the probability of B times the probability of A given B. Or you could represent this equivalently since A and B in this expression are interchangeable. A and B is the same thing as B and A. You could imagine also representing the probability of A and B as the probability of A times the probability of B given A, just switching all of the A's and B's. These three are all equivalent ways of trying to represent what joint probability means. And so you'll sometimes see all of these equations, and they might be useful to you as you begin to reason about probability and to think about what values might be taking place in the real world. Now, sometimes when we deal with probability, we don't just care about a Boolean event like did this happen or did this not happen. Sometimes we might want the ability to represent variable values in a probability space where some variable might take on multiple different possible values. And in probability, we call a variable in probability theory a random variable. A random variable in probability is just some variable in probability theory that has some domain of values that it can take on. So what do I mean by this? Well, what I mean is I might have a random variable that is just called roll, for example, that has six possible values. Roll is my variable, and the possible values, the domain of values that it can take on are 1, 2, 3, 4, 5, and 6. And I might like to know the probability of each. In this case, they happen to all be the same. But in other random variables, that might not be the case. For example, I might have a random variable to represent the weather, for example, where the domain of values it could take on are things like sun or cloudy or rainy or windy or snowy. And each of those might have a different probability. And I care about knowing what is the probability that the weather equals sun or that the weather equals clouds, for instance. And I might like to do some mathematical calculations based on that information. Other random variables might be something like traffic. What are the odds that there is no traffic or light traffic or heavy traffic? Traffic, in this case, is my random variable. And the values that that random variable can take on are here. It's either none or light or heavy. And I, the person doing these calculations, I, the person encoding these random variables into my computer, need to make the decision as to what these possible values actually are. You might imagine, for example, for a flight. If I care about whether or not I make it or do a flight on time, my flight has a couple of possible values that it could take on. My flight could be on time. My flight could be delayed. My flight could be canceled. So flight, in this case, is my random variable. And these are the values that it can take on. And often, I want to know something about the probability that my random variable takes on each of those possible values. And this is what we then call a probability distribution. A probability distribution takes a random variable and gives me the probability for each of the possible values in its domain. So in the case of this flight, for example, my probability distribution might look something like this. My probability distribution says the probability that the random variable flight is equal to the value on time is 0.6. Or otherwise, put into more English human-friendly terms, the likelihood that my flight is on time is 60%, for example. And in this case, the probability that my flight is delayed is 30%. The probability that my flight is canceled is 10% or 0.1. And if you sum up all of these possible values, the sum is going to be 1, right? If you take all of the possible worlds, here are my three possible worlds for the value of the random variable flight, add them all up together, the result needs to be the number 1 per that axiom of probability theory that we've discussed before. So this now is one way of representing this probability distribution for the random variable flight. Sometimes you'll see it represented a little bit more concisely that this is pretty verbose for really just trying to express three possible values. And so often, you'll instead see the same notation representing using a vector. And all a vector is is a sequence of values. As opposed to just a single value, I might have multiple values. And so I could extend instead, represent this idea this way. Bold p, so a larger p, generally meaning the probability distribution of this variable flight is equal to this vector represented in angle brackets. The probability distribution is 0.6, 0.3, and 0.1. And I would just have to know that this probability distribution is in order of on time or delayed and canceled to know how to interpret this vector. To mean the first value in the vector is the probability that my flight is on time. The second value in the vector is the probability that my flight is delayed. And the third value in the vector is the probability that my flight is canceled. And so this is just an alternate way of representing this idea, a little more verbosely. But oftentimes, you'll see us just talk about a probability distribution over a random variable. And whenever we talk about that, what we're really doing is trying to figure out the probabilities of each of the possible values that that random variable can take on. But this notation is just a little bit more succinct, even though it can sometimes be a little confusing, depending on the context in which you see it. So we'll start to look at examples where we use this sort of notation to describe probability and to describe events that might take place. A couple of other important ideas to know with regards to probability theory. One is this idea of independence. And independence refers to the idea that the knowledge of one event doesn't influence the probability of another event. So for example, in the context of my two dice rolls, where I had the red die and the blue die, the probability that I roll the red die and the blue die, those two events, red die and blue die, are independent. Knowing the result of the red die doesn't change the probabilities for the blue die. It doesn't give me any additional information about what the value of the blue die is ultimately going to be. But that's not always going to be the case. You might imagine that in the case of weather, something like clouds and rain, those are probably not independent. But if it is cloudy, that might increase the probability that later in the day it's going to rain. So some information informs some other event or some other random variable. So independence refers to the idea that one event doesn't influence the other. And if they're not independent, then there might be some relationship. So mathematically, formally, what does independence actually mean? Well, recall this formula from before, that the probability of A and B is the probability of A times the probability of B given A. And the more intuitive way to think about this is that to know how likely it is that A and B happen, well, let's first figure out the likelihood that A happens. And then given that we know that A happens, let's figure out the likelihood that B happens and multiply those two things together. But if A and B were independent, meaning knowing A doesn't change anything about the likelihood that B is true, well, then the probability of B given A, meaning the probability that B is true, given that I know A is true, well, that I know A is true shouldn't really make a difference if these two things are independent, that A shouldn't influence B at all. So the probability of B given A is really just the probability of B. If it is true that A and B are independent. And so this right here is one example of a definition for what it means for A and B to be independent. The probability of A and B is just the probability of A times the probability of B. Anytime you find two events A and B where this relationship holds, then you can say that A and B are independent. So an example of that might be the dice that we were taking a look at before. Here, if I wanted the probability of red being a 6 and blue being a 6, well, that's just the probability that red is a 6 multiplied by the probability that blue is a 6. It's both equal to 1 over 36. So I can say that these two events are independent. What wouldn't be independent, for example, would be an example. So this, for example, has a probability of 1 over 36, as we talked about before. But what wouldn't be independent would be a case like this, the probability that the red die rolls a 6 and the red die rolls a 4. If you just naively took, OK, red die 6, red die 4, well, if I'm only rolling the die once, you might imagine the naive approach is to say, well, each of these has a probability of 1 over 6. So multiply them together, and the probability is 1 over 36. But of course, if you're only rolling the red die once, there's no way you could get two different values for the red die. It couldn't both be a 6 and a 4. So the probability should be 0. But if you were to multiply probability of red 6 times probability of red 4, well, that would equal 1 over 36. But of course, that's not true. Because we know that there is no way, probability 0, that when we roll the red die once, we get both a 6 and a 4, because only one of those possibilities can actually be the result. And so we can say that the event that red roll is 6 and the event that red roll is 4, those two events are not independent. If I know that the red roll is a 6, I know that the red roll cannot possibly be a 4, so these things are not independent. And instead, if I wanted to calculate the probability, I would need to use this conditional probability as the regular definition of the probability of two events taking place. And the probability of this now, well, the probability of the red roll being a 6, that's 1 over 6. But what's the probability that the roll is a 4 given that the roll is a 6? Well, this is just 0, because there's no way for the red roll to be a 4, given that we already know the red roll is a 6. And so the value, if we do add all that multiplication, is we get the number 0. So this idea of conditional probability is going to come up again and again, especially as we begin to reason about multiple different random variables that might be interacting with each other in some way. And this gets us to one of the most important rules in probability theory, which is known as Bayes rule. And it turns out that just using the information we've already learned about probability and just applying a little bit of algebra, we can actually derive Bayes rule for ourselves. But it's a very important rule when it comes to inference and thinking about probability in the context of what it is that a computer can do or what a mathematician could do by having access to information about probability. So let's go back to these equations to be able to derive Bayes rule ourselves. We know the probability of A and B, the likelihood that A and B take place, is the likelihood of B, and then the likelihood of A, given that we know that B is already true. And likewise, the probability of A given A and B is the probability of A times the probability of B, given that we know that A is already true. This is sort of a symmetric relationship where it doesn't matter the order of A and B and B and A mean the same thing. And so in these equations, we can just swap out A and B to be able to represent the exact same idea. So we know that these two equations are already true. We've seen that already. And now let's just do a little bit of algebraic manipulation of this stuff. Both of these expressions on the right-hand side are equal to the probability of A and B. So what I can do is take these two expressions on the right-hand side and just set them equal to each other. If they're both equal to the probability of A and B, then they both must be equal to each other. So probability of A times probability of B given A is equal to the probability of B times the probability of A given B. And now all we're going to do is do a little bit of division. I'm going to divide both sides by P of A. And now I get what is Bayes' rule. The probability of B given A is equal to the probability of B times the probability of A given B divided by the probability of A. And sometimes in Bayes' rule, you'll see the order of these two arguments switched. So instead of B times A given B, it'll be A given B times B. That ultimately doesn't matter because in multiplication, you can switch the order of the two things you're multiplying, and it doesn't change the result. But this here right now is the most common formulation of Bayes' rule. The probability of B given A is equal to the probability of A given B times the probability of B divided by the probability of A. And this rule, it turns out, is really important when it comes to trying to infer things about the world, because it means you can express one conditional probability, the conditional probability of B given A, using knowledge about the probability of A given B, using the reverse of that conditional probability. So let's first do a little bit of an example with this, just to see how we might use it, and then explore what this means a little bit more generally. So we're going to construct a situation where I have some information. There are two events that I care about, the idea that it's cloudy in the morning and the idea that it is rainy in the afternoon. Those are two different possible events that could take place, cloudy in the morning, or the AM, rainy in the PM. And what I care about is, given clouds in the morning, what is the probability of rain in the afternoon? A reasonable question I might ask, in the morning, I look outside, or an AI's camera looks outside and sees that there are clouds in the morning. And we want to conclude, we want to figure out what is the probability that in the afternoon, there is going to be rain. Of course, in the abstract, we don't have access to this kind of information, but we can use data to begin to try and figure this out. So let's imagine now that I have access to some pieces of information. I have access to the idea that 80% of rainy afternoons start out with a cloudy morning. And you might imagine that I could have gathered this data just by looking at data over a sequence of time, that I know that 80% of the time when it's raining in the afternoon, it was cloudy that morning. I also know that 40% of days have cloudy mornings. And I also know that 10% of days have rainy afternoons. And now using this information, I would like to figure out, given clouds in the morning, what is the probability that it rains in the afternoon? I want to know the probability of afternoon rain given morning clouds. And I can do that, in particular, using this fact, the probability of, so if I know that 80% of rainy afternoons start with cloudy mornings, then I know the probability of cloudy mornings given rainy afternoons. So using sort of the reverse conditional probability, I can figure that out. Expressed in terms of Bayes rule, this is what that would look like. Probability of rain given clouds is the probability of clouds given rain times the probability of rain divided by the probability of clouds. Here I'm just substituting in for the values of a and b from that equation of Bayes rule from before. And then I can just do the math. I have this information. I know that 80% of the time, if it was raining, then there were clouds in the morning. So 0.8 here. Probability of rain is 0.1, because 10% of days were rainy, and 40% of days were cloudy. I do the math, and I can figure out the answer is 0.2. So the probability that it rains in the afternoon, given that it was cloudy in the morning, is 0.2 in this case. And this now is an application of Bayes rule, the idea that using one conditional probability, we can get the reverse conditional probability. And this is often useful when one of the conditional probabilities might be easier for us to know about or easier for us to have data about. And using that information, we can calculate the other conditional probability. So what does this look like? Well, it means that knowing the probability of cloudy mornings given rainy afternoons, we can calculate the probability of rainy afternoons given cloudy mornings. Or, for example, more generally, if we know the probability of some visible effect, some effect that we can see and observe, given some unknown cause that we're not sure about, well, then we can calculate the probability of that unknown cause given the visible effect. So what might that look like? Well, in the context of medicine, for example, I might know the probability of some medical test result given a disease. Like, I know that if someone has a disease, then x% of the time the medical test result will show up as this, for instance. And using that information, then I can calculate, all right, what is the probability that given I know the medical test result, what is the likelihood that someone has the disease? This is the piece of information that is usually easier to know, easier to immediately have access to data for. And this is the information that I actually want to calculate. Or I might want to know, for example, if I know that some probability of counterfeit bills have blurry text around the edges, because counterfeit printers aren't nearly as good at printing text precisely. So I have some information about, given that something is a counterfeit bill, like x% of counterfeit bills have blurry text, for example. And using that information, then I can calculate some piece of information that I might want to know, like, given that I know there's blurry text on a bill, what is the probability that that bill is counterfeit? So given one conditional probability, I can calculate the other conditional probability as well. And so now we've taken a look at a couple of different types of probability. And we've looked at unconditional probability, where I just look at what is the probability of this event occurring, given no additional evidence that I might have access to. And we've also looked at conditional probability, where I have some sort of evidence, and I would like to, using that evidence, be able to calculate some other probability as well. And the other kind of probability that will be important for us to think about is joint probability. And this is when we're considering the likelihood of multiple different events simultaneously. And so what do we mean by this? For example, I might have probability distributions that look a little something like this. Like, oh, I want to know the probability distribution of clouds in the morning. And that distribution looks like this. 40% of the time, C, which is my random variable here, is equal to it's cloudy. And 60% of the time, it's not cloudy. So here is just a simple probability distribution that is effectively telling me that 40% of the time, it's cloudy. I might also have a probability distribution for rain in the afternoon, where 10% of the time, or with probability 0.1, it is raining in the afternoon. And with probability 0.9, it is not raining in the afternoon. And using just these two pieces of information, I don't actually have a whole lot of information about how these two variables relate to each other. But I could if I had access to their joint probability, meaning for every combination of these two things, meaning morning cloudy and afternoon rain, morning cloudy and afternoon not rain, morning not cloudy and afternoon rain, and morning not cloudy and afternoon not raining, if I had access to values for each of those four, I'd have more information. So information that'd be organized in a table like this, and this, rather than just a probability distribution, is a joint probability distribution. It tells me the probability distribution of each of the possible combinations of values that these random variables can take on. So if I want to know what is the probability that on any given day it is both cloudy and rainy, well, I would say, all right, we're looking at cases where it is cloudy and cases where it is raining. And the intersection of those two, that row in that column, is 0.08. So that is the probability that it is both cloudy and rainy using that information. And using this conditional probability table, using this joint probability table, I can begin to draw other pieces of information about things like conditional probability. So I might ask a question like, what is the probability distribution of clouds given that I know that it is raining? Meaning I know for sure that it's raining. Tell me the probability distribution over whether it's cloudy or not, given that I know already that it is, in fact, raining. And here I'm using C to stand for that random variable. I'm looking for a distribution, meaning the answer to this is not going to be a single value. It's going to be two values, a vector of two values, where the first value is probability of clouds, the second value is probability that it is not cloudy, but the sum of those two values is going to be 1. Because when you add up the probabilities of all of the possible worlds, the result that you get must be the number 1. And well, what do we know about how to calculate a conditional probability? Well, we know that the probability of A given B is the probability of A and B divided by the probability of B. So what does this mean? Well, it means that I can calculate the probability of clouds given that it's raining as the probability of clouds and raining divided by the probability of rain. And this comma here for the probability distribution of clouds and rain, this comma sort of stands in for the word and. You'll sort of see in the logical operator and and the comma used interchangeably. This means the probability distribution over the clouds and knowing the fact that it is raining divided by the probability of rain. And the interesting thing to note here and what we'll often do in order to simplify our mathematics is that dividing by the probability of rain, the probability of rain here is just some numerical constant. It is some number. Dividing by probability of rain is just dividing by some constant, or in other words, multiplying by the inverse of that constant. And it turns out that oftentimes we can just not worry about what the exact value of this is and just know that it is, in fact, a constant value. And we'll see why in a moment. So instead of expressing this as this joint probability divided by the probability of rain, sometimes we'll just represent it as alpha times the numerator here, the probability distribution of C, this variable, and that we know that it is raining, for instance. So all we've done here is said this value of 1 over the probability of rain, that's really just a constant we're going to divide by or equivalently multiply by the inverse of at the end. We'll just call it alpha for now and deal with it a little bit later. But the key idea here now, and this is an idea that's going to come up again, is that the conditional distribution of C given rain is proportional to, meaning just some factor multiplied by the joint probability of C and rain being true. And so how do we figure this out? Well, this is going to be the probability that it is cloudy given that it's raining, which is 0.08, and the probability that it's not cloudy given that it's raining, which is 0.02. And so we get alpha times here now is that probability distribution. 0.08 is clouds and rain. 0.02 is not cloudy and rain. But of course, 0.08 and 0.02 don't sum up to the number 1. And we know that in a probability distribution, if you consider all of the possible values, they must sum up to a probability of 1. And so we know that we just need to figure out some constant to normalize, so to speak, these values, something we can multiply or divide by to get it so that all these probabilities sum up to 1, and it turns out that if we multiply both numbers by 10, then we can get that result of 0.8 and 0.2. The proportions are still equivalent, but now 0.8 plus 0.2, those sum up to the number 1. So take a look at this and see if you can understand step by step how it is we're getting from one point to another. The key idea here is that by using the joint probabilities, these probabilities that it is both cloudy and rainy and that it is not cloudy and rainy, I can take that information and figure out the conditional probability given that it's raining. What is the chance that it's cloudy versus not cloudy? Just by multiplying by some normalization constant, so to speak. And this is what a computer can begin to use to be able to interact with these various different types of probabilities. And it turns out there are a number of other probability rules that are going to be useful to us as we begin to explore how we can actually use this information to encode into our computers some more complex analysis that we might want to do about probability and distributions and random variables that we might be interacting with. So here are a couple of those important probability rules. One of the simplest rules is just this negation rule. What is the probability of not event A? So A is an event that has some probability, and I would like to know what is the probability that A does not occur. And it turns out it's just 1 minus P of A, which makes sense. Because if those are the two possible cases, either A happens or A doesn't happen, then when you add up those two cases, you must get 1, which means that P of not A must just be 1 minus P of A. Because P of A and P of not A must sum up to the number 1. They must include all of the possible cases. We've seen an expression for calculating the probability of A and B. We might also reasonably want to calculate the probability of A or B. What is the probability that one thing happens or another thing happens? So for example, I might want to calculate what is the probability that if I roll two dice, a red die and a blue die, what is the likelihood that A is a 6 or B is a 6, like one or the other? And what you might imagine you could do, and the wrong way to approach it, would be just to say, all right, well, A comes up as a 6 with the red die comes up as a 6 with probability 1 over 6. The same for the blue die, it's also 1 over 6. Add them together, and you get 2 over 6, otherwise known as 1 third. But this suffers from a problem of over counting, that we've double counted the case, where both A and B, both the red die and the blue die, both come up as a 6-roll. And I've counted that instance twice. So to resolve this, the actual expression for calculating the probability of A or B uses what we call the inclusion-exclusion formula. So I take the probability of A, add it to the probability of B. That's all same as before. But then I need to exclude the cases that I've double counted. So I subtract from that the probability of A and B. And that gets me the result for A or B. I consider all the cases where A is true and all the cases where B is true. And if you imagine this is like a Venn diagram of cases where A is true, cases where B is true, I just need to subtract out the middle to get rid of the cases that I have overcounted by double counting them inside of both of these individual expressions. One other rule that's going to be quite helpful is a rule called marginalization. So marginalization is answering the question of how do I figure out the probability of A using some other variable that I might have access to, like B? Even if I don't know additional information about it, I know that B, some event, can have two possible states, either B happens or B doesn't happen, assuming it's a Boolean, true or false. And well, what that means is that for me to be able to calculate the probability of A, there are only two cases. Either A happens and B happens, or A happens and B doesn't happen. And those are two disjoint, meaning they can't both happen together. Either B happens or B doesn't happen. They're disjoint or separate cases. And so I can figure out the probability of A just by adding up those two cases. The probability that A is true is the probability that A and B is true, plus the probability that A is true and B isn't true. So by marginalizing, I've looked at the two possible cases that might take place, either B happens or B doesn't happen. And in either of those cases, I look at what's the probability that A happens. And if I add those together, well, then I get the probability that A happens as a whole. So take a look at that rule. It doesn't matter what B is or how it's related to A. So long as I know these joint distributions, I can figure out the overall probability of A. And this can be a useful way if I have a joint distribution, like the joint distribution of A and B, to just figure out some unconditional probability, like the probability of A. And we'll see examples of this soon as well. Now, sometimes these might not just be random, might not just be variables that are events that are like they happened or they didn't happen, like B is here. They might be some broader probability distribution where there are multiple possible values. And so here, in order to use this marginalization rule, I need to sum up not just over B and not B, but for all of the possible values that the other random variable could take on. And so here, we'll see a version of this rule for random variables. And it's going to include that summation notation to indicate that I'm summing up, adding up a whole bunch of individual values. So here's the rule. Looks a lot more complicated, but it's actually the equivalent exactly the same rule. What I'm saying here is that if I have two random variables, one called x and one called y, well, the probability that x is equal to some value x sub i, this is just some value that this variable takes on. How do I figure it out? Well, I'm going to sum up over j, where j is going to range over all of the possible values that y can take on. Well, let's look at the probability that x equals xi and y equals yj. So the exact same rule, the only difference here is now I'm summing up over all of the possible values that y can take on, saying let's add up all of those possible cases and look at this joint distribution, this joint probability, that x takes on the value I care about, given all of the possible values for y. And if I add all those up, then I can get this unconditional probability of what x is equal to, whether or not x is equal to some value x sub i. So let's take a look at this rule, because it does look a little bit complicated. Let's try and put a concrete example to it. Here again is that same joint distribution from before. I have cloud, not cloudy, rainy, not rainy. And maybe I want to access some variable. I want to know what is the probability that it is cloudy. Well, marginalization says that if I have this joint distribution and I want to know what is the probability that it is cloudy, well, I need to consider the other variable, the variable that's not here, the idea that it's rainy. And I consider the two cases, either it's raining or it's not raining. And I just sum up the values for each of those possibilities. In other words, the probability that it is cloudy is equal to the sum of the probability that it's cloudy and it's rainy and the probability that it's cloudy and it is not raining. And so these now are values that I have access to. These are values that are just inside of this joint probability table. What is the probability that it is both cloudy and rainy? Well, it's just the intersection of these two here, which is 0.08. And the probability that it's cloudy and not raining is, all right, here's cloudy, here's not raining. It's 0.32. So it's 0.08 plus 0.32, which just gives us equal to 0.4. That is the unconditional probability that it is, in fact, cloudy. And so marginalization gives us a way to go from these joint distributions to just some individual probability that I might care about. And you'll see a little bit later why it is that we care about that and why that's actually useful to us as we begin doing some of these calculations. Last rule we'll take a look at before transitioning to something a little bit different is this rule of conditioning, very similar to the marginalization rule. But it says that, again, if I have two events, a and b, but instead of having access to their joint probabilities, I have access to their conditional probabilities, how they relate to each other. Well, again, if I want to know the probability that a happens, and I know that there's some other variable b, either b happens or b doesn't happen, and so I can say that the probability of a is the probability of a given b times the probability of b, meaning b happened. And given that I know b happened, what's the likelihood that a happened? And then I consider the other case, that b didn't happen. So here's the probability that b didn't happen. And here's the probability that a happens, given that I know that b didn't happen. And this is really the equivalent rule just using conditional probability instead of joint probability, where I'm saying let's look at both of these two cases and condition on b. Look at the case where b happens, and look at the case where b doesn't happen, and look at what probabilities I get as a result. And just as in the case of marginalization, where there was an equivalent rule for random variables that could take on multiple possible values in a domain of possible values, here, too, conditioning has the same equivalent rule. Again, there's a summation to mean I'm summing over all of the possible values that some random variable y could take on. But if I want to know what is the probability that x takes on this value, then I'm going to sum up over all the values j that y could take on, and say, all right, what's the chance that y takes on that value yj? And multiply it by the conditional probability that x takes on this value, given that y took on that value yj. So equivalent rule just using conditional probabilities instead of joint probabilities. And using the equation we know about joint probabilities, we can translate between these two. So all right, we've seen a whole lot of mathematics, and we've just laid the foundation for mathematics. And no need to worry if you haven't seen probability in too much detail up until this point. These are the foundations of the ideas that are going to come up as we begin to explore how we can now take these ideas from probability and begin to apply them to represent something inside of our computer, something inside of the AI agent we're trying to design that is able to represent information and probabilities and the likelihoods between various different events. So there are a number of different probabilistic models that we can generate, but the first of the models we're going to talk about are what are known as Bayesian networks. And a Bayesian network is just going to be some network of random variables, connected random variables that are going to represent the dependence between these random variables. The odds are most random variables in this world are not independent from each other, but there's some relationship between things that are happening that we care about. If it is rainy today, that might increase the likelihood that my flight or my train gets delayed, for example. There are some dependence between these random variables, and a Bayesian network is going to be able to capture those dependencies. So what is a Bayesian network? What is its actual structure, and how does it work? Well, a Bayesian network is going to be a directed graph. And again, we've seen directed graphs before. They are individual nodes with arrows or edges that connect one node to another node pointing in a particular direction. And so this directed graph is going to have nodes as well, where each node in this directed graph is going to represent a random variable, something like the weather, or something like whether my train was on time or delayed. And we're going to have an arrow from a node x to a node y to mean that x is a parent of y. So that'll be our notation. If there's an arrow from x to y, x is going to be considered a parent of y. And the reason that's important is because each of these nodes is going to have a probability distribution that we're going to store along with it, which is the distribution of x given some evidence, given the parents of x. So the way to more intuitively think about this is the parents seem to be thought of as sort of causes for some effect that we're going to observe. And so let's take a look at an actual example of a Bayesian network and think about the types of logic that might be involved in reasoning about that network. Let's imagine for a moment that I have an appointment out of town, and I need to take a train in order to get to that appointment. So what are the things I might care about? Well, I care about getting to my appointment on time. Whether I make it to my appointment and I'm able to attend it or I miss the appointment. And you might imagine that that's influenced by the train, that the train is either on time or it's delayed, for example. But that train itself is also influenced. Whether the train is on time or not depends maybe on the rain. Is there no rain? Is it light rain? Is there heavy rain? And it might also be influenced by other variables too. It might be influenced as well by whether or not there's maintenance on the train track, for example. If there is maintenance on the train track, that probably increases the likelihood that my train is delayed. And so we can represent all of these ideas using a Bayesian network that looks a little something like this. Here I have four nodes representing four random variables that I would like to keep track of. I have one random variable called rain that can take on three possible values in its domain, either none or light or heavy, for no rain, light rain, or heavy rain. I have a variable called maintenance for whether or not there is maintenance on the train track, which it has two possible values, just either yes or no. Either there is maintenance or there's no maintenance happening on the track. Then I have a random variable for the train indicating whether or not the train was on time or not. That random variable has two possible values in its domain. The train is either on time or the train is delayed. And then finally, I have a random variable for whether I make it to my appointment. For my appointment down here, I have a random variable called appointment that itself has two possible values, attend and miss. And so here are the possible values. Here are my four nodes, each of which represents a random variable, each of which has a domain of possible values that it can take on. And the arrows, the edges pointing from one node to another, encode some notion of dependence inside of this graph, that whether I make it to my appointment or not is dependent upon whether the train is on time or delayed. And whether the train is on time or delayed is dependent on two things given by the two arrows pointing at this node. It is dependent on whether or not there was maintenance on the train track. And it is also dependent upon whether or not it was raining or whether it is raining. And just to make things a little complicated, let's say as well that whether or not there is maintenance on the track, this too might be influenced by the rain. That if there's heavier rain, well, maybe it's less likely that it's going to be maintenance on the train track that day because they're more likely to want to do maintenance on the track on days when it's not raining, for example. And so these nodes might have different relationships between them. But the idea is that we can come up with a probability distribution for any of these nodes based only upon its parents. And so let's look node by node at what this probability distribution might actually look like. And we'll go ahead and begin with this root node, this rain node here, which is at the top, and has no arrows pointing into it, which means its probability distribution is not going to be a conditional distribution. It's not based on anything. I just have some probability distribution over the possible values for the rain random variable. And that distribution might look a little something like this. None, light and heavy, each have a possible value. Here I'm saying the likelihood of no rain is 0.7, of light rain is 0.2, of heavy rain is 0.1, for example. So here is a probability distribution for this root node in this Bayesian network. And let's now consider the next node in the network, maintenance. Track maintenance is yes or no. And the general idea of what this distribution is going to encode, at least in this story, is the idea that the heavier the rain is, the less likely it is that there's going to be maintenance on the track. Because the people that are doing maintenance on the track probably want to wait until a day when it's not as rainy in order to do the track maintenance, for example. And so what might that probability distribution look like? Well, this now is going to be a conditional probability distribution, that here are the three possible values for the rain random variable, which I'm here just going to abbreviate to R, either no rain, light rain, or heavy rain. And for each of those possible values, either there is yes track maintenance or no track maintenance. And those have probabilities associated with them. That I see here that if it is not raining, then there is a probability of 0.4 that there's track maintenance and a probability of 0.6 that there isn't. But if there's heavy rain, then here the chance that there is track maintenance is 0.1 and the chance that there is not track maintenance is 0.9. Each of these rows is going to sum up to 1. Because each of these represent different values of whether or not it's raining, the three possible values that that random variable can take on. And each is associated with its own probability distribution that is ultimately all going to add up to the number 1. So that there is our distribution for this random variable called maintenance, about whether or not there is maintenance on the train track. And now let's consider the next variable. Here we have a node inside of our Bayesian network called train that has two possible values, on time and delayed. And this node is going to be dependent upon the two nodes that are pointing towards it, that whether or not the train is on time or delayed depends on whether or not there is track maintenance. And it depends on whether or not there is rain, that heavier rain probably means more likely that my train is delayed. And if there is track maintenance, that also probably means it's more likely that my train is delayed as well. And so you could construct a larger probability distribution, a conditional probability distribution, that instead of conditioning on just one variable, as was the case here, is now conditioning on two variables, conditioning both on rain represented by r and on maintenance represented by yes. Again, each of these rows has two values that sum up to the number 1, one for whether the train is on time, one for whether the train is delayed. And here I can say something like, all right, if I know there was light rain and track maintenance, well, OK, that would be r is light and m is yes. Well, then there is a probability of 0.6 that my train is on time, and a probability of 0.4 the train is delayed. And you can imagine gathering this data just by looking at real world data, looking at data about, all right, if I knew that it was light rain and there was track maintenance, how often was a train delayed or not delayed? And you could begin to construct this thing. The interesting thing is intelligently, being able to try to figure out how might you go about ordering these things, what things might influence other nodes inside of this Bayesian network. And the last thing I care about is whether or not I make it to my appointment. So did I attend or miss the appointment? And ultimately, whether I attend or miss the appointment, it is influenced by track maintenance, because it's indirectly this idea that, all right, if there is track maintenance, well, then my train might more likely be delayed. And if my train is more likely to be delayed, then I'm more likely to miss my appointment. But what we encode in this Bayesian network are just what we might consider to be more direct relationships. So the train has a direct influence on the appointment. And given that I know whether the train is on time or delayed, knowing whether there's track maintenance isn't going to give me any additional information that I didn't already have. That if I know train, these other nodes that are up above isn't really going to influence the result. And so here we might represent it using another conditional probability distribution that looks a little something like this. The train can take on two possible values. Either my train is on time or my train is delayed. And for each of those two possible values, I have a distribution for what are the odds that I'm able to attend the meeting and what are the odds that I missed the meeting. And obviously, if my train is on time, I'm much more likely to be able to attend the meeting than if my train is delayed, in which case I'm more likely to miss that meeting. So all of these nodes put all together here represent this Bayesian network, this network of random variables whose values I ultimately care about, and that have some sort of relationship between them, some sort of dependence where these arrows from one node to another indicate some dependence, that I can calculate the probability of some node given the parents that happen to exist there. So now that we've been able to describe the structure of this Bayesian network and the relationships between each of these nodes by associating each of the nodes in the network with a probability distribution, whether that's an unconditional probability distribution in the case of this root node here, like rain, and a conditional probability distribution in the case of all of the other nodes whose probabilities are dependent upon the values of their parents, we can begin to do some computation and calculation using the information inside of that table. So let's imagine, for example, that I just wanted to compute something simple like the probability of light rain. How would I get the probability of light rain? Well, light rain, rain here is a root node. And so if I wanted to calculate that probability, I could just look at the probability distribution for rain and extract from it the probability of light rains, just a single value that I already have access to. But we could also imagine wanting to compute more complex joint probabilities, like the probability that there is light rain and also no track maintenance. This is a joint probability of two values, light rain and no track maintenance. And the way I might do that is first by starting by saying, all right, well, let me get the probability of light rain. But now I also want the probability of no track maintenance. But of course, this node is dependent upon the value of rain. So what I really want is the probability of no track maintenance, given that I know that there was light rain. And so the expression for calculating this idea that the probability of light rain and no track maintenance is really just the probability of light rain and the probability that there is no track maintenance, given that I know that there already is light rain. So I take the unconditional probability of light rain, multiply it by the conditional probability of no track maintenance, given that I know there is light rain. And you can continue to do this again and again for every variable that you want to add into this joint probability that I might want to calculate. If I wanted to know the probability of light rain and no track maintenance and a delayed train, well, that's going to be the probability of light rain, multiplied by the probability of no track maintenance, given light rain, multiplied by the probability of a delayed train, given light rain and no track maintenance. Because whether the train is on time or delayed is dependent upon both of these other two variables. And so I have two pieces of evidence that go into the calculation of that conditional probability. And each of these three values is just a value that I can look up by looking at one of these individual probability distributions that is encoded into my Bayesian network. And if I wanted a joint probability over all four of the variables, something like the probability of light rain and no track maintenance and a delayed train and I miss my appointment, well, that's going to be multiplying four different values, one from each of these individual nodes. It's going to be the probability of light rain, then of no track maintenance given light rain, then of a delayed train, given light rain and no track maintenance. And then finally, for this node here, for whether I make it to my appointment or not, it's not dependent upon these two variables, given that I know whether or not the train is on time. I only need to care about the conditional probability that I miss my train, or that I miss my appointment, given that the train happens to be delayed. And so that's represented here by four probabilities, each of which is located inside of one of these probability distributions for each of the nodes, all multiplied together. And so I can take a variable like that and figure out what the joint probability is by multiplying a whole bunch of these individual probabilities from the Bayesian network. But of course, just as with last time, where what I really wanted to do was to be able to get new pieces of information, here, too, this is what we're going to want to do with our Bayesian network. In the context of knowledge, we talked about the problem of inference. Given things that I know to be true, can I draw conclusions, make deductions about other facts about the world that I also know to be true? And what we're going to do now is apply the same sort of idea to probability. Using information about which I have some knowledge, whether some evidence or some probabilities, can I figure out not other variables for certain, but can I figure out the probabilities of other variables taking on particular values? And so here, we introduce the problem of inference in a probabilistic setting, in a case where variables might not necessarily be true for sure, but they might be random variables that take on different values with some probability. So how do we formally define what exactly this inference problem actually is? Well, the inference problem has a couple of parts to it. We have some query, some variable x that we want to compute the distribution for. Maybe I want the probability that I miss my train, or I want the probability that there is track maintenance, something that I want information about. And then I have some evidence variables. Maybe it's just one piece of evidence. Maybe it's multiple pieces of evidence. But I've observed certain variables for some sort of event. So for example, I might have observed that it is raining. This is evidence that I have. I know that there is light rain, or I know that there is heavy rain. And that is evidence I have. And using that evidence, I want to know what is the probability that my train is delayed, for example. And that is a query that I might want to ask based on this evidence. So I have a query, some variable. Evidence, which are some other variables that I have observed inside of my Bayesian network. And of course, that does leave some hidden variables. Why? These are variables that are not evidence variables and not query variables. So you might imagine in the case where I know whether or not it's raining, and I want to know whether my train is going to be delayed or not, the hidden variable, the thing I don't have access to, is something like, is there maintenance on the track? Or am I going to make or not make my appointment, for example? These are variables that I don't have access to. They're hidden because they're not things I observed, and they're also not the query, the thing that I'm asking. And so ultimately, what we want to calculate is I want to know the probability distribution of x given e, the event that I observed. So given that I observed some event, I observed that it is raining, I would like to know what is the distribution over the possible values of the train random variable. Is it on time? Is it delayed? What's the likelihood it's going to be there? And it turns out we can do this calculation just using a lot of the probability rules that we've already seen in action. And ultimately, we're going to take a look at the math at a little bit of a high level, at an abstract level. But ultimately, we can allow computers and programming libraries that already exist to begin to do some of this math for us. But it's good to get a general sense for what's actually happening when this inference process takes place. Let's imagine, for example, that I want to compute the probability distribution of the appointment random variable given some evidence, given that I know that there was light rain and no track maintenance. So there's my evidence, these two variables that I observe the values of. I observe the value of rain. I know there's light rain. And I know that there is no track maintenance going on today. And what I care about knowing, my query, is this random variable appointment. I want to know the distribution of this random variable appointment, like what is the chance that I'm able to attend my appointment? What is the chance that I miss my appointment given this evidence? And the hidden variable, the information that I don't have access to, is this variable train. This is information that is not part of the evidence that I see, not something that I observe. But it is also not the query that I'm asking for. And so what might this inference procedure look like? Well, if you recall back from when we were defining conditional probability and doing math with conditional probabilities, we know that a conditional probability is proportional to the joint probability. And we remembered this by recalling that the probability of A given B is just some constant factor alpha multiplied by the probability of A and B. That constant factor alpha turns out to be like dividing over the probability of B. But the important thing is that it's just some constant multiplied by the joint distribution, the probability that all of these individual things happen. So in this case, I can take the probability of the appointment random variable given light rain and no track maintenance and say that is just going to be proportional, some constant alpha, multiplied by the joint probability, the probability of a particular value for the appointment random variable and light rain and no track maintenance. Well, all right, how do I calculate this, probability of appointment and light rain and no track maintenance, when what I really care about is knowing I need all four of these values to be able to calculate a joint distribution across everything because in a particular appointment depends upon the value of train? Well, in order to do that, here I can begin to use that marginalization trick, that there are only two ways I can get any configuration of an appointment, light rain, and no track maintenance. Either this particular setting of variables happens and the train is on time, or this particular setting of variables happens and the train is delayed. Those are two possible cases that I would want to consider. And if I add those two cases up, well, then I get the result just by adding up all of the possibilities for the hidden variable or variables that there are multiple. But since there's only one hidden variable here, train, all I need to do is iterate over all the possible values for that hidden variable train and add up their probabilities. So this probability expression here becomes probability distribution over appointment, light, no rain, and train is on time, and the probability distribution over the appointment, light rain, no track maintenance, and that the train is delayed, for example. So I take both of the possible values for train, go ahead and add them up. These are just joint probabilities that we saw earlier, how to calculate just by going parent, parent, parent, parent, and calculating those probabilities and multiplying them together. And then you'll need to normalize them at the end, speaking at a high level, to make sure that everything adds up to the number 1. So the formula for how you do this in a process known as inference by enumeration looks a little bit complicated, but ultimately it looks like this. And let's now try to distill what it is that all of these symbols actually mean. Let's start here. What I care about knowing is the probability of x, my query variable, given some sort of evidence. What do I know about conditional probabilities? Well, a conditional probability is proportional to the joint probability. So it is some alpha, some normalizing constant, multiplied by this joint probability of x and evidence. And how do I calculate that? Well, to do that, I'm going to marginalize over all of the hidden variables, all the variables that I don't directly observe the values for. I'm basically going to iterate over all of the possibilities that it could happen and just sum them all up. And so I can translate this into a sum over all y, which ranges over all the possible hidden variables and the values that they could take on, and adds up all of those possible individual probabilities. And that is going to allow me to do this process of inference by enumeration. Now, ultimately, it's pretty annoying if we as humans have to do all this math for ourselves. But turns out this is where computers and AI can be particularly helpful, that we can program a computer to understand a Bayesian network, to be able to understand these inference procedures, and to be able to do these calculations. And using the information you've seen here, you could implement a Bayesian network from scratch yourself. But turns out there are a lot of libraries, especially written in Python, that allow us to make it easier to do this sort of probabilistic inference, to be able to take a Bayesian network and do these sorts of calculations, so that you don't need to know and understand all of the underlying math, though it's helpful to have a general sense for how it works. But you just need to be able to describe the structure of the network and make queries in order to be able to produce the result. And so let's take a look at an example of that right now. It turns out that there are a lot of possible libraries that exist in Python for doing this sort of inference. It doesn't matter too much which specific library you use. They all behave in fairly similar ways. But the library I'm going to use here is one known as pomegranate. And here inside of model.py, I have defined a Bayesian network, just using the structure and the syntax that the pomegranate library expects. And what I'm effectively doing is just, in Python, creating nodes to represent each of the nodes of the Bayesian network that you saw me describe a moment ago. So here on line four, after I've imported pomegranate, I'm defining a variable called rain that is going to represent a node inside of my Bayesian network. It's going to be a node that follows this distribution, where there are three possible values, none for no rain, light for light rain, heavy for heavy rain. And these are the probabilities of each of those taking place. 0.7 is the likelihood of no rain, 0.2 for light rain, 0.1 for heavy rain. Then after that, we go to the next variable, the variable for track maintenance, for example, which is dependent upon that rain variable. And this, instead of being an unconditional distribution, is a conditional distribution, as indicated by a conditional probability table here. And the idea is that I'm following this is conditional on the distribution of rain. So if there is no rain, then the chance that there is, yes, track maintenance is 0.4. If there's no rain, the chance that there is no track maintenance is 0.6. Likewise, for light rain, I have a distribution. For heavy rain, I have a distribution as well. But I'm effectively encoding the same information you saw represented graphically a moment ago. But I'm telling this Python program that the maintenance node obeys this particular conditional probability distribution. And we do the same thing for the other random variables as well. Train was a node inside my distribution that was a conditional probability table with two parents. It was dependent not only on rain, but also on track maintenance. And so here I'm saying something like, given that there is no rain and, yes, track maintenance, the probability that my train is on time is 0.8. And the probability that it's delayed is 0.2. And likewise, I can do the same thing for all of the other possible values of the parents of the train node inside of my Bayesian network by saying, for all of those possible values, here is the distribution that the train node should follow. Then I do the same thing for an appointment based on the distribution of the variable train. Then at the end, what I do is actually construct this network by describing what the states of the network are and by adding edges between the dependent nodes. So I create a new Bayesian network, add states to it, one for rain, one for maintenance, one for the train, one for the appointment. And then I add edges connecting the related pieces. Rain has an arrow to maintenance because rain influences track maintenance. Rain also influences the train. Maintenance also influences the train. And train influences whether I make it to my appointment and bake just finalizes the model and does some additional computation. So the specific syntax of this is not really the important part. Pomegranate just happens to be one of several different libraries that can all be used for similar purposes. And you could describe and define a library for yourself that implemented similar things. But the key idea here is that someone can design a library for a general Bayesian network that has nodes that are based upon its parents. And then all a programmer needs to do using one of those libraries is to define what those nodes and what those probability distributions are. And we can begin to do some interesting logic based on it. So let's try doing that conditional or joint probability calculation that we saw us do by hand before by going into likelihood.py, where here I'm importing the model that I just defined a moment ago. And here I'd just like to calculate model.probability, which calculates the probability for a given observation. And I'd like to calculate the probability of no rain, no track maintenance, my train is on time, and I'm able to attend the meeting. So sort of the optimal scenario that there is no rain and no maintenance on the track, my train is on time, and I'm able to attend the meeting. What is the probability that all of that actually happens? And I can calculate that using the library and just print out its probability. And so I'll go ahead and run python of likelihood.py. And I see that, OK, the probability is about 0.34. So about a third of the time, everything goes right for me in this case. No rain, no track maintenance, train is on time, and I'm able to attend the meeting. But I could experiment with this, try and calculate other probabilities as well. What's the probability that everything goes right up until the train, but I still miss my meeting? So no rain, no track maintenance, train is on time, but I miss the appointment. Let's calculate that probability. And all right, that has a probability of about 0.04. So about 4% of the time, the train will be on time, there won't be any rain, no track maintenance, and yet I'll still miss the meeting. And so this is really just an implementation of the calculation of the joint probabilities that we did before. What this library is likely doing is first figuring out the probability of no rain, then figuring out the probability of no track maintenance given no rain, then the probability that my train is on time given both of these values, and then the probability that I miss my appointment given that I know that the train was on time. So this, again, is the calculation of that joint probability. And turns out we can also begin to have our computer solve inference problems as well, to begin to infer, based on information, evidence that we see, what is the likelihood of other variables also being true. So let's go into inference.py, for example. We're here, I'm again importing that exact same model from before, importing all the nodes and all the edges and the probability distribution that is encoded there as well. And now there's a function for doing some sort of prediction. And here, into this model, I pass in the evidence that I observe. So here, I've encoded into this Python program the evidence that I have observed. I have observed the fact that the train is delayed. And that is the value for one of the four random variables inside of this Bayesian network. And using that information, I would like to be able to draw inspiration and figure out inferences about the values of the other random variables that are inside of my Bayesian network. I would like to make predictions about everything else. So all of the actual computational logic is happening in just these three lines, where I'm making this call to this prediction. Down below, I'm just iterating over all of the states and all the predictions and just printing them out so that we can visually see what the results are. But let's find out, given the train is delayed, what can I predict about the values of the other random variables? Let's go ahead and run python inference.py. I run that, and all right, here is the result that I get. Given the fact that I know that the train is delayed, this is evidence that I have observed. Well, given that there is a 45% chance or a 46% chance that there was no rain, a 31% chance there was light rain, a 23% chance there was heavy rain, I can see a probability distribution of a track maintenance and a probability distribution over whether I'm able to attend or miss my appointment. Now, we know that whether I attend or miss the appointment, that is only dependent upon the train being delayed or not delayed. It shouldn't depend on anything else. So let's imagine, for example, that I knew that there was heavy rain. That shouldn't affect the distribution for making the appointment. And indeed, if I go up here and add some evidence, say that I know that the value of rain is heavy. That is evidence that I now have access to. I now have two pieces of evidence. I know that the rain is heavy, and I know that my train is delayed. I can calculate the probability by running this inference procedure again and seeing the result. I know that the rain is heavy. I know my train is delayed. The probability distribution for track maintenance changed. Given that I know that there's heavy rain, now it's more likely that there is no track maintenance, 88%, as opposed to 64% from here before. And now, what is the probability that I make the appointment? Well, that's the same as before. It's still going to be attend the appointment with probability 0.6, missed the appointment with probability 0.4, because it was only dependent upon whether or not my train was on time or delayed. And so this here is implementing that idea of that inference algorithm to be able to figure out, based on the evidence that I have, what can we infer about the values of the other variables that exist as well. So inference by enumeration is one way of doing this inference procedure, just looping over all of the values the hidden variables could take on and figuring out what the probability is. Now, it turns out this is not particularly efficient. And there are definitely optimizations you can make by avoiding repeated work. If you're calculating the same sort of probability multiple times, there are ways of optimizing the program to avoid having to recalculate the same probabilities again and again. But even then, as the number of variables get large, as the number of possible values of variables could take on, get large, we're going to start to have to do a lot of computation, a lot of calculation, to be able to do this inference. And at that point, it might start to get unreasonable, in terms of the amount of time that it would take to be able to do this sort of exact inference. And it's for that reason that oftentimes, when it comes towards probability and things we're not entirely sure about, we don't always care about doing exact inference and knowing exactly what the probability is. But if we can approximate the inference procedure, do some sort of approximate inference, that that can be pretty good as well. That if I don't know the exact probability, but I have a general sense for the probability that I can get increasingly accurate with more time, that that's probably pretty good, especially if I can get that to happen even faster. So how could I do approximate inference inside of a Bayesian network? Well, one method is through a procedure known as sampling. In the process of sampling, I'm going to take a sample of all of the variables inside of this Bayesian network here. And how am I going to sample? Well, I'm going to sample one of the values from each of these nodes according to their probability distribution. So how might I take a sample of all these nodes? Well, I'll start at the root. I'll start with rain. Here's the distribution for rain. And I'll go ahead and, using a random number generator or something like it, randomly pick one of these three values. I'll pick none with probability 0.7, light with probability 0.2, and heavy with probability 0.1. So I'll randomly just pick one of them according to that distribution. And maybe in this case, I pick none, for example. Then I do the same thing for the other variable. Maintenance also has a probability distribution. And I'm going to sample. Now, there are three probability distributions here. But I'm only going to sample from this first row here, because I've observed already in my sample that the value of rain is none. So given that rain is none, I'm going to sample from this distribution to say, all right, what should the value of maintenance be? And in this case, maintenance is going to be, let's just say yes, which happens 40% of the time in the event that there is no rain, for example. And we'll sample all of the rest of the nodes in this way as well, that I want to sample from the train distribution. And I'll sample from this first row here, where there is no rain, but there is track maintenance. And I'll sample 80% of the time. I'll say the train is on time. 20% of the time, I'll say the train is delayed. And finally, we'll do the same thing for whether I make it to my appointment or not. Did I attend or miss the appointment? We'll sample based on this distribution and maybe say that in this case, I attend the appointment, which happens 90% of the time when the train is actually on time. So by going through these nodes, I can very quickly just do some sampling and get a sample of the possible values that could come up from going through this entire Bayesian network according to those probability distributions. And where this becomes powerful is if I do this not once, but I do this thousands or tens of thousands of times and generate a whole bunch of samples all using this distribution. I get different samples. Maybe some of them are the same. But I get a value for each of the possible variables that could come up. And so then if I'm ever faced with a question, a question like, what is the probability that the train is on time, you could do an exact inference procedure. This is no different than the inference problem we had before where I could just marginalize, look at all the possible other values of the variables, and do the computation of inference by enumeration to find out this probability exactly. But I could also, if I don't care about the exact probability, just sample it, approximate it to get close. And this is a powerful tool in AI where we don't need to be right 100% of the time or we don't need to be exactly right. If we just need to be right with some probability, we can often do so more effectively, more efficiently. And so if here now are all of those possible samples, I'll highlight the ones where the train is on time. I'm ignoring the ones where the train is delayed. And in this case, there's like six out of eight of the samples have the train is arriving on time. And so maybe in this case, I can say that in six out of eight cases, that's the likelihood that the train is on time. And with eight samples, that might not be a great prediction. But if I had thousands upon thousands of samples, then this could be a much better inference procedure to be able to do these sorts of calculations. So this is a direct sampling method to just do a bunch of samples and then figure out what the probability of some event is. Now, this from before was an unconditional probability. What is the probability that the train is on time? And I did that by looking at all the samples and figuring out, right, here are the ones where the train is on time. But sometimes what I want to calculate is not an unconditional probability, but rather a conditional probability, something like what is the probability that there is light rain, given that the train is on time, something to that effect. And to do that kind of calculation, well, what I might do is here are all the samples that I have. And I want to calculate a probability distribution, given that I know that the train is on time. So to be able to do that, I can kind of look at the two cases where the train was delayed and ignore or reject them, sort of exclude them from the possible samples that I'm considering. And now I want to look at these remaining cases where the train is on time. Here are the cases where there is light rain. And I say, OK, these are two out of the six possible cases. That can give me an approximation for the probability of light rain, given the fact that I know the train was on time. And I did that in almost exactly the same way, just by adding an additional step, by saying that, all right, when I take each sample, let me reject all of the samples that don't match my evidence and only consider the samples that do match what it is that I have in my evidence that I want to make some sort of calculation about. And it turns out, using the libraries that we've had for Bayesian networks, we can begin to implement this same sort of idea, like implement rejection sampling, which is what this method is called, to be able to figure out some probability, not via direct inference, but instead by sampling. So what I have here is a program called sample.py. Imports the exact same model. And what I define first is a program to generate a sample. And the way I generate a sample is just by looping over all of the states. The states need to be in some sort of order to make sure I'm looping in the correct order. But effectively, if it is a conditional distribution, I'm going to sample based on the parents. And otherwise, I'm just going to directly sample the variable, like rain, which has no parents. It's just an unconditional distribution and keep track of all those parent samples and return the final sample. The exact syntax of this, again, not particularly important. It just happens to be part of the implementation details of this particular library. The interesting logic is down below. Now that I have the ability to generate a sample, if I want to know the distribution of the appointment random variable, given that the train is delayed, well, then I can begin to do calculations like this. Let me take 10,000 samples and assemble all my results in this list called data. I'll go ahead and loop n times, in this case, 10,000 times. I'll generate a sample. And I want to know the distribution of appointment, given that the train is delayed. So according to rejection sampling, I'm only going to consider samples where the train is delayed. If the train is not delayed, I'm not going to consider those values at all. So I'm going to say, all right, if I take the sample, look at the value of the train random variable, if the train is delayed, well, let me go ahead and add to my data that I'm collecting the value of the appointment random variable that it took on in this particular sample. So I'm only considering the samples where the train is delayed. And for each of those samples, considering what the value of appointment is, and then at the end, I'm using a Python class called counter, which quickly counts up all the values inside of a data set. So I can take this list of data and figure out how many times was my appointment made and how many times was my appointment missed. And so this here, with just a couple lines of code, is an implementation of rejection sampling. And I can run it by going ahead and running Python sample.py. And when I do that, here is the result I get. This is the result of the counter. 1,251 times, I was able to attend the meeting. And 856 times, I was able to miss the meeting. And you can imagine, by doing more and more samples, I'll be able to get a better and better, more accurate result. And this is a randomized process. It's going to be an approximation of the probability. If I run it a different time, you'll notice the numbers are similar, 12, 72, and 905. But they're not identical because there's some randomization, some likelihood that things might be higher or lower. And so this is why we generally want to try and use more samples so that we can have a greater amount of confidence in our result, be more sure about the result that we're getting of whether or not it accurately reflects or represents the actual underlying probabilities that are inherent inside of this distribution. And so this, then, was an instance of rejection sampling. And it turns out there are a number of other sampling methods that you could use to begin to try to sample. One problem that rejection sampling has is that if the evidence you're looking for is a fairly unlikely event, well, you're going to be rejecting a lot of samples. Like if I'm looking for the probability of x given some evidence e, if e is very unlikely to occur, like occurs maybe one every 1,000 times, then I'm only going to be considering 1 out of every 1,000 samples that I do, which is a pretty inefficient method for trying to do this sort of calculation. I'm throwing away a lot of samples. And it takes computational effort to be able to generate those samples. So I'd like to not have to do something like that. So there are other sampling methods that can try and address this. One such sampling method is called likelihood weighting. In likelihood weighting, we follow a slightly different procedure. And the goal is to avoid needing to throw out samples that didn't match the evidence. And so what we'll do is we'll start by fixing the values for the evidence variables. Rather than sample everything, we're going to fix the values of the evidence variables and not sample those. Then we're going to sample all the other non-evidence variables in the same way, just using the Bayesian network looking at the probability distributions, sampling all the non-evidence variables. But then what we need to do is weight each sample by its likelihood. If our evidence is really unlikely, we want to make sure that we've taken into account how likely was the evidence to actually show up in the sample. If I have a sample where the evidence was much more likely to show up than another sample, then I want to weight the more likely one higher. So we're going to weight each sample by its likelihood, where likelihood is just defined as the probability of all the evidence. Given all the evidence we have, what is the probability that it would happen in that particular sample? So before, all of our samples were weighted equally. They all had a weight of 1 when we were calculating the overall average. In this case, we're going to weight each sample, multiply each sample by its likelihood in order to get the more accurate distribution. So what would this look like? Well, if I ask the same question, what is the probability of light rain, given that the train is on time, when I do the sampling procedure and start by trying to sample, I'm going to start by fixing the evidence variable. I'm already going to have in my sample the train is on time. That way, I don't have to throw out anything. I'm only sampling things where I know the value of the variables that are my evidence are what I expect them to be. So I'll go ahead and sample from rain. And maybe this time, I sample light rain instead of no rain. Then I'll sample from track maintenance and say, maybe, yes, there's track maintenance. Then for train, well, I've already fixed it in place. Train was an evidence variable. So I'm not going to bother sampling again. I'll just go ahead and move on. I'll move on to appointment and go ahead and sample from appointment as well. So now I've generated a sample. I've generated a sample by fixing this evidence variable and sampling the other three. And the last step is now weighting the sample. How much weight should it have? And the weight is based on how probable is it that the train was actually on time, this evidence actually happened, given the values of these other variables, light rain and the fact that, yes, there was track maintenance. Well, to do that, I can just go back to the train variable and say, all right, if there was light rain and track maintenance, the likelihood of my evidence, the likelihood that my train was on time, is 0.6. And so this particular sample would have a weight of 0.6. And I could repeat the sampling procedure again and again. Each time every sample would be given a weight according to the probability of the evidence that I see associated with it. And there are other sampling methods that exist as well, but all of them are designed to try and get it the same idea, to approximate the inference procedure of figuring out the value of a variable. So we've now dealt with probability as it pertains to particular variables that have these discrete values. But what we haven't really considered is how values might change over time. That we've considered something like a variable for rain, where rain can take on values of none or light rain or heavy rain. But in practice, usually when we consider values for variables like rain, we like to consider it for over time, how do the values of these variables change? What do we do with when we're dealing with uncertainty over a period of time, which can come up in the context of weather, for example, if I have sunny days and I have rainy days. And I'd like to know not just what is the probability that it's raining now, but what is the probability that it rains tomorrow, or the day after that, or the day after that. And so to do this, we're going to introduce a slightly different kind of model. But here, we're going to have a random variable, not just one for the weather, but for every possible time step. And you can define time step however you like. A simple way is just to use days as your time step. And so we can define a variable called x sub t, which is going to be the weather at time t. So x sub 0 might be the weather on day 0. x sub 1 might be the weather on day 1, so on and so forth. x sub 2 is the weather on day 2. But as you can imagine, if we start to do this over longer and longer periods of time, there's an incredible amount of data that might go into this. If you're keeping track of data about the weather for a year, now suddenly you might be trying to predict the weather tomorrow, given 365 days of previous pieces of evidence. And that's a lot of evidence to have to deal with and manipulate and calculate. Probably nobody knows what the exact conditional probability distribution is for all of those combinations of variables. And so when we're trying to do this inference inside of a computer, when we're trying to reasonably do this sort of analysis, it's helpful to make some simplifying assumptions, some assumptions about the problem that we can just assume are true, to make our lives a little bit easier. Even if they're not totally accurate assumptions, if they're close to accurate or approximate, they're usually pretty good. And the assumption we're going to make is called the Markov assumption, which is the assumption that the current state depends only on a finite fixed number of previous states. So the current day's weather depends not on all the previous day's weather for the rest of all of history, but the current day's weather I can predict just based on yesterday's weather, or just based on the last two days weather, or the last three days weather. But oftentimes, we're going to deal with just the one previous state that helps to predict this current state. And by putting a whole bunch of these random variables together, using this Markov assumption, we can create what's called a Markov chain, where a Markov chain is just some sequence of random variables where each of the variables distribution follows that Markov assumption. And so we'll do an example of this where the Markov assumption is, I can predict the weather. Is it sunny or rainy? And we'll just consider those two possibilities for now, even though there are other types of weather. But I can predict each day's weather just on the prior day's weather, using today's weather, I can come up with a probability distribution for tomorrow's weather. And here's what this weather might look like. It's formatted in terms of a matrix, as you might describe it, as rows and columns of values, where on the left-hand side, I have today's weather, represented by the variable x sub t. And over here in the columns, I have tomorrow's weather, represented by the variable x sub t plus 1, t plus 1 day's weather instead. And what this matrix is saying is, if today is sunny, well, then it's more likely than not that tomorrow is also sunny. Oftentimes, the weather stays consistent for multiple days in a row. And for example, let's say that if today is sunny, our model says that tomorrow, with probability 0.8, it will also be sunny. And with probability 0.2, it will be raining. And likewise, if today is raining, then it's more likely than not that tomorrow is also raining. With probability 0.7, it'll be raining. With probability 0.3, it will be sunny. So this matrix, this description of how it is we transition from one state to the next state is what we're going to call the transition model. And using the transition model, you can begin to construct this Markov chain by just predicting, given today's weather, what's the likelihood of tomorrow's weather happening. And you can imagine doing a similar sampling procedure, where you take this information, you sample what tomorrow's weather is going to be. Using that, you sample the next day's weather. And the result of that is you can form this Markov chain of like x0, time and time, day zero is sunny, the next day is sunny, maybe the next day it changes to raining, then raining, then raining. And the pattern that this Markov chain follows, given the distribution that we had access to, this transition model here, is that when it's sunny, it tends to stay sunny for a little while. The next couple of days tend to be sunny too. And when it's raining, it tends to be raining as well. And so you get a Markov chain that looks like this, and you can do analysis on this. You can say, given that today is raining, what is the probability that tomorrow is raining? Or you can begin to ask probability questions like, what is the probability of this sequence of five values, sun, sun, rain, rain, rain, and answer those sorts of questions too. And it turns out there are, again, many Python libraries for interacting with models like this of probabilities that have distributions and random variables that are based on previous variables according to this Markov assumption. And pomegranate2 has ways of dealing with these sorts of variables. So I'll go ahead and go into the chain directory, where I have some information about Markov chains. And here, I've defined a file called model.py, where I've defined in a very similar syntax. And again, the exact syntax doesn't matter so much as the idea that I'm encoding this information into a Python program so that the program has access to these distributions. I've here defined some starting distribution. So every Markov model begins at some point in time, and I need to give it some starting distribution. And so we'll just say, you know at the start, you can pick 50-50 between sunny and rainy. We'll say it's sunny 50% of the time, rainy 50% of the time. And then down below, I've here defined the transition model, how it is that I transition from one day to the next. And here, I've encoded that exact same matrix from before, that if it was sunny today, then with probability 0.8, it will be sunny tomorrow. And it'll be rainy tomorrow with probability 0.2. And I likewise have another distribution for if it was raining today instead. And so that alone defines the Markov model. You can begin to answer questions using that model. But one thing I'll just do is sample from the Markov chain. It turns out there is a method built into this Markov chain library that allows me to sample 50 states from the chain, basically just simulating like 50 instances of weather. And so let me go ahead and run this. Python model.py. And when I run it, what I get is that it's going to sample from this Markov chain 50 states, 50 days worth of weather that it's just going to randomly sample. And you can imagine sampling many times to be able to get more data, to be able to do more analysis. But here, for example, it's sunny two days in a row, rainy a whole bunch of days in a row before it changes back to sun. And so you get this model that follows the distribution that we originally described, that follows the distribution of sunny days tend to lead to more sunny days. Rainy days tend to lead to more rainy days. And that then is a Markov model. And Markov models rely on us knowing the values of these individual states. I know that today is sunny or that today is raining. And using that information, I can draw some sort of inference about what tomorrow is going to be like. But in practice, this often isn't the case. It often isn't the case that I know for certain what the exact state of the world is. Oftentimes, the state of the world is exactly unknown. But I'm able to somehow sense some information about that state, that a robot or an AI doesn't have exact knowledge about the world around it. But it has some sort of sensor, whether that sensor is a camera or sensors that detect distance or just a microphone that is sensing audio, for example. It is sensing data. And using that data, that data is somehow related to the state of the world, even if it doesn't actually know, our AI doesn't know, what the underlying true state of the world actually is. And for that, we need to get into the world of sensor models, the way of describing how it is that we translate what the hidden state, the underlying true state of the world, is with what the observation, what it is that the AI knows or the AI has access to, actually is. And so for example, a hidden state might be a robot's position. If a robot is exploring new uncharted territory, the robot likely doesn't know exactly where it is. But it does have an observation. It has robot sensor data, where it can sense how far away are possible obstacles around it. And using that information, using the observed information that it has, it can infer something about the hidden state. Because what the true hidden state is influences those observations. Whatever the robot's true position is affects or has some effect upon what the sensor data of the robot is able to collect is, even if the robot doesn't actually know for certain what its true position is. Likewise, if you think about a voice recognition or a speech recognition program that listens to you and is able to respond to you, something like Alexa or what Apple and Google are doing with their voice recognition as well, that you might imagine that the hidden state, the underlying state, is what words are actually spoken. The true nature of the world contains you saying a particular sequence of words, but your phone or your smart home device doesn't know for sure exactly what words you said. The only observation that the AI has access to is some audio waveforms. And those audio waveforms are, of course, dependent upon this hidden state. And you can infer, based on those audio waveforms, what the words spoken likely were. But you might not know with 100% certainty what that hidden state actually is. And it might be a task to try and predict, given this observation, given these audio waveforms, can you figure out what the actual words spoken are. And likewise, you might imagine on a website, true user engagement. Might be information you don't directly have access to. But you can observe data, like website or app analytics, about how often was this button clicked or how often are people interacting with a page in a particular way. And you can use that to infer things about your users as well. So this type of problem comes up all the time when we're dealing with AI and trying to infer things about the world. That often AI doesn't really know the hidden true state of the world. All the AI has access to is some observation that is related to the hidden true state. But it's not direct. There might be some noise there. The audio waveform might have some additional noise that might be difficult to parse. The sensor data might not be exactly correct. There's some noise that might not allow you to conclude with certainty what the hidden state is, but can allow you to infer what it might be. And so the simple example we'll take a look at here is imagining the hidden state as the weather, whether it's sunny or rainy or not. And imagine you are programming an AI inside of a building that maybe has access to just a camera to inside the building. And all you have access to is an observation as to whether or not employees are bringing an umbrella into the building or not. You can detect whether it's an umbrella or not. And so you might have an observation as to whether or not an umbrella is brought into the building or not. And using that information, you want to predict whether it's sunny or rainy, even if you don't know what the underlying weather is. So the underlying weather might be sunny or rainy. And if it's raining, obviously people are more likely to bring an umbrella. And so whether or not people bring an umbrella, your observation, tells you something about the hidden state. And of course, this is a bit of a contrived example, but the idea here is to think about this more broadly in terms of more generally, any time you observe something, it having to do with some underlying hidden state. And so to try and model this type of idea where we have these hidden states and observations, rather than just use a Markov model, which has state, state, state, state, each of which is connected by that transition matrix that we described before, we're going to use what we call a hidden Markov model. Very similar to a Markov model, but this is going to allow us to model a system that has hidden states that we don't directly observe, along with some observed event that we do actually see. And so in addition to that transition model that we still need of saying, given the underlying state of the world, if it's sunny or rainy, what's the probability of tomorrow's weather? We also need another model that, given some state, is going to give us an observation of green, yes, someone brings an umbrella into the office, or red, no, nobody brings umbrellas into the office. And so the observation might be that if it's sunny, then odds are nobody is going to bring an umbrella to the office. But maybe some people are just being cautious, and they do bring an umbrella to the office anyways. And if it's raining, then with much higher probability, then people are going to bring umbrellas into the office. But maybe if the rain was unexpected, people didn't bring an umbrella. And so it might have some other probability as well. And so using the observations, you can begin to predict with reasonable likelihood what the underlying state is, even if you don't actually get to observe the underlying state, if you don't get to see what the hidden state is actually equal to. This here we'll often call the sensor model. It's also often called the emission probabilities, because the state, the underlying state, emits some sort of emission that you then observe. And so that can be another way of describing that same idea. And the sensor Markov assumption that we're going to use is this assumption that the evidence variable, the thing we observe, the emission that gets produced, depends only on the corresponding state, meaning it can predict whether or not people will bring umbrellas or not entirely dependent just on whether it is sunny or rainy today. Of course, again, this assumption might not hold in practice, that in practice, it might depend whether or not people bring umbrellas, might depend not just on today's weather, but also on yesterday's weather and the day before. But for simplification purposes, it can be helpful to apply this sort of assumption just to allow us to be able to reason about these probabilities a little more easily. And if we're able to approximate it, we can still often get a very good answer. And so what these hidden Markov models end up looking like is a little something like this, where now, rather than just have one chain of states, like sun, sun, rain, rain, rain, we instead have this upper level, which is the underlying state of the world. Is it sunny or is it rainy? And those are connected by that transition matrix we described before. But each of these states produces an emission, produces an observation that I see, that on this day, it was sunny and people didn't bring umbrellas. And on this day, it was sunny, but people did bring umbrellas. And on this day, it was raining and people did bring umbrellas, and so on and so forth. And so each of these underlying states represented by x sub t for x sub 1, 0, 1, 2, so on and so forth, produces some sort of observation or emission, which is what the e stands for, e sub 0, e sub 1, e sub 2, so on and so forth. And so this, too, is a way of trying to represent this idea. And what you want to think about is that these underlying states are the true nature of the world, the robot's position as it moves over time, and that produces some sort of sensor data that might be observed, or what people are actually saying and using the emission data of what audio waveforms do you detect in order to process that data and try and figure it out. And there are a number of possible tasks that you might want to do given this kind of information. And one of the simplest is trying to infer something about the future or the past or about these sort of hidden states that might exist. And so the tasks that you'll often see, and we're not going to go into the mathematics of these tasks, but they're all based on the same idea of conditional probabilities and using the probability distributions we have to draw these sorts of conclusions. One task is called filtering, which is given observations from the start until now, calculate the distribution for the current state, meaning given information about from the beginning of time until now, on which days do people bring an umbrella or not bring an umbrella, can I calculate the probability of the current state that today, is it sunny or is it raining? Another task that might be possible is prediction, which is looking towards the future. Given observations about people bringing umbrellas from the beginning of when we started counting time until now, can I figure out the distribution that tomorrow is it sunny or is it raining? And you can also go backwards as well by a smoothing, where I can say given observations from start until now, calculate the distributions for some past state. Like I know that today people brought umbrellas and tomorrow people brought umbrellas. And so given two days worth of data of people bringing umbrellas, what's the probability that yesterday it was raining? And that I know that people brought umbrellas today, that might inform that decision as well. It might influence those probabilities. And there's also a most likely explanation task, in addition to other tasks that might exist as well, which is combining some of these given observations from the start up until now, figuring out the most likely sequence of states. And this is what we're going to take a look at now, this idea that if I have all these observations, umbrella, no umbrella, umbrella, no umbrella, can I calculate the most likely states of sun, rain, sun, rain, and whatnot that actually represented the true weather that would produce these observations? And this is quite common when you're trying to do something like voice recognition, for example, that you have these emissions of the audio waveforms, and you would like to calculate based on all of the observations that you have, what is the most likely sequence of actual words, or syllables, or sounds that the user actually made when they were speaking to this particular device, or other tasks that might come up in that context as well. And so we can try this out by going ahead and going into the HMM directory, HMM for Hidden Markov Model. And here, what I've done is I've defined a model where this model first defines my possible state, sun, and rain, along with their emission probabilities, the observation model, or the emission model, where here, given that I know that it's sunny, the probability that I see people bring an umbrella is 0.2, the probability of no umbrella is 0.8. And likewise, if it's raining, then people are more likely to bring an umbrella. Umbrella has probability 0.9, no umbrella has probability 0.1. So the actual underlying hidden states, those states are sun and rain, but the things that I observe, the observations that I can see, are either umbrella or no umbrella as the things that I observe as a result. So this then, I also need to add to it a transition matrix, same as before, saying that if today is sunny, then tomorrow is more likely to be sunny. And if today is rainy, then tomorrow is more likely to be raining. As of before, I give it some starting probabilities, saying at first, 50-50 chance for whether it's sunny or rainy. And then I can create the model based on that information. Again, the exact syntax of this is not so important, so much as it is the data that I am now encoding into a program, such that now I can begin to do some inference. So I can give my program, for example, a list of observations, umbrella, umbrella, no umbrella, umbrella, umbrella, so on and so forth, no umbrella, no umbrella. And I would like to calculate, I would like to figure out the most likely explanation for these observations. What is likely is whether rain, rain, is this rain, or is it more likely that this was actually sunny, and then it switched back to it being rainy? And that's an interesting question. We might not be sure, because it might just be that it just so happened on this rainy day, people decided not to bring an umbrella. Or it could be that it switched from rainy to sunny back to rainy, which doesn't seem too likely, but it certainly could happen. And using the data we give to the hidden Markov model, our model can begin to predict these answers, can begin to figure it out. So we're going to go ahead and just predict these observations. And then for each of those predictions, go ahead and print out what the prediction is. And this library just so happens to have a function called predict that does this prediction process for me. So I'll run python sequence.py. And the result I get is this. This is the prediction based on the observations of what all of those states are likely to be. And it's likely to be rain and rain. In this case, it thinks that what most likely happened is that it was sunny for a day and then went back to being rainy. But in different situations, if it was rainy for longer maybe, or if the probabilities were slightly different, you might imagine that it's more likely that it was rainy all the way through. And it just so happened on one rainy day, people decided not to bring umbrellas. And so here, too, Python libraries can begin to allow for the sort of inference procedure. And by taking what we know and by putting it in terms of these tasks that already exist, these general tasks that work with hidden Markov models, then any time we can take an idea and formulate it as a hidden Markov model, formulate it as something that has hidden states and observed emissions that result from those states, then we can take advantage of these algorithms that are known to exist for trying to do this sort of inference. So now we've seen a couple of ways that AI can begin to deal with uncertainty. We've taken a look at probability and how we can use probability to describe numerically things that are likely or more likely or less likely to happen than other events or other variables. And using that information, we can begin to construct these standard types of models, things like Bayesian networks and Markov chains and hidden Markov models that all allow us to be able to describe how particular events relate to other events or how the values of particular variables relate to other variables, not for certain, but with some sort of probability distribution. And by formulating things in terms of these models that already exist, we can take advantage of Python libraries that implement these sort of models already and allow us just to be able to use them to produce some sort of resulting effect. So all of this then allows our AI to begin to deal with these sort of uncertain problems so that our AI doesn't need to know things for certain but can infer based on information it doesn't know. Next time, we'll take a look at additional types of problems that we can solve by taking advantage of AI-related algorithms, even beyond the world of the types of problems we've already explored. We'll see you next time. OK. Welcome back, everyone, to an introduction to artificial intelligence with Python. And now, so far, we've taken a look at a couple of different types of problems. We've seen classical search problems where we're trying to get from an initial state to a goal by figuring out some optimal path. We've taken a look at adversarial search where we have a game-playing agent that is trying to make the best move. We've seen knowledge-based problems where we're trying to use logic and inference to be able to figure out and draw some additional conclusions. And we've seen some probabilistic models as well where we might not have certain information about the world, but we want to use the knowledge about probabilities that we do have to be able to draw some conclusions. Today, we're going to turn our attention to another category of problems generally known as optimization problems, where optimization is really all about choosing the best option from a set of possible options. And we've already seen optimization in some contexts, like game-playing, where we're trying to create an AI that chooses the best move out of a set of possible moves. But what we'll take a look at today is a category of types of problems and algorithms to solve them that can be used in order to deal with a broader range of potential optimization problems. And the first of the algorithms that we'll take a look at is known as a local search. And local search differs from search algorithms we've seen before in the sense that the search algorithms we've looked at so far, which are things like breadth-first search or A-star search, for example, generally maintain a whole bunch of different paths that we're simultaneously exploring, and we're looking at a bunch of different paths at once trying to find our way to the solution. On the other hand, in local search, this is going to be a search algorithm that's really just going to maintain a single node, looking at a single state. And we'll generally run this algorithm by maintaining that single node and then moving ourselves to one of the neighboring nodes throughout this search process. And this is generally useful in context not like these problems, which we've seen before, like a maze-solving situation where we're trying to find our way from the initial state to the goal by following some path. But local search is most applicable when we really don't care about the path at all, and all we care about is what the solution is. And in the case of solving a maze, the solution was always obvious. You could point to the solution. You know exactly what the goal is, and the real question is, what is the path to get there? But local search is going to come up in cases where figuring out exactly what the solution is, exactly what the goal looks like, is actually the heart of the challenge. And to give an example of one of these kinds of problems, we'll consider a scenario where we have two types of buildings, for example. We have houses and hospitals. And our goal might be in a world that's formatted as this grid, where we have a whole bunch of houses, a house here, house here, two houses over there, maybe we want to try and find a way to place two hospitals on this map. So maybe a hospital here and a hospital there. And the problem now is we want to place two hospitals on the map, but we want to do so with some sort of objective. And our objective in this case is to try and minimize the distance of any of the houses from a hospital. So you might imagine, all right, what's the distance from each of the houses to their nearest hospital? There are a number of ways we could calculate that distance. But one way is using a heuristic we've looked at before, which is the Manhattan distance, this idea of how many rows and columns would you have to move inside of this grid layout in order to get to a hospital, for example. And it turns out, if you take each of these four houses and figure out, all right, how close are they to their nearest hospital, you get something like this, where this house is three away from a hospital, this house is six away, and these two houses are each four away. And if you add all those numbers up together, you get a total cost of 17, for example. So for this particular configuration of hospitals, a hospital here and a hospital there, that state, we might say, has a cost of 17. And the goal of this problem now that we would like to apply a search algorithm to figure out is, can you solve this problem to find a way to minimize that cost? Minimize the total amount if you sum up all of the distances from all the houses to the nearest hospital. How can we minimize that final value? And if we think about this problem a little bit more abstractly, abstracting away from this specific problem and thinking more generally about problems like it, you can often formulate these problems by thinking about them as a state-space landscape, as we'll soon call it. Here in this diagram of a state-space landscape, each of these vertical bars represents a particular state that our world could be in. So for example, each of these vertical bars represents a particular configuration of two hospitals. And the height of this vertical bar is generally going to represent some function of that state, some value of that state. So maybe in this case, the height of the vertical bar represents what is the cost of this particular configuration of hospitals in terms of what is the sum total of all the distances from all of the houses to their nearest hospital. And generally speaking, when we have a state-space landscape, we want to do one of two things. We might be trying to maximize the value of this function, trying to find a global maximum, so to speak, of this state-space landscape, a single state whose value is higher than all of the other states that we could possibly choose from. And generally in this case, when we're trying to find a global maximum, we'll call the function that we're trying to optimize some objective function, some function that measures for any given state how good is that state, such that we can take any state, pass it into the objective function, and get a value for how good that state is. And ultimately, what our goal is is to find one of these states that has the highest possible value for that objective function. An equivalent but reversed problem is the problem of finding a global minimum, some state that has a value after you pass it into this function that is lower than all of the other possible values that we might choose from. And generally speaking, when we're trying to find a global minimum, we call the function that we're calculating a cost function. Generally, each state has some sort of cost, whether that cost is a monetary cost, or a time cost, or in the case of the houses and hospitals, we've been looking at just now, a distance cost in terms of how far away each of the houses is from a hospital. And we're trying to minimize the cost, find the state that has the lowest possible value of that cost. So these are the general types of ideas we might be trying to go for within a state space landscape, trying to find a global maximum, or trying to find a global minimum. And how exactly do we do that? We'll recall that in local search, we generally operate this algorithm by maintaining just a single state, just some current state represented inside of some node, maybe inside of a data structure, where we're keeping track of where we are currently. And then ultimately, what we're going to do is from that state, move to one of its neighbor states. So in this case, represented in this one-dimensional space by just the state immediately to the left or to the right of it. But for any different problem, you might define what it means for there to be a neighbor of a particular state. In the case of a hospital, for example, that we were just looking at, a neighbor might be moving one hospital one space to the left or to the right or up or down. Some state that is close to our current state, but slightly different, and as a result, might have a slightly different value in terms of its objective function or in terms of its cost function. So this is going to be our general strategy in local search, to be able to take a state, maintaining some current node, and move where we're looking at in the state space landscape in order to try to find a global maximum or a global minimum somehow. And perhaps the simplest of algorithms that we could use to implement this idea of local search is an algorithm known as hill climbing. And the basic idea of hill climbing is, let's say I'm trying to maximize the value of my state. I'm trying to figure out where the global maximum is. I'm going to start at a state. And generally, what hill climbing is going to do is it's going to consider the neighbors of that state, that from this state, all right, I could go left or I could go right, and this neighbor happens to be higher and this neighbor happens to be lower. And in hill climbing, if I'm trying to maximize the value, I'll generally pick the highest one I can between the state to the left and right of me. This one is higher. So I'll go ahead and move myself to consider that state instead. And then I'll repeat this process, continually looking at all of my neighbors and picking the highest neighbor, doing the same thing, looking at my neighbors, picking the highest of my neighbors, until I get to a point like right here, where I consider both of my neighbors and both of my neighbors have a lower value than I do. This current state has a value that is higher than any of its neighbors. And at that point, the algorithm terminates. And I can say, all right, here I have now found the solution. And the same thing works in exactly the opposite way for trying to find a global minimum. But the algorithm is fundamentally the same. If I'm trying to find a global minimum and say my current state starts here, I'll continually look at my neighbors, pick the lowest value that I possibly can, until I eventually, hopefully, find that global minimum, a point at which when I look at both of my neighbors, they each have a higher value. And I'm trying to minimize the total score or cost or value that I get as a result of calculating some sort of cost function. So we can formulate this graphical idea in terms of pseudocode. And the pseudocode for hill climbing might look like this. We define some function called hill climb that takes as input the problem that we're trying to solve. And generally, we're going to start in some sort of initial state. So I'll start with a variable called current that is keeping track of my initial state, like an initial configuration of hospitals. And maybe some problems lend themselves to an initial state, some place where you begin. In other cases, maybe not, in which case we might just randomly generate some initial state, just by choosing two locations for hospitals at random, for example, and figuring out from there how we might be able to improve. But that initial state, we're going to store inside of current. And now, here comes our loop, some repetitive process we're going to do again and again until the algorithm terminates. And what we're going to do is first say, let's figure out all of the neighbors of the current state. From my state, what are all of the neighboring states for some definition of what it means to be a neighbor? And I'll go ahead and choose the highest value of all of those neighbors and save it inside of this variable called neighbor. So keep track of the highest-valued neighbor. This is in the case where I'm trying to maximize the value. In the case where I'm trying to minimize the value, you might imagine here, you'll pick the neighbor with the lowest possible value. But these ideas are really fundamentally interchangeable. And it's possible, in some cases, there might be multiple neighbors that each have an equally high value or an equally low value in the minimizing case. And in that case, we can just choose randomly from among them. Choose one of them and save it inside of this variable neighbor. And then the key question to ask is, is this neighbor better than my current state? And if the neighbor, the best neighbor that I was able to find, is not better than my current state, well, then the algorithm is over. And I'll just go ahead and return the current state. If none of my neighbors are better, then I may as well stay where I am, is the general logic of the hill climbing algorithm. But otherwise, if the neighbor is better, then I may as well move to that neighbor. So you might imagine setting current equal to neighbor, where the general idea is if I'm at a current state and I see a neighbor that is better than me, then I'll go ahead and move there. And then I'll repeat the process, continually moving to a better neighbor until I reach a point at which none of my neighbors are better than I am. And at that point, we'd say the algorithm can just terminate there. So let's take a look at a real example of this with these houses and hospitals. So we've seen now that if we put the hospitals in these two locations, that has a total cost of 17. And now we need to define, if we're going to implement this hill climbing algorithm, what it means to take this particular configuration of hospitals, this particular state, and get a neighbor of that state. And a simple definition of neighbor might be just, let's pick one of the hospitals and move it by one square, the left or right or up or down, for example. And that would mean we have six possible neighbors from this particular configuration. We could take this hospital and move it to any of these three possible squares, or we take this hospital and move it to any of those three possible squares. And each of those would generate a neighbor. And what I might do is say, all right, here's the locations and the distances between each of the houses and their nearest hospital. Let me consider all of the neighbors and see if any of them can do better than a cost of 17. And it turns out there are a couple of ways that we could do that. And it doesn't matter if we randomly choose among all the ways that are the best. But one such possible way is by taking a look at this hospital here and considering the directions in which it might move. If we hold this hospital constant, if we take this hospital and move it one square up, for example, that doesn't really help us. It gets closer to the house up here, but it gets further away from the house down here. And it doesn't really change anything for the two houses along the left-hand side. But if we take this hospital on the right and move it one square down, it's the opposite problem. It gets further away from the house up above, and it gets closer to the house down below. The real idea, the goal should be to be able to take this hospital and move it one square to the left. By moving it one square to the left, we move it closer to both of these houses on the right without changing anything about the houses on the left. For them, this hospital is still the closer one, so they aren't affected. So we're able to improve the situation by picking a neighbor that results in a decrease in our total cost. And so we might do that. Move ourselves from this current state to a neighbor by just taking that hospital and moving it. And at this point, there's not a whole lot that can be done with this hospital. But there's still other optimizations we can make, other neighbors we can move to that are going to have a better value. If we consider this hospital, for example, we might imagine that right now it's a bit far up, that both of these houses are a little bit lower. So we might be able to do better by taking this hospital and moving it one square down, moving it down so that now instead of a cost of 15, we're down to a cost of 13 for this particular configuration. And we can do even better by taking the hospital and moving it one square to the left. Now instead of a cost of 13, we have a cost of 11, because this house is one away from the hospital. This one is four away. This one is three away. And this one is also three away. So we've been able to do much better than that initial cost that we had using the initial configuration. Just by taking every state and asking ourselves the question, can we do better by just making small incremental changes, moving to a neighbor, moving to a neighbor, and moving to a neighbor after that? And now at this point, we can potentially see that at this point, the algorithm is going to terminate. There's actually no neighbor we can move to that is going to improve the situation, get us a cost that is less than 11. Because if we take this hospital and move it upper to the right, well, that's going to make it further away. If we take it and move it down, that doesn't really change the situation. It gets further away from this house but closer to that house. And likewise, the same story was true for this hospital. Any neighbor we move it to, up, left, down, or right, is either going to make it further away from the houses and increase the cost, or it's going to have no effect on the cost whatsoever. And so the question we might now ask is, is this the best we could do? Is this the best placement of the hospitals we could possibly have? And it turns out the answer is no, because there's a better way that we could place these hospitals. And in particular, there are a number of ways you could do this. But one of the ways is by taking this hospital here and moving it to this square, for example, moving it diagonally by one square, which was not part of our definition of neighbor. We could only move left, right, up, or down. But this is, in fact, better. It has a total cost of 9. It is now closer to both of these houses. And as a result, the total cost is less. But we weren't able to find it, because in order to get there, we had to go through a state that actually wasn't any better than the current state that we had been on previously. And so this appears to be a limitation, or a concern you might have as you go about trying to implement a hill climbing algorithm, is that it might not always give you the optimal solution. If we're trying to maximize the value of any particular state, we're trying to find the global maximum, a concern might be that we could get stuck at one of the local maxima, highlighted here in blue, where a local maxima is any state whose value is higher than any of its neighbors. If we ever find ourselves at one of these two states when we're trying to maximize the value of the state, we're not going to make any changes. We're not going to move left or right. We're not going to move left here, because those states are worse. But yet, we haven't found the global optimum. We haven't done as best as we could do. And likewise, in the case of the hospitals, what we're ultimately trying to do is find a global minimum, find a value that is lower than all of the others. But we have the potential to get stuck at one of the local minima, any of these states whose value is lower than all of its neighbors, but still not as low as the local minima. And so the takeaway here is that it's not always going to be the case that when we run this naive hill climbing algorithm, that we're always going to find the optimal solution. There are things that could go wrong. If we started here, for example, and tried to maximize our value as much as possible, we might move to the highest possible neighbor, move to the highest possible neighbor, move to the highest possible neighbor, and stop, and never realize that there's actually a better state way over there that we could have gone to instead. And other problems you might imagine just by taking a look at this state space landscape are these various different types of plateaus, something like this flat local maximum here, where all six of these states each have the exact same value. And so in the case of the algorithm we showed before, none of the neighbors are better, so we might just get stuck at this flat local maximum. And even if you allowed yourself to move to one of the neighbors, it wouldn't be clear which neighbor you would ultimately move to, and you could get stuck here as well. And there's another one over here. This one is called a shoulder. It's not really a local maximum, because there's still places where we can go higher, not a local minimum, because we can go lower. So we can still make progress, but it's still this flat area, where if you have a local search algorithm, there's potential to get lost here, unable to make some upward or downward progress, depending on whether we're trying to maximize or minimize it, and therefore another potential for us to be able to find a solution that might not actually be the optimal solution. And so because of this potential, the potential that hill climbing has to not always find us the optimal result, it turns out there are a number of different varieties and variations on the hill climbing algorithm that help to solve the problem better depending on the context, and depending on the specific type of problem, some of these variants might be more applicable than others. What we've taken a look at so far is a version of hill climbing generally called steepest ascent hill climbing, where the idea of steepest ascent hill climbing is we are going to choose the highest valued neighbor, in the case where we're trying to maximize or the lowest valued neighbor in cases where we're trying to minimize. But generally speaking, if I have five neighbors and they're all better than my current state, I will pick the best one of those five. Now, sometimes that might work pretty well. It's sort of a greedy approach of trying to take the best operation at any particular time step, but it might not always work. There might be cases where actually I want to choose an option that is slightly better than me, but maybe not the best one because that later on might lead to a better outcome ultimately. So there are other variants that we might consider of this basic hill climbing algorithm. One is known as stochastic hill climbing. And in this case, we choose randomly from all of our higher value neighbors. So if I'm at my current state and there are five neighbors that are all better than I am, rather than choosing the best one, as steep as the set would do, stochastic will just choose randomly from one of them, thinking that if it's better, then it's better. And maybe there's a potential to make forward progress, even if it is not locally the best option I could possibly choose. First choice hill climbing ends up just choosing the very first highest valued neighbor that it follows, behaving on a similar idea, rather than consider all of the neighbors. As soon as we find a neighbor that is better than our current state, we'll go ahead and move there. There may be some efficiency improvements there and maybe has the potential to find a solution that the other strategies weren't able to find. And with all of these variants, we still suffer from the same potential risk, this risk that we might end up at a local minimum or a local maximum. And we can reduce that risk by repeating the process multiple times. So one variant of hill climbing is random restart hill climbing, where the general idea is we'll conduct hill climbing multiple times. If we apply steepest descent hill climbing, for example, we'll start at some random state, try and figure out how to solve the problem and figure out what is the local maximum or local minimum we get to. And then we'll just randomly restart and try again, choose a new starting configuration, try and figure out what the local maximum or minimum is, and do this some number of times. And then after we've done it some number of times, we can pick the best one out of all of the ones that we've taken a look at. So there's another option we have access to as well. And then, although I said that generally local search will usually just keep track of a single node and then move to one of its neighbors, there are variants of hill climbing that are known as local beam searches, where rather than keep track of just one current best state, we're keeping track of k highest valued neighbors, such that rather than starting at one random initial configuration, I might start with 3 or 4 or 5, randomly generate all the neighbors, and then pick the 3 or 4 or 5 best of all of the neighbors that I find, and continually repeat this process, with the idea being that now I have more options that I'm considering, more ways that I could potentially navigate myself to the optimal solution that might exist for a particular problem. So let's now take a look at some actual code that can implement some of these kinds of ideas, something like steepest ascent hill climbing, for example, for trying to solve this hospital problem. So I'm going to go ahead and go into my hospitals directory, where I've actually set up the basic framework for solving this type of problem. I'll go ahead and go into hospitals.py, and we'll take a look at the code we've created here. I've defined a class that is going to represent the state space. So the space has a height, and a width, and also some number of hospitals. So you can configure how big is your map, how many hospitals should go here. We have a function for adding a new house to the state space, and then some functions that are going to get me all of the available spaces for if I want to randomly place hospitals in particular locations. And here now is the hill climbing algorithm. So what are we going to do in the hill climbing algorithm? Well, we're going to start by randomly initializing where the hospitals are going to go. We don't know where the hospitals should actually be, so let's just randomly place them. So here I'm running a loop for each of the hospitals that I have. I'm going to go ahead and add a new hospital at some random location. So I basically get all of the available spaces, and I randomly choose one of them as where I would like to add this particular hospital. I have some logging output and generating some images, which we'll take a look at a little bit later. But here is the key idea. So I'm going to just keep repeating this algorithm. I could specify a maximum of how many times I want it to run, or I could just run it up until it hits a local maximum or local minimum. And now we'll basically consider all of the hospitals that could potentially move. So consider each of the two hospitals or more hospitals if they're more than that. And consider all of the places where that hospital could move to, some neighbor of that hospital that we can move the neighbor to. And then see, is this going to be better than where we were currently? So if it is going to be better, then we'll go ahead and update our best neighbor and keep track of this new best neighbor that we found. And then afterwards, we can ask ourselves the question, if best neighbor cost is greater than or equal to the cost of the current set of hospitals, meaning if the cost of our best neighbor is greater than the current cost, meaning our best neighbor is worse than our current state, well, then we shouldn't make any changes at all. And we should just go ahead and return the current set of hospitals. But otherwise, we can update our hospitals in order to change them to one of the best neighbors. And if there are multiple that are all equivalent, I'm here using random.choice to say go ahead and choose one randomly. So this is really just a Python implementation of that same idea that we were just talking about, this idea of taking a current state, some current set of hospitals, generating all of the neighbors, looking at all of the ways we could take one hospital and move it one square to the left or right or up or down, and then figuring out, based on all of that information, which is the best neighbor or the set of all the best neighbors, and then choosing from one of those. And each time, we go ahead and generate an image in order to do that. And so now what we're doing is if we look down at the bottom, I'm going to randomly generate a space with height 10 and width 20. And I'll say go ahead and put three hospitals somewhere in the space. I'll randomly generate 15 houses that I just go ahead and add in random locations. And now I'm going to run this hill climbing algorithm in order to try and figure out where we should place those hospitals. So we'll go ahead and run this program by running Python hospitals. And we see that we started. Our initial state had a cost of 72, but we were able to continually find neighbors that were able to decrease that cost, decrease to 69, 66, 63, so on and so forth, all the way down to 53, as the best neighbor we were able to ultimately find. And we can take a look at what that looked like by just opening up these files. So here, for example, was the initial configuration. We randomly selected a location for each of these 15 different houses and then randomly selected locations for one, two, three hospitals that were just located somewhere inside of the state space. And if you add up all the distances from each of the houses to their nearest hospital, you get a total cost of about 72. And so now the question is, what neighbors can we move to that improve the situation? And it looks like the first one the algorithm found was by taking this house that was over there on the right and just moving it to the left. And that probably makes sense because if you look at the houses in that general area, really these five houses look like they're probably the ones that are going to be closest to this hospital over here. Moving it to the left decreases the total distance, at least to most of these houses, though it does increase that distance for one of them. And so we're able to make these improvements to the situation by continually finding ways that we can move these hospitals around until we eventually settle at this particular state that has a cost of 53, where we figured out a position for each of the hospitals. And now none of the neighbors that we could move to are actually going to improve the situation. We can take this hospital and this hospital and that hospital and look at each of the neighbors. And none of those are going to be better than this particular configuration. And again, that's not to say that this is the best we could do. There might be some other configuration of hospitals that is a global minimum. And this might just be a local minimum that is the best of all of its neighbors, but maybe not the best in the entire possible state space. And you could search through the entire state space by considering all of the possible configurations for hospitals. But ultimately, that's going to be very time intensive, especially as our state space gets bigger and there might be more and more possible states. It's going to take quite a long time to look through all of them. And so being able to use these sort of local search algorithms can often be quite good for trying to find the best solution we can do. And especially if we don't care about doing the best possible and we just care about doing pretty good and finding a pretty good placement of those hospitals, then these methods can be particularly powerful. But of course, we can try and mitigate some of this concern by instead of using hill climbing to use random restart, this idea of rather than just hill climb one time, we can hill climb multiple times and say, try hill climbing a whole bunch of times on the exact same map and figure out what is the best one that we've been able to find. And so I've here implemented a function for random restart that restarts some maximum number of times. And what we're going to do is repeat that number of times this process of just go ahead and run the hill climbing algorithm, figure out what the cost is of getting from all the houses to the hospitals, and then figure out is this better than we've done so far. So I can try this exact same idea where instead of running hill climbing, I'll go ahead and run random restart. And I'll randomly restart maybe 20 times, for example. And we'll go ahead and now I'll remove all the images and then rerun the program. And now we started by finding a original state. When we initially ran hill climbing, the best cost we were able to find was 56. Each of these iterations is a different iteration of the hill climbing algorithm. We're running hill climbing not one time, but 20 times here, each time going until we find a local minimum in this case. And we look and see each time did we do better than we did the best time we've done so far. So we went from 56 to 46. This one was greater, so we ignored it. This one was 41, which was less, so we went ahead and kept that one. And for all of the remaining 16 times that we tried to implement hill climbing and we tried to run the hill climbing algorithm, we couldn't do any better than that 41. Again, maybe there is a way to do better that we just didn't find, but it looks like that way ended up being a pretty good solution to the problem. That was attempt number three, starting from counting at zero. So we can take a look at that, open up number three. And this was the state that happened to have a cost of 41, that after running the hill climbing algorithm on some particular random initial configuration of hospitals, this is what we found was the local minimum in terms of trying to minimize the cost. And it looks like we did pretty well. This hospital is pretty close to this region. This one is pretty close to these houses here. This hospital looks about as good as we can do for trying to capture those houses over on that side. And so these sorts of algorithms can be quite useful for trying to solve these problems. But the real problem with many of these different types of hill climbing, steepest of sense, stochastic, first choice, and so forth, is that they never make a move that makes our situation worse. They're always going to take ourselves in our current state, look at the neighbors, and consider can we do better than our current state and move to one of those neighbors. Which of those neighbors we choose might vary among these various different types of algorithms, but we never go from a current position to a position that is worse than our current position. And ultimately, that's what we're going to need to do if we want to be able to find a global maximum or a global minimum. Because sometimes if we get stuck, we want to find some way of dislodging ourselves from our local maximum or local minimum in order to find the global maximum or the global minimum or increase the probability that we do find it. And so the most popular technique for trying to approach the problem from that angle is a technique known as simulated annealing, simulated because it's modeling after a real physical process of annealing, where you can think about this in terms of physics, a physical situation where you have some system of particles. And you might imagine that when you heat up a particular physical system, there's a lot of energy there. Things are moving around quite randomly. But over time, as the system cools down, it eventually settles into some final position. And that's going to be the general idea of simulated annealing. We're going to simulate that process of some high temperature system where things are moving around randomly quite frequently, but over time decreasing that temperature until we eventually settle at our ultimate solution. And the idea is going to be if we have some state space landscape that looks like this and we begin at its initial state here, if we're looking for a global maximum and we're trying to maximize the value of the state, our traditional hill climbing algorithms would just take the state and look at the two neighbor ones and always pick the one that is going to increase the value of the state. But if we want some chance of being able to find the global maximum, we can't always make good moves. We have to sometimes make bad moves and allow ourselves to make a move in a direction that actually seems for now to make our situation worse such that later we can find our way up to that global maximum in terms of trying to solve that problem. Of course, once we get up to this global maximum, once we've done a whole lot of the searching, then we probably don't want to be moving to states that are worse than our current state. And so this is where this metaphor for annealing starts to come in, where we want to start making more random moves and over time start to make fewer of those random moves based on a particular temperature schedule. So the basic outline looks something like this. Early on in simulated annealing, we have a higher temperature state. And what we mean by a higher temperature state is that we are more likely to accept neighbors that are worse than our current state. We might look at our neighbors. And if one of our neighbors is worse than the current state, especially if it's not all that much worse, if it's pretty close but just slightly worse, then we might be more likely to accept that and go ahead and move to that neighbor anyways. But later on as we run simulated annealing, we're going to decrease that temperature. And at a lower temperature, we're going to be less likely to accept neighbors that are worse than our current state. Now to formalize this and put a little bit of pseudocode to it, here is what that algorithm might look like. We have a function called simulated annealing that takes as input the problem we're trying to solve and also potentially some maximum number of times we might want to run the simulated annealing process, how many different neighbors we're going to try and look for. And that value is going to vary based on the problem you're trying to solve. We'll, again, start with some current state that will be equal to the initial state of the problem. But now we need to repeat this process over and over for max number of times. Repeat some process some number of times where we're first going to calculate a temperature. And this temperature function takes the current time t starting at 1 going all the way up to max and then gives us some temperature that we can use in our computation, where the idea is that this temperature is going to be higher early on and it's going to be lower later on. So there are a number of ways this temperature function could often work. One of the simplest ways is just to say it is like the proportion of time that we still have remaining. Out of max units of time, how much time do we have remaining? You start off with a lot of that time remaining. And as time goes on, the temperature is going to decrease because you have less and less of that remaining time still available to you. So we calculate a temperature for the current time. And then we pick a random neighbor of the current state. No longer are we going to be picking the best neighbor that we possibly can or just one of the better neighbors that we can. We're going to pick a random neighbor. It might be better. It might be worse. But we're going to calculate that. We're going to calculate delta E, E for energy in this case, which is just how much better is the neighbor than the current state. So if delta E is positive, that means the neighbor is better than our current state. If delta E is negative, that means the neighbor is worse than our current state. And so we can then have a condition that looks like this. If delta E is greater than 0, that means the neighbor state is better than our current state. And if ever that situation arises, we'll just go ahead and update current to be that neighbor. Same as before, move where we are currently to be the neighbor because the neighbor is better than our current state. We'll go ahead and accept that. But now the difference is that whereas before, we never, ever wanted to take a move that made our situation worse, now we sometimes want to make a move that is actually going to make our situation worse because sometimes we're going to need to dislodge ourselves from a local minimum or local maximum to increase the probability that we're able to find the global minimum or the global maximum a little bit later. And so how do we do that? How do we decide to sometimes accept some state that might actually be worse? Well, we're going to accept a worse state with some probability. And that probability needs to be based on a couple of factors. It needs to be based in part on the temperature, where if the temperature is higher, we're more likely to move to a worse neighbor. And if the temperature is lower, we're less likely to move to a worse neighbor. But it also, to some degree, should be based on delta E. If the neighbor is much worse than the current state, we probably want to be less likely to choose that than if the neighbor is just a little bit worse than the current state. So again, there are a couple of ways you could calculate this. But it turns out one of the most popular is just to calculate E to the power of delta E over T, where E is just a constant. Delta E over T are based on delta E and T here. We calculate that value. And that'll be some value between 0 and 1. And that is the probability with which we should just say, all right, let's go ahead and move to that neighbor. And it turns out that if you do the math for this value, when delta E is such that the neighbor is not that much worse than the current state, that's going to be more likely that we're going to go ahead and move to that state. And likewise, when the temperature is lower, we're going to be less likely to move to that neighboring state as well. So now this is the big picture for simulated annealing, this process of taking the problem and going ahead and generating random neighbors will always move to a neighbor if it's better than our current state. But even if the neighbor is worse than our current state, we'll sometimes move there depending on how much worse it is and also based on the temperature. And as a result, the hope, the goal of this whole process is that as we begin to try and find our way to the global maximum or the global minimum, we can dislodge ourselves if we ever get stuck at a local maximum or local minimum in order to eventually make our way to exploring the part of the state space that is going to be the best. And then as the temperature decreases, eventually we settle there without moving around too much from what we've found to be the globally best thing that we can do thus far. So at the very end, we just return whatever the current state happens to be. And that is the conclusion of this algorithm. We've been able to figure out what the solution is. And these types of algorithms have a lot of different applications. Any time you can take a problem and formulate it as something where you can explore a particular configuration and then ask, are any of the neighbors better than this current configuration and have some way of measuring that, then there is an applicable case for these hill climbing, simulated annealing types of algorithms. So sometimes it can be for facility location type problems, like for when you're trying to plan a city and figure out where the hospitals should be. But there are definitely other applications as well. And one of the most famous problems in computer science is the traveling salesman problem. Traveling salesman problem generally is formulated like this. I have a whole bunch of cities here indicated by these dots. And what I'd like to do is find some route that takes me through all of the cities and ends up back where I started. So some route that starts here, goes through all these cities, and ends up back where I originally started. And what I might like to do is minimize the total distance that I have to travel or the total cost of taking this entire path. And you can imagine this is a problem that's very applicable in situations like when delivery companies are trying to deliver things to a whole bunch of different houses, they want to figure out, how do I get from the warehouse to all these various different houses and get back again, all using as minimal time and distance and energy as possible. So you might want to try to solve these sorts of problems. But it turns out that solving this particular kind of problem is very computationally difficult. It is a very computationally expensive task to be able to figure it out. This falls under the category of what are known as NP-complete problems, problems that there is no known efficient way to try and solve these sorts of problems. And so what we ultimately have to do is come up with some approximation, some ways of trying to find a good solution, even if we're not going to find the globally best solution that we possibly can, at least not in a feasible or tractable amount of time. And so what we could do is take the traveling salesman problem and try to formulate it using local search and ask a question like, all right, I can pick some state, some configuration, some route between all of these nodes. And I can measure the cost of that state, figure out what the distance is. And I might now want to try to minimize that cost as much as possible. And then the only question now is, what does it mean to have a neighbor of this state? What does it mean to take this particular route and have some neighboring route that is close to it but slightly different and such that it might have a different total distance? And there are a number of different definitions for what a neighbor of a traveling salesman configuration might look like. But one way is just to say, a neighbor is what happens if we pick two of these edges between nodes and switch them effectively. So for example, I might pick these two edges here, these two that just happened across this node goes here, this node goes there, and go ahead and switch them. And what that process will generally look like is removing both of these edges from the graph, taking this node, and connecting it to the node it wasn't connected to. So connecting it up here instead. We'll need to take these arrows that were originally going this way and reverse them, so move them going the other way, and then just fill in that last remaining blank, add an arrow that goes in that direction instead. So by taking two edges and just switching them, I have been able to consider one possible neighbor of this particular configuration. And it looks like this neighbor is actually better. It looks like this probably travels a shorter distance in order to get through all the cities through this route than the current state did. And so you could imagine implementing this idea inside of a hill climbing or simulated annealing algorithm, where we repeat this process to try and take a state of this traveling salesman problem, look at all the neighbors, and then move to the neighbors if they're better, or maybe even move to the neighbors if they're worse, until we eventually settle upon some best solution that we've been able to find. And it turns out that these types of approximation algorithms, even if they don't always find the very best solution, can often do pretty well at trying to find solutions that are helpful too. So that then was a look at local search, a particular category of algorithms that can be used for solving a particular type of problem, where we don't really care about the path to the solution. I didn't care about the steps I took to decide where the hospitals should go. I just cared about the solution itself. I just care about where the hospitals should be, or what the route through the traveling salesman journey really ought to be. Another type of algorithm that might come up are known as these categories of linear programming types of problems. And linear programming often comes up in the context where we're trying to optimize for some mathematical function. But oftentimes, linear programming will come up when we might have real numbered values. So it's not just discrete fixed values that we might have, but any decimal values that we might want to be able to calculate. And so linear programming is a family of types of problems where we might have a situation that looks like this, where the goal of linear programming is to minimize a cost function. And you can invert the numbers and say try and maximize it, but often we'll frame it as trying to minimize a cost function that has some number of variables, x1, x2, x3, all the way up to xn, just some number of variables that are involved, things that I want to know the values to. And this cost function might have coefficients in front of those variables. And this is what we would call a linear equation, where we just have all of these variables that might be multiplied by a coefficient and then add it together. We're not going to square anything or cube anything, because that'll give us different types of equations. With linear programming, we're just dealing with linear equations in addition to linear constraints, where a constraint is going to look something like if we sum up this particular equation that is just some linear combination of all of these variables, it is less than or equal to some bound b. And we might have a whole number of these various different constraints that we might place onto our linear programming exercise. And likewise, just as we can have constraints that are saying this linear equation is less than or equal to some bound b, it might also be equal to something. That if you want some sum of some combination of variables to be equal to a value, you can specify that. And we can also maybe specify that each variable has lower and upper bounds, that it needs to be a positive number, for example, or it needs to be a number that is less than 50, for example. And there are a number of other choices that we can make there for defining what the bounds of a variable are. But it turns out that if you can take a problem and formulate it in these terms, formulate the problem as your goal is to minimize a cost function, and you're minimizing that cost function subject to particular constraints, subjects to equations that are of the form like this of some sequence of variables is less than a bound or is equal to some particular value, then there are a number of algorithms that already exist for solving these sorts of problems. So let's go ahead and take a look at an example. Here's an example of a problem that might come up in the world of linear programming. Often, this is going to come up when we're trying to optimize for something. And we want to be able to do some calculations, and we have constraints on what we're trying to optimize. And so it might be something like this. In the context of a factory, we have two machines, x1 and x2. x1 costs $50 an hour to run. x2 costs $80 an hour to run. And our goal, what we're trying to do, our objective, is to minimize the total cost. So that's what we'd like to do. But we need to do so subject to certain constraints. So there might be a labor constraint that x1 requires five units of labor per hour, x2 requires two units of labor per hour, and we have a total of 20 units of labor that we have to spend. So this is a constraint. We have no more than 20 units of labor that we can spend, and we have to spend it across x1 and x2, each of which requires a different amount of labor. And we might also have a constraint like this that tells us x1 is going to produce 10 units of output per hour, x2 is going to produce 12 units of output per hour, and the company needs 90 units of output. So we have some goal, something we need to achieve. We need to achieve 90 units of output, but there are some constraints that x1 can only produce 10 units of output per hour, x2 produces 12 units of output per hour. These types of problems come up quite frequently, and you can start to notice patterns in these types of problems, problems where I am trying to optimize for some goal, minimizing cost, maximizing output, maximizing profits, or something like that. And there are constraints that are placed on that process. And so now we just need to formulate this problem in terms of linear equations. So let's start with this first point. Two machines, x1 and x2, x costs $50 an hour, x2 costs $80 an hour. Here we can come up with an objective function that might look like this. This is our cost function, rather. 50 times x1 plus 80 times x2, where x1 is going to be a variable representing how many hours do we run machine x1 for, x2 is going to be a variable representing how many hours are we running machine x2 for. And what we're trying to minimize is this cost function, which is just how much it costs to run each of these machines per hour summed up. This is an example of a linear equation, just some combination of these variables plus coefficients that are placed in front of them. And I would like to minimize that total value. But I need to do so subject to these constraints. x1 requires 50 units of labor per hour, x2 requires 2, and we have a total of 20 units of labor to spend. And so that gives us a constraint of this form. 5 times x1 plus 2 times x2 is less than or equal to 20. 20 is the total number of units of labor we have to spend. And that's spent across x1 and x2, each of which requires a different number of units of labor per hour, for example. And finally, we have this constraint here. x1 produces 10 units of output per hour, x2 produces 12, and we need 90 units of output. And so this might look something like this. That 10x1 plus 12x2, this is amount of output per hour, it needs to be at least 90. We can do better or great, but it needs to be at least 90. And if you recall from my formulation before, I said that generally speaking in linear programming, we deal with equals constraints or less than or equal to constraints. So we have a greater than or equal to sign here. That's not a problem. Whenever we have a greater than or equal to sign, we can just multiply the equation by negative 1, and that'll flip it around to a less than or equals negative 90, for example, instead of a greater than or equal to 90. And that's going to be an equivalent expression that we can use to represent this problem. So now that we have this cost function and these constraints that it's subject to, it turns out there are a number of algorithms that can be used in order to solve these types of problems. And these problems go a little bit more into geometry and linear algebra than we're really going to get into. But the most popular of these types of algorithms are simplex, which was one of the first algorithms discovered for trying to solve linear programs. And later on, a class of interior point algorithms can be used to solve this type of problem as well. The key is not to understand exactly how these algorithms work, but to realize that these algorithms exist for efficiently finding solutions any time we have a problem of this particular form. And so we can take a look, for example, at the production directory here, where here I have a file called production.py, where here I'm using scipy, which was the library for a lot of science-related functions within Python. And I can go ahead and just run this optimization function in order to run a linear program. .linprog here is going to try and solve this linear program for me, where I provide to this expression, to this function call, all of the data about my linear program. So it needs to be in a particular format, which might be a little confusing at first. But this first argument to scipy.optimize.linprogramming is the cost function, which is in this case just an array or a list that has 50 and 80, because my original cost function was 50 times x1 plus 80 times x2. So I just tell Python, 50 and 80, those are the coefficients that I am now trying to optimize for. And then I provide all of the constraints. So the constraints, and I wrote them up above in comments, is the constraint 1 is 5x1 plus 2x2 is less than or equal to 20. And constraint 2 is negative 10x1 plus negative 12x2 is less than or equal to negative 90. And so scipy expects these constraints to be in a particular format. It first expects me to provide all of the coefficients for the upper bound equations, ub just for upper bound, where the coefficients of the first equation are 5 and 2, because we have 5x1 and 2x2. And the coefficients for the second equation are negative 10 and negative 12, because I have negative 10x1 plus negative 12x2. And then here, we provide it as a separate argument, just to keep things separate, what the actual bound is. What is the upper bound for each of these constraints? Well, for the first constraint, the upper bound is 20. That was constraint number 1. And then for constraint number 2, the upper bound is 90. So a bit of a cryptic way of representing it. It's not quite as simple as just writing the mathematical equations. What really is being expected here are all of the coefficients and all of the numbers that are in these equations by first providing the coefficients for the cost function, then providing all the coefficients for the inequality constraints, and then providing all of the upper bounds for those inequality constraints. And once all of that information is there, then we can run any of these interior point algorithms or the simplex algorithm. Even if you don't understand how it works, you can just run the function and figure out what the result should be. And here, I said if the result is a success, we were able to solve this problem. Go ahead and print out what the value of x1 and x2 should be. Otherwise, go ahead and print out no solution. And so if I run this program by running python production.py, it takes a second to calculate. But then we see here is what the optimal solution should be. x1 should run for 1.5 hours. x2 should run for 6.25 hours. And we were able to do this by just formulating the problem as a linear equation that we were trying to optimize, some cost that we were trying to minimize, and then some constraints that were placed on that. And many, many problems fall into this category of problems that you can solve if you can just figure out how to use equations and use these constraints to represent that general idea. And that's a theme that's going to come up a couple of times today, where we want to be able to take some problem and reduce it down to some problem we know how to solve in order to begin to find a solution and to use existing methods that we can use in order to find a solution more effectively or more efficiently. And it turns out that these types of problems, where we have constraints, show up in other ways too. And there's an entire class of problems that's more generally just known as constraint satisfaction problems. And we're going to now take a look at how you might formulate a constraint satisfaction problem and how you might go about solving a constraint satisfaction problem. But the basic idea of a constraint satisfaction problem is we have some number of variables that need to take on some values. And we need to figure out what values each of those variables should take on. But those variables are subject to particular constraints that are going to limit what values those variables can actually take on. So let's take a look at a real world example, for example. Let's look at exam scheduling, that I have four students here, students 1, 2, 3, and 4. Each of them is taking some number of different classes. Classes here are going to be represented by letters. So student 1 is enrolled in courses A, B, and C. Student 2 is enrolled in courses B, D, and E, so on and so forth. And now, say university, for example, is trying to schedule exams for all of these courses. But there are only three exam slots on Monday, Tuesday, and Wednesday. And we have to schedule an exam for each of these courses. But the constraint now, the constraint we have to deal with with the scheduling, is that we don't want anyone to have to take two exams on the same day. We would like to try and minimize that or eliminate it if at all possible. So how do we begin to represent this idea? How do we structure this in a way that a computer with an AI algorithm can begin to try and solve the problem? Well, let's in particular just look at these classes that we might take and represent each of the courses as some node inside of a graph. And what we'll do is we'll create an edge between two nodes in this graph if there is a constraint between those two nodes. So what does this mean? Well, we can start with student 1, who's enrolled in courses A, B, and C. What that means is that A and B can't have an exam at the same time. A and C can't have an exam at the same time. And B and C also can't have an exam at the same time. And I can represent that in this graph by just drawing edges. One edge between A and B, one between B and C, and then one between C and A. And that encodes now the idea that between those nodes, there is a constraint. And in particular, the constraint happens to be that these two can't be equal to each other, though there are other types of constraints that are possible, depending on the type of problem that you're trying to solve. And then we can do the same thing for each of the other students. So for student 2, who's enrolled in courses B, D, and E, well, that means B, D, and E, those all need to have edges that connect each other as well. Student 3 is enrolled in courses C, E, and F. So we'll go ahead and take C, E, and F and connect those by drawing edges between them too. And then finally, student 4 is enrolled in courses E, F, and G. And we can represent that by drawing edges between E, F, and G, although E and F already had an edge between them. We don't need another one, because this constraint is just encoding the idea that course E and course F cannot have an exam on the same day. So this then is what we might call the constraint graph. There's some graphical representation of all of my variables, so to speak, and the constraints between those possible variables. Where in this particular case, each of the constraints represents an inequality constraint, that an edge between B and D means whatever value the variable B takes on cannot be the value that the variable D takes on as well. So what then actually is a constraint satisfaction problem? Well, a constraint satisfaction problem is just some set of variables, x1 all the way through xn, some set of domains for each of those variables. So every variable needs to take on some values. Maybe every variable has the same domain, but maybe each variable has a slightly different domain. And then there's a set of constraints, and we'll just call a set C, that is some constraints that are placed upon these variables, like x1 is not equal to x2. But there could be other forms too, like maybe x1 equals x2 plus 1 if these variables are taking on numerical values in their domain, for example. The types of constraints are going to vary based on the types of problems. And constraint satisfaction shows up all over the place as well, in any situation where we have variables that are subject to particular constraints. So one popular game is Sudoku, for example, this 9 by 9 grid where you need to fill in numbers in each of these cells, but you want to make sure there's never a duplicate number in any row, or in any column, or in any grid of 3 by 3 cells, for example. So what might this look like as a constraint satisfaction problem? Well, my variables are all of the empty squares in the puzzle. So represented here is just like an x comma y coordinate, for example, as all of the squares where I need to plug in a value, where I don't know what value it should take on. The domain is just going to be all of the numbers from 1 through 9, any value that I could fill in to one of these cells. So that is going to be the domain for each of these variables. And then the constraints are going to be of the form, like this cell can't be equal to this cell, can't be equal to this cell, can't be, and all of these need to be different, for example, and same for all of the rows, and the columns, and the 3 by 3 squares as well. So those constraints are going to enforce what values are actually allowed. And we can formulate the same idea in the case of this exam scheduling problem, where the variables we have are the different courses, a up through g. The domain for each of these variables is going to be Monday, Tuesday, and Wednesday. Those are the possible values each of the variables can take on, that in this case just represent when is the exam for that class. And then the constraints are of this form, a is not equal to b, a is not equal to c, meaning a and b can't have an exam on the same day, a and c can't have an exam on the same day. Or more formally, these two variables cannot take on the same value within their domain. So that then is this formulation of a constraint satisfaction problem that we can begin to use to try and solve this problem. And constraints can come in a number of different forms. There are hard constraints, which are constraints that must be satisfied for a correct solution. So something like in the Sudoku puzzle, you cannot have this cell and this cell that are in the same row take on the same value. That is a hard constraint. But problems can also have soft constraints, where these are constraints that express some notion of preference, that maybe a and b can't have an exam on the same day, but maybe someone has a preference that a's exam is earlier than b's exam. It doesn't need to be the case with some expression that some solution is better than another solution. And in that case, you might formulate the problem as trying to optimize for maximizing people's preferences. You want people's preferences to be satisfied as much as possible. In this case, though, we'll mostly just deal with hard constraints, constraints that must be met in order to have a correct solution to the problem. So we want to figure out some assignment of these variables to their particular values that is ultimately going to give us a solution to the problem by allowing us to assign some day to each of the classes such that we don't have any conflicts between classes. So it turns out that we can classify the constraints in a constraint satisfaction problem into a number of different categories. The first of those categories are perhaps the simplest of the types of constraints, which are known as unary constraints, where unary constraint is a constraint that just involves a single variable. For example, a unary constraint might be something like, a does not equal Monday, meaning Course A cannot have its exam on Monday. If for some reason the instructor for the course isn't available on Monday, you might have a constraint in your problem that looks like this, something that just has a single variable a in it, and maybe says a is not equal to Monday, or a is equal to something, or in the case of numbers greater than or less than something, a constraint that just has one variable, we consider to be a unary constraint. And this is in contrast to something like a binary constraint, which is a constraint that involves two variables, for example. So this would be a constraint like the ones we were looking at before. Something like a does not equal b is an example of a binary constraint, because it is a constraint that has two variables involved in it, a and b. And we represented that using some arc or some edge that connects variable a to variable b. And using this knowledge of, OK, what is a unary constraint? What is a binary constraint? There are different types of things we can say about a particular constraint satisfaction problem. And one thing we can say is we can try and make the problem node consistent. So what does node consistency mean? Node consistency means that we have all of the values in a variable's domain satisfying that variable's unary constraints. So for each of the variables inside of our constraint satisfaction problem, if all of the values satisfy the unary constraints for that particular variable, we can say that the entire problem is node consistent, or we can even say that a particular variable is node consistent if we just want to make one node consistent within itself. So what does that actually look like? Let's look at now a simplified example, where instead of having a whole bunch of different classes, we just have two classes, a and b, each of which has an exam on either Monday or Tuesday or Wednesday. So this is the domain for the variable a, and this is the domain for the variable b. And now let's imagine we have these constraints, a not equal to Monday, b not equal to Tuesday, b not equal to Monday, a not equal to b. So those are the constraints that we have on this particular problem. And what we can now try to do is enforce node consistency. And node consistency just means we make sure that all of the values for any variable's domain satisfy its unary constraints. And so we could start by trying to make node a node consistent. Is it consistent? Does every value inside of a's domain satisfy its unary constraints? Well, initially, we'll see that Monday does not satisfy a's unary constraints, because we have a constraint, a unary constraint here, that a is not equal to Monday. But Monday is still in a's domain. And so this is something that is not node consistent, because we have Monday in the domain. But this is not a valid value for this particular node. And so how do we make this node consistent? Well, to make the node consistent, what we'll do is we'll just go ahead and remove Monday from a's domain. Now a can only be on Tuesday or Wednesday, because we had this constraint that said a is not equal to Monday. And at this point now, a is node consistent. For each of the values that a can take on, Tuesday and Wednesday, there is no constraint that is a unary constraint that conflicts with that idea. There is no constraint that says that a can't be Tuesday. There is no unary constraint that says that a cannot be on Wednesday. And so now we can turn our attention to b. b also has a domain, Monday, Tuesday, and Wednesday. And we can begin to see whether those variables satisfy the unary constraints as well. Well, here is a unary constraint, b is not equal to Tuesday. And that does not appear to be satisfied by this domain of Monday, Tuesday, and Wednesday, because Tuesday, this possible value that the variable b could take on is not consistent with this unary constraint, that b is not equal to Tuesday. So to solve that problem, we'll go ahead and remove Tuesday from b's domain. Now b's domain only contains Monday and Wednesday. But as it turns out, there's yet another unary constraint that we placed on the variable b, which is here. b is not equal to Monday. And that means that this value, Monday, inside of b's domain, is not consistent with b's unary constraints, because we have a constraint that says the b cannot be Monday. And so we can remove Monday from b's domain. And now we've made it through all of the unary constraints. We've not yet considered this constraint, which is a binary constraint. But we've considered all of the unary constraints, all of the constraints that involve just a single variable. And we've made sure that every node is consistent with those unary constraints. So we can say that now we have enforced node consistency, that for each of these possible nodes, we can pick any of these values in the domain. And there won't be a unary constraint that is violated as a result of it. So node consistency is fairly easy to enforce. We just take each node, make sure the values in the domain satisfy the unary constraints. Where things get a little bit more interesting is when we consider different types of consistency, something like arc consistency, for example. And arc consistency refers to when all of the values in a variable's domain satisfy the variable's binary constraints. So when we're looking at trying to make a arc consistent, we're no longer just considering the unary constraints that involve a. We're trying to consider all of the binary constraints that involve a as well. So any edge that connects a to another variable inside of that constraint graph that we were taking a look at before. Put a little bit more formally, arc consistency. And arc really is just another word for an edge that connects two of these nodes inside of our constraint graph. We can define arc consistency a little more precisely like this. In order to make some variable x arc consistent with respect to some other variable y, we need to remove any element from x's domain to make sure that every choice for x, every choice in x's domain, has a possible choice for y. So put another way, if I have a variable x and I want to make x an arc consistent, then I'm going to look at all of the possible values that x can take on and make sure that for all of those possible values, there is still some choice that I can make for y, if there's some arc between x and y, to make sure that y has a possible option that I can choose as well. So let's look at an example of that going back to this example from before. We enforced node consistency already by saying that a can only be on Tuesday or Wednesday because we knew that a could not be on Monday. And we also said that b's only domain only consists of Wednesday because we know that b does not equal Tuesday and also b does not equal Monday. So now let's begin to consider arc consistency. Let's try and make a arc consistent with b. And what that means is to make a arc consistent with respect to b means that for any choice we make in a's domain, there is some choice we can make in b's domain that is going to be consistent. And we can try that. For a, we can choose Tuesday as a possible value for a. If I choose Tuesday for a, is there a value for b that satisfies the binary constraint? Well, yes, b Wednesday would satisfy this constraint that a does not equal b because Tuesday does not equal Wednesday. However, if we chose Wednesday for a, well, then there is no choice in b's domain that satisfies this binary constraint. There is no way I can choose something for b that satisfies a does not equal b because I know b must be Wednesday. And so if ever I run into a situation like this where I see that here is a possible value for a such that there is no choice of value for b that satisfies the binary constraint, well, then this is not arc consistent. And to make it arc consistent, I would need to take Wednesday and remove it from a's domain. Because Wednesday was not going to be a possible choice I can make for a because it wasn't consistent with this binary constraint for b. There was no way I could choose Wednesday for a and still have an available solution by choosing something for b as well. So here now, I've been able to enforce arc consistency. And in doing so, I've actually solved this entire problem, that given these constraints where a and b can have exams on either Monday or Tuesday or Wednesday, the only solution, as it would appear, is that a's exam must be on Tuesday and b's exam must be on Wednesday. And that is the only option available to me. So if we want to apply our consistency to a larger graph, not just looking at one particular pair of our consistency, there are ways we can do that too. And we can begin to formalize what the pseudocode would look like for trying to write an algorithm that enforces arc consistency. And we'll start by defining a function called revise. Revise is going to take as input a CSP, otherwise known as a constraint satisfaction problem, and also two variables, x and y. And what revise is going to do is it is going to make x arc consistent with respect to y, meaning remove anything from x's domain that doesn't allow for a possible option for y. How does this work? Well, we'll go ahead and first keep track of whether or not we've made a revision. Revise is ultimately going to return true or false. It'll return true in the event that we did make a revision to x's domain. It'll return false if we didn't make any change to x's domain. And we'll see in a moment why that's going to be helpful. But we start by saying revised equals false. We haven't made any changes. Then we'll say, all right, let's go ahead and loop over all of the possible values in x's domain. So loop over x's domain for each little x in x's domain. I want to make sure that for each of those choices, I have some available choice in y that satisfies the binary constraints that are defined inside of my CSP, inside of my constraint satisfaction problem. So if ever it's the case that there is no value y in y's domain that satisfies the constraint for x and y, well, if that's the case, that means that this value x shouldn't be in x's domain. So we'll go ahead and delete x from x's domain. And I'll set revised equal to true because I did change x's domain. I changed x's domain by removing little x. And I removed little x because it wasn't art consistent. There was no way I could choose a value for y that would satisfy this xy constraint. So in this case, we'll go ahead and set revised equal true. And we'll do this again and again for every value in x's domain. Sometimes it might be fine. In other cases, it might not allow for a possible choice for y, in which case we need to remove this value from x's domain. And at the end, we just return revised to indicate whether or not we actually made a change. So this function, then, this revised function is effectively an implementation of what you saw me do graphically a moment ago. And it makes one variable, x, arc consistent with another variable, in this case, y. But generally speaking, when we want to enforce our consistency, we'll often want to enforce our consistency not just for a single arc, but for the entire constraint satisfaction problem. And it turns out there's an algorithm to do that as well. And that algorithm is known as AC3. AC3 takes a constraint satisfaction problem. And it enforces our consistency across the entire problem. How does it do that? Well, it's going to basically maintain a queue or basically just a line of all of the arcs that it needs to make consistent. And over time, we might remove things from that queue as we begin dealing with our consistency. And we might need to add things to that queue as well if there are more things we need to make arc consistent. So we'll go ahead and start with a queue that contains all of the arcs in the constraint satisfaction problem, all of the edges that connect two nodes that have some sort of binary constraint between them. And now, as long as the queue is non-empty, there is work to be done. The queue is all of the things that we need to make arc consistent. So as long as the queue is non-empty, there's still things we have to do. What do we have to do? Well, we'll start by de-queuing from the queue, remove something from the queue. And strictly speaking, it doesn't need to be a queue, but a queue is a traditional way of doing this. We'll de-queue from the queue, and that'll give us an arc, x and y, these two variables where I would like to make x arc consistent with y. So how do we make x arc consistent with y? Well, we can go ahead and just use that revise function that we talked about a moment ago. We called the revise function, passing as input the constraint satisfaction problem, and also these variables x and y, because I want to make x arc consistent with y. In other words, remove any values from x's domain that don't leave an available option for y. And recall, what does revised return? Well, it returns true if we actually made a change, if we removed something from x's domain, because there wasn't an available option for y, for example. And it returns false if we didn't make any change to x's domain at all. And it turns out if revised returns false, if we didn't make any changes, well, then there's not a whole lot more work to be done here for this arc. We can just move ahead to the next arc that's in the queue. But if we did make a change, if we did reduce x's domain by removing values from x's domain, well, then what we might realize is that this creates potential problems later on, that it might mean that some arc that was arc consistent with x, that node might no longer be arc consistent with x, because while there used to be an option that we could choose for x, now there might not be, because now we might have removed something from x that was necessary for some other arc to be arc consistent. And so if ever we did revise x's domain, we're going to need to add some things to the queue, some additional arcs that we might want to check. How do we do that? Well, first thing we want to check is to make sure that x's domain is not 0. If x's domain is 0, that means there are no available options for x at all. And that means that there's no way you can solve the constraint satisfaction problem. If we've removed everything from x's domain, we'll go ahead and just return false here to indicate there's no way to solve the problem, because there's nothing left in x's domain. But otherwise, if there are things left in x's domain, but fewer things than before, well, then what we'll do is we'll loop over each variable z that is in all of x's neighbors, except for y, y we already handled. But we'll consider all of x's other's neighbors and ask ourselves, all right, will that arc from each of those z's to x, that arc might no longer be arc consistent, because while for each z, there might have been a possible option we could choose for x to correspond with each of z's possible values, now there might not be, because we removed some elements from x's domain. And so what we'll do here is we'll go ahead and enqueue, adding something to the queue, this arc zx for all of those neighbors z. So we need to add back some arcs to the queue in order to continue to enforce arc consistency. At the very end, if we make it through all this process, then we can return true. But this now is AC3, this algorithm for enforcing arc consistency on a constraint satisfaction problem. And the big idea is really just keep track of all of the arcs that we might need to make arc consistent, make it arc consistent by calling the revise function. And if we did revise it, then there are some new arcs that might need to be added to the queue in order to make sure that everything is still arc consistent, even after we've removed some of the elements from a particular variable's domain. So what then would happen if we tried to enforce arc consistency on a graph like this, on a graph where each of these variables has a domain of Monday, Tuesday, and Wednesday? Well, it turns out that by enforcing arc consistency on this graph, well, it can solve some types of problems. Nothing actually changes here. For any particular arc, just considering two variables, there's always a way for me to just, for any of the choices I make for one of them, make a choice for the other one, because there are three options, and I just need the two to be different from each other. So this is actually quite easy to just take an arc and just declare that it is arc consistent, because if I pick Monday for D, then I just pick something that isn't Monday for B. In arc consistency, we only consider consistency between a binary constraint between two nodes, and we're not really considering all of the rest of the nodes yet. So just using AC3, the enforcement of arc consistency, that can sometimes have the effect of reducing domains to make it easier to find solutions, but it will not always actually solve the problem. We might still need to somehow search to try and find a solution. And we can use classical traditional search algorithms to try to do so. You'll recall that a search problem generally consists of these parts. We have some initial state, some actions, a transition model that takes me from one state to another state, a goal test to tell me have I satisfied my objective correctly, and then some path cost function, because in the case of like maze solving, I was trying to get to my goal as quickly as possible. So you could formulate a CSP, or a constraint satisfaction problem, as one of these types of search problems. The initial state will just be an empty assignment, where an assignment is just a way for me to assign any particular variable to any particular value. So if an empty assignment is no variables that are assigned to any values yet, then the action I can take is adding some new variable equals value pair to that assignment, saying for this assignment, let me add a new value for this variable. And the transition model just defines what happens when you take that action. You get a new assignment that has that variable equal to that value inside of it. The goal test is just checking to make sure all the variables have been assigned and making sure all the constraints have been satisfied. And the path cost function is sort of irrelevant. I don't really care about what the path really is. I just care about finding some assignment that actually satisfies all of the constraints. So really, all the paths have the same cost. I don't really care about the path to the goal. I just care about the solution itself, much as we've talked about now before. The problem here, though, is that if we just implement this naive search algorithm just by implementing like breadth-first search or depth-first search, this is going to be very, very inefficient. And there are ways we can take advantage of efficiencies in the structure of a constraint satisfaction problem itself. And one of the key ideas is that we can really just order these variables. And it doesn't matter what order we assign variables in. The assignment a equals 2 and then b equals 8 is identical to the assignment of b equals 8 and then a equals 2. Switching the order doesn't really change anything about the fundamental nature of that assignment. And so there are some ways that we can try and revise this idea of a search algorithm to apply it specifically for a problem like a constraint satisfaction problem. And it turns out the search algorithm we'll generally use when talking about constraint satisfaction problems is something known as backtracking search. And the big idea of backtracking search is we'll go ahead and make assignments from variables to values. And if ever we get stuck, we arrive at a place where there is no way we can make any forward progress while still preserving the constraints that we need to enforce, we'll go ahead and backtrack and try something else instead. So the very basic sketch of what backtracking search looks like is it looks like this. Function called backtrack that takes as input an assignment and a constraint satisfaction problem. So initially, we don't have any assigned variables. So when we begin backtracking search, this assignment is just going to be the empty assignment with no variables inside of it. But we'll see later this is going to be a recursive function. So backtrack takes as input the assignment and the problem. If the assignment is complete, meaning all of the variables have been assigned, we just return that assignment. That, of course, won't be true initially, because we start with an empty assignment. But over time, we might add things to that assignment. So if ever the assignment actually is complete, then we're done. Then just go ahead and return that assignment. But otherwise, there is some work to be done. So what we'll need to do is select an unassigned variable for this particular problem. So we need to take the problem, look at the variables that have already been assigned, and pick a variable that has not yet been assigned. And I'll go ahead and take that variable. And then I need to consider all of the values in that variable's domain. So we'll go ahead and call this domain values function. We'll talk a little more about that later, that takes a variable and just gives me back an ordered list of all of the values in its domain. So I've taken a random unselected variable. I'm going to loop over all of the possible values. And the idea is, let me just try all of these values as possible values for the variable. So if the value is consistent with the assignment so far, it doesn't violate any of the constraints, well then let's go ahead and add variable equals value to the assignment because it's so far consistent. And now let's recursively call backtrack to try and make the rest of the assignments also consistent. So I'll go ahead and call backtrack on this new assignment that I've added the variable equals value to. And now I recursively call backtrack and see what the result is. And if the result isn't a failure, well then let me just return that result. And otherwise, what else could happen? Well, if it turns out the result was a failure, well then that means this value was probably a bad choice for this particular variable because when I assigned this variable equal to that value, eventually down the road I ran into a situation where I violated constraints. There was nothing more I could do. So now I'll remove variable equals value from the assignment, effectively backtracking to say, all right, that value didn't work. Let's try another value instead. And then at the very end, if we were never able to return a complete assignment, we'll just go ahead and return failure because that means that none of the values worked for this particular variable. This now is the idea for backtracking search, to take each of the variables, try values for them, and recursively try backtracking search, see if we can make progress. And if ever we run into a dead end, we run into a situation where there is no possible value we can choose that satisfies the constraints, we return failure. And that propagates up, and eventually we make a different choice by going back and trying something else instead. So let's put this algorithm into practice. Let's actually try and use backtracking search to solve this problem now, where I need to figure out how to assign each of these courses to an exam slot on Monday or Tuesday or Wednesday in such a way that it satisfies these constraints, that each of these edges mean those two classes cannot have an exam on the same day. So I can start by just starting at a node. It doesn't really matter which I start with, but in this case, I'll just start with A. And I'll ask the question, all right, let me loop over the values in the domain. And maybe in this case, I'll just start with Monday and say, all right, let's go ahead and assign A to Monday. We'll just go and order Monday, Tuesday, Wednesday. And now let's consider node B. So I've made an assignment to A, so I recursively call backtrack with this new part of the assignment. And now I'm looking to pick another unassigned variable like B. And I'll say, all right, maybe I'll start with Monday, because that's the very first value in B's domain. And I ask, all right, does Monday violate any constraints? And it turns out, yes, it does. It violates this constraint here between A and B, because A and B are now both on Monday, and that doesn't work, because B can't be on the same day as A. So that doesn't work. So we might instead try Tuesday, try the next value in B's domain. And is that consistent with the assignment so far? Well, yeah, B, Tuesday, A, Monday, that is consistent so far, because they're not on the same day. So that's good. Now we can recursively call backtrack. Try again. Pick another unassigned variable, something like D, and say, all right, let's go through its possible values. Is Monday consistent with this assignment? Well, yes, it is. B and D are on different days, Monday versus Tuesday. And A and B are also on different days, Monday versus Tuesday. So that's fine so far, too. We'll go ahead and try again. Maybe we'll go to this variable here, E. Say, can we make that consistent? Let's go through the possible values. We've recursively called backtrack. We might start with Monday and say, all right, that's not consistent, because D and E now have exams on the same day. So we might try Tuesday instead, going to the next one. Ask, is that consistent? Well, no, it's not, because B and E, those have exams on the same day. And so we try, all right, is Wednesday consistent? And in turn, it's like, all right, yes, it is. Wednesday is consistent, because D and E now have exams on different days. B and E now have exams on different days. All seems to be well so far. I recursively call backtrack, select another unassigned variable, we'll say maybe choose C this time, and say, all right, let's try the values that C could take on. Let's start with Monday. And it turns out that's not consistent, because now A and C both have exams on the same day. So I try Tuesday and say, that's not consistent either, because B and C now have exams on the same day. And then I say, all right, let's go ahead and try Wednesday. But that's not consistent either, because C and E each have exams on the same day too. So now we've gone through all the possible values for C, Monday, Tuesday, and Wednesday. And none of them are consistent. There is no way we can have a consistent assignment. Backtrack, in this case, will return a failure. And so then we'd say, all right, we have to backtrack back to here. Well, now for E, we've tried all of Monday, Tuesday, and Wednesday. And none of those work, because Wednesday, which seemed to work, turned out to be a failure. So that means there's no possible way we can assign E. So that's a failure too. We have to go back up to D, which means that Monday assignment to D, that must be wrong. We must try something else. So we can try, all right, what if instead of Monday, we try Tuesday? Tuesday, it turns out, is not consistent, because B and D now have an exam on the same day. But Wednesday, as it turns out, works. And now we can begin to mix and forward progress again. We go back to E and say, all right, which of these values works? Monday turns out to work by not violating any constraints. Then we go up to C now. Monday doesn't work, because it violates a constraint. Violates two, actually. Tuesday doesn't work, because it violates a constraint as well. But Wednesday does work. Then we can go to the next variable, F, and say, all right, does Monday work? We'll know. It violates a constraint. But Tuesday does work. And then finally, we can look at the last variable, G, recursively calling backtrack one more time. Monday is inconsistent. That violates a constraint. Tuesday also violates a constraint. But Wednesday, that doesn't violate a constraint. And so now at this point, we recursively call backtrack one last time. We now have a satisfactory assignment of all of the variables. And at this point, we can say that we are now done. We have now been able to successfully assign a variable or a value to each one of these variables in such a way that we're not violating any constraints. We're going to go ahead and have classes A and E have their exams on Monday. Classes B and F can have their exams on Tuesday. And classes C, D, and G can have their exams on Wednesday. And there's no violated constraints that might come up there. So that then was a graphical look at how this might work. Let's now take a look at some code we could use to actually try and solve this problem as well. So here I'll go ahead and go into the scheduling directory. We're here now. We'll start by looking at schedule0.py. We're here. I define a list of variables, A, B, C, D, E, F, G. Those are all different classes. Then underneath that, I define my list of constraints. So constraint A and B. That is a constraint because they can't be on the same day. Likewise, A and C, B and C, so on and so forth, enforcing those exact same constraints. And here then is what the backtracking function might look like. First, if the assignment is complete, if I've made an assignment of every variable to a value, go ahead and just return that assignment. Then we'll select an unassigned variable from that assignment. Then for each of the possible values in the domain, Monday, Tuesday, Wednesday, let's go ahead and create a new assignment that assigns the variable to that value. I'll call this consistent function, which I'll show you in a moment, that just checks to make sure this new assignment is consistent. But if it is consistent, we'll go ahead and call backtrack to go ahead and continue trying to run backtracking search. And as long as the result is not none, meaning it wasn't a failure, we can go ahead and return that result. But if we make it through all the values and nothing works, then it is a failure. There's no solution. We go ahead and return none here. What do these functions do? Select unassigned variable is just going to choose a variable not yet assigned. So it's going to loop over all the variables. And if it's not already assigned, we'll go ahead and just return that variable. And what does the consistent function do? Well, the consistent function goes through all the constraints. And if we have a situation where we've assigned both of those values to variables, but they are the same, well, then that is a violation of the constraint, in which case we'll return false. But if nothing is inconsistent, then the assignment is consistent and will return true. And then all the program does is it calls backtrack on an empty assignment, an empty dictionary that has no variable assigned and no values yet, save that inside a solution, and then print out that solution. So by running this now, I can run Python schedule0.py. And what I get as a result of that is an assignment of all these variables to values. And it turns out we assign a to Monday as we would expect, b to Tuesday, c to Wednesday, exactly the same type of thing we were talking about before, an assignment of each of these variables to values that doesn't violate any constraints. And I had to do a fair amount of work in order to implement this idea myself. I had to write the backtrack function that went ahead and went through this process of recursively trying to do this backtracking search. But it turns out the constraint satisfaction problems are so popular that there exist many libraries that already implement this type of idea. Again, as with before, the specific library is not as important as the fact that libraries do exist. This is just one example of a Python constraint library, where now, rather than having to do all the work from scratch inside of schedule1.py, I'm just taking advantage of a library that implements a lot of these ideas already. So here, I create a new problem, add variables to it with particular domains. I add a whole bunch of these individual constraints, where I call addConstraint and pass in a function describing what the constraint is. And the constraint basically says the function that takes two variables, x and y, and makes sure that x is not equal to y, enforcing the idea that these two classes cannot have exams on the same day. And then, for any constraint satisfaction problem, I can call getSolutions to get all the solutions to that problem. And then, for each of those solutions, print out what that solution happens to be. And if I run python schedule1.py, and now see, there are actually a number of different solutions that can be used to solve the problem. There are, in fact, six different solutions, assignments of variables to values that will give me a satisfactory answer to this constraint satisfaction problem. So this then was an implementation of a very basic backtracking search method, where really we just went through each of the variables, picked one that wasn't assigned, tried the possible values the variable could take on. And then, if it worked, if it didn't violate any constraints, then we kept trying other variables. And if ever we hit a dead end, we had to backtrack. But ultimately, we might be able to be a little bit more intelligent about how we do this in order to improve the efficiency of how we solve these sorts of problems. And one thing we might imagine trying to do is going back to this idea of inference, using the knowledge we know to be able to draw conclusions in order to make the rest of the problem solving process a little bit easier. And let's now go back to where we got stuck in this problem the first time. When we were solving this constraint satisfaction problem, we dealt with B. And then we went on to D. And we went ahead and just assigned D to Monday, because that seemed to work with the assignment so far. It didn't violate any constraints. But it turned out that later on that choice turned out to be a bad one, that that choice wasn't consistent with the rest of the values that we could take on here. And the question is, is there anything we could do to avoid getting into a situation like this, avoid trying to go down a path that's ultimately not going to lead anywhere by taking advantage of knowledge that we have initially? And it turns out we do have that kind of knowledge. We can look at just the structure of this graph so far. And we can say that right now C's domain, for example, contains values Monday, Tuesday, and Wednesday. And based on those values, we can say that this graph is not arc consistent. Recall that arc consistency is all about making sure that for every possible value for a particular node, that there is some other value that we are able to choose. And as we can see here, Monday and Tuesday are not going to be possible values that we can choose for C. They're not going to be consistent with a node like B, for example, because B is equal to Tuesday, which means that C cannot be Tuesday. And because A is equal to Monday, C also cannot be Monday. So using that information, by making C arc consistent with A and B, we could remove Monday and Tuesday from C's domain and just leave C with Wednesday, for example. And if we continued to try and enforce arc consistency, we'd see there are some other conclusions we can draw as well. We see that B's only option is Tuesday and C's only option is Wednesday. And so if we want to make E arc consistent, well, E can't be Tuesday, because that wouldn't be arc consistent with B. And E can't be Wednesday, because that wouldn't be arc consistent with C. So we can go ahead and say E and just set that equal to Monday, for example. And then we can begin to do this process again and again, that in order to make D arc consistent with B and E, then D would have to be Wednesday. That's the only possible option. And likewise, we can make the same judgments for F and G as well. And it turns out that without having to do any additional search, just by enforcing arc consistency, we were able to actually figure out what the assignment of all the variables should be without needing to backtrack at all. And the way we did that is by interleaving this search process and the inference step, by this step of trying to enforce arc consistency. And the algorithm to do this is often called just the maintaining arc consistency algorithm, which just enforces arc consistency every time we make a new assignment of a value to an existing variable. So sometimes we can enforce our consistency using that AC3 algorithm at the very beginning of the problem before we even begin searching in order to limit the domain of the variables in order to make it easier to search. But we can also take advantage of the interleaving of enforcing our consistency with search such that every time in the search process we make a new assignment, we go ahead and enforce arc consistency as well to make sure that we're just eliminating possible values from domains whenever possible. And how do we do this? Well, this is really equivalent to just every time we make a new assignment to a variable x. We'll go ahead and call our AC3 algorithm, this algorithm that enforces arc consistency on a constraint satisfaction problem. And we go ahead and call that, starting it with a Q, not of all of the arcs, which we did originally, but just of all of the arcs that we want to make arc consistent with x, this thing that we have just made an assignment to. So all arcs yx, where y is a neighbor of x, something that shares a constraint with x, for example. And by maintaining arc consistency in the backtracking search process, we can ultimately make our search process a little bit more efficient. And so this is the revised version of this backtrack function. Same as before, the changes here are highlighted in yellow. Every time we add a new variable equals value to our assignment, we'll go ahead and run this inference procedure, which might do a number of different things. But one thing it could do is call the maintaining arc consistency algorithm to make sure we're able to enforce arc consistency on the problem. And we might be able to draw new inferences as a result of that process. Get new guarantees of this variable needs to be equal to that value, for example. That might happen one time. It might happen many times. And so long as those inferences are not a failure, as long as they don't lead to a situation where there is no possible way to make forward progress, well, then we can go ahead and add those inferences, those new knowledge, that new pieces of knowledge I know about what variables should be assigned to what values, I can add those to the assignment in order to more quickly make forward progress by taking advantage of information that I can just deduce, information I know based on the rest of the structure of the constraint satisfaction problem. And the only other change I'll need to make now is if it turns out this value doesn't work, well, then down here, I'll go ahead and need to remove not only variable equals value, but also any of those inferences that I made, remove that from the assignment as well. So here, then, we're often able to solve the problem by backtracking less than we might originally have needed to, just by taking advantage of the fact that every time we make a new assignment of one variable to one value, that might reduce the domains of other variables as well. And we can use that information to begin to more quickly draw conclusions in order to try and solve the problem more efficiently as well. And it turns out there are other heuristics we can use to try and improve the efficiency of our search process as well. And it really boils down to a couple of these functions that I've talked about, but we haven't really talked about how they're working. And one of them is this function here, select unassigned variable, where we're selecting some variable in the constraint satisfaction problem that has not yet been assigned. So far, I've sort of just been selecting variables randomly, just like picking one variable and one unassigned variable in order to decide, all right, this is the variable that we're going to assign next, and then going from there. But it turns out that by being a little bit intelligent, by following certain heuristics, we might be able to make the search process much more efficient just by choosing very carefully which variable we should explore next. So some of those heuristics include the minimum remaining values, or MRV heuristic, which generally says that if I have a choice between which variable I should select, I should select the variable with the smallest domain, the variable that has the fewest number of remaining values left. With the idea being, if there are only two remaining values left, well, I may as well prune one of them very quickly in order to get to the other, because one of those two has got to be the solution, if a solution does exist. Sometimes minimum remaining values might not give a conclusive result if all the nodes have the same number of remaining values, for example. And in that case, another heuristic that can be helpful to look at is the degree heuristic. The degree of a node is the number of nodes that are attached to that node, the number of nodes that are constrained by that particular node. And if you imagine which variable should I choose, should I choose a variable that has a high degree that is connected to a lot of different things, or a variable with a low degree that is not connected to a lot of different things, well, it can often make sense to choose the variable that has the highest degree that is connected to the most other nodes as the thing you would search first. Why is that the case? Well, it's because by choosing a variable with a high degree, that is immediately going to constrain the rest of the variables more, and it's more likely to be able to eliminate large sections of the state space that you don't need to search through at all. So what could this actually look like? Let's go back to this search problem here. In this particular case, I've made an assignment here. I've made an assignment here. And the question is, what should I look at next? And according to the minimum remaining values heuristic, what I should choose is the variable that has the fewest remaining possible values. And in this case, that's this node here, node C, that only has one variable left in this domain, which in this case is Wednesday, which is a very reasonable choice of a next assignment to make, because I know it's the only option, for example. I know that the only possible option for C is Wednesday, so I may as well make that assignment and then potentially explore the rest of the space after that. But meanwhile, at the very start of the problem, when I didn't have any knowledge of what nodes should have what values yet, I still had to pick what node should be the first one that I try and assign a value to. And I arbitrarily just chose the one at the top, node A originally. But we can be more intelligent about that. We can look at this particular graph. All of them have domains of the same size, domain of size 3. So minimum remaining values doesn't really help us there. But we might notice that node E has the highest degree. It is connected to the most things. And so perhaps it makes sense to begin our search, rather than starting at node A at the very top, start with the node with the highest degree. Start by searching from node E, because from there, that's going to much more easily allow us to enforce the constraints that are nearby, eliminating large portions of the search space that I might not need to search through. And in fact, by starting with E, we can immediately then assign other variables. And following that, we can actually assign the rest of the variables without needing to do any backtracking at all, even if I'm not using this inference procedure. Just by starting with a node that has a high degree, that is going to very quickly restrict the possible values that other nodes can take on. So that then is how we can go about selecting an unassigned variable in a particular order. Rather than randomly picking a variable, if we're a little bit intelligent about how we choose it, we can make our search process much, much more efficient by making sure we don't have to search through portions of the search space that ultimately aren't going to matter. The other variable we haven't really talked about, the other function here, is this domain values function. This domain values function that takes a variable and gives me back a sequence of all of the values inside of that variable's domain. The naive way to approach it is what we did before, which is just go in order, go Monday, then Tuesday, then Wednesday. But the problem is that going in that order might not be the most efficient order to search in, that sometimes it might be more efficient to choose values that are likely to be solutions first and then go to other values. Now, how do you assess whether a value is likelier to lead to a solution or less likely to lead to a solution? Well, one thing you can take a look at is how many constraints get added, how many things get removed from domains as you make this new assignment of a variable to this particular value. And the heuristic we can use here is the least constraining value heuristic, which is the idea that we should return variables in order based on the number of choices that are ruled out for neighboring values. And I want to start with the least constraining value, the value that rules out the fewest possible options. And the idea there is that if all I care about doing is finding a solution, if I start with a value that rules out a lot of other choices, I'm ruling out a lot of possibilities that maybe is going to make it less likely that this particular choice leads to a solution. Whereas on the other hand, if I have a variable and I start by choosing a value that doesn't rule out very much, well, then I still have a lot of space where there might be a solution that I could ultimately find. And this might seem a little bit counterintuitive and a little bit at odds with what we were talking about before, where I said, when you're picking a variable, you should pick the variable that is going to have the fewest possible values remaining. But here, I want to pick the value for the variable that is the least constraining. But the general idea is that when I am picking a variable, I would like to prune large portions of the search space by just choosing a variable that is going to allow me to quickly eliminate possible options. Whereas here, within a particular variable, as I'm considering values that that variable could take on, I would like to just find a solution. And so what I want to do is ultimately choose a value that still leaves open the possibility of me finding a solution to be as likely as possible. By not ruling out many options, I leave open the possibility that I can still find a solution without needing to go back later and backtrack. So an example of that might be in this particular situation here, if I'm trying to choose a variable for a value for node C here, that C is equal to either Tuesday or Wednesday. We know it can't be Monday because it conflicts with this domain here, where we already know that A is Monday, so C must be Tuesday or Wednesday. And the question is, should I try Tuesday first, or should I try Wednesday first? And if I try Tuesday, what gets ruled out? Well, one option gets ruled out here, a second option gets ruled out here, and a third option gets ruled out here. So choosing Tuesday would rule out three possible options. And what about choosing Wednesday? Well, choosing Wednesday would rule out one option here, and it would rule out one option there. And so I have two choices. I can choose Tuesday that rules out three options, or Wednesday that rules out two options. And according to the least constraining value heuristic, what I should probably do is go ahead and choose Wednesday, the one that rules out the fewest number of possible options, leaving open as many chances as possible for me to eventually find the solution inside of the state space. And ultimately, if you continue this process, we will find the solution, an assignment of variables, two values, that allows us to give each of these exams, each of these classes, an exam date that doesn't conflict with anyone that happens to be enrolled in two classes at the same time. So the big takeaway now with all of this is that there are a number of different ways we can formulate a problem. The ways we've looked at today are we can formulate a problem as a local search problem, a problem where we're looking at a current node and moving to a neighbor based on whether that neighbor is better or worse than the current node that we are looking at. We looked at formulating problems as linear programs, where just by putting things in terms of equations and constraints, we're able to solve problems a little bit more efficiently. And we saw formulating a problem as a constraint satisfaction problem, creating this graph of all of the constraints that connect two variables that have some constraint between them, and using that information to be able to figure out what the solution should be. And so the takeaway of all of this now is that if we have some problem in artificial intelligence that we would like to use AI to be able to solve them, whether that's trying to figure out where hospitals should be or trying to solve the traveling salesman problem, trying to optimize productions and costs and whatnot, or trying to figure out how to satisfy certain constraints, whether that's in a Sudoku puzzle, or whether that's in trying to figure out how to schedule exams for a university, or any number of a wide variety of types of problems, if we can formulate that problem as one of these sorts of problems, then we can use these known algorithms, these algorithms for enforcing art consistency and backtracking search, these hill climbing and simulated annealing algorithms, these simplex algorithms and interior point algorithms that can be used to solve linear programs, that we can use those techniques to begin to solve a whole wide variety of problems all in this world of optimization inside of artificial intelligence. This was an introduction to artificial intelligence with Python for today. We will see you next time. [\" All right. Welcome back, everyone, to an introduction to artificial intelligence with Python. Now, so far in this class, we've used AI to solve a number of different problems, giving AI instructions for how to search for a solution, or how to satisfy certain constraints in order to find its way from some input point to some output point in order to solve some sort of problem. Today, we're going to turn to the world of learning, in particular the idea of machine learning, which generally refers to the idea where we are not going to give the computer explicit instructions for how to perform a task, but rather we are going to give the computer access to information in the form of data, or patterns that it can learn from, and let the computer try and figure out what those patterns are, try and understand that data to be able to perform a task on its own. Now, machine learning comes in a number of different forms, and it's a very wide field. So today, we'll explore some of the foundational algorithms and ideas that are behind a lot of the different areas within machine learning. And one of the most popular is the idea of supervised machine learning, or just supervised learning. And supervised learning is a particular type of task. It refers to the task where we give the computer access to a data set, where that data set consists of input-output pairs. And what we would like the computer to do is we would like our AI to be able to figure out some function that maps inputs to outputs. So we have a whole bunch of data that generally consists of some kind of input, some evidence, some information that the computer will have access to. And we would like the computer, based on that input information, to predict what some output is going to be. And we'll give it some data so that the computer can train its model on and begin to understand how it is that this information works and how it is that the inputs and outputs relate to each other. But ultimately, we hope that our computer will be able to figure out some function that, given those inputs, is able to get those outputs. There are a couple of different tasks within supervised learning. The one we'll focus on and start with is known as classification. And classification is the problem where, if I give you a whole bunch of inputs, you need to figure out some way to map those inputs into discrete categories, where you can decide what those categories are, and it's the job of the computer to predict what those categories are going to be. So that might be, for example, I give you information about a bank note, like a US dollar, and I'm asking you to predict for me, does it belong to the category of authentic bank notes, or does it belong to the category of counterfeit bank notes? You need to categorize the input, and we want to train the computer to figure out some function to be able to do that calculation. Another example might be the case of weather, someone we've talked about a little bit so far in this class, where we would like to predict on a given day, is it going to rain on that day? Is it going to be cloudy on that day? And before we've seen how we could do this, if we really give the computer all the exact probabilities for if these are the conditions, what's the probability of rain? Oftentimes, we don't have access to that information, though. But what we do have access to is a whole bunch of data. So if we wanted to be able to predict something like, is it going to rain or is it not going to rain, we would give the computer historical information about days when it was raining and days when it was not raining and ask the computer to look for patterns in that data. So what might that data look like? Well, we could structure that data in a table like this. This might be what our table looks like, where for any particular day, going back, we have information about that day's humidity, that day's air pressure, and then importantly, we have a label, something where the human has said that on this particular day, it was raining or it was not raining. So you could fill in this table with a whole bunch of data. And what makes this what we would call a supervised learning exercise is that a human has gone in and labeled each of these data points, said that on this day, when these were the values for the humidity and pressure, that day was a rainy day and this day was a not rainy day. And what we would like the computer to be able to do then is to be able to figure out, given these inputs, given the humidity and the pressure, can the computer predict what label should be associated with that day? Does that day look more like it's going to be a day that rains or does it look more like a day when it's not going to rain? Put a little bit more mathematically, you can think of this as a function that takes two inputs, the inputs being the data points that our computer will have access to, things like humidity and pressure. So we could write a function f that takes as input both humidity and pressure. And then the output is going to be what category we would ascribe to these particular input points, what label we would associate with that input. So we've seen a couple of example data points here, where given this value for humidity and this value for pressure, we predict, is it going to rain or is it not going to rain? And that's information that we just gathered from the world. We measured on various different days what the humidity and pressure were. We observed whether or not we saw rain or no rain on that particular day. And this function f is what we would like to approximate. Now, the computer and we humans don't really know exactly how this function f works. It's probably quite a complex function. So what we're going to do instead is attempt to estimate it. We would like to come up with a hypothesis function. h, which is going to try to approximate what f does. We want to come up with some function h that will also take the same inputs and will also produce an output, rain or no rain. And ideally, we'd like these two functions to agree as much as possible. So the goal then of the supervised learning classification tasks is going to be to figure out, what does that function h look like? How can we begin to estimate, given all of this information, all of this data, what category or what label should be assigned to a particular data point? So where could you begin doing this? Well, a reasonable thing to do, especially in this situation, I have two numerical values, is I could try to plot this on a graph that has two axes, an x-axis and a y-axis. And in this case, we're just going to be using two numerical values as input. But these same types of ideas scale as you add more and more inputs as well. We'll be plotting things in two dimensions. But as we soon see, you could add more inputs and just imagine things in multiple dimensions. And while we humans have trouble conceptualizing anything really beyond three dimensions, at least visually, a computer has no problem with trying to imagine things in many, many more dimensions, that for a computer, each dimension is just some separate number that it is keeping track of. So it wouldn't be unreasonable for a computer to think in 10 dimensions or 100 dimensions to be able to try to solve a problem. But for now, we've got two inputs. So we'll graph things along two axes, an x-axis, which will here represent humidity, and a y-axis, which here represents pressure. And what we might do is say, let's take all of the days that were raining and just try to plot them on this graph and see where they fall on this graph. And here might be all of the rainy days, where each rainy day is one of these blue dots here that corresponds to a particular value for humidity and a particular value for pressure. And then I might do the same thing with the days that were not rainy. So take all the not rainy days, figure out what their values were for each of these two inputs, and go ahead and plot them on this graph as well. And I've here plotted them in red. So blue here stands for a rainy day. Red here stands for a not rainy day. And this then is the input that my computer has access to all of this input. And what I would like the computer to be able to do is to train a model such that if I'm ever presented with a new input that doesn't have a label associated with it, something like this white dot here, I would like to predict, given those values for each of the two inputs, should we classify it as a blue dot, a rainy day, or should we classify it as a red dot, a not rainy day? And if you're just looking at this picture graphically, trying to say, all right, this white dot, does it look like it belongs to the blue category, or does it look like it belongs to the red category, I think most people would agree that it probably belongs to the blue category. And why is that? Well, it looks like it's close to other blue dots. And that's not a very formal notion, but it's a notion that we'll formalize in just a moment. That because it seems to be close to this blue dot here, nothing else is closer to it, then we might say that it should be categorized as blue. It should fall into that category of, I think that day is going to be a rainy day based on that input. Might not be totally accurate, but it's a pretty good guess. And this type of algorithm is actually a very popular and common machine learning algorithm known as nearest neighbor classification. It's an algorithm for solving these classification-type problems. And in nearest neighbor classification, it's going to perform this algorithm. What it will do is, given an input, it will choose the class of the nearest data point to that input. By class, we just here mean category, like rain or no rain, counterfeit or not counterfeit. And we choose the category or the class based on the nearest data point. So given all that data, we just looked at, is the nearest data point a blue point or is it a red point? And depending on the answer to that question, we were able to make some sort of judgment. We were able to say something like, we think it's going to be blue or we think it's going to be red. So likewise, we could apply this to other data points that we encounter as well. If suddenly this data point comes about, well, its nearest data is red. So we would go ahead and classify this as a red point, not raining. Things get a little bit trickier, though, when you look at a point like this white point over here and you ask the same sort of question. Should it belong to the category of blue points, the rainy days? Or should it belong to the category of red points, the not rainy days? Now, nearest neighbor classification would say the way you solve this problem is look at which point is nearest to that point. You look at this nearest point and say it's red. It's a not rainy day. And therefore, according to nearest neighbor classification, I would say that this unlabeled point, well, that should also be red. It should also be classified as a not rainy day. But your intuition might think that that's a reasonable judgment to make, that it's the closest thing is a not rainy day. So may as well guess that it's a not rainy day. But it's probably also reasonable to look at the bigger picture of things to say, yes, it is true that the nearest point to it was a red point. But it's surrounded by a whole bunch of other blue points. So looking at the bigger picture, there's potentially an argument to be made that this point should actually be blue. And with only this data, we actually don't know for sure. We are given some input, something we're trying to predict. And we don't necessarily know what the output is going to be. So in this case, which one is correct is difficult to say. But oftentimes, considering more than just a single neighbor, considering multiple neighbors can sometimes give us a better result. And so there's a variant on the nearest neighbor classification algorithm that is known as the K nearest neighbor classification algorithm, where K is some parameter, some number that we choose, for how many neighbors are we going to look at. So one nearest neighbor classification is what we saw before. Just pick the one nearest neighbor and use that category. But with K nearest neighbor classification, where K might be 3, or 5, or 7, to say look at the 3, or 5, or 7 closest neighbors, closest data points to that point, works a little bit differently. This algorithm, we'll give it an input. Choose the most common class out of the K nearest data points to that input. So if we look at the five nearest points, and three of them say it's raining, and two of them say it's not raining, we'll go with the three instead of the two, because each one effectively gets one vote towards what they believe the category ought to be. And ultimately, you choose the category that has the most votes as a consequence of that. So K nearest neighbor classification, fairly straightforward one to understand intuitively. You just look at the neighbors and figure out what the answer might be. And it turns out this can work very, very well for solving a whole variety of different types of classification problems. But not every model is going to work under every situation. And so one of the things we'll take a look at today, especially in the context of supervised machine learning, is that there are a number of different approaches to machine learning, a number of different algorithms that we can apply, all solving the same type of problem, all solving some kind of classification problem where we want to take inputs and organize it into different categories. And no one algorithm is necessarily always going to be better than some other algorithm. They each have their trade-offs. And maybe depending on the data, one type of algorithm is going to be better suited to trying to model that information than some other algorithm. And so this is what a lot of machine learning research ends up being about, that when you're trying to apply machine learning techniques, you're often looking not just at one particular algorithm, but trying multiple different algorithms, trying to see what is going to give you the best results for trying to predict some function that maps inputs to outputs. So what then are the drawbacks of K nearest neighbor classification? Well, there are a couple. One might be that in a naive approach, at least, it could be fairly slow to have to go through and measure the distance between a point and every single one of these points that exist here. Now, there are ways of trying to get around that. There are data structures that can help to make it more quickly to be able to find these neighbors. There are also techniques you can use to try and prune some of this data, remove some of the data points so that you're only left with the relevant data points just to make it a little bit easier. But ultimately, what we might like to do is come up with another way of trying to do this classification. And one way of trying to do the classification was looking at what are the neighboring points. But another way might be to try to look at all of the data and see if we can come up with some decision boundary, some boundary that will separate the rainy days from the not rainy days. And in the case of two dimensions, we can do that by drawing a line, for example. So what we might want to try to do is just find some line, find some separator that divides the rainy days, the blue points over here, from the not rainy days, the red points over there. We're now trying a different approach in contrast with the nearest neighbor approach, which just looked at local data around the input data point that we cared about. Now what we're doing is trying to use a technique known as linear regression to find some sort of line that will separate the two halves from each other. Now sometimes it'll actually be possible to come up with some line that perfectly separates all the rainy days from the not rainy days. Realistically, though, this is probably cleaner than many data sets will actually be. Oftentimes, data is messier. There are outliers. There's random noise that happens inside of a particular system. And what we'd like to do is still be able to figure out what a line might look like. So in practice, the data will not always be linearly separable. Or linearly separable refers to some data set where I could draw a line just to separate the two halves of it perfectly. Instead, you might have a situation like this, where there are some rainy points that are on this side of the line and some not rainy points that are on that side of the line. And there may not be a line that perfectly separates what path of the inputs from the other half, that perfectly separates all the rainy days from the not rainy days. But we can still say that this line does a pretty good job. And we'll try to formalize a little bit later what we mean when we say something like this line does a pretty good job of trying to make that prediction. But for now, let's just say we're looking for a line that does as good of a job as we can at trying to separate one category of things from another category of things. So let's now try to formalize this a little bit more mathematically. We want to come up with some sort of function, some way we can define this line. And our inputs are things like humidity and pressure in this case. So our inputs we might call x1 is going to represent humidity, and x2 is going to represent pressure. These are inputs that we are going to provide to our machine learning algorithm. And given those inputs, we would like for our model to be able to predict some sort of output. And we are going to predict that using our hypothesis function, which we called h. Our hypothesis function is going to take as input x1 and x2, humidity and pressure in this case. And you can imagine if we didn't just have two inputs, we had three or four or five inputs or more, we could have this hypothesis function take all of those as input. And we'll see examples of that a little bit later as well. And now the question is, what does this hypothesis function do? Well, it really just needs to measure, is this data point on one side of the boundary, or is it on the other side of the boundary? And how do we formalize that boundary? Well, the boundary is generally going to be a linear combination of these input variables, at least in this particular case. So what we're trying to do when we say linear combination is take each of these inputs and multiply them by some number that we're going to have to figure out. We'll generally call that number a weight for how important should these variables be in trying to determine the answer. So we'll weight each of these variables with some weight, and we might add a constant to it just to try and make the function a little bit different. And the result, we just need to compare. Is it greater than 0, or is it less than 0 to say, does it belong on one side of the line or the other side of the line? So what that mathematical expression might look like is this. We would take each of my variables, x1 and x2, multiply them by some weight. I don't yet know what that weight is, but it's going to be some number, weight 1 and weight 2. And maybe we just want to add some other weight 0 to it, because the function might require us to shift the entire value up or down by a certain amount. And then we just compare. If we do all this math, is it greater than or equal to 0? If so, we might categorize that data point as a rainy day. And otherwise, we might say, no rain. So the key here, then, is that this expression is how we are going to calculate whether it's a rainy day or not. We're going to do a bunch of math where we take each of the variables, multiply them by a weight, maybe add an extra weight to it, see if the result is greater than or equal to 0. And using that result of that expression, we're able to determine whether it's raining or not raining. This expression here is in this case going to refer to just some line. If you were to plot that graphically, it would just be some line. And what the line actually looks like depends upon these weights. x1 and x2 are the inputs, but these weights are really what determine the shape of that line, the slope of that line, and what that line actually looks like. So we then would like to figure out what these weights should be. We can choose whatever weights we want, but we want to choose weights in such a way that if you pass in a rainy day's humidity and pressure, then you end up with a result that is greater than or equal to 0. And we would like it such that if we passed into our hypothesis function a not rainy day's inputs, then the output that we get should be not raining. So before we get there, let's try and formalize this a little bit more mathematically just to get a sense for how it is that you'll often see this if you ever go further into supervised machine learning and explore this idea. One thing is that generally for these categories, we'll sometimes just use the names of the categories like rain and not rain. Often mathematically, if we're trying to do comparisons between these things, it's easier just to deal in the world of numbers. So we could just say 1 and 0, 1 for raining, 0 for not raining. So we do all this math. And if the result is greater than or equal to 0, we'll go ahead and say our hypothesis function outputs 1, meaning raining. And otherwise, it outputs 0, meaning not raining. And oftentimes, this type of expression will instead express using vector mathematics. And all a vector is, if you're not familiar with the term, is it refers to a sequence of numerical values. You could represent that in Python using a list of numerical values or a tuple with numerical values. And here, we have a couple of sequences of numerical values. One of our vectors, one of our sequences of numerical values, are all of these individual weights, w0, w1, and w2. So we could construct what we'll call a weight vector, and we'll see why this is useful in a moment, called w, generally represented using a boldface w, that is just a sequence of these three weights, weight 0, weight 1, and weight 2. And to be able to calculate, based on those weights, whether we think a day is raining or not raining, we're going to multiply each of those weights by one of our input variables. That w2, this weight, is going to be multiplied by input variable x2. w1 is going to be multiplied by input variable x1. And w0, well, it's not being multiplied by anything. But to make sure the vectors are the same length, and we'll see why that's useful in just a second, we'll just go ahead and say w0 is being multiplied by 1. Because you can multiply by something by 1, and you end up getting the exact same number. So in addition to the weight vector w, we'll also have an input vector that we'll call x that has three values, 1, again, because we're just multiplying w0 by 1 eventually, and then x1 and x2. So here, then, we've represented two distinct vectors, a vector of weights that we need to somehow learn. The goal of our machine learning algorithm is to learn what this weight vector is supposed to be. We could choose any arbitrary set of numbers, and it would produce a function that tries to predict rain or not rain, but it probably wouldn't be very good. What we want to do is come up with a good choice of these weights so that we're able to do the accurate predictions. And then this input vector represents a particular input to the function, a data point for which we would like to estimate, is that day a rainy day, or is that day a not rainy day? And so that's going to vary just depending on what input is provided to our function, what it is that we are trying to estimate. And then to do the calculation, we want to calculate this expression here, and it turns out that expression is what we would call the dot product of these two vectors. The dot product of two vectors just means taking each of the terms in the vectors and multiplying them together, w0 multiply it by 1, w1 multiply it by x1, w2 multiply it by x2, and that's why these vectors need to be the same length. And then we just add all of the results together. So the dot product of w and x, our weight vector and our input vector, that's just going to be w0 times 1, or just w0, plus w1 times x1, multiplying these two terms together, plus w2 times x2, multiplying those terms together. So we have our weight vector, which we need to figure out. We need our machine learning algorithm to figure out what the weights should be. We have the input vector representing the data point that we're trying to predict a category for, predict a label for. And we're able to do that calculation by taking this dot product, which you'll often see represented in vector form. But if you haven't seen vectors before, you can think of it as identical to just this mathematical expression, just doing the multiplication, adding the results together, and then seeing whether the result is greater than or equal to 0 or not. This expression here is identical to the expression that we're calculating to see whether or not that answer is greater than or equal to 0 in this case. And so for that reason, you'll often see the hypothesis function written as something like this, a simpler representation where the hypothesis takes as input some input vector x, some humidity and pressure for some day. And we want to predict an output like rain or no rain or 1 or 0 if we choose to represent things numerically. And the way we do that is by taking the dot product of the weights and our input. If it's greater than or equal to 0, we'll go ahead and say the output is 1. Otherwise, the output is going to be 0. And this hypothesis, we say, is parameterized by the weights. Depending on what weights we choose, we'll end up getting a different hypothesis. If we choose the weights randomly, we're probably not going to get a very good hypothesis function. We'll get a 1 or a 0. But it's probably not accurately going to reflect whether we think a day is going to be rainy or not rainy. But if we choose the weights right, we can often do a pretty good job of trying to estimate whether we think the output of the function should be a 1 or a 0. And so the question, then, is how to figure out what these weights should be, how to be able to tune those parameters. And there are a number of ways you can do that. One of the most common is known as the perceptron learning rule. And we'll see more of this later. But the idea of the perceptron learning rule, and we're not going to get too deep into the mathematics, we'll mostly just introduce it more conceptually, is to say that given some data point that we would like to learn from, some data point that has an input x and an output y, where y is like 1 for rain or 0 for not rain, then we're going to update the weights. And we'll look at the formula in just a moment. But the big picture idea is that we can start with random weights, but then learn from the data. Take the data points one at a time. And for each one of the data points, figure out, all right, what parameters do we need to change inside of the weights in order to better match that input point. And so that is the value of having access to a lot of data in the supervised machine learning algorithm, is that you take each of the data points and maybe look at them multiple times and constantly try and figure out whether you need to shift your weights in order to better create some weight vector that is able to correctly or more accurately try to estimate what the output should be, whether we think it's going to be raining or whether we think it's not going to be raining. So what does that weight update look like? Without going into too much of the mathematics, we're going to update each of the weights to be the result of the original weight plus some additional expression. And to understand this expression, y, well, y is what the actual output is. And hypothesis of x, the input, that's going to be what we thought the input was. And so I can replace this by saying what the actual value was minus what our estimate was. And based on the difference between the actual value and what our estimate was, we might want to change our hypothesis, change the way that we do that estimation. If the actual value and the estimate were the same thing, meaning we were correctly able to predict what category this data point belonged to, well, then actual value minus estimate, that's just going to be 0, which means this whole term on the right-hand side goes to be 0, and the weight doesn't change. Weight i, where i is like weight 1 or weight 2 or weight 0, weight i just stays at weight i. And none of the weights change if we were able to correctly predict what category the input belonged to. But if our hypothesis didn't correctly predict what category the input belonged to, well, then maybe then we need to make some changes, adjust the weights so that we're better able to predict this kind of data point in the future. And what is the way we might do that? Well, if the actual value was bigger than the estimate, then, and for now we'll go ahead and assume that these x's are positive values, then if the actual value was bigger than the estimate, well, that means we need to increase the weight in order to make it such that the output is bigger, and therefore we're more likely to get to the right actual value. And so if the actual value is bigger than the estimate, then actual value minus estimate, that'll be a positive number. And so you imagine we're just adding some positive number to the weight just to increase it ever so slightly. And likewise, the inverse case is true, that if the actual value was less than the estimate, the actual value was 0, but we estimated 1, meaning it actually was not raining, but we predicted it was going to be raining. Well, then we want to decrease the value of the weight, because then in that case, we want to try and lower the total value of computing that dot product in order to make it less likely that we would predict that it would actually be raining. So no need to get too deep into the mathematics of that, but the general idea is that every time we encounter some data point, we can adjust these weights accordingly to try and make the weights better line up with the actual data that we have access to. And you can repeat this process with data point after data point until eventually, hopefully, your algorithm converges to some set of weights that do a pretty good job of trying to figure out whether a day is going to be rainy or not raining. And just as a final point about this particular equation, this value alpha here is generally what we'll call the learning rate. It's just some parameter, some number we choose for how quickly we're actually going to be updating these weight values. So that if alpha is bigger, then we're going to update these weight values by a lot. And if alpha is smaller, then we'll update the weight values by less. And you can choose a value of alpha. Depending on the problem, different values might suit the situation better or worse than others. So after all of that, after we've done this training process of take all this data and using this learning rule, look at all the pieces of data and use each piece of data as an indication to us of do the weights stay the same, do we increase the weights, do we decrease the weights, and if so, by how much? What you end up with is effectively a threshold function. And we can look at what the threshold function looks like like this. On the x-axis here, we have the output of that function, taking the weights, taking the dot product of it with the input. And on the y-axis, we have what the output is going to be, 0, which in this case represented not raining, and 1, which in this case represented raining. And the way that our hypothesis function works is it calculates this value. And if it's greater than 0 or greater than some threshold value, then we declare that it's a rainy day. And otherwise, we declare that it's a not rainy day. And this then graphically is what that function looks like, that initially when the value of this dot product is small, it's not raining, it's not raining, it's not raining. But as soon as it crosses that threshold, we suddenly say, OK, now it's raining, now it's raining, now it's raining. And the way to interpret this kind of representation is that anything on this side of the line, that would be the category of data points where we say, yes, it's raining. Anything that falls on this side of the line are the data points where we would say, it's not raining. And again, we want to choose some value for the weights that results in a function that does a pretty good job of trying to do this estimation. But one tricky thing with this type of hard threshold is that it only leaves two possible outcomes. We plug in some data as input. And the output we get is raining or not raining. And there's no room for anywhere in between. And maybe that's what you want. Maybe all you want is given some data point, you would like to be able to classify it into one or two or more of these various different categories. But it might also be the case that you care about knowing how strong that prediction is, for example. So if we go back to this instance here, where we have rainy days on this side of the line, not rainy days on that side of the line, you might imagine that let's look now at these two white data points. This data point here that we would like to predict a label or a category for. And this data point over here that we would also like to predict a label or a category for. It seems likely that you could pretty confidently say that this data point, that should be a rainy day. Seems close to the other rainy days if we're going by the nearest neighbor strategy. It's on this side of the line if we're going by the strategy of just saying, which side of the line does it fall on by figuring out what those weights should be. And if we're using the line strategy of just which side of the line does it fall on, which side of this decision boundary, well, we'd also say that this point here is also a rainy day because it falls on the side of the line that corresponds to rainy days. But it's likely that even in this case, we would know that we don't feel nearly as confident about this data point on the left as compared to this data point on the right. That for this one on the right, we can feel very confident that yes, it's a rainy day. This one, it's pretty close to the line if we're judging just by distance. And so you might be less sure. But our threshold function doesn't allow for a notion of less sure or more sure about something. It's what we would call a hard threshold. It's once you've crossed this line, then immediately we say, yes, this is going to be a rainy day. Anywhere before it, we're going to say it's not a rainy day. And that may not be helpful in a number of cases. One, this is not a particularly easy function to deal with. As you get deeper into the world of machine learning and are trying to do things like taking derivatives of these curves with this type of function makes things challenging. But the other challenge is that we don't really have any notion of gradation between things. We don't have a notion of yes, this is a very strong belief that it's going to be raining as opposed to it's probably more likely than not that it's going to be raining, but maybe not totally sure about that either. So what we can do by taking advantage of a technique known as logistic regression is instead of using this hard threshold type of function, we can use instead a logistic function, something we might call a soft threshold. And that's going to transform this into looking something a little more like this, something that more nicely curves. And as a result, the possible output values are no longer just 0 and 1, 0 for not raining, 1 for raining. But you can actually get any real numbered value between 0 and 1. But if you're way over on this side, then you get a value of 0. OK, it's not going to be raining, and we're pretty sure about that. And if you're over on this side, you get a value of 1. And yes, we're very sure that it's going to be raining. But in between, you could get some real numbered value, where a value like 0.7 might mean we think it's going to rain. It's more probable that it's going to rain than not based on the data. But we're not as confident as some of the other data points might be. So one of the advantages of the soft threshold is that it allows us to have an output that could be some real number that potentially reflects some sort of probability, the likelihood that we think that this particular data point belongs to that particular category. And there are some other nice mathematical properties of that as well. So that then is two different approaches to trying to solve this type of classification problem. One is this nearest neighbor type of approach, where you just take a data point and look at the data points that are nearby to try and estimate what category we think it belongs to. And the other approach is the approach of saying, all right, let's just try and use linear regression, figure out what these weights should be, adjust the weights in order to figure out what line or what decision boundary is going to best separate these two categories. It turns out that another popular approach, a very popular approach if you just have a data set and you want to start trying to do some learning on it, is what we call the support vector machine. And we're not going to go too much into the mathematics of the support vector machine, but we'll at least explore it graphically to see what it is that it looks like. And the idea or the motivation behind the support vector machine is the idea that there are actually a lot of different lines that we could draw, a lot of different decision boundaries that we could draw to separate two groups. So for example, I had the red data points over here and the blue data points over here. One possible line I could draw is a line like this, that this line here would separate the red points from the blue points. And it does so perfectly. All the red points are on one side of the line. All the blue points are on the other side of the line. But this should probably make you a little bit nervous. If you come up with a model and the model comes up with a line that looks like this. And the reason why is that you worry about how well it's going to generalize to other data points that are not necessarily in the data set that we have access to. For example, if there was a point that fell like right here, for example, on the right side of the line, well, then based on that, we might want to guess that it is, in fact, a red point, but it falls on the side of the line where instead we would estimate that it's a blue point instead. And so based on that, this line is probably not a great choice just because it is so close to these various data points. We might instead prefer like a diagonal line that just goes diagonally through the data set like we've seen before. But there too, there's a lot of diagonal lines that we could draw as well. For example, I could draw this diagonal line here, which also successfully separates all the red points from all of the blue points. From the perspective of something like just trying to figure out some setting of weights that allows us to predict the correct output, this line will predict the correct output for this particular set of data every single time because the red points are on one side, the blue points are on the other. But yet again, you should probably be a little nervous because this line is so close to these red points, even though we're able to correctly predict on the input data, if there was a point that fell somewhere in this general area, our algorithm, this model, would say that, yeah, we think it's a blue point, when in actuality, it might belong to the red category instead just because it looks like it's close to the other red points. What we really want to be able to say, given this data, how can you generalize this as best as possible, is to come up with a line like this that seems like the intuitive line to draw. And the reason why it's intuitive is because it seems to be as far apart as possible from the red data and the blue data. So that if we generalize a little bit and assume that maybe we have some points that are different from the input but still slightly further away, we can still say that something on this side probably red, something on that side probably blue, and we can make those judgments that way. And that is what support vector machines are designed to do. They're designed to try and find what we call the maximum margin separator, where the maximum margin separator is just some boundary that maximizes the distance between the groups of points rather than come up with some boundary that's very close to one set or the other, where in the case before, we wouldn't have cared. As long as we're categorizing the input well, that seems all we need to do. The support vector machine will try and find this maximum margin separator, some way of trying to maximize that particular distance. And it does so by finding what we call the support vectors, which are the vectors that are closest to the line, and trying to maximize the distance between the line and those particular points. And it works that way in two dimensions. It also works in higher dimensions, where we're not looking for some line that separates the two data points, but instead looking for what we generally call a hyperplane, some decision boundary, effectively, that separates one set of data from the other set of data. And this ability of support vector machines to work in higher dimensions actually has a number of other applications as well. But one is that it helpfully deals with cases where data may not be linearly separable. So we talked about linear separability before, this idea that you can take data and just draw a line or some linear combination of the inputs that allows us to perfectly separate the two sets from each other. There are some data sets that are not linearly separable. And some were even two. You would not be able to find a good line at all that would try to do that kind of separation. Something like this, for example. Or if you imagine here are the red points and the blue points around it. If you try to find a line that divides the red points from the blue points, it's actually going to be difficult, if not impossible, to do that any line you choose, well, if you draw a line here, then you ignore all of these blue points that should actually be blue and not red. Anywhere else you draw a line, there's going to be a lot of error, a lot of mistakes, a lot of what we'll soon call loss to that line that you draw, a lot of points that you're going to categorize incorrectly. What we really want is to be able to find a better decision boundary that may not be just a straight line through this two dimensional space. And what support vector machines can do is they can begin to operate in higher dimensions and be able to find some other decision boundary, like the circle in this case, that actually is able to separate one of these sets of data from the other set of data a lot better. So oftentimes in data sets where the data is not linearly separable, support vector machines by working in higher dimensions can actually figure out a way to solve that kind of problem effectively. So that then, three different approaches to trying to solve these sorts of problems. We've seen support vector machines. We've seen trying to use linear regression and the perceptron learning rule to be able to figure out how to categorize inputs and outputs. We've seen the nearest neighbor approach. No one necessarily better than any other again. It's going to depend on the data set, the information you have access to. It's going to depend on what the function looks like that you're ultimately trying to predict. And this is where a lot of research and experimentation can be involved in trying to figure out how it is to best perform that kind of estimation. But classification is only one of the tasks that you might encounter in supervised machine learning. Because in classification, what we're trying to predict is some discrete category. We're trying to predict red or blue, rain or not rain, authentic or counterfeit. But sometimes what we want to predict is a real numbered value. And for that, we have a related problem, not classification, but instead known as regression. And regression is the supervised learning problem where we try and learn a function mapping inputs to outputs same as before. But instead of the outputs being discrete categories, things like rain or not rain, in a regression problem, the output values are generally continuous values, some real number that we would like to predict. This happens all the time as well. You might imagine that a company might take this approach if it's trying to figure out, for instance, what the effect of its advertising is. How do advertising dollars spent translate into sales for the company's product, for example? And so they might like to try to predict some function that takes as input the amount of money spent on advertising. And here, we're just going to use one input. But again, you could scale this up to many more inputs as well if you have a lot of different kinds of data you have access to. And the goal is to learn a function that given this amount of spending on advertising, we're going to get this amount in sales. And you might judge, based on having access to a whole bunch of data, like for every past month, here is how much we spent on advertising, and here is what sales were. And we would like to predict some sort of hypothesis function that, again, given the amount spent on advertising, we can predict, in this case, some real number, some number estimate of how much sales we expect that company to do in this month or in this quarter or whatever unit of time we're choosing to measure things in. And so again, the approach to solving this type of problem, we could try using a linear regression type approach where we take this data and we just plot it. On the x-axis, we have advertising dollars spent. On the y-axis, we have sales. And we might just want to try and draw a line that does a pretty good job of trying to estimate this relationship between advertising and sales. And in this case, unlike before, we're not trying to separate the data points into discrete categories. But instead, in this case, we're just trying to find a line that approximates this relationship between advertising and sales so that if we want to figure out what the estimated sales are for a particular advertising budget, you just look it up in this line, figure out for this amount of advertising, we would have this amount of sales and just try and make the estimate that way. And so you can try and come up with a line, again, figuring out how to modify the weights using various different techniques to try and make it so that this line fits as well as possible. So with all of these approaches, then, to trying to solve machine learning style problems, the question becomes, how do we evaluate these approaches? How do we evaluate the various different hypotheses that we could come up with? Because each of these algorithms will give us some sort of hypothesis, some function that maps inputs to outputs, and we want to know, how well does that function work? And you can think of evaluating these hypotheses and trying to get a better hypothesis as kind of like an optimization problem. In an optimization problem, as you recall from before, we were either trying to maximize some objective function by trying to find a global maximum, or we were trying to minimize some cost function by trying to find some global minimum. And in the case of evaluating these hypotheses, one thing we might say is that this cost function, the thing we're trying to minimize, we might be trying to minimize what we would call a loss function. And what a loss function is, is it is a function that is going to estimate for us how poorly our function performs. More formally, it's like a loss of utility by whenever we predict something that is wrong, that is a loss of utility. That's going to add to the output of our loss function. And you could come up with any loss function that you want, just some mathematical way of estimating, given each of these data points, given what the actual output is, and given what our projected output is, our estimate, you could calculate some sort of numerical loss for it. But there are a couple of popular loss functions that are worth discussing, just so that you've seen them before. When it comes to discrete categories, things like rain or not rain, counterfeit or not counterfeit, one approaches the 0, 1 loss function. And the way that works is for each of the data points, our loss function takes as input what the actual output is, like whether it was actually raining or not raining, and takes our prediction into account. Did we predict, given this data point, that it was raining or not raining? And if the actual value equals the prediction, well, then the 0, 1 loss function will just say the loss is 0. There was no loss of utility, because we were able to predict correctly. And otherwise, if the actual value was not the same thing as what we predicted, well, then in that case, our loss is 1. We lost something, lost some utility, because what we predicted was the output of the function, was not what it actually was. And the goal, then, in a situation like this would be to come up with some hypothesis that minimizes the total empirical loss, the total amount that we've lost, if you add up for all these data points what the actual output is and what your hypothesis would have predicted. So in this case, for example, if we go back to classifying days as raining or not raining, and we came up with this decision boundary, how would we evaluate this decision boundary? How much better is it than drawing the line here or drawing the line there? Well, we could take each of the input data points, and each input data point has a label, whether it was raining or whether it was not raining. And we could compare it to the prediction, whether we predicted it would be raining or not raining, and assign it a numerical value as a result. So for example, these points over here, they were all rainy days, and we predicted they would be raining, because they fall on the bottom side of the line. So they have a loss of 0, nothing lost from those situations. And likewise, same is true for some of these points over here, where it was not raining and we predicted it would not be raining either. Where we do have loss are points like this point here and that point there, where we predicted that it would not be raining, but in actuality, it's a blue point. It was raining. Or likewise here, we predicted that it would be raining, but in actuality, it's a red point. It was not raining. And so as a result, we miscategorized these data points that we were trying to train on. And as a result, there is some loss here. One loss here, there, here, and there, for a total loss of 4, for example, in this case. And that might be how we would estimate or how we would say that this line is better than a line that goes somewhere else or a line that's further down, because this line might minimize the loss. So there is no way to do better than just these four points of loss if you're just drawing a straight line through our space. So the 0, 1 loss function checks. Did we get it right? Did we get it wrong? If we got it right, the loss is 0, nothing lost. If we got it wrong, then our loss function for that data point says 1. And we add up all of those losses across all of our data points to get some sort of empirical loss, how much we have lost across all of these original data points that our algorithm had access to. There are other forms of loss as well that work especially well when we deal with more real valued cases, cases like the mapping between advertising budget and amount that we do in sales, for example. Because in that case, you care not just that you get the number exactly right, but you care how close you were to the actual value. If the actual value is you did like $2,800 in sales and you predicted that you would do $2,900 in sales, maybe that's pretty good. That's much better than if you had predicted you'd do $1,000 in sales, for example. And so we would like our loss function to be able to take that into account as well, take into account not just whether the actual value and the expected value are exactly the same, but also take into account how far apart they were. And so for that one approach is what we call L1 loss. L1 loss doesn't just look at whether actual and predicted are equal to each other, but we take the absolute value of the actual value minus the predicted value. In other words, we just ask how far apart were the actual and predicted values, and we sum that up across all of the data points to be able to get what our answer ultimately is. So what might this actually look like for our data set? Well, if we go back to this representation where we had advertising along the x-axis, sales along the y-axis, our line was our prediction, our estimate for any given amount of advertising, what we predicted sales was going to be. And our L1 loss is just how far apart vertically along the sales axis our prediction was from each of the data points. So we could figure out exactly how far apart our prediction was from each of the data points and figure out as a result of that what our loss is overall for this particular hypothesis just by adding up all of these various different individual losses for each of these data points. And our goal then is to try and minimize that loss, to try and come up with some line that minimizes what the utility loss is by judging how far away our estimate amount of sales is from the actual amount of sales. And turns out there are other loss functions as well. One that's quite popular is the L2 loss. The L2 loss, instead of just using the absolute value, like how far away the actual value is from the predicted value, it uses the square of actual minus predicted. So how far apart are the actual and predicted value? And it squares that value, effectively penalizing much more harshly anything that is a worse prediction. So you imagine if you have two data points that you predict as being one value away from their actual value, as opposed to one data point that you predict as being two away from its actual value, the L2 loss function will more harshly penalize that one that is two away, because it's going to square, however, much the differences between the actual value and the predicted value. And depending on the situation, you might want to choose a loss function depending on what you care about minimizing. If you really care about minimizing the error on more outlier cases, then you might want to consider something like this. But if you've got a lot of outliers, and you don't necessarily care about modeling them, then maybe an L1 loss function is preferable. But there are trade-offs here that you need to decide, based on a particular set of data. But what you do run the risk of with any of these loss functions, with anything that we're trying to do, is a problem known as overfitting. And overfitting is a big problem that you can encounter in machine learning, which happens anytime a model fits too closely with a data set, and as a result, fails to generalize. We would like our model to be able to accurately predict data and inputs and output pairs for the data that we have access to. But the reason we wanted to do so is because we want our model to generalize well to data that we haven't seen before. I would like to take data from the past year of whether it was raining or not raining, and use that data to generalize it towards the future. Say, in the future, is it going to be raining or not raining? Or if I have a whole bunch of data on what counterfeit and not counterfeit US dollar bills look like in the past when people have encountered them, I'd like to train a computer to be able to, in the future, generalize to other dollar bills that I might see as well. And the problem with overfitting is that if you try and tie yourself too closely to the data set that you're training your model on, you can end up not generalizing very well. So what does this look like? Well, we might imagine the rainy day and not rainy day example again from here, where the blue points indicate rainy days and the red points indicate not rainy days. And we decided that we felt pretty comfortable with drawing a line like this as the decision boundary between rainy days and not rainy days. So we can pretty comfortably say that points on this side more likely to be rainy days, points on that side more likely to be not rainy days. But the loss, the empirical loss, isn't zero in this particular case because we didn't categorize everything perfectly. There was this one outlier, this one day that it wasn't raining, but yet our model still predicts that it is raining. But that doesn't necessarily mean our model is bad. It just means the model isn't 100% accurate. If you really wanted to try and find a hypothesis that resulted in minimizing the loss, you could come up with a different decision boundary. It wouldn't be a line, but it would look something like this. This decision boundary does separate all of the red points from all of the blue points because the red points fall on this side of this decision boundary, the blue points fall on the other side of the decision boundary. But this, we would probably argue, is not as good of a prediction. Even though it seems to be more accurate based on all of the available training data that we have for training this machine learning model, we might say that it's probably not going to generalize well. That if there were other data points like here and there, we might still want to consider those to be rainy days because we think this was probably just an outlier. So if the only thing you care about is minimizing the loss on the data you have available to you, you run the risk of overfitting. And this can happen in the classification case. It can also happen in the regression case, that here we predicted what we thought was a pretty good line relating advertising to sales, trying to predict what sales were going to be for a given amount of advertising. But I could come up with a line that does a better job of predicting the training data, and it would be something that looks like this, just connecting all of the various different data points. And now there is no loss at all. Now I've perfectly predicted, given any advertising, what sales are. And for all the data available to me, it's going to be accurate. But it's probably not going to generalize very well. I have overfit my model on the training data that is available to me. And so in general, we want to avoid overfitting. We'd like strategies to make sure that we haven't overfit our model to a particular data set. And there are a number of ways that you could try to do this. One way is by examining what it is that we're optimizing for. In an optimization problem, all we do is we say, there is some cost, and I want to minimize that cost. And so far, we've defined that cost function, the cost of a hypothesis, just as being equal to the empirical loss of that hypothesis, like how far away are the actual data points, the outputs, away from what I predicted them to be based on that particular hypothesis. And if all you're trying to do is minimize cost, meaning minimizing the loss in this case, then the result is going to be that you might overfit, that to minimize cost, you're going to try and find a way to perfectly match all the input data. And that might happen as a result of overfitting on that particular input data. So in order to address this, you could add something to the cost function. What counts as cost will not just loss, but also some measure of the complexity of the hypothesis. The word the complexity of the hypothesis is something that you would need to define for how complicated does our line look. This is sort of an Occam's razor-style approach where we want to give preference to a simpler decision boundary, like a straight line, for example, some simpler curve, as opposed to something far more complex that might represent the training data better but might not generalize as well. We'll generally say that a simpler solution is probably the better solution and probably the one that is more likely to generalize well to other inputs. So we measure what the loss is, but we also measure the complexity. And now that all gets taken into account when we consider the overall cost, that yes, something might have less loss if it better predicts the training data, but if it's much more complex, it still might not be the best option that we have. And we need to come up with some balance between loss and complexity. And for that reason, you'll often see this represented as multiplying the complexity by some parameter that we have to choose, parameter lambda in this case, where we're saying if lambda is a greater value, then we really want to penalize more complex hypotheses. Whereas if lambda is smaller, we're going to penalize more complex hypotheses a little bit, and it's up to the machine learning programmer to decide where they want to set that value of lambda for how much do I want to penalize a more complex hypothesis that might fit the data a little better. And again, there's no one right answer to a lot of these things, but depending on the data set, depending on the data you have available to you and the problem you're trying to solve, your choice of these parameters may vary, and you may need to experiment a little bit to figure out what the right choice of that is ultimately going to be. This process, then, of considering not only loss, but also some measure of the complexity is known as regularization. Regularization is the process of penalizing a hypothesis that is more complex in order to favor a simpler hypothesis that is more likely to generalize well, more likely to be able to apply to other situations that are dealing with other input points unlike the ones that we've necessarily seen before. So oftentimes, you'll see us add some regularizing term to what we're trying to minimize in order to avoid this problem of overfitting. Now, another way of making sure we don't overfit is to run some experiments and to see whether or not we are able to generalize our model that we've created to other data sets as well. And it's for that reason that oftentimes when you're doing a machine learning experiment, when you've got some data and you want to try and come up with some function that predicts, given some input, what the output is going to be, you don't necessarily want to do your training on all of the data you have available to you that you could employ a method known as holdout cross-validation, where in holdout cross-validation, we split up our data. We split up our data into a training set and a testing set. The training set is the set of data that we're going to use to train our machine learning model. And the testing set is the set of data that we're going to use in order to test to see how well our machine learning model actually performed. So the learning happens on the training set. We figure out what the parameters should be. We figure out what the right model is. And then we see, all right, now that we've trained the model, we'll see how well it does at predicting things inside of the testing set, some set of data that we haven't seen before. And the hope then is that we're going to be able to predict the testing set pretty well if we're able to generalize based on the training data that's available to us. If we've overfit the training data, though, and we're not able to generalize, well, then when we look at the testing set, it's likely going to be the case that we're not going to predict things in the testing set nearly as effectively. So this is one method of cross-validation, validating to make sure that the work we have done is actually going to generalize to other data sets as well. And there are other statistical techniques we can use as well. One of the downsides of this just hold out cross-validation is if you say I just split it 50-50, I train using 50% of the data and test using the other 50%, or you could choose other percentages as well, is that there is a fair amount of data that I am now not using to train, that I might be able to get a better model as a result, for example. So one approach is known as k-fold cross-validation. In k-fold cross-validation, rather than just divide things into two sets and run one experiment, we divide things into k different sets. So maybe I divide things up into 10 different sets and then run 10 different experiments. So if I split up my data into 10 different sets of data, then what I'll do is each time for each of my 10 experiments, I will hold out one of those sets of data, where I'll say, let me train my model on these nine sets, and then test to see how well it predicts on set number 10. And then pick another set of nine sets to train on, and then test it on the other one that I held out, where each time I train the model on everything minus the one set that I'm holding out, and then test to see how well our model performs on the test that I did hold out. And what you end up getting is 10 different results, 10 different answers for how accurately our model worked. And oftentimes, you could just take the average of those 10 to get an approximation for how well we think our model performs overall. But the key idea is separating the training data from the testing data, because you want to test your model on data that is different from what you trained the model on. Because the training, you want to avoid overfitting. You want to be able to generalize. And the way you test whether you're able to generalize is by looking at some data that you haven't seen before and seeing how well we're actually able to perform. And so if we want to actually implement any of these techniques inside of a programming language like Python, number of ways we could do that. We could write this from scratch on our own, but there are libraries out there that allow us to take advantage of existing implementations of these algorithms, that we can use the same types of algorithms in a lot of different situations. And so there's a library, very popular one, known as Scikit-learn, which allows us in Python to be able to very quickly get set up with a lot of these different machine learning models. This library has already written an algorithm for nearest neighbor classification, for doing perceptron learning, for doing a bunch of other types of inference and supervised learning that we haven't yet talked about. But using it, we can begin to try actually testing how these methods work and how accurately they perform. So let's go ahead and take a look at one approach to trying to solve this type of problem. All right, so I'm first going to pull up banknotes.csv, which is a whole bunch of data provided by UC Irvine, which is information about various different banknotes that people took pictures of various different banknotes and measured various different properties of those banknotes. And in particular, some human categorized each of those banknotes as either a counterfeit banknote or as not counterfeit. And so what you're looking at here is each row represents one banknote. This is formatted as a CSV spreadsheet, where just comma separated values separating each of these various different fields. We have four different input values for each of these data points, just information, some measurement that was made on the banknote. And what those measurements exactly are aren't as important as the fact that we do have access to this data. But more importantly, we have access for each of these data points to a label, where 0 indicates something like this was not a counterfeit bill, meaning it was an authentic bill. And a data point labeled 1 means that it is a counterfeit bill, at least according to the human researcher who labeled this particular data. So we have a whole bunch of data representing a whole bunch of different data points, each of which has these various different measurements that were made on that particular bill, and each of which has an output value, 0 or 1, 0 meaning it was a genuine bill, 1 meaning it was a counterfeit bill. And what we would like to do is use supervised learning to begin to predict or model some sort of function that can take these four values as input and predict what the output would be. We want our learning algorithm to find some sort of pattern that is able to predict based on these measurements, something that you could measure just by taking a photo of a bill, predict whether that bill is authentic or whether that bill is counterfeit. And so how can we do that? Well, I'm first going to open up banknote0.py and see how it is that we do this. I'm first importing a lot of things from Scikit-learn, but importantly, I'm going to set my model equal to the perceptron model, which is one of those models that we talked about before. We're just going to try and figure out some setting of weights that is able to divide our data into two different groups. Then I'm going to go ahead and read data in for my file from banknotes.csv. And basically, for every row, I'm going to separate that row into the first four values of that row, which is the evidence for that row. And then the label, where if the final column in that row is a 0, the label is authentic. And otherwise, it's going to be counterfeit. So I'm effectively reading data in from the CSV file, dividing into a whole bunch of rows where each row has some evidence, those four input values that are going to be inputs to my hypothesis function. And then the label, the output, whether it is authentic or counterfeit, that is the thing that I am then trying to predict. So the next step is that I would like to split up my data set into a training set and a testing set, some set of data that I would like to train my machine learning model on, and some set of data that I would like to use to test that model, see how well it performed. So what I'll do is I'll go ahead and figure out length of the data, how many data points do I have. I'll go ahead and take half of them, save that number as a number called holdout. That is how many items I'm going to hold out for my data set to save for the testing phase. I'll randomly shuffle the data so it's in some random order. And then I'll say my testing set will be all of the data up to the holdout. So I'll take holdout many data items, and that will be my testing set. My training data will be everything else, the information that I'm going to train my model on. And then I'll say I need to divide my training data into two different sets. I need to divide it into my x values, where x here represents the inputs. So the x values, the x values that I'm going to train on, are basically for every row in my training set, I'm going to get the evidence for that row, those four values, where it's basically a vector of four numbers, where that is going to be all of the input. And then I need the y values. What are the outputs that I want to learn from, the labels that belong to each of these various different input points? Well, that's going to be the same thing for each row in the training data. But this time, I take that row and get what its label is, whether it is authentic or counterfeit. So I end up with one list of all of these vectors of my input data, and one list, which follows the same order, but is all of the labels that correspond with each of those vectors. And then to train my model, which in this case is just this perceptron model, I just call model.fit, pass in the training data, and what the labels for those training data are. And scikit-learn will take care of fitting the model, will do the entire algorithm for me. And then when it's done, I can then test to see how well that model performed. So I can say, let me get all of these input vectors for what I want to test on. So for each row in my testing data set, go ahead and get the evidence. And the y values, those are what the actual values were for each of the rows in the testing data set, what the actual label is. But then I'm going to generate some predictions. I'm going to use this model and try and predict, based on the testing vectors, I want to predict what the output is. And my goal then is to now compare y testing with predictions. I want to see how well my predictions, based on the model, actually reflect what the y values were, what the output is, that were actually labeled. Because I now have this label data, I can assess how well the algorithm worked. And so now I can just compute how well we did. I'm going to, this zip function basically just lets me look through two different lists, one by one at the same time. So for each actual value and for each predicted value, if the actual is the same thing as what I predicted, I'll go ahead and increment the counter by one. Otherwise, I'll increment my incorrect counter by one. And so at the end, I can print out, here are the results, here's how many I got right, here's how many I got wrong, and here was my overall accuracy, for example. So I can go ahead and run this. I can run python banknote0.py. And it's going to train on half the data set and then test on half the data set. And here are the results for my perceptron model. In this case, it correctly was able to classify 679 bills as correctly either authentic or counterfeit and incorrectly classified seven of them for an overall accuracy of close to 99% accurate. So on this particular data set, using this perceptron model, we were able to predict very well what the output was going to be. And we can try different models, too, that scikit-learn makes it very easy just to swap out one model for another model. So instead of the perceptron model, I can use the support vector machine using the SVC, otherwise known as a support vector classifier, using a support vector machine to classify things into two different groups. And now see, all right, how well does this perform? And all right, this time, we were able to correctly predict 682 and incorrectly predicted four for accuracy of 99.4%. And we could even try the k-neighbors classifier as the model instead. And this takes a parameter, n neighbors, for how many neighbors do you want to look at? Let's just look at one neighbor, the one nearest neighbor, and use that to predict. Go ahead and run this as well. And it looks like, based on the k-neighbors classifier, looking at just one neighbor, we were able to correctly classify 685 data points, incorrectly classified one. Maybe let's try three neighbors instead, instead of just using one neighbor. Do more of a k-nearest neighbors approach, where I look at the three nearest neighbors and see how that performs. And that one, in this case, seems to have gotten 100% of all of the predictions correctly described as either authentic banknotes or as counterfeit banknotes. And we could run these experiments multiple times, because I'm randomly reorganizing the data every time. We're technically training these on slightly different data sets. And so you might want to run multiple experiments to really see how well they're actually going to perform. But in short, they all perform very well. And while some of them perform slightly better than others here, that might not always be the case for every data set. But you can begin to test now by very quickly putting together these machine learning models using Scikit-learn to be able to train on some training set and then test on some testing set as well. And this splitting up into training groups and testing groups and testing happens so often that Scikit-learn has functions built in for trying to do it. I did it all by hand just now. But if we take a look at banknotes one, we take advantage of some other features that exist in Scikit-learn, where we can really simplify a lot of our logic, that there is a function built into Scikit-learn called train test split, which will automatically split data into a training group and a testing group. I just have to say what proportion should be in the testing group, something like 0.5, half the data inside the testing group. Then I can fit the model on the training data, make the predictions on the testing data, and then just count up. And Scikit-learn has some nice methods for just counting up how many times our testing data match the predictions, how many times our testing data didn't match the predictions. So very quickly, you can write programs with not all that many lines of code. It's maybe like 40 lines of code to get through all of these predictions. And then as a result, see how well we're able to do. So these types of libraries can allow us, without really knowing the implementation details of these algorithms, to be able to use the algorithms in a very practical way to be able to solve these types of problems. So that then was supervised learning, this task of given a whole set of data, some input output pairs, we would like to learn some function that maps those inputs to those outputs. But turns out there are other forms of learning as well. And another popular type of machine learning, especially nowadays, is known as reinforcement learning. And the idea of reinforcement learning is rather than just being given a whole data set at the beginning of input output pairs, reinforcement learning is all about learning from experience. In reinforcement learning, our agent, whether it's like a physical robot that's trying to make actions in the world or just some virtual agent that is a program running somewhere, our agent is going to be given a set of rewards or punishments in the form of numerical values. But you can think of them as reward or punishment. And based on that, it learns what actions to take in the future, that our agent, our AI, will be put in some sort of environment. It will make some actions. And based on the actions that it makes, it learns something. It either gets a reward when it does something well, it gets a punishment when it does something poorly, and it learns what to do or what not to do in the future based on those individual experiences. And so what this will often look like is it will often start with some agent, some AI, which might, again, be a physical robot, if you're imagining a physical robot moving around, but it can also just be a program. And our agent is situated in their environment, where the environment is where they're going to make their actions, and it's what's going to give them rewards or punishments for various actions that they're in. So for example, the environment is going to start off by putting our agent inside of a state. Our agent has some state that, in a game, might be the state of the game that the agent is playing. In a world that the agent is exploring might be some position inside of a grid representing the world that they're exploring. But the agent is in some sort of state. And in that state, the agent needs to choose to take an action. The agent likely has multiple actions they can choose from, but they pick an action. So they take an action in a particular state. And as a result of that, the agent will generally get two things in response as we model them. The agent gets a new state that they find themselves in. After being in this state, taking one action, they end up in some other state. And they're also given some sort of numerical reward, positive meaning reward, meaning it was a good thing, negative generally meaning they did something bad, they received some sort of punishment. And that is all the information the agent has. It's told what state it's in. It makes some sort of action. And based on that, it ends up in another state. And it ends up getting some particular reward. And it needs to learn, based on that information, what actions to begin to take in the future. And so you could imagine generalizing this to a lot of different situations. This is oftentimes how you train if you've ever seen those robots that are now able to walk around the way humans do. It would be quite difficult to program the robot in exactly the right way to get it to walk the way humans do. You could instead train it through reinforcement learning, give it some sort of numerical reward every time it does something good, like take steps forward, and punish it every time it does something bad, like fall over, and then let the AI just learn based on that sequence of rewards, based on trying to take various different actions. You can begin to have the agent learn what to do in the future and what not to do. So in order to begin to formalize this, the first thing we need to do is formalize this notion of what we mean about states and actions and rewards, like what does this world look like? And oftentimes, we'll formulate this world as what's known as a Markov decision process, similar in spirit to Markov chains, which you might recall from before. But a Markov decision process is a model that we can use for decision making, for an agent trying to make decisions in its environment. And it's a model that allows us to represent the various different states that an agent can be in, the various different actions that they can take, and also what the reward is for taking one action as opposed to another action. So what then does it actually look like? Well, if you recall a Markov chain from before, a Markov chain looked a little something like this, where we had a whole bunch of these individual states, and each state immediately transitioned to another state based on some probability distribution. We saw this in the context of the weather before, where if it was sunny, we said with some probability, it'll be sunny the next day. With some other probability, it'll be rainy, for example. But we could also imagine generalizing this. It's not just sun and rain anymore. We just have these states, where one state leads to another state according to some probability distribution. But in this original model, there was no agent that had any control over this process. It was just entirely probability based, where with some probability, we moved to this next state. But maybe it's going to be some other state with some other probability. What we'll now have is the ability for the agent in this state to choose from a set of actions, where maybe instead of just one path forward, they have three different choices of actions that each lead up down different paths. And even this is a bit of an oversimplification, because in each of these states, you might imagine more branching points where there are more decisions that can be taken as well. So we've extended the Markov chain to say that from a state, you now have available action choices. And each of those actions might be associated with its own probability distribution of going to various different states. Then in addition, we'll add another extension, where any time you move from a state, taking an action, going into this other state, we can associate a reward with that outcome, saying either r is positive, meaning some positive reward, or r is negative, meaning there was some sort of punishment. And this then is what we'll consider to be a Markov decision process. That a Markov decision process has some initial set of states, of states in the world that we can be in. We have some set of actions that, given a state, I can say, what are the actions that are available to me in that state, an action that I can choose from? Then we have some transition model. The transition model before just said that, given my current state, what is the probability that I end up in that next state or this other state? The transition model now has effectively two things we're conditioning on. We're saying, given that I'm in this state and that I take this action, what's the probability that I end up in this next state? Now maybe we live in a very deterministic world in this Markov decision process. We're given a state and given an action. We know for sure what next state we'll end up in. But maybe there's some randomness in the world that when you take in a state and you take an action, you might not always end up in the exact same state. There might be some probabilities involved there as well. The Markov decision process can handle both of those possible cases. And then finally, we have a reward function, generally called r, that in this case says, what is the reward for being in this state, taking this action, and then getting to s prime this next state? So I'm in this original state. I take this action. I get to this next state. What is the reward for doing that process? And you can add up these rewards every time you take an action to get the total amount of rewards that an agent might get from interacting in a particular environment modeled using this Markov decision process. So what might this actually look like in practice? Well, let's just create a little simulated world here where I have this agent that is just trying to navigate its way. This agent is this yellow dot here, like a robot in the world, trying to navigate its way through this grid. And ultimately, it's trying to find its way to the goal. And if it gets to the green goal, then it's going to get some sort of reward. But then we might also have some red squares that are places where you get some sort of punishment, some bad place where we don't want the agent to go. And if it ends up in the red square, then our agent is going to get some sort of punishment as a result of that. But the agent originally doesn't know all of these details. It doesn't know that these states are associated with punishments. But maybe it does know that this state is associated with a reward. Maybe it doesn't. But it just needs to sort of interact with the environment to try and figure out what to do and what not to do. So the first thing the agent might do is, given no additional information, if it doesn't know what the punishments are, it doesn't know where the rewards are, it just might try and take an action. And it takes an action and ends up realizing that it got some sort of punishment. And so what does it learn from that experience? Well, it might learn that when you're in this state in the future, don't take the action move to the right, that that is a bad action to take. That in the future, if you ever find yourself back in the state, don't take this action of going to the right when you're in this particular state, because that leads to punishment. That might be the intuition at least. And so you could try doing other actions. You move up, all right, that didn't lead to any immediate rewards. Maybe try something else. Then maybe try something else. And all right, now you found that you got another punishment. And so you learn something from that experience. So the next time you do this whole process, you know that if you ever end up in this square, you shouldn't take the down action, because being in this state and taking that action ultimately leads to some sort of punishment, a negative reward, in other words. And this process repeats. You might imagine just letting our agent explore the world, learning over time what states tend to correspond with poor actions, learning over time what states correspond with poor actions, until eventually, if it tries enough things randomly, it might find that eventually when you get to this state, if you take the up action in this state, it might find that you actually get a reward from that. And what it can learn from that is that if you're in this state, you should take the up action, because that leads to a reward. And over time, you can also learn that if you're in this state, you should take the left action, because that leads to this state that also lets you eventually get to the reward. So you begin to learn over time not only which actions are good in particular states, but also which actions are bad, such that once you know some sequence of good actions that leads you to some sort of reward, our agent can just follow those instructions, follow the experience that it has learned. We didn't tell the agent what the goal was. We didn't tell the agent where the punishments were. But the agent can begin to learn from this experience and learn to begin to perform these sorts of tasks better in the future. And so let's now try to formalize this idea, formalize the idea that we would like to be able to learn in this state taking this action, is that a good thing or a bad thing? There are lots of different models for reinforcement learning. We're just going to look at one of them today. And the one that we're going to look at is a method known as Q-learning. And what Q-learning is all about is about learning a function, a function Q, that takes inputs S and A, where S is a state and A is an action that you take in that state. And what this Q function is going to do is it is going to estimate the value. How much reward will I get from taking this action in this state? Originally, we don't know what this Q function should be. But over time, based on experience, based on trying things out and seeing what the result is, I would like to try and learn what Q of SA is for any particular state and any particular action that I might take in that state. So what is the approach? Well, the approach originally is we'll start with Q SA equal to 0 for all states S and for all actions A. That initially, before I've ever started anything, before I've had any experiences, I don't know the value of taking any action in any given state. So I'm going to assume that the value is just 0 all across the board. But then as I interact with the world, as I experience rewards or punishments, or maybe I go to a cell where I don't get either reward or a punishment, I want to somehow update my estimate of Q SA. I want to continually update my estimate of Q SA based on the experiences and rewards and punishments that I've received, such that in the future, my knowledge of what actions are good and what states will be better. So when we take an action and receive some sort of reward, I want to estimate the new value of Q SA. And I estimate that based on a couple of different things. I estimate it based on the reward that I'm getting from taking this action and getting into the next state. But assuming the situation isn't over, assuming there are still future actions that I might take as well, I also need to take into account the expected future rewards. That if you imagine an agent interacting with the environment, then sometimes you'll take an action and get a reward, but then you can keep taking more actions and get more rewards, that these both are relevant, both the current reward I'm getting from this current step and also my future reward. And it might be the case that I'll want to take a step that doesn't immediately lead to a reward, because later on down the line, I know it will lead to more rewards as well. So there's a balancing act between current rewards that the agent experiences and future rewards that the agent experiences as well. And then we need to update QSA. So we estimate the value of QSA based on the current reward and the expected future rewards. And then we need to update this Q function to take into account this new estimate. Now, we already, as we go through this process, we'll already have an estimate for what we think the value is. Now we have a new estimate, and then somehow we need to combine these two estimates together, and we'll look at more formal ways that we can actually begin to do that. So to actually show you what this formula looks like, here is the approach we'll take with Q learning. We're going to, again, start with Q of S and A being equal to 0 for all states. And then every time we take an action A in state S and observer reward R, we're going to update our value, our estimate, for Q of SA. And the idea is that we're going to figure out what the new value estimate is minus what our existing value estimate is. And so we have some preconceived notion for what the value is for taking this action in this state. Maybe our expectation is we currently think the value is 10. But then we're going to estimate what we now think it's going to be. Maybe the new value estimate is something like 20. So there's a delta of 10 that our new value estimate is 10 points higher than what our current value estimate happens to be. And so we have a couple of options here. We need to decide how much we want to adjust our current expectation of what the value is of taking this action in this particular state. And what that difference is, how much we add or subtract from our existing notion of how much do we expect the value to be, is dependent on this parameter alpha, also called a learning rate. And alpha represents, in effect, how much we value new information compared to how much we value old information. An alpha value of 1 means we really value new information. But if we have a new estimate, then it doesn't matter what our old estimate is. We're only going to consider our new estimate because we always just want to take into consideration our new information. So the way that works is that if you imagine alpha being 1, well, then we're taking the old value of QSA and then adding 1 times the new value minus the old value. And that just leaves us with the new value. So when alpha is 1, all we take into consideration is what our new estimate happens to be. But over time, as we go through a lot of experiences, we already have some existing information. We might have tried taking this action nine times already. And now we just tried it a 10th time. And we don't only want to consider this 10th experience. I also want to consider the fact that my prior nine experiences, those were meaningful, too. And that's data I don't necessarily want to lose. And so this alpha controls that decision, controls how important is the new information. 0 would mean ignore all the new information. Just keep this Q value the same. 1 means replace the old information entirely with the new information. And somewhere in between, keep some sort of balance between these two values. We can put this equation a little bit more formally as well. The old value estimate is our old estimate for what the value is of taking this action in a particular state. That's just Q of SNA. So we have it once here, and we're going to add something to it. We're going to add alpha times the new value estimate minus the old value estimate. But the old value estimate, we just look up by calling this Q function. And what then is the new value estimate? Based on this experience we have just taken, what is our new estimate for the value of taking this action in this particular state? Well, it's going to be composed of two parts. It's going to be composed of what reward did I just get from taking this action in this state. And then it's going to be, what can I expect my future rewards to be from this point forward? So it's going to be R, some reward I'm getting right now, plus whatever I estimate I'm going to get in the future. And how do I estimate what I'm going to get in the future? Well, it's a bit of another call to this Q function. It's going to be take the maximum across all possible actions I could take next and say, all right, of all of these possible actions I could take, which one is going to have the highest reward? And so this then looks a little bit complicated. This is going to be our notion for how we're going to perform this kind of update. I have some estimate, some old estimate, for what the value is of taking this action in this state. And I'm going to update it based on new information that I experience some reward. I predict what my future reward is going to be. And using that I update what I estimate the reward will be for taking this action in this particular state. And there are other additions you might make to this algorithm as well. Sometimes it might not be the case that future rewards you want to wait equally to current rewards. Maybe you want an agent that values reward now over reward later. And so sometimes you can even add another term in here, some other parameter, where you discount future rewards and say future rewards are not as valuable as rewards immediately. That getting reward in the current time step is better than waiting a year and getting rewards later. But that's something up to the programmer to decide what that parameter ought to be. But the big picture idea of this entire formula is to say that every time we experience some new reward, we take that into account. We update our estimate of how good is this action. And then in the future, we can make decisions based on that algorithm. Once we have some good estimate for every state and for every action, what the value is of taking that action, then we can do something like implement a greedy decision making policy. That if I am in a state and I want to know what action should I take in that state, well, then I consider for all of my possible actions, what is the value of QSA? What is my estimated value of taking that action in that state? And I will just pick the action that has the highest value after I evaluate that expression. So I pick the action that has the highest value. And based on that, that tells me what action I should take. At any given state that I'm in, I can just greedily say across all my actions, this action gives me the highest expected value. And so I'll go ahead and choose that action as the action that I take as well. But there is a downside to this kind of approach. And then downside comes up in a situation like this, where we know that there is some solution that gets me to the reward. And our agent has been able to figure that out. But it might not necessarily be the best way or the fastest way. If the agent is allowed to explore a little bit more, it might find that it can get the reward faster by taking some other route instead, by going through this particular path that is a faster way to get to that ultimate goal. And maybe we would like for the agent to be able to figure that out as well. But if the agent always takes the actions that it knows to be best, well, when it gets to this particular square, it doesn't know that this is a good action because it's never really tried it. But it knows that going down eventually leads its way to this reward. So it might learn in the future that it should just always take this route and it's never going to explore and go along that route instead. So in reinforcement learning, there is this tension between exploration and exploitation. And exploitation generally refers to using knowledge that the AI already has. The AI already knows that this is a move that leads to reward. So we'll go ahead and use that move. And exploration is all about exploring other actions that we may not have explored as thoroughly before because maybe one of these actions, even if I don't know anything about it, might lead to better rewards faster or to more rewards in the future. And so an agent that only ever exploits information and never explores might be able to get reward, but it might not maximize its rewards because it doesn't know what other possibilities are out there, possibilities that we only know about by taking advantage of exploration. And so how can we try and address this? Well, one possible solution is known as the Epsilon greedy algorithm, where we set Epsilon equal to how often we want to just make a random move, where occasionally we will just make a random move in order to say, let's try to explore and see what happens. And then the logic of the algorithm will be with probability 1 minus Epsilon, choose the estimated best move. In a greedy case, we'd always choose the best move. But in Epsilon greedy, we're most of the time going to choose the best move or sometimes going to choose the best move. But sometimes with probability Epsilon, we're going to choose a random move instead. So every time we're faced with the ability to take an action, sometimes we're going to choose the best move. Sometimes we're just going to choose a random move. So this type of algorithm can be quite powerful in a reinforcement learning context by not always just choosing the best possible move right now, but sometimes, especially early on, allowing yourself to make random moves that allow you to explore various different possible states and actions more, and maybe over time, you might decrease your value of Epsilon. More and more often, choosing the best move after you're more confident that you've explored what all of the possibilities actually are. So we can put this into practice. And one very common application of reinforcement learning is in game playing, that if you want to teach an agent how to play a game, you just let the agent play the game a whole bunch. And then the reward signal happens at the end of the game. When the game is over, if our AI won the game, it gets a reward of like 1, for example. And if it lost the game, it gets a reward of negative 1. And from that, it begins to learn what actions are good and what actions are bad. You don't have to tell the AI what's good and what's bad, but the AI figures it out based on that reward. Winning the game is some signal, losing the game is some signal, and based on all of that, it begins to figure out what decisions it should actually make. So one very simple game, which you may have played before, is a game called Nim. And in the game of Nim, you've got a whole bunch of objects in a whole bunch of different piles, where here I've represented each pile as an individual row. So you've got one object in the first pile, three in the second pile, five in the third pile, seven in the fourth pile. And the game of Nim is a two player game where players take turns removing objects from piles. And the rule is that on any given turn, you were allowed to remove as many objects as you want from any one of these piles, any one of these rows. You have to remove at least one object, but you remove as many as you want from exactly one of the piles. And whoever takes the last object loses. So player one might remove four from this pile here. Player two might remove four from this pile here. So now we've got four piles left, one, three, one, and three. Player one might remove the entirety of the second pile. Player two, if they're being strategic, might remove two from the third pile. Now we've got three piles left, each with one object left. Player one might remove one from one pile. Player two removes one from the other pile. And now player one is left with choosing this one object from the last pile, at which point player one loses the game. So fairly simple game. Piles of objects, any turn you choose how many objects to remove from a pile, whoever removes the last object loses. And this is the type of game you could encode into an AI fairly easily, because the states are really just four numbers. Every state is just how many objects in each of the four piles. And the actions are things like, how many am I going to remove from each one of these individual piles? And the reward happens at the end, that if you were the player that had to remove the last object, then you get some sort of punishment. But if you were not, and the other player had to remove the last object, well, then you get some sort of reward. So we could actually try and show a demonstration of this, that I've implemented an AI to play the game of Nim. All right, so here, what we're going to do is create an AI as a result of training the AI on some number of games, that the AI is going to play against itself, where the idea is the AI will play games against itself, learn from each of those experiences, and learn what to do in the future. And then I, the human, will play against the AI. So initially, we'll say train zero times, meaning we're not going to let the AI play any practice games against itself in order to learn from its experiences. We're just going to see how well it plays. And it looks like there are four piles. I can choose how many I remove from any one of the piles. So maybe from pile three, I will remove five objects, for example. So now, AI chose to take one item from pile zero. So I'm left with these piles now, for example. And so here, I could choose maybe to say, I would like to remove from pile two, I'll remove all five of them, for example. And so AI chose to take two away from pile one. Now I'm left with one pile that has one object, one pile that has two objects. So from pile three, I will remove two objects. And now I've left the AI with no choice but to take that last one. And so the game is over, and I was able to win. But I did so because the AI was really just playing randomly. It didn't have any prior experience that it was using in order to make these sorts of judgments. Now let me let the AI train itself on 10,000 games. I'm going to let the AI play 10,000 games of nim against itself. Every time it wins or loses, it's going to learn from that experience and learn in the future what to do and what not to do. So here then, I'll go ahead and run this again. And now you see the AI running through a whole bunch of training games, 10,000 training games against itself. And now it's going to let me make these sorts of decisions. So now I'm going to play against the AI. Maybe I'll remove one from pile three. And the AI took everything from pile three, so I'm left with three piles. I'll go ahead and from pile two maybe remove three items. And the AI removes one item from pile zero. I'm left with two piles, each of which has two items in it. I'll remove one from pile one, I guess. And the AI took two from pile two, leaving me with no choice but to take one away from pile one. So it seems like after playing 10,000 games of nim against itself, the AI has learned something about what states and what actions tend to be good and has begun to learn some sort of pattern for how to predict what actions are going to be good and what actions are going to be bad in any given state. So reinforcement learning can be a very powerful technique for achieving these sorts of game-playing agents, agents that are able to play a game well just by learning from experience, whether that's playing against other people or by playing against itself and learning from those experiences as well. Now, nim is a bit of an easy game to use reinforcement learning for because there are so few states. There are only states that are as many as how many different objects are in each of these various different piles. You might imagine that it's going to be harder if you think of a game like chess or games where there are many, many more states and many, many more actions that you can imagine taking, where it's not going to be as easy to learn for every state and for every action what the value is going to be. So oftentimes in that case, we can't necessarily learn exactly what the value is for every state and for every action, but we can approximate it. So much as we saw with minimax, so we could use a depth-limiting approach to stop calculating at a certain point in time, we can do a similar type of approximation known as function approximation in a reinforcement learning context where instead of learning a value of q for every state and every action, we just have some function that estimates what the value is for taking this action in this particular state that might be based on various different features of the state that the agent happens to be in, where you might have to choose what those features actually are. But you can begin to learn some patterns that generalize beyond one specific state and one specific action that you can begin to learn if certain features tend to be good things or bad things. Reinforcement learning can allow you, using a very similar mechanism, to generalize beyond one particular state and say, if this other state looks kind of like this state, then maybe the similar types of actions that worked in one state will also work in another state as well. And so this type of approach can be quite helpful as you begin to deal with reinforcement learning that exist in larger and larger state spaces where it's just not feasible to explore all of the possible states that could actually exist. So there, then, are two of the main categories of reinforcement learning. Supervised learning, where you have labeled input and output pairs, and reinforcement learning, where an agent learns from rewards or punishments that it receives. The third major category of machine learning that we'll just touch on briefly is known as unsupervised learning. And unsupervised learning happens when we have data without any additional feedback, without labels, that in the supervised learning case, all of our data had labels. We labeled the data point with whether that was a rainy day or not rainy day. And using those labels, we were able to infer what the pattern was. Or we labeled data as a counterfeit banknote or not a counterfeit. And using those labels, we were able to draw inferences and patterns to figure out what does a banknote look like versus not. In unsupervised learning, we don't have any access to any of those labels. But we still would like to learn some of those patterns. And one of the tasks that you might want to perform in unsupervised learning is something like clustering, where clustering is just the task of, given some set of objects, organize it into distinct clusters, groups of objects that are similar to one another. And there's lots of applications for clustering. It comes up in genetic research, where you might have a whole bunch of different genes and you want to cluster them into similar genes if you're trying to analyze them across a population or across species. It comes up in an image if you want to take all the pixels of an image, cluster them into different parts of the image. Comes a lot up in market research if you want to divide your consumers into different groups so you know which groups to target with certain types of product advertisements, for example, and a number of other contexts as well in which clustering can be very applicable. One technique for clustering is an algorithm known as k-means clustering. And what k-means clustering is going to do is it is going to divide all of our data points into k different clusters. And it's going to do so by repeating this process of assigning points to clusters and then moving around those clusters at centers. We're going to define a cluster by its center, the middle of the cluster, and then assign points to that cluster based on which center is closest to that point. And I'll show you an example of that now. Here, for example, I have a whole bunch of unlabeled data, just various data points that are in some sort of graphical space. And I would like to group them into various different clusters. But I don't know how to do that originally. And let's say I want to assign like three clusters to this group. And you have to choose how many clusters you want in k-means clustering that you could try multiple and see how well those values perform. But I'll start just by randomly picking some places to put the centers of those clusters. Maybe I have a blue cluster, a red cluster, and a green cluster. And I'm going to start with the centers of those clusters just being in these three locations here. And what k-means clustering tells us to do is once I have the centers of the clusters, assign every point to a cluster based on which cluster center it is closest to. So we end up with something like this, where all of these points are closer to the blue cluster center than any other cluster center. All of these points here are closer to the green cluster center than any other cluster center. And then these two points plus these points over here, those are all closest to the red cluster center instead. So here then is one possible assignment of all these points to three different clusters. But it's not great that it seems like in this red cluster, these points are kind of far apart. In this green cluster, these points are kind of far apart. It might not be my ideal choice of how I would cluster these various different data points. But k-means clustering is an iterative process that after I do this, there is a next step, which is that after I've assigned all of the points to the cluster center that it is nearest to, we are going to re-center the clusters, meaning take the cluster centers, these diamond shapes here, and move them to the middle, or the average, effectively, of all of the points that are in that cluster. So we'll take this blue point, this blue center, and go ahead and move it to the middle or to the center of all of the points that were assigned to the blue cluster, moving it slightly to the right in this case. And we'll do the same thing for red. We'll move the cluster center to the middle of all of these points, weighted by how many points there are. There are more points over here, so the red center ends up moving a little bit further that way. And likewise, for the green center, there are many more points on this side of the green center. So the green center ends up being pulled a little bit further in this direction. So we re-center all of the clusters, and then we repeat the process. We go ahead and now reassign all of the points to the cluster center that they are now closest to. And now that we've moved around the cluster centers, these cluster assignments might change. That this point originally was closer to the red cluster center, but now it's actually closer to the blue cluster center. Same goes for this point as well. And these three points that were originally closer to the green cluster center are now closer to the red cluster center instead. So we can reassign what colors or which clusters each of these data points belongs to, and then repeat the process again, moving each of these cluster means and the middles of the clusterism to the mean, the average, of all of the other points that happen to be there, and repeat the process again. Go ahead and assign each of the points to the cluster that they are closest to. So once we reach a point where we've assigned all the points to clusters to the cluster that they are nearest to, and nothing changed, we've reached a sort of equilibrium in this situation, where no points are changing their allegiance. And as a result, we can declare this algorithm is now over. And we now have some assignment of each of these points into three different clusters. And it looks like we did a pretty good job of trying to identify which points are more similar to one another than they are to points in other groups. So we have the green cluster down here, this blue cluster here, and then this red cluster over there as well. And we did so without any access to some labels to tell us what these various different clusters were. We just used an algorithm in an unsupervised sense without any of those labels to figure out which points belonged to which categories. And again, lots of applications for this type of clustering technique. And there are many more algorithms in each of these various different fields within machine learning, supervised and reinforcement and unsupervised. But those are many of the big picture foundational ideas that underlie a lot of these techniques, where these are the problems that we're trying to solve. And we try and solve those problems using a number of different methods of trying to take data and learn patterns in that data, whether that's trying to find neighboring data points that are similar or trying to minimize some sort of loss function or any number of other techniques that allow us to begin to try to solve these sorts of problems. That then was a look at some of the principles that are at the foundation of modern machine learning, this ability to take data and learn from that data so that the computer can perform a task even if they haven't explicitly been given instructions in order to do so. Next time, we'll continue this conversation about machine learning, looking at other techniques we can use for solving these sorts of problems. We'll see you then. All right, welcome back, everyone, to an introduction to artificial intelligence with Python. Now, last time, we took a look at machine learning, a set of techniques that computers can use in order to take a set of data and learn some patterns inside of that data, learn how to perform a task even if we the programmers didn't give the computer explicit instructions for how to perform that task. Today, we transition to one of the most popular techniques and tools within machine learning, that of neural networks. And neural networks were inspired as early as the 1940s by researchers who were thinking about how it is that humans learn, studying neuroscience in the human brain and trying to see whether or not we could apply those same ideas to computers as well and model computer learning off of human learning. So how is the brain structured? Well, very simply put, the brain consists of a whole bunch of neurons. And those neurons are connected to one another and communicate with one another in some way. In particular, if you think about the structure of a biological neural network, something like this, there are a couple of key properties that scientists observed. One was that these neurons are connected to each other and receive electrical signals from one another, that one neuron can propagate electrical signals to another neuron. And another point is that neurons process those input signals and then can be activated, that a neuron becomes activated at a certain point and then can propagate further signals onto neurons in the future. And so the question then became, could we take this biological idea of how it is that humans learn with brains and with neurons and apply that to a machine as well, in effect designing an artificial neural network, or an ANN, which will be a mathematical model for learning that is inspired by these biological neural networks? And what artificial neural networks will allow us to do is they will first be able to model some sort of mathematical function. Every time you look at a neural network, which we'll see more of later today, each one of them is really just some mathematical function that is mapping certain inputs to particular outputs based on the structure of the network, that depending on where we place particular units inside of this neural network, that's going to determine how it is that the network is going to function. And in particular, artificial neural networks are going to lend themselves to a way that we can learn what the network's parameters should be. We'll see more on that in just a moment. But in effect, we want a model such that it is easy for us to be able to write some code that allows for the network to be able to figure out how to model the right mathematical function given a particular set of input data. So in order to create our artificial neural network, instead of using biological neurons, we're just going to use what we're going to call units, units inside of a neural network, which we can represent kind of like a node in a graph, which will here be represented just by a blue circle like this. And these artificial units, these artificial neurons, can be connected to one another. So here, for instance, we have two units that are connected by this edge inside of this graph, effectively. And so what we're going to do now is think of this idea as some sort of mapping from inputs to outputs. So we have one unit that is connected to another unit that we might think of this side of the input and that side of the output. And what we're trying to do then is to figure out how to solve a problem, how to model some sort of mathematical function. And this might take the form of something we saw last time, which was something like we have certain inputs, like variables x1 and x2. And given those inputs, we want to perform some sort of task, a task like predicting whether or not it's going to rain. And ideally, we'd like some way, given these inputs, x1 and x2, which stand for some sort of variables to do with the weather, we would like to be able to predict, in this case, a Boolean classification. Is it going to rain, or is it not going to rain? And we did this last time by way of a mathematical function. We defined some function, h, for our hypothesis function, that took as input x1 and x2, the two inputs that we cared about processing, in order to determine whether we thought it was going to rain or whether we thought it was not going to rain. The question then becomes, what does this hypothesis function do in order to make that determination? And we decided last time to use a linear combination of these input variables to determine what the output should be. So our hypothesis function was equal to something like this. Weight 0 plus weight 1 times x1 plus weight 2 times x2. So what's going on here is that x1 and x2, those are input variables, the inputs to this hypothesis function. And each of those input variables is being multiplied by some weight, which is just some number. So x1 is being multiplied by weight 1, x2 is being multiplied by weight 2. And we have this additional weight, weight 0, that doesn't get multiplied by an input variable at all, that just serves to either move the function up or move the function's value down. You can think of this as either a weight that's just multiplied by some dummy value, like the number 1. It's multiplied by 1, and so it's not multiplied by anything. Or sometimes, you'll see in the literature, people call this variable weight 0 a bias, so that you can think of these variables as slightly different. We have weights that are multiplied by the input, and we separately add some bias to the result as well. You'll hear both of those terminologies used when people talk about neural networks and machine learning. So in effect, what we've done here is that in order to define a hypothesis function, we just need to decide and figure out what these weights should be to determine what values to multiply by our inputs to get some sort of result. Of course, at the end of this, what we need to do is make some sort of classification, like rainy or not rainy. And to do that, we use some sort of function that defines some sort of threshold. And so we saw, for instance, the step function, which is defined as 1 if the result of multiplying the weights by the inputs is at least 0, otherwise it's 0. And you can think of this line down the middle as kind of like a dotted line. Effectively, it stays at 0 all the way up to one point, and then the function steps or jumps up to 1. So it's 0 before it reaches some threshold, and then it's 1 after it reaches a particular threshold. And so this was one way we could define what will come to call an activation function, a function that determines when it is that this output becomes active, changes to 1 instead of being a 0. But we also saw that if we didn't just want a purely binary classification, we didn't want purely 1 or 0, but we wanted to allow for some in-between real numbered values, we could use a different function. And there are a number of choices, but the one that we looked at was the logistic sigmoid function that has sort of an s-shaped curve, where we could represent this as a probability that may be somewhere in between the probability of rain or something like 0.5. Maybe a little bit later, the probability of rain is 0.8. And so rather than just have a binary classification of 0 or 1, we could allow for numbers that are in between as well. And it turns out there are many other different types of activation functions, where an activation function just takes the output of multiplying the weights together and adding that bias, and then figuring out what the actual output should be. Another popular one is the rectified linear unit, otherwise known as ReLU. And the way that works is that it just takes its input and takes the maximum of that input and 0. So if it's positive, it remains unchanged. But if it's 0, if it's negative, it goes ahead and levels out at 0. And there are other activation functions that we could choose as well. But in short, each of these activation functions, you can just think of as a function that gets applied to the result of all of this computation. We take some function g and apply it to the result of all of that calculation. And this then is what we saw last time, the way of defining some hypothesis function that takes in inputs, calculate some linear combination of those inputs, and then passes it through some sort of activation function to get our output. And this actually turns out to be the model for the simplest of neural networks, that we're going to instead represent this mathematical idea graphically by using a structure like this. Here then is a neural network that has two inputs. We can think of this as x1 and this as x2. And then one output, which you can think of as classifying whether or not we think it's going to rain or not rain, for example, in this particular instance. And so how exactly does this model work? Well, each of these two inputs represents one of our input variables, x1 and x2. And notice that these inputs are connected to this output via these edges, which are going to be defined by their weights. So these edges each have a weight associated with them, weight 1 and weight 2. And then this output unit, what it's going to do is it is going to calculate an output based on those inputs and based on those weights. This output unit is going to multiply all the inputs by their weights, add in this bias term, which you can think of as an extra w0 term that gets added into it, and then we pass it through an activation function. So this then is just a graphical way of representing the same idea we saw last time just mathematically. And we're going to call this a very simple neural network. And we'd like for this neural network to be able to learn how to calculate some function, that we want some function for the neural network to learn. And the neural network is going to learn what should the values of w0, w1, and w2 be? What should the activation function be in order to get the result that we would expect? So we can actually take a look at an example of this. What then is a very simple function that we might calculate? Well, if we recall back from when we were looking at propositional logic, one of the simplest functions we looked at was something like the or function that takes two inputs, x and y, and outputs 1, otherwise known as true, if either one of the inputs or both of them are 1, and outputs of 0 if both of the inputs are 0 or false. So this then is the or function. And this was the truth table for the or function, that as long as either of the inputs are 1, the output of the function is 1, and the only case where the output is 0 is where both of the inputs are 0. So the question is, how could we take this and train a neural network to be able to learn this particular function? What would those weights look like? Well, we could do something like this. Here's our neural network. And I'll propose that in order to calculate the or function, we're going to use a value of 1 for each of the weights. And we'll use a bias of negative 1. And then we'll just use this step function as our activation function. How then does this work? Well, if I wanted to calculate something like 0 or 0, which we know to be 0 because false or false is false, then what are we going to do? Well, our output unit is going to calculate this input multiplied by the weight, 0 times 1, that's 0. Same thing here, 0 times 1, that's 0. And we'll add to that the bias minus 1. So that'll give us a result of negative 1. If we plot that on our activation function, negative 1 is here. It's before the threshold, which means either 0 or 1. It's only 1 after the threshold. Since negative 1 is before the threshold, the output that this unit provides is going to be 0. And that's what we would expect it to be, that 0 or 0 should be 0. What if instead we had had 1 or 0, where this is the number 1? Well, in this case, in order to calculate what the output is going to be, we again have to do this weighted sum, 1 times 1, that's 1. 0 times 1, that's 0. Sum of that so far is 1. Add negative 1 to that. Well, then the output is 0. And if we plot 0 on the step function, 0 ends up being here. It's just at the threshold. And so the output here is going to be 1, because the output of 1 or 0, that's 1. So that's what we would expect as well. And just for one more example, if I had 1 or 1, what would the result be? Well, 1 times 1 is 1. 1 times 1 is 1. The sum of those is 2. I add the bias term to that. I get the number 1. 1 plotted on this graph is way over there. That's well beyond the threshold. And so this output is going to be 1 as well. The output is always 0 or 1, depending on whether or not we're past the threshold. And this neural network then models the OR function, a very simple function, definitely. But it still is able to model it correctly. If I give it the inputs, it will tell me what x1 or x2 happens to be. And you could imagine trying to do this for other functions as well. A function like the AND function, for instance, that takes two inputs and calculates whether both x and y are true. So if x is 1 and y is 1, then the output of x and y is 1. But in all the other cases, the output is 0. How could we model that inside of a neural network as well? Well, it turns out we could do it in the same way, except instead of negative 1 as the bias, we can use negative 2 as the bias instead. What does that end up looking like? Well, if I had 1 and 1, that should be 1, because 1 true and true is equal to true. Well, I take 1 times 1, that's 1. 1 times 1 is 1. I get a total sum of 2 so far. Now I add the bias of negative 2, and I get the value 0. And 0, when I plot it on the activation function, is just past that threshold, and so the output is going to be 1. But if I had any other input, for example, like 1 and 0, well, the weighted sum of these is 1 plus 0 is going to be 1. Minus 2 is going to give us negative 1, and negative 1 is not past that threshold, and so the output is going to be 0. So those then are some very simple functions that we can model using a neural network that has two inputs and one output, where our goal is to be able to figure out what those weights should be in order to determine what the output should be. And you could imagine generalizing this to calculate more complex functions as well, that maybe, given the humidity and the pressure, we want to calculate what's the probability that it's going to rain, for example. Or we might want to do a regression-style problem. We're given some amount of advertising, and given what month it is maybe, we want to predict what our expected sales are going to be for that particular month. So you could imagine these inputs and outputs being different as well. And it turns out that in some problems, we're not just going to have two inputs, and the nice thing about these neural networks is that we can compose multiple units together, make our networks more complex just by adding more units into this particular neural network. So the network we've been looking at has two inputs and one output. But we could just as easily say, let's go ahead and have three inputs in there, or have even more inputs, where we could arbitrarily decide however many inputs there are to our problem, all going to be calculating some sort of output that we care about figuring out the value of. How then does the math work for figuring out that output? Well, it's going to work in a very similar way. In the case of two inputs, we had two weights indicated by these edges, and we multiplied the weights by the numbers, adding this bias term. And we'll do the same thing in the other cases as well. If I have three inputs, you'll imagine multiplying each of these three inputs by each of these weights. If I had five inputs instead, we're going to do the same thing. Here I'm saying sum up from 1 to 5, xi multiplied by weight i. So take each of the five input variables, multiply them by their corresponding weight, and then add the bias to that. So this would be a case where there are five inputs into this neural network, for example. But there could be more, arbitrarily many nodes that we want inside of this neural network, where each time we're just going to sum up all of those input variables multiplied by their weight and then add the bias term at the very end. And so this allows us to be able to represent problems that have even more inputs just by growing the size of our neural network. Now, the next question we might ask is a question about how it is that we train these neural networks. In the case of the or function and the and function, they were simple enough functions that I could just tell you, like here, what the weights should be. And you could probably reason through it yourself what the weights should be in order to calculate the output that you want. But in general, with functions like predicting sales or predicting whether or not it's going to rain, these are much trickier functions to be able to figure out. We would like the computer to have some mechanism of calculating what it is that the weights should be, how it is to set the weights so that our neural network is able to accurately model the function that we care about trying to estimate. And it turns out that the strategy for doing this, inspired by the domain of calculus, is a technique called gradient descent. And what gradient descent is, it is an algorithm for minimizing loss when you're training a neural network. And recall that loss refers to how bad our hypothesis function happens to be, that we can define certain loss functions. And we saw some examples of loss functions last time that just give us a number for any particular hypothesis, saying, how poorly does it model the data? How many examples does it get wrong? How are they worse or less bad as compared to other hypothesis functions that we might define? And this loss function is just a mathematical function. And when you have a mathematical function, in calculus what you could do is calculate something known as the gradient, which you can think of as like a slope. It's the direction the loss function is moving at any particular point. And what it's going to tell us is, in which direction should we be moving these weights in order to minimize the amount of loss? And so generally speaking, we won't get into the calculus of it. But the high level idea for gradient descent is going to look something like this. If we want to train a neural network, we'll go ahead and start just by choosing the weights randomly. Just pick random weights for all of the weights in the neural network. And then we'll use the input data that we have access to in order to train the network, in order to figure out what the weights should actually be. So we'll repeat this process again and again. The first step is we're going to calculate the gradient based on all of the data points. So we'll look at all the data and figure out what the gradient is at the place where we currently are for the current setting of the weights, which means in which direction should we move the weights in order to minimize the total amount of loss, in order to make our solution better. And once we've calculated that gradient, which direction we should move in the loss function, well, then we can just update those weights according to the gradient. Take a small step in the direction of those weights in order to try to make our solution a little bit better. And the size of the step that we take, that's going to vary. And you can choose that when you're training a particular neural network. But in short, the idea is going to be take all the data points, figure out based on those data points in what direction the weights should move, and then move the weights one small step in that direction. And if you repeat that process over and over again, adjusting the weights a little bit at a time based on all the data points, eventually you should end up with a pretty good solution to trying to solve this sort of problem. At least that's what we would hope to happen. Now, if you look at this algorithm, a good question to ask anytime you're analyzing an algorithm is what is going to be the expensive part of doing the calculation? What's going to take a lot of work to try to figure out? What is going to be expensive to calculate? And in particular, in the case of gradient descent, the really expensive part is this all data points part right here, having to take all of the data points and using all of those data points figure out what the gradient is at this particular setting of all of the weights. Because odds are in a big machine learning problem where you're trying to solve a big problem with a lot of data, you have a lot of data points in order to calculate. And figuring out the gradient based on all of those data points is going to be expensive. And you'll have to do it many times. You'll likely repeat this process again and again and again, going through all the data points, taking one small step over and over as you try and figure out what the optimal setting of those weights happens to be. It turns out that we would ideally like to be able to train our neural networks faster, to be able to more quickly converge to some sort of solution that is going to be a good solution to the problem. So in that case, there are alternatives to just standard gradient descent, which looks at all of the data points at once. We can employ a method like stochastic gradient descent, which will randomly just choose one data point at a time to calculate the gradient based on, instead of calculating it based on all of the data points. So the idea there is that we have some setting of the weights. We pick a data point. And based on that one data point, we figure out in which direction should we move all of the weights and move the weights in that small direction, then take another data point and do that again and repeat this process again and again, maybe looking at each of the data points multiple times, but each time only using one data point to calculate the gradient, to calculate which direction we should move in. Now, just using one data point instead of all of the data points probably gives us a less accurate estimate of what the gradient actually is. But on the plus side, it's going to be much faster to be able to calculate, that we can much more quickly calculate what the gradient is based on one data point, instead of calculating based on all of the data points and having to do all of that computational work again and again. So there are trade-offs here between looking at all of the data points and just looking at one data point. And it turns out that a middle ground that is also quite popular is a technique called mini-batch gradient descent, where the idea there is instead of looking at all of the data versus just a single point, we instead divide our data set up into small batches, groups of data points, where you can decide how big a particular batch is. But in short, you're just going to look at a small number of points at any given time, hopefully getting a more accurate estimate of the gradient, but also not requiring all of the computational effort needed to look at every single one of these data points. So gradient descent, then, is this technique that we can use in order to train these neural networks, in order to figure out what the setting of all of these weights should be if we want some way to try and get an accurate notion of how it is that this function should work, some way of modeling how to transform the inputs into particular outputs. Now, so far, the networks that we've taken a look at have all been structured similar to this. We have some number of inputs, maybe two or three or five or more. And then we have one output that is just predicting like rain or no rain or just predicting one particular value. But often in machine learning problems, we don't just care about one output. We might care about an output that has multiple different values associated with it. So in the same way that we could take a neural network and add units to the input layer, we can likewise add inputs or add outputs to the output layer as well. Instead of just one output, you could imagine we have two outputs, or we could have four outputs, for example, where in each case, as we add more inputs or add more outputs, if we want to keep this network fully connected between these two layers, we just need to add more weights, that now each of these input nodes has four weights associated with each of the four outputs. And that's true for each of these various different input nodes. So as we add nodes, we add more weights in order to make sure that each of the inputs can somehow be connected to each of the outputs so that each output value can be calculated based on what the value of the input happens to be. So what might a case be where we want multiple different output values? Well, you might consider that in the case of weather predicting, for example, we might not just care whether it's raining or not raining. There might be multiple different categories of weather that we would like to categorize the weather into. With just a single output variable, we can do a binary classification, like rain or no rain, for instance, 1 or 0. But it doesn't allow us to do much more than that. With multiple output variables, I might be able to use each one to predict something a little different. Maybe I want to categorize the weather into one of four different categories, something like is it going to be raining or sunny or cloudy or snowy. And I now have four output variables that can be used to represent maybe the probability that it is rainy as opposed to sunny as opposed to cloudy or as opposed to snowy. How then would this neural network work? Well, we have some input variables that represent some data that we have collected about the weather. Each of those inputs gets multiplied by each of these various different weights. We have more multiplications to do, but these are fairly quick mathematical operations to perform. And then what we get is after passing them through some sort of activation function in the outputs, we end up getting some sort of number, where that number, you might imagine, you could interpret as a probability, like a probability that it is one category as opposed to another category. So here we're saying that based on the inputs, we think there is a 10% chance that it's raining, a 60% chance that it's sunny, a 20% chance of cloudy, a 10% chance that it's snowy. And given that output, if these represent a probability distribution, well, then you could just pick whichever one has the highest value, in this case, sunny, and say that, well, most likely, we think that this categorization of inputs means that the output should be snowy or should be sunny. And that is what we would expect the weather to be in this particular instance. And so this allows us to do these sort of multi-class classifications, where instead of just having a binary classification, 1 or 0, we can have as many different categories as we want. And we can have our neural network output these probabilities over which categories are more likely than other categories. And using that data, we're able to draw some sort of inference on what it is that we should do. So this was sort of the idea of supervised machine learning. I can give this neural network a whole bunch of data, a whole bunch of input data corresponding to some label, some output data, like we know that it was raining on this day, we know that it was sunny on that day. And using all of that data, the algorithm can use gradient descent to figure out what all of the weights should be in order to create some sort of model that hopefully allows us a way to predict what we think the weather is going to be. But neural networks have a lot of other applications as well. You could imagine applying the same sort of idea to a reinforcement learning sort of example as well, where you remember that in reinforcement learning, what we wanted to do is train some sort of agent to learn what action to take, depending on what state they currently happen to be in. So depending on the current state of the world, we wanted the agent to pick from one of the available actions that is available to them. And you might model that by having each of these input variables represent some information about the state, some data about what state our agent is currently in. And then the output, for example, could be each of the various different actions that our agent could take, action 1, 2, 3, and 4. And you might imagine that this network would work in the same way, but based on these particular inputs, we go ahead and calculate values for each of these outputs. And those outputs could model which action is better than other actions. And we could just choose, based on looking at those outputs, which action we should take. And so these neural networks are very broadly applicable, that all they're really doing is modeling some mathematical function. So anything that we can frame as a mathematical function, something like classifying inputs into various different categories or figuring out based on some input state what action we should take, these are all mathematical functions that we could attempt to model by taking advantage of this neural network structure, and in particular, taking advantage of this technique, gradient descent, that we can use in order to figure out what the weights should be in order to do this sort of calculation. Now, how is it that you would go about training a neural network that has multiple outputs instead of just one? Well, with just a single output, we could see what the output for that value should be, and then you update all of the weights that corresponded to it. And when we have multiple outputs, at least in this particular case, we can really think of this as four separate neural networks, that really we just have one network here that has these three inputs corresponding with these three weights corresponding to this one output value. And the same thing is true for this output value. This output value effectively defines yet another neural network that has these same three inputs, but a different set of weights that correspond to this output. And likewise, this output has its own set of weights as well, and same thing for the fourth output too. And so if you wanted to train a neural network that had four outputs instead of just one, in this case where the inputs are directly connected to the outputs, you could really think of this as just training four independent neural networks. We know what the outputs for each of these four should be based on our input data, and using that data, we can begin to figure out what all of these individual weights should be. And maybe there's an additional step at the end to make sure that we turn these values into a probability distribution such that we can interpret which one is better than another or more likely than another as a category or something like that. So this then seems like it does a pretty good job of taking inputs and trying to predict what outputs should be. And we'll see some real examples of this in just a moment as well. But it's important then to think about what the limitations of this sort of approach is, of just taking some linear combination of inputs and passing it into some sort of activation function. And it turns out that when we do this in the case of binary classification, trying to predict does it belong to one category or another, we can only predict things that are linearly separable. Because we're taking a linear combination of inputs and using that to define some decision boundary or threshold, then what we get is a situation where if we have this set of data, we can predict a line that separates linearly the red points from the blue points, but a single unit that is making a binary classification, otherwise known as a perceptron, can't deal with a situation like this, where we've seen this type of situation before, where there is no straight line that just goes straight through the data that will divide the red points away from the blue points. It's a more complex decision boundary. The decision boundary somehow needs to capture the things inside of this circle. And there isn't really a line that will allow us to deal with that. So this is the limitation of the perceptron, these units that just make these binary decisions based on their inputs, that a single perceptron is only capable of learning a linearly separable decision boundary. All it can do is define a line. And sure, it can give us probabilities based on how close to that decision boundary we are, but it can only really decide based on a linear decision boundary. And so this doesn't seem like it's going to generalize well to situations where real world data is involved, because real world data often isn't linearly separable. It often isn't the case that we can just draw a line through the data and be able to divide it up into multiple groups. So what then is the solution to this? Well, what was proposed was the idea of a multilayer neural network, that so far all of the neural networks we've seen have had a set of inputs and a set of outputs, and the inputs are connected to those outputs. But in a multilayer neural network, this is going to be an artificial neural network that has an input layer still. It has an output layer, but also has one or more hidden layers in between. Other layers of artificial neurons or units that are going to calculate their own values as well. So instead of a neural network that looks like this with three inputs and one output, you might imagine in the middle here injecting a hidden layer, something like this. This is a hidden layer that has four nodes. You could choose how many nodes or units end up going into the hidden layer. You can have multiple hidden layers as well. And so now each of these inputs isn't directly connected to the output. Each of the inputs is connected to this hidden layer. And then all of the nodes in the hidden layer, those are connected to the one output. And so this is just another step that we can take towards calculating more complex functions. Each of these hidden units will calculate its output value, otherwise known as its activation, based on a linear combination of all the inputs. And once we have values for all of these nodes, as opposed to this just being the output, we do the same thing again. Calculate the output for this node based on multiplying each of the values for these units by their weights as well. So in effect, the way this works is that we start with inputs. They get multiplied by weights in order to calculate values for the hidden nodes. Those get multiplied by weights in order to figure out what the ultimate output is going to be. And the advantage of layering things like this is it gives us an ability to model more complex functions, that instead of just having a single decision boundary, a single line dividing the red points from the blue points, each of these hidden nodes can learn a different decision boundary. And we can combine those decision boundaries to figure out what the ultimate output is going to be. And as we begin to imagine more complex situations, you could imagine each of these nodes learning some useful property or learning some useful feature of all of the inputs and us somehow learning how to combine those features together in order to get the output that we actually want. Now, the natural question when we begin to look at this now is to ask the question of, how do we train a neural network that has hidden layers inside of it? And this turns out to initially be a bit of a tricky question, because the input data that we are given is we are given values for all of the inputs, and we're given what the value of the output should be, what the category is, for example. But the input data doesn't tell us what the values for all of these nodes should be. So we don't know how far off each of these nodes actually is because we're only given data for the inputs and the outputs. The reason this is called the hidden layer is because the data that is made available to us doesn't tell us what the values for all of these intermediate nodes should actually be. And so the strategy people came up with was to say that if you know what the error or the losses on the output node, well, then based on what these weights are, if one of these weights is higher than another, you can calculate an estimate for how much the error from this node was due to this part of the hidden node, or this part of the hidden layer, or this part of the hidden layer, based on the values of these weights, in effect saying that based on the error from the output, I can back propagate the error and figure out an estimate for what the error is for each of these nodes in the hidden layer as well. And there's some more calculus here that we won't get into the details of, but the idea of this algorithm is known as back propagation. It's an algorithm for training a neural network with multiple different hidden layers. And the idea for this, the pseudocode for it, will again be if we want to run gradient descent with back propagation. We'll start with a random choice of weights, as we did before. And now we'll go ahead and repeat the training process again and again. But what we're going to do each time is now we're going to calculate the error for the output layer first. We know the output and what it should be, and we know what we calculated so we can figure out what the error there is. But then we're going to repeat for every layer, starting with the output layer, moving back into the hidden layer, then the hidden layer before that if there are multiple hidden layers, going back all the way to the very first hidden layer, assuming there are multiple, we're going to propagate the error back one layer. Whatever the error was from the output, figure out what the error should be a layer before that based on what the values of those weights are. And then we can update those weights. So graphically, the way you might think about this is that we first start with the output. We know what the output should be. We know what output we calculated. And based on that, we can figure out, all right, how do we need to update those weights? Backpropagating the error to these nodes. And using that, we can figure out how we should update these weights. And you might imagine if there are multiple layers, we could repeat this process again and again to begin to figure out how all of these weights should be updated. And this backpropagation algorithm is really the key algorithm that makes neural networks possible. It makes it possible to take these multi-level structures and be able to train those structures depending on what the values of these weights are in order to figure out how it is that we should go about updating those weights in order to create some function that is able to minimize the total amount of loss, to figure out some good setting of the weights that will take the inputs and translate it into the output that we expect. And this works, as we said, not just for a single hidden layer. But you can imagine multiple hidden layers, where each hidden layer we just define however many nodes we want, where each of the nodes in one layer, we can connect to the nodes in the next layer, defining more and more complex networks that are able to model more and more complex types of functions. And so this type of network is what we might call a deep neural network, part of a larger family of deep learning algorithms, if you've ever heard that term. And all deep learning is about is it's using multiple layers to be able to predict and be able to model higher level features inside of the input, to be able to figure out what the output should be. And so a deep neural network is just a neural network that has multiple of these hidden layers, where we start at the input, calculate values for this layer, then this layer, then this layer, and then ultimately get an output. And this allows us to be able to model more and more sophisticated types of functions, that each of these layers can calculate something a little bit different, and we can combine that information to figure out what the output should be. Of course, as with any situation of machine learning, as we begin to make our models more and more complex, to model more and more complex functions, the risk we run is something like overfitting. And we talked about overfitting last time in the context of overfitting based on when we were training our models to be able to learn some sort of decision boundary, where overfitting happens when we fit too closely to the training data. And as a result, we don't generalize well to other situations as well. And one of the risks we run with a far more complex neural network that has many, many different nodes is that we might overfit based on the input data. We might grow over reliant on certain nodes to calculate things just purely based on the input data that doesn't allow us to generalize very well to the output. And there are a number of strategies for dealing with overfitting. But one of the most popular in the context of neural networks is a technique known as dropout. And what dropout does is it, when we're training the neural network, what we'll do in dropout is temporarily remove units, temporarily remove these artificial neurons from our network chosen at random. And the goal here is to prevent over-reliance on certain units. What generally happens in overfitting is that we begin to over-rely on certain units inside the neural network to be able to tell us how to interpret the input data. What dropout will do is randomly remove some of these units in order to reduce the chance that we over-rely on certain units to make our neural network more robust, to be able to handle the situations even when we just drop out particular neurons entirely. So the way that might work is we have a network like this. And as we're training it, when we go about trying to update the weights the first time, we'll just randomly pick some percentage of the nodes to drop out of the network. It's as if those nodes aren't there at all. It's as if the weights associated with those nodes aren't there at all. And we'll train it this way. Then the next time we update the weights, we'll pick a different set and just go ahead and train that way. And then again, randomly choose and train with other nodes that have been dropped out as well. And the goal of that is that after the training process, if you train by dropping out random nodes inside of this neural network, you hopefully end up with a network that's a little bit more robust, that doesn't rely too heavily on any one particular node, but more generally learns how to approximate a function in general. So that then is a look at some of these techniques that we can use in order to implement a neural network, to get at the idea of taking this input, passing it through these various different layers in order to produce some sort of output. And what we'd like to do now is take those ideas and put them into code. And to do that, there are a number of different machine learning libraries, neural network libraries that we can use that allow us to get access to someone's implementation of back propagation and all of these hidden layers. And one of the most popular, developed by Google, is known as TensorFlow, a library that we can use for quickly creating neural networks and modeling them and running them on some sample data to see what the output is going to be. And before we actually start writing code, we'll go ahead and take a look at TensorFlow's playground, which will be an opportunity for us just to play around with this idea of neural networks in different layers, just to get a sense for what it is that we can do by taking advantage of neural networks. So let's go ahead and go into TensorFlow's playground, which you can go to by visiting that URL from before. And what we're going to do now is we're going to try and learn the decision boundary for this particular output. I want to learn to separate the orange points from the blue points. And I'd like to learn some sort of setting of weights inside of a neural network that will be able to separate those from each other. The features we have access to, our input data, are the x value and the y value, so the two values along each of the two axes. And what I'll do now is I can set particular parameters, like what activation function I would like to use. And I'll just go ahead and press play and see what happens. And what happens here is that you'll see that just by using these two input features, the x value and the y value, with no hidden layers, just take the input, x and y values, and figure out what the decision boundary is. Our neural network learns pretty quickly that in order to divide these two points, we should just use this line. This line acts as a decision boundary that separates this group of points from that group of points, and it does it very well. You can see up here what the loss is. The training loss is 0, meaning we were able to perfectly model separating these two points from each other inside of our training data. So this was a fairly simple case of trying to apply a neural network because the data is very clean. It's very nicely linearly separable. We could just draw a line that separates all of those points from each other. Let's now consider a more complex case. So I'll go ahead and pause the simulation, and we'll go ahead and look at this data set here. This data set is a little bit more complex now. In this data set, we still have blue and orange points that we'd like to separate from each other. But there's no single line that we can draw that is going to be able to figure out how to separate the blue from the orange, because the blue is located in these two quadrants, and the orange is located here and here. It's a more complex function to be able to learn. So let's see what happens. If we just try and predict based on those inputs, the x and y coordinates, what the output should be, I'll press Play. And what you'll notice is that we're not really able to draw much of a conclusion, that we're not able to very cleanly see how we should divide the orange points from the blue points, and you don't see a very clean separation there. So it seems like we don't have enough sophistication inside of our network to be able to model something that is that complex. We need a better model for this neural network. And I'll do that by adding a hidden layer. So now I have a hidden layer that has two neurons inside of it. So I have two inputs that then go to two neurons inside of a hidden layer that then go to our output. And now I'll press Play. And what you'll notice here is that we're able to do slightly better. We're able to now say, all right, these points are definitely blue. These points are definitely orange. We're still struggling a little bit with these points up here, though. And what we can do is we can see for each of these hidden neurons, what is it exactly that these hidden neurons are doing? Each hidden neuron is learning its own decision boundary. And we can see what that boundary is. This first neuron is learning, all right, this line that seems to separate some of the blue points from the rest of the points. This other hidden neuron is learning another line that seems to be separating the orange points in the lower right from the rest of the points. So that's why we're able to figure out these two areas in the bottom region. But we're still not able to perfectly classify all of the points. So let's go ahead and add another neuron. Now we've got three neurons inside of our hidden layer and see what we're able to learn now. All right, well, now we seem to be doing a better job. By learning three different decision boundaries, which each of the three neurons inside of our hidden layer, we're able to much better figure out how to separate these blue points from the orange points. And we can see what each of these hidden neurons is learning. Each one is learning a slightly different decision boundary. And then we're combining those decision boundaries together to figure out what the overall output should be. And then we can try it one more time by adding a fourth neuron there and try learning that. And it seems like now we can do even better at trying to separate the blue points from the orange points. But we were only able to do this by adding a hidden layer, by adding some layer that is learning some other boundaries and combining those boundaries to determine the output. And the strength, the size and thickness of these lines indicate how high these weights are, how important each of these inputs is for making this sort of calculation. And we can do maybe one more simulation. Let's go ahead and try this on a data set that looks like this. Go ahead and get rid of the hidden layer. Here now we're trying to separate the blue points from the orange points where all the blue points are located, again, inside of a circle effectively. So we're not going to be able to learn a line. Notice I press Play. And we're really not able to draw any sort of classification at all because there is no line that cleanly separates the blue points from the orange points. So let's try to solve this by introducing a hidden layer. I'll go ahead and press Play. And all right, with two neurons in a hidden layer, we're able to do a little better because we effectively learned two different decision boundaries. We learned this line here. And we learned this line on the right-hand side. And right now we're just saying, all right, well, if it's in between, we'll call it blue. And if it's outside, we'll call it orange. So not great, but certainly better than before, that we're learning one decision boundary and another. And based on those, we can figure out what the output should be. But let's now go ahead and add a third neuron and see what happens now. I go ahead and train it. And now, using three different decision boundaries that are learned by each of these hidden neurons, we're able to much more accurately model this distinction between blue points and orange points. We're able to figure out maybe with these three decision boundaries, combining them together, you can imagine figuring out what the output should be and how to make that sort of classification. And so the goal here is just to get a sense for having more neurons in these hidden layers allows us to learn more structure in the data, allows us to figure out what the relevant and important decision boundaries are. And then using this backpropagation algorithm, we're able to figure out what the values of these weights should be in order to train this network to be able to classify one category of points away from another category of points instead. And this is ultimately what we're going to be trying to do whenever we're training a neural network. So let's go ahead and actually see an example of this. You'll recall from last time that we had this banknotes file that included information about counterfeit banknotes as opposed to authentic banknotes, where I had four different values for each banknote and then a categorization of whether that banknote is considered to be authentic or a counterfeit note. And what I wanted to do was, based on that input information, figure out some function that could calculate based on the input information what category it belonged to. And what I've written here in banknotes.py is a neural network that will learn just that, a network that learns based on all of the input whether or not we should categorize a banknote as authentic or as counterfeit. The first step is the same as what we saw from last time. I'm really just reading the data in and getting it into an appropriate format. And so this is where more of the writing Python code on your own comes in, in terms of manipulating this data, massaging the data into a format that will be understood by a machine learning library like scikit-learn or like TensorFlow. And so here I separate it into a training and a testing set. And now what I'm doing down below is I'm creating a neural network. Here I'm using TF, which stands for TensorFlow. Up above, I said import TensorFlow as TF, TF just an abbreviation that we'll often use so we don't need to write out TensorFlow every time we want to use anything inside of the library. I'm using TF.keras. Keras is an API, a set of functions that we can use in order to manipulate neural networks inside of TensorFlow. And it turns out there are other machine learning libraries that also use the Keras API. But here I'm saying, all right, go ahead and give me a model that is a sequential model, a sequential neural network, meaning one layer after another. And now I'm going to add to that model what layers I want inside of my neural network. So here I'm saying model.add. Go ahead and add a dense layer. And when we say a dense layer, we mean a layer that is just each of the nodes inside of the layer is going to be connected to each of the nodes from the previous layer. So we have a densely connected layer. This layer is going to have eight units inside of it. So it's going to be a hidden layer inside of a neural network with eight different units, eight artificial neurons, each of which might learn something different. And I just sort of chose eight arbitrarily. You could choose a different number of hidden nodes inside of the layer. And as we saw before, depending on the number of units there are inside of your hidden layer, more units means you can learn more complex functions. So maybe you can more accurately model the training data. But it comes at the cost. More units means more weights that you need to figure out how to update. So it might be more expensive to do that calculation. And you also run the risk of overfitting on the data. If you have too many units and you learn to just overfit on the training data, that's not good either. So there is a balance. And there's often a testing process where you'll train on some data and maybe validate how well you're doing on a separate set of data, often called a validation set, to see, all right, which setting of parameters. How many layers should I have? How many units should be in each layer? Which one of those performs the best on the validation set? So you can do some testing to figure out what these hyper parameters, so called, should be equal to. Next, I specify what the input shape is. Meaning, all right, what does my input look like? My input has four values. And so the input shape is just four, because we have four inputs. And then I specify what the activation function is. And the activation function, again, we can choose. There are a number of different activation functions. Here I'm using relu, which you might recall from earlier. And then I'll add an output layer. So I have my hidden layer. Now I'm adding one more layer that will just have one unit, because all I want to do is predict something like counterfeit build or authentic build. So I just need a single unit. And the activation function I'm going to use here is that sigmoid activation function, which, again, was that S-shaped curve that just gave us a probability of what is the probability that this is a counterfeit build, as opposed to an authentic build. So that, then, is the structure of my neural network, a sequential neural network that has one hidden layer with eight units inside of it, and then one output layer that just has a single unit inside of it. And I can choose how many units there are. I can choose the activation function. Then I'm going to compile this model. TensorFlow gives you a choice of how you would like to optimize the weights. There are various different algorithms for doing that. What type of loss function you want to use. Again, many different options for doing that. And then how I want to evaluate my model, well, I care about accuracy. I care about how many of my points am I able to classify correctly versus not correctly as counterfeit or not counterfeit. And I would like it to report to me how accurate my model is performing. Then, now that I've defined that model, I call model.fit to say go ahead and train the model. Train it on all the training data plus all of the training labels. So labels for each of those pieces of training data. And I'm saying run it for 20 epics, meaning go ahead and go through each of these training points 20 times, effectively. Go through the data 20 times and keep trying to update the weights. If I did it for more, I could train for even longer and maybe get a more accurate result. But then after I fit it on all the data, I'll go ahead and just test it. I'll evaluate my model using model.evaluate built into TensorFlow that is just going to tell me how well do I perform on the testing data. So ultimately, this is just going to give me some numbers that tell me how well we did in this particular case. So now what I'm going to do is go into banknotes and go ahead and run banknotes.py. And what's going to happen now is it's going to read in all of that training data. It's going to generate a neural network with all my inputs, my eight hidden units inside my layer, and then an output unit. And now what it's doing is it's training. It's training 20 times. And each time you can see how my accuracy is increasing on my training data. It starts off the very first time not very accurate, though better than random, something like 79% of the time. It's able to accurately classify one bill from another. But as I keep training, notice this accuracy value improves and improves and improves until after I've trained through all the data points 20 times, it looks like my accuracy is above 99% on the training data. And here's where I tested it on a whole bunch of testing data. And it looks like in this case, I was also like 99.8% accurate. So just using that, I was able to generate a neural network that can detect counterfeit bills from authentic bills based on this input data 99.8% of the time, at least based on this particular testing data. And I might want to test it with more data as well, just to be confident about that. But this is really the value of using a machine learning library like TensorFlow. And there are others available for Python and other languages as well. But all I have to do is define the structure of the network and define the data that I'm going to pass into the network. And then TensorFlow runs the backpropagation algorithm for learning what all of those weights should be, for figuring out how to train this neural network to be able to accurately, as accurately as possible, figure out what the output values should be there as well. And so this then was a look at what it is that neural networks can do just using these sequences of layer after layer after layer. And you can begin to imagine applying these to much more general problems. And one big problem in computing and artificial intelligence more generally is the problem of computer vision. Computer vision is all about computational methods for analyzing and understanding images. You might have pictures that you want the computer to figure out how to deal with, how to process those images and figure out how to produce some sort of useful result out of this. You've seen this in the context of social media websites that are able to look at a photo that contains a whole bunch of faces. And it's able to figure out what's a picture of whom and label those and tag them with appropriate people. This is becoming increasingly relevant as we begin to discuss self-driving cars, that these cars now have cameras. And we would like for the computer to have some sort of algorithm that looks at the image and figures out what color is the light, what cars are around us and in what direction, for example. And so computer vision is all about taking an image and figuring out what sort of computation, what sort of calculation we can do with that image. It's also relevant in the context of something like handwriting recognition. This, what you're looking at, is an example of the MNIST data set. It's a big data set just of handwritten digits that we could use to ideally try and figure out how to predict, given someone's handwriting, given a photo of a digit that they have drawn, can you predict whether it's a 0, 1, 2, 3, 4, 5, 6, 7, 8, or 9, for example. So this sort of handwriting recognition is yet another task that we might want to use computer vision tasks and tools to be able to apply it towards. This might be a task that we might care about. So how, then, can we use neural networks to be able to solve a problem like this? Well, neural networks rely upon some sort of input where that input is just numerical data. We have a whole bunch of units where each one of them just represents some sort of number. And so in the context of something like handwriting recognition or in the context of just an image, you might imagine that an image is really just a grid of pixels, grid of dots where each dot has some sort of color. And in the context of something like handwriting recognition, you might imagine that if you just fill in each of these dots in a particular way, you can generate a 2 or an 8, for example, based on which dots happen to be shaded in and which dots are not. And we can represent each of these pixel values just using numbers. So for a particular pixel, for example, 0 might represent entirely black. Depending on how you're representing color, it's often common to represent color values on a 0 to 255 range so that you can represent a color using 8 bits for a particular value, like how much white is in the image. So 0 might represent all black. 255 might represent entirely white as a pixel. And somewhere in between might represent some shade of gray, for example. But you might imagine not just having a single slider that determines how much white is in the image, but if you had a color image, you might imagine three different numerical values, a red, green, and blue value, where the red value controls how much red is in the image. We have one value for controlling how much green is in the pixel and one value for how much blue is in the pixel as well. And depending on how it is that you set these values of red, green, and blue, you can get a different color. And so any pixel can really be represented, in this case, by three numerical values, a red value, a green value, and a blue value. And if you take a whole bunch of these pixels, assemble them together inside of a grid of pixels, then you really just have a whole bunch of numerical values that you can use in order to perform some sort of prediction task. And so what you might imagine doing is using the same techniques we talked about before, just design a neural network with a lot of inputs, that for each of the pixels, we might have one or three different inputs in the case of a color image, a different input that is just connected to a deep neural network, for example. And this deep neural network might take all of the pixels inside of the image of what digit a person drew. And the output might be like 10 neurons that classify it as a 0, or a 1, or a 2, or a 3, or just tells us in some way what that digit happens to be. Now, there are a couple of drawbacks to this approach. The first drawback to the approach is just the size of this input array, that we have a whole bunch of inputs. If we have a big image that has a lot of different channels, we're looking at a lot of inputs, and therefore a lot of weights that we have to calculate. And a second problem is the fact that by flattening everything into just this structure of all the pixels, we've lost access to a lot of the information about the structure of the image that's relevant, that really, when a person looks at an image, they're looking at particular features of the image. They're looking at curves. They're looking at shapes. They're looking at what things can you identify in different regions of the image, and maybe put those things together in order to get a better picture of what the overall image is about. And by just turning it into pixel values for each of the pixels, sure, you might be able to learn that structure, but it might be challenging in order to do so. It might be helpful to take advantage of the fact that you can use properties of the image itself, the fact that it's structured in a particular way, to be able to improve the way that we learn based on that image too. So in order to figure out how we can train our neural networks to better be able to deal with images, we'll introduce a couple of ideas, a couple of algorithms that we can apply that allow us to take the image and extract some useful information out of that image. And the first idea we'll introduce is the notion of image convolution. And what image convolution is all about is it's about filtering an image, sort of extracting useful or relevant features out of the image. And the way we do that is by applying a particular filter that basically adds the value for every pixel with the values for all of the neighboring pixels to it, according to some sort of kernel matrix, which we'll see in a moment, is going to allow us to weight these pixels in various different ways. And the goal of image convolution, then, is to extract some sort of interesting or useful features out of an image, to be able to take a pixel and, based on its neighboring pixels, maybe predict some sort of valuable information. Something like taking a pixel and looking at its neighboring pixels, you might be able to predict whether or not there's some sort of curve inside the image, or whether it's forming the outline of a particular line or a shape, for example. And that might be useful if you're trying to use all of these various different features to combine them to say something meaningful about an image as a whole. So how, then, does image convolution work? Well, we start with a kernel matrix. And the kernel matrix looks something like this. And the idea of this is that, given a pixel that will be the middle pixel, we're going to multiply each of the neighboring pixels by these values in order to get some sort of result by summing up all the numbers together. So if I take this kernel, which you can think of as a filter that I'm going to apply to the image, and let's say that I take this image. This is a 4 by 4 image. We'll think of it as just a black and white image, where each one is just a single pixel value. So somewhere between 0 and 255, for example. So we have a whole bunch of individual pixel values like this. And what I'd like to do is apply this kernel, this filter, so to speak, to this image. And the way I'll do that is, all right, the kernel is 3 by 3. You can imagine a 5 by 5 kernel or a larger kernel, too. And I'll take it and just first apply it to the first 3 by 3 section of the image. And what I'll do is I'll take each of these pixel values, multiply it by its corresponding value in the filter matrix, and add all of the results together. So here, for example, I'll say 10 times 0, plus 20 times negative 1, plus 30 times 0, so on and so forth, doing all of this calculation. And at the end, if I take all these values, multiply them by their corresponding value in the kernel, add the results together, for this particular set of 9 pixels, I get the value of 10, for example. And then what I'll do is I'll slide this 3 by 3 grid, effectively, over. I'll slide the kernel by 1 to look at the next 3 by 3 section. Here, I'm just sliding it over by 1 pixel. But you might imagine a different stride length, or maybe I jump by multiple pixels at a time if you really wanted to. You have different options here. But here, I'm just sliding over, looking at the next 3 by 3 section. And I'll do the same math, 20 times 0, plus 30 times negative 1, plus 40 times 0, plus 20 times negative 1, so on and so forth, plus 30 times 5. And what I end up getting is the number 20. Then you can imagine shifting over to this one, doing the same thing, calculating the number 40, for example, and then doing the same thing here, and calculating a value there as well. And so what we have now is what we'll call a feature map. We have taken this kernel, applied it to each of these various different regions, and what we get is some representation of a filtered version of that image. And so to give a more concrete example of why it is that this kind of thing could be useful, let's take this kernel matrix, for example, which is quite a famous one, that has an 8 in the middle, and then all of the neighboring pixels get a negative 1. And let's imagine we wanted to apply that to a 3 by 3 part of an image that looks like this, where all the values are the same. They're all 20, for instance. Well, in this case, if you do 20 times 8, and then subtract 20, subtract 20, subtract 20 for each of the eight neighbors, well, the result of that is you just get that expression, which comes out to be 0. You multiplied 20 by 8, but then you subtracted 20 eight times, according to that particular kernel. The result of all that is just 0. So the takeaway here is that when a lot of the pixels are the same value, we end up getting a value close to 0. If, though, we had something like this, 20 is along this first row, then 50 is in the second row, and 50 is in the third row, well, then when you do this, because it's the same kind of math, 20 times negative 1, 20 times negative 1, so on and so forth, then I get a higher value, a value like 90 in this particular case. And so the more general idea here is that by applying this kernel, negative 1s, 8 in the middle, and then negative 1s, what I get is when this middle value is very different from the neighboring values, like 50 is greater than these 20s, then you'll end up with a value higher than 0. If this number is higher than its neighbors, you end up getting a bigger output. But if this value is the same as all of its neighbors, then you get a lower output, something like 0. And it turns out that this sort of filter can therefore be used in something like detecting edges in an image. Or I want to detect the boundaries between various different objects inside of an image. I might use a filter like this, which is able to tell whether the value of this pixel is different from the values of the neighboring pixel, if it's greater than the values of the pixels that happen to surround it. And so we can use this in terms of image filtering. And so I'll show you an example of that. I have here in filter.py a file that uses Python's image library, or PIL, to do some image filtering. I go ahead and open an image. And then all I'm going to do is apply a kernel to that image. It's going to be a 3 by 3 kernel, same kind of kernel we saw before. And here is the kernel. This is just a list representation of the same matrix that I showed you a moment ago. It's negative 1, negative 1, negative 1. The second row is negative 1, 8, negative 1. And the third row is all negative 1s. And then at the end, I'm going to go ahead and show the filtered image. So if, for example, I go into convolution directory and I open up an image, like bridge.png, this is what an input image might look like, just an image of a bridge over a river. Now I'm going to go ahead and run this filter program on the bridge. And what I get is this image here. Just by taking the original image and applying that filter to each 3 by 3 grid, I've extracted all of the boundaries, all of the edges inside the image that separate one part of the image from another. So here I've got a representation of boundaries between particular parts of the image. And you might imagine that if a machine learning algorithm is trying to learn what an image is of, a filter like this could be pretty useful. Maybe the machine learning algorithm doesn't care about all of the details of the image. It just cares about certain useful features. It cares about particular shapes that are able to help it determine that based on the image, this is going to be a bridge, for example. And so this type of idea of image convolution can allow us to apply filters to images that allow us to extract useful results out of those images, taking an image and extracting its edges, for example. And you might imagine many other filters that could be applied to an image that are able to extract particular values as well. And a filter might have separate kernels for the red values, the green values, and the blue values that are all summed together at the end, such that you could have particular filters looking for, is there red in this part of the image? Are there green in other parts of the image? You can begin to assemble these relevant and useful filters that are able to do these calculations as well. So that then was the idea of image convolution, applying some sort of filter to an image to be able to extract some useful features out of that image. But all the while, these images are still pretty big. There's a lot of pixels involved in the image. And realistically speaking, if you've got a really big image, that poses a couple of problems. One, it means a lot of input going into the neural network. But two, it also means that we really have to care about what's in each particular pixel. Whereas realistically, we often, if you're looking at an image, you don't care whether something is in one particular pixel versus the pixel immediately to the right of it. They're pretty close together. You really just care about whether there's a particular feature in some region of the image. And maybe you don't care about exactly which pixel it happens to be in. And so there's a technique we can use known as pooling. And what pooling is, is it means reducing the size of an input by sampling from regions inside of the input. So we're going to take a big image and turn it into a smaller image by using pooling. And in particular, one of the most popular types of pooling is called max pooling. And what max pooling does is it pools just by choosing the maximum value in a particular region. So for example, let's imagine I had this 4 by 4 image. But I wanted to reduce its dimensions. I wanted to make it a smaller image so that I have fewer inputs to work with. Well, what I could do is I could apply a 2 by 2 max pool, where the idea would be that I'm going to first look at this 2 by 2 region and say, what is the maximum value in that region? Well, it's the number 50. So we'll go ahead and just use the number 50. And then we'll look at this 2 by 2 region. What is the maximum value here? It's 110, so that's going to be my value. Likewise here, the maximum value looks like 20. Go ahead and put that there. Then for this last region, the maximum value was 40. So we'll go ahead and use that. And what I have now is a smaller representation of this same original image that I obtained just by picking the maximum value from each of these regions. So again, the advantages here are now I only have to deal with a 2 by 2 input instead of a 4 by 4. And you can imagine shrinking the size of an image even more. But in addition to that, I'm now able to make my analysis independent of whether a particular value was in this pixel or this pixel. I don't care if the 50 was here or here. As long as it was generally in this region, I'll still get access to that value. So it makes our algorithms a little bit more robust as well. So that then is pooling, taking the size of the image, reducing it a little bit by just sampling from particular regions inside of the image. And now we can put all of these ideas together, pooling, image convolution, and neural networks all together into another type of neural network called a convolutional neural network, or a CNN, which is a neural network that uses this convolution step usually in the context of analyzing an image, for example. And so the way that a convolutional neural network works is that we start with some sort of input image, some grid of pixels. But rather than immediately put that into the neural network layers that we've seen before, we'll start by applying a convolution step, where the convolution step involves applying some number of different image filters to our original image in order to get what we call a feature map, the result of applying some filter to an image. And we could do this once, but in general, we'll do this multiple times, getting a whole bunch of different feature maps, each of which might extract some different relevant feature out of the image, some different important characteristic of the image that we might care about using in order to calculate what the result should be. And in the same way that when we train neural networks, we can train neural networks to learn the weights between particular units inside of the neural networks, we can also train neural networks to learn what those filters should be, what the values of the filters should be in order to get the most useful, most relevant information out of the original image just by figuring out what setting of those filter values, the values inside of that kernel, results in minimizing the loss function, minimizing how poorly our hypothesis actually performs in figuring out the classification of a particular image, for example. So we first apply this convolution step, get a whole bunch of these various different feature maps. But these feature maps are quite large. There's a lot of pixel values that happen to be here. And so a logical next step to take is a pooling step, where we reduce the size of these images by using max pooling, for example, extracting the maximum value from any particular region. There are other pooling methods that exist as well, depending on the situation. You could use something like average pooling, where instead of taking the maximum value from a region, you take the average value from a region, which has its uses as well. But in effect, what pooling will do is it will take these feature maps and reduce their dimensions so that we end up with smaller grids with fewer pixels. And this then is going to be easier for us to deal with. It's going to mean fewer inputs that we have to worry about. And it's also going to mean we're more resilient, more robust against potential movements of particular values, just by one pixel, when ultimately we really don't care about those one-pixel differences that might arise in the original image. And now, after we've done this pooling step, now we have a whole bunch of values that we can then flatten out and just put into a more traditional neural network. So we go ahead and flatten it, and then we end up with a traditional neural network that has one input for each of these values in each of these resulting feature maps after we do the convolution and after we do the pooling step. And so this then is the general structure of a convolutional network. We begin with the image, apply convolution, apply pooling, flatten the results, and then put that into a more traditional neural network that might itself have hidden layers. You can have deep convolutional networks that have hidden layers in between this flattened layer and the eventual output to be able to calculate various different features of those values. But this then can help us to be able to use convolution and pooling to use our knowledge about the structure of an image to be able to get better results, to be able to train our networks faster in order to better capture particular parts of the image. And there's no reason necessarily why you can only use these steps once. In fact, in practice, you'll often use convolution and pooling multiple times in multiple different steps. See, what you might imagine doing is starting with an image, first applying convolution to get a whole bunch of maps, then applying pooling, then applying convolution again, because these maps are still pretty big. You can apply convolution to try and extract relevant features out of this result. Then take those results, apply pooling in order to reduce their dimensions, and then take that and feed it into a neural network that maybe has fewer inputs. So here I have two different convolution and pooling steps. I do convolution and pooling once, and then I do convolution and pooling a second time, each time extracting useful features from the layer before it, each time using pooling to reduce the dimensions of what you're ultimately looking at. And the goal now of this sort of model is that in each of these steps, you can begin to learn different types of features of the original image. That maybe in the first step, you learn very low level features. Just learn and look for features like edges and curves and shapes, because based on pixels and their neighboring values, you can figure out, all right, what are the edges? What are the curves? What are the various different shapes that might be present there? But then once you have a mapping that just represents where the edges and curves and shapes happen to be, you can imagine applying the same sort of process again to begin to look for higher level features, look for objects, maybe look for people's eyes and facial recognition, for example. Maybe look for more complex shapes like the curves on a particular number if you're trying to recognize a digit in a handwriting recognition sort of scenario. And then after all of that, now that you have these results that represent these higher level features, you can pass them into a neural network, which is really just a deep neural network that looks like this, where you might imagine making a binary classification or classifying into multiple categories or performing various different tasks on this sort of model. So convolutional neural networks can be quite powerful and quite popular when it comes towards trying to analyze images. We don't strictly need them. We could have just used a vanilla neural network that just operates with layer after layer, as we've seen before. But these convolutional neural networks can be quite helpful, in particular, because of the way they model the way a human might look at an image, that instead of a human looking at every single pixel simultaneously and trying to convolve all of them by multiplying them together, you might imagine that what convolution is really doing is looking at various different regions of the image and extracting relevant information and features out of those parts of the image, the same way that a human might have visual receptors that are looking at particular parts of what they see and using those combining them to figure out what meaning they can draw from all of those various different inputs. And so you might imagine applying this to a situation like handwriting recognition. So we'll go ahead and see an example of that now, where I'll go ahead and open up handwriting.py. Again, what we do here is we first import TensorFlow. And then TensorFlow, it turns out, has a few data sets that are built into the library that you can just immediately access. And one of the most famous data sets in machine learning is the MNIST data set, which is just a data set of a whole bunch of samples of people's handwritten digits. I showed you a slide of that a little while ago. And what we can do is just immediately access that data set which is built into the library so that if I want to do something like train on a whole bunch of handwritten digits, I can just use the data set that is provided to me. Of course, if I had my own data set of handwritten images, I can apply the same idea. I'd first just need to take those images and turn them into an array of pixels, because that's the way that these are going to be formatted. They're going to be formatted as, effectively, an array of individual pixels. Now there's a bit of reshaping I need to do, just turning the data into a format that I can put into my convolutional neural network. So this is doing things like taking all the values and dividing them by 255. If you remember, these color values tend to range from 0 to 255. So I can divide them by 255 just to put them into 0 to 1 range, which might be a little bit easier to train on. And then doing various other modifications to the data just to get it into a nice usable format. But here's the interesting and important part. Here is where I create the convolutional neural network, the CNN, where here I'm saying, go ahead and use a sequential model. And before I could use model.add to say add a layer, add a layer, add a layer, another way I could define it is just by passing as input to this sequential neural network a list of all of the layers that I want. And so here, the very first layer in my model is a convolution layer, where I'm first going to apply convolution to my image. I'm going to use 13 different filters. So my model is going to learn 32, rather, 32 different filters that I would like to learn on the input image, where each filter is going to be a 3 by 3 kernel. So we saw those 3 by 3 kernels before, where we could multiply each value in a 3 by 3 grid by a value, multiply it, and add all the results together. So here, I'm going to learn 32 different of these 3 by 3 filters. I can, again, specify my activation function. And I specify what my input shape is. My input shape in the banknotes case was just 4. I had 4 inputs. My input shape here is going to be 28, 28, 1, because for each of these handwritten digits, it turns out that the MNIST data set organizes their data. Each image is a 28 by 28 pixel grid. So we're going to have a 28 by 28 pixel grid. And each one of those images only has one channel value. These handwritten digits are just black and white. So there's just a single color value representing how much black or how much white. You might imagine that in a color image, if you were doing this sort of thing, you might have three different channels, a red, a green, and a blue channel, for example. But in the case of just handwriting recognition, recognizing a digit, we're just going to use a single value for, like, shaded in or not shaded in. And it might range, but it's just a single color value. And that, then, is the very first layer of our neural network, a convolutional layer that will take the input and learn a whole bunch of different filters that we can apply to the input to extract meaningful features. Next step is going to be a max pooling layer, also built right into TensorFlow, where this is going to be a layer that is going to use a pool size of 2 by 2, meaning we're going to look at 2 by 2 regions inside of the image and just extract the maximum value. Again, we've seen why this can be helpful. It'll help to reduce the size of our input. And once we've done that, we'll go ahead and flatten all of the units just into a single layer that we can then pass into the rest of the neural network. And now, here's the rest of the neural network. Here, I'm saying, let's add a hidden layer to my neural network with 128 units, so a whole bunch of hidden units inside of the hidden layer. And just to prevent overfitting, I can add a dropout to that. Say, you know what, when you're training, randomly dropout half of the nodes from this hidden layer just to make sure we don't become over-reliant on any particular node, we begin to really generalize and stop ourselves from overfitting. So TensorFlow allows us, just by adding a single line, to add dropout into our model as well, such that when it's training, it will perform this dropout step in order to help make sure that we don't overfit on this particular data. And then finally, I add an output layer. The output layer is going to have 10 units, one for each category that I would like to classify digits into, so 0 through 9, 10 different categories. And the activation function I'm going to use here is called the softmax activation function. And in short, what the softmax activation function is going to do is it's going to take the output and turn it into a probability distribution. So ultimately, it's going to tell me, what did we estimate the probability is that this is a 2 versus a 3 versus a 4. And so it will turn it into that probability distribution for me. Next up, I'll go ahead and compile my model and fit it on all of my training data. And then I can evaluate how well the neural network performs. And then I've added to my Python program, if I've provided a command line argument like the name of a file, I'm going to go ahead and save the model to a file. And so this can be quite useful too. Once you've done the training step, which could take some time in terms of taking all the time, going through the data, running back propagation with gradient descent to be able to say, all right, how should we adjust the weight to this particular model? You end up calculating values for these weights, calculating values for these filters. You'd like to remember that information so you can use it later. And so TensorFlow allows us to just save a model to a file, such that later, if we want to use the model we've learned, use the weights that we've learned to make some sort of new prediction, we can just use the model that already exists. So what we're doing here is after we've done all the calculation, we go ahead and save the model to a file, such that we can use it a little bit later. So for example, if I go into digits, I'm going to run handwriting.py. I won't save it this time. We'll just run it and go ahead and see what happens. What will happen is we need to go through the model in order to train on all of these samples of handwritten digits. The MNIST data set gives us thousands and thousands of sample handwritten digits in the same format that we can use in order to train. And so now what you're seeing is this training process. And unlike the banknotes case, where there was much fewer data points, the data was very, very simple, here this data is more complex and this training process takes time. And so this is another one of those cases where when training neural networks, this is why computational power is so important that oftentimes you see people wanting to use sophisticated GPUs in order to more efficiently be able to do this sort of neural network training. It also speaks to the reason why more data can be helpful. The more sample data points you have, the better you can begin to do this training. So here we're going through 60,000 different samples of handwritten digits. And I said we're going to go through them 10 times. We're going to go through the data set 10 times, training each time, hopefully improving upon our weights with every time we run through this data set. And we can see over here on the right what the accuracy is each time we go ahead and run this model, that the first time it looks like we got an accuracy of about 92% of the digits correct based on this training set. We increased that to 96% or 97%. And every time we run this, we're going to see hopefully the accuracy improve as we continue to try and use that gradient descent, that process of trying to run the algorithm, to minimize the loss that we get in order to more accurately predict what the output should be. And what this process is doing is it's learning not only the weights, but it's learning the features to use, the kernel matrix to use when performing that convolution step. Because this is a convolutional neural network, where I'm first performing those convolutions and then doing the more traditional neural network structure, this is going to learn all of those individual steps as well. And so here we see the TensorFlow provides me with some very nice output, telling me about how many seconds are left with each of these training runs that allows me to see just how well we're doing. So we'll go ahead and see how this network performs. It looks like we've gone through the data set seven times. We're going through it an eighth time now. And at this point, the accuracy is pretty high. We saw we went from 92% up to 97%. Now it looks like 98%. And at this point, it seems like things are starting to level out. It's probably a limit to how accurate we can ultimately be without running the risk of overfitting. Of course, with enough nodes, you would just memorize the input and overfit upon them. But we'd like to avoid doing that. And Dropout will help us with this. But now we see we're almost done finishing our training step. We're at 55,000. All right, we finished training. And now it's going to go ahead and test for us on 10,000 samples. And it looks like on the testing set, we were at 98.8% accurate. So we ended up doing pretty well, it seems, on this testing set to see how accurately can we predict these handwritten digits. And so what we could do then is actually test it out. I've written a program called Recognition.py using PyGame. If you pass it a model that's been trained, and I pre-trained an example model using this input data, what we can do is see whether or not we've been able to train this convolutional neural network to be able to predict handwriting, for example. So I can try, just like drawing a handwritten digit. I'll go ahead and draw the number 2, for example. So there's my number 2. Again, this is messy. If you tried to imagine, how would you write a program with just ifs and thens to be able to do this sort of calculation, it would be tricky to do so. But here I'll press Classify, and all right, it seems I was able to correctly classify that what I drew was the number 2. I'll go ahead and reset it, try it again. We'll draw an 8, for example. So here is an 8. Press Classify. And all right, it predicts that the digit that I drew was an 8. And the key here is this really begins to show the power of what the neural network is doing, somehow looking at various different features of these different pixels, figuring out what the relevant features are, and figuring out how to combine them to get a classification. And this would be a difficult task to provide explicit instructions to the computer on how to do, to use a whole bunch of ifs ands to process all these pixel values to figure out what the handwritten digit is. Everyone's going to draw their 8s a little bit differently. If I drew the 8 again, it would look a little bit different. And yet, ideally, we want to train a network to be robust enough so that it begins to learn these patterns on its own. All I said was, here is the structure of the network, and here is the data on which to train the network. And the network learning algorithm just tries to figure out what is the optimal set of weights, what is the optimal set of filters to use them in order to be able to accurately classify a digit into one category or another. Just going to show the power of these sorts of convolutional neural networks. And so that then was a look at how we can use convolutional neural networks to begin to solve problems with regards to computer vision, the ability to take an image and begin to analyze it. So this is the type of analysis you might imagine that's happening in self-driving cars that are able to figure out what filters to apply to an image to understand what it is that the computer is looking at, or the same type of idea that might be applied to facial recognition and social media to be able to determine how to recognize faces in an image as well. You can imagine a neural network that instead of classifying into one of 10 different digits could instead classify like, is this person A or is this person B, trying to tell those people apart just based on convolution. And so now what we'll take a look at is yet another type of neural network that can be quite popular for certain types of tasks. But to do so, we'll try to generalize and think about our neural network a little bit more abstractly. That here we have a sample deep neural network where we have this input layer, a whole bunch of different hidden layers that are performing certain types of calculations, and then an output layer here that just generates some sort of output that we care about calculating. But we could imagine representing this a little more simply like this. Here is just a more abstract representation of our neural network. We have some input that might be like a vector of a whole bunch of different values as our input. That gets passed into a network that performs some sort of calculation or computation, and that network produces some sort of output. That output might be a single value. It might be a whole bunch of different values. But this is the general structure of the neural network that we've seen. There is some sort of input that gets fed into the network. And using that input, the network calculates what the output should be. And this sort of model for a neural network is what we might call a feed-forward neural network. Feed-forward neural networks have connections only in one direction. They move from one layer to the next layer to the layer after that, such that the inputs pass through various different hidden layers and then ultimately produce some sort of output. So feed-forward neural networks were very helpful for solving these types of classification problems that we saw before. We have a whole bunch of input. We want to learn what setting of weights will allow us to calculate the output effectively. But there are some limitations on feed-forward neural networks that we'll see in a moment. In particular, the input needs to be of a fixed shape, like a fixed number of neurons are in the input layer. And there's a fixed shape for the output, like a fixed number of neurons in the output layer. And that has some limitations of its own. And a possible solution to this, and we'll see examples of the types of problems we can solve for this in just a second, is instead of just a feed-forward neural network, where there are only connections in one direction from left to right effectively across the network, we could also imagine a recurrent neural network, where a recurrent neural network generates output that gets fed back into itself as input for future runs of that network. So whereas in a traditional neural network, we have inputs that get fed into the network, that get fed into the output. And the only thing that determines the output is based on the original input and based on the calculation we do inside of the network itself. This goes in contrast with a recurrent neural network, where in a recurrent neural network, you can imagine output from the network feeding back to itself into the network again as input for the next time you do the calculations inside of the network. What this allows is it allows the network to maintain some sort of state, to store some sort of information that can be used on future runs of the network. Previously, the network just defined some weights, and we passed inputs through the network, and it generated outputs. But the network wasn't saving any information based on those inputs to be able to remember for future iterations or for future runs. What a recurrent neural network will let us do is let the network store information that gets passed back in as input to the network again the next time we try and perform some sort of action. And this is particularly helpful when dealing with sequences of data. So we'll see a real world example of this right now, actually. Microsoft has developed an AI known as the caption bot. And what the caption bot does is it says, I can understand the content of any photograph, and I'll try to describe it as well as any human. I'll analyze your photo, but I won't store it or share it. And so what Microsoft's caption bot seems to be claiming to do is it can take an image and figure out what's in the image and just give us a caption to describe it. So let's try it out. Here, for example, is an image of Harvard Square. It's some people walking in front of one of the buildings at Harvard Square. I'll go ahead and take the URL for that image, and I'll paste it into caption bot and just press Go. So caption bot is analyzing the image, and then it says, I think it's a group of people walking in front of a building, which seems amazing. The AI is able to look at this image and figure out what's in the image. And the important thing to recognize here is that this is no longer just a classification task. We saw being able to classify images with a convolutional neural network where the job was take the image and then figure out, is it a 0 or a 1 or a 2, or is it this person's face or that person's face? What seems to be happening here is the input is an image, and we know how to get networks to take input of images, but the output is text. It's a sentence. It's a phrase, like a group of people walking in front of a building. And this would seem to pose a challenge for our more traditional feed-forward neural networks, for the reason being that in traditional neural networks, we just have a fixed-size input and a fixed-size output. There are a certain number of neurons in the input to our neural network and a certain number of outputs for our neural network, and then some calculation that goes on in between. But the size of the inputs and the number of values in the input and the number of values in the output, those are always going to be fixed based on the structure of the neural network. And that makes it difficult to imagine how a neural network could take an image like this and say it's a group of people walking in front of the building because the output is text, like it's a sequence of words. Now, it might be possible for a neural network to output one word, one word you could represent as a vector of values, and you can imagine ways of doing that. Next time, we'll talk a little bit more about AI as it relates to language and language processing. But a sequence of words is much more challenging because depending on the image, you might imagine the output is a different number of words. We could have sequences of different lengths, and somehow we still want to be able to generate the appropriate output. And so the strategy here is to use a recurrent neural network, a neural network that can feed its own output back into itself as input for the next time. And this allows us to do what we call a one-to-many relationship for inputs to outputs, that in vanilla, more traditional neural networks, these are what we might consider to be one-to-one neural networks. You pass in one set of values as input. You get one vector of values as the output. But in this case, we want to pass in one value as input, the image, and we want to get a sequence, many values as output, where each value is like one of these words that gets produced by this particular algorithm. And so the way we might do this is we might imagine starting by providing input, the image, into our neural network. And the neural network is going to generate output, but the output is not going to be the whole sequence of words, because we can't represent the whole sequence of words using just a fixed set of neurons. Instead, the output is just going to be the first word. We're going to train the network to output what the first word of the caption should be. And you could imagine that Microsoft has trained this by running a whole bunch of training samples through the AI, giving it a whole bunch of pictures and what the appropriate caption was, and having the AI begin to learn from that. But now, because the network generates output that can be fed back into itself, you could imagine the output of the network being fed back into the same network. This here looks like a separate network, but it's really the same network that's just getting different input, that this network's output gets fed back into itself, but it's going to generate another output. And that other output is going to be the second word in the caption. And this recurrent neural network then, this network is going to generate other output that can be fed back into itself to generate yet another word, fed back into itself to generate another word. And so recurrent neural networks allow us to represent this one-to-many structure. You provide one image as input, and the neural network can pass data into the next run of the network, and then again and again, such that you could run the network multiple times, each time generating a different output still based on that original input. And this is where recurrent neural networks become particularly useful when dealing with sequences of inputs or outputs. And my output is a sequence of words, and since I can't very easily represent outputting an entire sequence of words, I'll instead output that sequence one word at a time by allowing my network to pass information about what still needs to be said about the photo into the next stage of running the network. So you could run the network multiple times, the same network with the same weights, just getting different input each time. First, getting input from the image, and then getting input from the network itself as additional information about what additionally needs to be given in a particular caption, for example. So this then is a one-to-many relationship inside of a recurrent neural network, but it turns out there are other models that we can use, other ways we can try and use recurrent neural networks to be able to represent data that might be stored in other forms as well. We saw how we could use neural networks in order to analyze images in the context of convolutional neural networks that take an image, figure out various different properties of the image, and are able to draw some sort of conclusion based on that. But you might imagine that something like YouTube, they need to be able to do a lot of learning based on video. They need to look through videos to detect if they're like copyright violations, or they need to be able to look through videos to maybe identify what particular items are inside of the video, for example. And video, you might imagine, is much more difficult to put in as input to a neural network, because whereas an image, you could just treat each pixel as a different value, videos are sequences. They're sequences of images, and each sequence might be of different length. And so it might be challenging to represent that entire video as a single vector of values that you could pass in to a neural network. And so here, too, recurrent neural networks can be a valuable solution for trying to solve this type of problem. Then instead of just passing in a single input into our neural network, we could pass in the input one frame at a time, you might imagine. First, taking the first frame of the video, passing it into the network, and then maybe not having the network output anything at all yet. Let it take in another input, and this time, pass it into the network. But the network gets information from the last time we provided an input into the network. Then we pass in a third input, and then a fourth input, where each time, what the network gets is it gets the most recent input, like each frame of the video. But it also gets information the network processed from all of the previous iterations. So on frame number four, you end up getting the input for frame number four plus information the network has calculated from the first three frames. And using all of that data combined, this recurrent neural network can begin to learn how to extract patterns from a sequence of data as well. And so you might imagine, if you want to classify a video into a number of different genres, like an educational video, or a music video, or different types of videos, that's a classification task, where you want to take as input each of the frames of the video, and you want to output something like what it is, what category that it happens to belong to. And you can imagine doing this sort of thing, this sort of many-to-one learning, any time your input is a sequence. And so input is a sequence in the context of video. It could be in the context of, like, if someone has typed a message and you want to be able to categorize that message, like if you're trying to take a movie review and trying to classify it as, is it a positive review or a negative review? That input is a sequence of words, and the output is a classification, positive or negative. There, too, a recurrent neural network might be helpful for analyzing sequences of words. And they're quite popular when it comes to dealing with language. Could even be used for spoken language as well, that spoken language is an audio waveform that can be segmented into distinct chunks. And each of those could be passed in as an input into a recurrent neural network to be able to classify someone's voice, for instance. If you want to do voice recognition to say, is this one person or is this another, here are also cases where you might want this many-to-one architecture for a recurrent neural network. And then as one final problem, just to take a look at in terms of what we can do with these sorts of networks, imagine what Google Translate is doing. So what Google Translate is doing is it's taking some text written in one language and converting it into text written in some other language, for example, where now this input is a sequence of data. It's a sequence of words. And the output is a sequence of words as well. It's also a sequence. So here we want effectively a many-to-many relationship. Our input is a sequence and our output is a sequence as well. And it's not quite going to work to just say, take each word in the input and translate it into a word in the output. Because ultimately, different languages put their words in different orders. And maybe one language uses two words for something, whereas another language only uses one. So we really want some way to take this information, this input, encode it somehow, and use that encoding to generate what the output ultimately should be. And this has been one of the big advancements in automated translation technology, is the ability to use the neural networks to do this instead of older, more traditional methods. And this has improved accuracy dramatically. And the way you might imagine doing this is, again, using a recurrent neural network with multiple inputs and multiple outputs. We start by passing in all the input. Input goes into the network. Another input, like another word, goes into the network. And we do this multiple times, like once for each word in the input that I'm trying to translate. And only after all of that is done does the network now start to generate output, like the first word of the translated sentence, and the next word of the translated sentence, so on and so forth, where each time the network passes information to itself by allowing for this model of giving some sort of state from one run in the network to the next run, assembling information about all the inputs, and then passing in information about which part of the output in order to generate next. And there are a number of different types of these sorts of recurrent neural networks. One of the most popular is known as the long short-term memory neural network, otherwise known as LSTM. But in general, these types of networks can be very, very powerful whenever we're dealing with sequences, whether those are sequences of images or especially sequences of words when it comes towards dealing with natural language. And so that then were just some of the different types of neural networks that can be used to do all sorts of different computations. And these are incredibly versatile tools that can be applied to a number of different domains. We only looked at a couple of the most popular types of neural networks from more traditional feed-forward neural networks, convolutional neural networks, and recurrent neural networks. But there are other types as well. There are adversarial networks where networks compete with each other to try and be able to generate new types of data, as well as other networks that can solve other tasks based on what they happen to be structured and adapted for. And these are very powerful tools in machine learning from being able to very easily learn based on some set of input data and to be able to, therefore, figure out how to calculate some function from inputs to outputs, whether it's input to some sort of classification like analyzing an image and getting a digit or machine translation where the input is in one language and the output is in another. These tools have a lot of applications for machine learning more generally. Next time, we'll look at machine learning and AI in particular in the context of natural language. We talked a little bit about this today, but looking at how it is that our AI can begin to understand natural language and can begin to be able to analyze and do useful tasks with regards to human language, which turns out to be a challenging and interesting task. So we'll see you next time. And welcome back, everybody, to our final class in an introduction to artificial intelligence with Python. Now, so far in this class, we've been taking problems that we want to solve intelligently and framing them in ways that computers are going to be able to make sense of. We've been taking problems and framing them as search problems or constraint satisfaction problems or optimization problems, for example. In essence, we have been trying to communicate about problems in ways that our computer is going to be able to understand. Today, the goal is going to be to get computers to understand the way you and I communicate naturally via our own natural languages, languages like English. But natural language contains a lot of nuance and complexity that's going to make it challenging for computers to be able to understand. So we'll need to explore some new tools and some new techniques to allow computers to make sense of natural language. So what is it exactly that we're trying to get computers to do? Well, they all fall under this general heading of natural language processing, getting computers to work with natural language. And these tasks include tasks like automatic summarization. Given a long text, can we train the computer to be able to come up with a shorter representation of it? Information extraction, getting the computer to pull out relevant facts or details out of some text. Machine translation, like Google Translate, translating some text from one language into another language. Question answering, if you've ever asked a question to your phone or had a conversation with an AI chatbot where you provide some text to the computer, the computer is able to understand that text and then generate some text in response. Text classification, where we provide some text to the computer and the computer assigns it a label, positive or negative, inbox or spam, for example. And there are several other kinds of tasks that all fall under this heading of natural language processing. But before we take a look at how the computer might try to solve these kinds of tasks, it might be useful for us to think about language in general. What are the kinds of challenges that we might need to deal with as we start to think about language and getting a computer to be able to understand it? So one part of language that we'll need to consider is the syntax of language. Syntax is all about the structure of language. Language is composed of individual words. And those words are composed together in some kind of structured whole. And if our computer is going to be able to understand language, it's going to need to understand something about that structure. So let's take a couple of examples. Here, for instance, is a sentence. Just before 9 o'clock, Sherlock Holmes stepped briskly into the room. That sentence is made up of words. And those words together form a structured whole. This is syntactically valid as a sentence. But we could take some of those same words, rearrange them, and come up with a sentence that is not syntactically valid. Here, for example, just before Sherlock Holmes 9 o'clock stepped briskly the room is still composed of valid words. But they're not in any kind of logical whole. This is not a syntactically well-formed sentence. Another interesting challenge is that some sentences will have multiple possible valid structures. Here's a sentence, for example. I saw the man on the mountain with a telescope. And here, this is a valid sentence. But it actually has two different possible structures that lend themselves to two different interpretations and two different meanings. Maybe I, the one doing the seeing, am the one with the telescope. Or maybe the man on the mountain is the one with the telescope. And so natural language is ambiguous. Sometimes the same sentence can be interpreted in multiple ways. And that's something that we'll need to think about as well. And this lends itself to another problem within language that we'll need to think about, which is semantics. While syntax is all about the structure of language, semantics is about the meaning of language. It's not enough for a computer just to know that a sentence is well-structured if it doesn't know what that sentence means. And so semantics is going to concern itself with the meaning of words and the meaning of sentences. So if we go back to that same sentence as before, just before 9 o'clock, Sherlock Holmes stepped briskly into the room, I could come up with another sentence, say the sentence, a few minutes before 9, Sherlock Holmes walked quickly into the room. And those are two different sentences with some of the words the same and some of the words different. But the two sentences have essentially the same meaning. And so ideally, whatever model we build, we'll be able to understand that these two sentences, while different, mean something very similar. Some syntactically well-formed sentences don't mean anything at all. A famous example from linguist Noam Chomsky is the sentence, colorless green ideas sleep furiously. This is a syntactically, structurally well-formed sentence. We've got adjectives modifying a noun, ideas. We've got a verb and an adverb in the correct positions. But when taken as a whole, the sentence doesn't really mean anything. And so if our computers are going to be able to work with natural language and perform tasks in natural language processing, these are some concerns we'll need to think about. We'll need to be thinking about syntax. And we'll need to be thinking about semantics. So how could we go about trying to teach a computer how to understand the structure of natural language? Well, one approach we might take is by starting by thinking about the rules of natural language. Our natural languages have rules. In English, for example, nouns tend to come before verbs. Nouns can be modified by adjectives, for example. And so if only we could formalize those rules, then we could give those rules to a computer, and the computer would be able to make sense of them and understand them. And so let's try to do exactly that. We're going to try to define a formal grammar. Where a formal grammar is some system of rules for generating sentences in a language. This is going to be a rule-based approach to natural language processing. We're going to give the computer some rules that we know about language and have the computer use those rules to make sense of the structure of language. And there are a number of different types of formal grammars. Each one of them has slightly different use cases. But today, we're going to focus specifically on one kind of grammar known as a context-free grammar. So how does the context-free grammar work? Well, here is a sentence that we might want a computer to generate. She saw the city. And we're going to call each of these words a terminal symbol. A terminal symbol, because once our computer has generated the word, there's nothing else for it to generate. Once it's generated the sentence, the computer is done. We're going to associate each of these terminal symbols with a non-terminal symbol that generates it. So here we've got n, which stands for noun, like she or city. We've got v as a non-terminal symbol, which stands for a verb. And then we have d, which stands for determiner. A determiner is a word like the or a or an in English, for example. So each of these non-terminal symbols can generate the terminal symbols that we ultimately care about generating. But how do we know, or how does the computer know which non-terminal symbols are associated with which terminal symbols? Well, to do that, we need some kind of rule. Here are some what we call rewriting rules that have a non-terminal symbol on the left-hand side of an arrow. And on the right side is what that non-terminal symbol can be replaced with. So here we're saying the non-terminal symbol n, again, which stands for noun, could be replaced by any of these options separated by vertical bars. n could be replaced by she or city or car or hairy. d for determiner could be replaced by the a or an and so forth. Each of these non-terminal symbols could be replaced by any of these words. We can also have non-terminal symbols that are replaced by other non-terminal symbols. Here is an interesting rule, np arrow n bar dn. So what does that mean? Well, np stands for a noun phrase. Sometimes when we have a noun phrase in a sentence, it's not just a single word, it could be multiple words. And so here we're saying a noun phrase could be just a noun, or it could be a determiner followed by a noun. So we might have a noun phrase that's just a noun, like she, that's a noun phrase. Or we could have a noun phrase that's multiple words, something like the city also acts as a noun phrase. But in this case, it's composed of two words, a determiner, the, and a noun city. We could do the same for verb phrases. A verb phrase, or VP, might be just a verb, or it might be a verb followed by a noun phrase. So we could have a verb phrase that's just a single word, like the word walked, or we could have a verb phrase that is an entire phrase, something like saw the city, as an entire verb phrase. A sentence, meanwhile, we might then define as a noun phrase followed by a verb phrase. And so this would allow us to generate a sentence like she saw the city, an entire sentence made up of a noun phrase, which is just the word she, and then a verb phrase, which is saw the city, saw which is a verb, and then the city, which itself is also a noun phrase. And so if we could give these rules to a computer explaining to it what non-terminal symbols could be replaced by what other symbols, then a computer could take a sentence and begin to understand the structure of that sentence. And so let's take a look at an example of how we might do that. And to do that, we're going to use a Python library called NLTK, or the Natural Language Toolkit, which we'll see a couple of times today. It contains a lot of helpful features and functions that we can use for trying to deal with and process natural language. So here we'll take a look at how we can use NLTK in order to parse a context-free grammar. So let's go ahead and open up cfg0.py, cfg standing for context-free grammar. And what you'll see in this file is that I first import NLTK, the Natural Language Toolkit. And the first thing I do is define a context-free grammar, saying that a sentence is a noun phrase followed by a verb phrase. I'm defining what a noun phrase is, defining what a verb phrase is, and then giving some examples of what I can do with these non-terminal symbols, D for determiner, N for noun, and V for verb. We're going to use NLTK to parse that grammar. Then we'll ask the user for some input in the form of a sentence and split it into words. And then we'll use this context-free grammar parser to try to parse that sentence and print out the resulting syntax tree. So let's take a look at an example. We'll go ahead and go into my cfg directory, and we'll run cfg0.py. And here I'm asked to type in a sentence. Let's say I type in she walked. And when I do that, I see that she walked is a valid sentence, where she is a noun phrase, and walked is the corresponding verb phrase. I could try to do this with a more complex sentence too. I could do something like she saw the city. And here we see that she is the noun phrase, and then saw the city is the entire verb phrase that makes up this sentence. So that was a very simple grammar. Let's take a look at a slightly more complex grammar. Here is cfg1.py, where a sentence is still a noun phrase followed by a verb phrase, but I've added some other possible non-terminal symbols too. I have AP for adjective phrase and PP for prepositional phrase. And we specified that we could have an adjective phrase before a noun phrase or a prepositional phrase after a noun, for example. So lots of additional ways that we might try to structure a sentence and interpret and parse one of those resulting sentences. So let's see that one in action. We'll go ahead and run cfg1.py with this new grammar. And we'll try a sentence like she saw the wide street. Here, Python's NLTK is able to parse that sentence and identify that she saw the wide street has this particular structure, a sentence with a noun phrase and a verb phrase, where that verb phrase has a noun phrase that within it contains an adjective. And so it's able to get some sense for what the structure of this language actually is. Let's try another example. Let's say she saw the dog with the binoculars. And we'll try that sentence. And here, we get one possible syntax tree, she saw the dog with the binoculars. But notice that this sentence is actually a little bit ambiguous in our own natural language. Who has the binoculars? Is it she who has the binoculars or the dog who has the binoculars? And NLTK is able to identify both possible structures for the sentence. In this case, the dog with the binoculars is an entire noun phrase. It's all underneath this NP here. So it's the dog that has the binoculars. But we also got an alternative parse tree, where the dog is just the noun phrase. And with the binoculars is a prepositional phrase modifying saw. So she saw the dog and she used the binoculars in order to see the dog as well. So this allows us to get a sense for the structure of natural language. But it relies on us writing all of these rules. And it would take a lot of effort to write all of the rules for any possible sentence that someone might write or say in the English language. Language is complicated. And as a result, there are going to be some very complex rules. So what else might we try? We might try to take a statistical lens towards approaching this problem of natural language processing. If we were able to give the computer a lot of existing data of sentences written in the English language, what could we try to learn from that data? Well, it might be difficult to try and interpret long pieces of text all at once. So instead, what we might want to do is break up that longer text into smaller pieces of information instead. In particular, we might try to create n-grams out of a longer sequence of text. An n-gram is just some contiguous sequence of n items from a sample of text. It might be n characters in a row or n words in a row, for example. So let's take a passage from Sherlock Holmes. And let's look for all of the trigrams. A trigram is an n-gram where n is equal to 3. So in this case, we're looking for sequences of three words in a row. So the trigrams here would be phrases like how often have. That's three words in a row. Often have I is another trigram. Have I said, I said to, said to you, to you that. These are all trigrams, sequences of three words that appear in sequence. And if we could give the computer a large corpus of text and have it pull out all of the trigrams in this case, it could get a sense for what sequences of three words tend to appear next to each other in our own natural language and, as a result, get some sense for what the structure of the language actually is. So let's take a look at an example of that. How can we use NLTK to try to get access to information about n-grams? So here, we're going to open up ngrams.py. And this is a Python program that's going to load a corpus of data, just some text files, into our computer's memory. And then we're going to use NLTK's ngrams function, which is going to go through the corpus of text, pulling out all of the ngrams for a particular value of n. And then, by using Python's counter class, we're going to figure out what are the most common ngrams inside of this entire corpus of text. And we're going to need a data set in order to do this. And I've prepared a data set of some of the stories of Sherlock Holmes. So it's just a bunch of text files. A lot of words for it to analyze. And as a result, we'll get a sense for what sequences of two words or three words that tend to be most common in natural language. So let's give this a try. We'll go into my ngrams directory. And we'll run ngrams.py. We'll try an n value of 2. So we're looking for sequences of two words in a row. And we'll use our corpus of stories from Sherlock Holmes. And when we run this program, we get a list of the most common ngrams where n is equal to 2, otherwise known as a bigram. So the most common one is of the. That's a sequence of two words that appears quite frequently in natural language. Then in the. And it was. These are all common sequences of two words that appear in a row. Let's instead now try running ngrams with n equal to 3. Let's get all of the trigrams and see what we get. And now we see the most common trigrams are it was a. One of the. I think that. These are all sequences of three words that appear quite frequently. And we were able to do this essentially via a process known as tokenization. Tokenization is the process of splitting a sequence of characters into pieces. In this case, we're splitting a long sequence of text into individual words and then looking at sequences of those words to get a sense for the structure of natural language. So once we've done this, once we've done the tokenization, once we've built up our corpus of ngrams, what can we do with that information? So the one thing that we might try is we could build a Markov chain, which you might recall from when we talked about probability. Recall that a Markov chain is some sequence of values where we can predict one value based on the values that came before it. And as a result, if we know all of the common ngrams in the English language, what words tend to be associated with what other words in sequence, we can use that to predict what word might come next in a sequence of words. And so we could build a Markov chain for language in order to try to generate natural language that follows the same statistical patterns as some input data. So let's take a look at that and build a Markov chain for natural language. And as input, I'm going to use the works of William Shakespeare. So here I have a file Shakespeare.txt, which is just a bunch of the works of William Shakespeare. It's a long text file, so plenty of data to analyze. And here in generator.py, I'm using a third party Python library in order to do this analysis. We're going to read in the sample of text, and then we're going to train a Markov model based on that text. And then we're going to have the Markov chain generate some sentences. We're going to generate a sentence that doesn't appear in the original text, but that follows the same statistical patterns that's generating it based on the ngrams trying to predict what word is likely to come next that we would expect based on those statistical patterns. So we'll go ahead and go into our Markov directory, run this generator with the works of William Shakespeare's input. And what we're going to get are five new sentences, where these sentences are not necessarily sentences from the original input text itself, but just that follow the same statistical patterns. It's predicting what word is likely to come next based on the input data that we've seen and the types of words that tend to appear in sequence there too. And so we're able to generate these sentences. Of course, so far, there's no guarantee that any of the sentences that are generated actually mean anything or make any sense. They just happen to follow the statistical patterns that our computer is already aware of. So we'll return to this issue of how to generate text in perhaps a more accurate or more meaningful way a little bit later. So let's now turn our attention to a slightly different problem, and that's the problem of text classification. Text classification is the problem where we have some text and we want to put that text into some kind of category. We want to apply some sort of label to that text. And this kind of problem shows up in a wide variety of places. A commonplace might be your email inbox, for example. You get an email and you want your computer to be able to identify whether the email belongs in your inbox or whether it should be filtered out into spam. So we need to classify the text. Is it a good email or is it spam? Another common use case is sentiment analysis. We might want to know whether the sentiment of some text is positive or negative. And so how might we do that? This comes up in situations like product reviews, where we might have a bunch of reviews for a product on some website. My grandson loved it so much fun. Product broke after a few days. One of the best games I've played in a long time and kind of cheap and flimsy, not worth it. Here's some example sentences that you might see on a product review website. And you and I could pretty easily look at this list of product reviews and decide which ones are positive and which ones are negative. We might say the first one and the third one, those seem like positive sentiment messages. But the second one and the fourth one seem like negative sentiment messages. But how did we know that? And how could we train a computer to be able to figure that out as well? Well, you might have clued your eye in on particular key words, where those particular words tend to mean something positive or negative. So you might have identified words like loved and fun and best tend to be associated with positive messages. And words like broke and cheap and flimsy tend to be associated with negative messages. So if only we could train a computer to be able to learn what words tend to be associated with positive versus negative messages, then maybe we could train a computer to do this kind of sentiment analysis as well. So we're going to try to do just that. We're going to use a model known as the bag of words model, which is a model that represents text as just an unordered collection of words. For the purpose of this model, we're not going to worry about the sequence and the ordering of the words, which word came first, second, or third. We're just going to treat the text as a collection of words in no particular order. And we're losing information there, right? The order of words is important. And we'll come back to that a little bit later. But for now, to simplify our model, it'll help us tremendously just to think about text as some unordered collection of words. And in particular, we're going to use the bag of words model to build something known as a naive Bayes classifier. So what is a naive Bayes classifier? Well, it's a tool that's going to allow us to classify text based on Bayes rule, again, which you might remember from when we talked about probability. Bayes rule says that the probability of B given A is equal to the probability of A given B multiplied by the probability of B divided by the probability of A. So how are we going to use this rule to be able to analyze text? Well, what are we interested in? We're interested in the probability that a message has a positive sentiment and the probability that a message has a negative sentiment, which I'm here for simplicity going to represent just with these emoji, happy face and frown face, as positive and negative sentiment. And so if I had a review, something like my grandson loved it, then what I'm interested in is not just the probability that a message has positive sentiment, but the conditional probability that a message has positive sentiment given that this is the message my grandson loved it. But how do I go about calculating this value, the probability that the message is positive given that the review is this sequence of words? Well, here's where the bag of words model comes in. Rather than treat this review as a string of a sequence of words in order, we're just going to treat it as an unordered collection of words. We're going to try to calculate the probability that the review is positive given that all of these words, my grandson loved it, are in the review in no particular order, just this unordered collection of words. And this is a conditional probability, which we can then apply Bayes rule to try to make sense of. And so according to Bayes rule, this conditional probability is equal to what? It's equal to the probability that all of these four words are in the review given that the review is positive multiplied by the probability that the review is positive divided by the probability that all of these words happen to be in the review. So this is the value now that we're going to try to calculate. Now, one thing you might notice is that the denominator here, the probability that all of these words appear in the review, doesn't actually depend on whether or not we're looking at the positive sentiment or negative sentiment case. So we can actually get rid of this denominator. We don't need to calculate it. We can just say that this probability is proportional to the numerator. And then at the end, we're going to need to normalize the probability distribution to make sure that all of the values sum up to the value 1. So now, how do we calculate this value? Well, this is the probability of all of these words given positive times probability of positive. And that, by the definition of joint probability, is just one big joint probability, the probability that all of these things are the case, that it's a positive review, and that all four of these words are in the review. But still, it's not entirely obvious how we calculate that value. And here is where we need to make one more assumption. And this is where the naive part of naive Bayes comes in. We're going to make the assumption that all of the words are independent of each other. And by that, I mean that if the word grandson is in the review, that doesn't change the probability that the word loved is in the review or that the word it is in the review, for example. And in practice, this assumption might not be true. It's almost certainly the case that the probability of words do depend on each other. But it's going to simplify our analysis and still give us reasonably good results just to assume that the words are independent of each other and they only depend on whether it's positive or negative. You might, for example, expect the word loved to appear more often in a positive review than in a negative review. So what does that mean? Well, if we make this assumption, then we can say that this value, the probability we're interested in, is not directly proportional to, but it's naively proportional to this value. The probability that the review is positive times the probability that my is in the review, given that it's positive, times the probability that grandson is in the review, given that it's positive, and so on for the other two words that happen to be in this review. And now this value, which looks a little more complex, is actually a value that we can calculate pretty easily. So how are we going to estimate the probability that the review is positive? Well, if we have some training data, some example data of example reviews where each one has already been labeled as positive or negative, then we can estimate the probability that a review is positive just by counting the number of positive samples and dividing by the total number of samples that we have in our training data. And for the conditional probabilities, the probability of loved, given that it's positive, well, that's going to be the number of positive samples with loved in it divided by the total number of positive samples. So let's take a look at an actual example to see how we could try to calculate these values. Here I've put together some sample data. The way to interpret the sample data is that based on the training data, 49% of the reviews are positive, 51% are negative. And then over here in this table, we have some conditional probabilities. And then we have if the review is positive, then there is a 30% chance that my appears in it. And if the review is negative, there is a 20% chance that my appears in it. And based on our training data among the positive reviews, 1% of them contain the word grandson. And among the negative reviews, 2% contain the word grandson. So using this data, let's try to calculate this value, the value we're interested in. And to do that, we'll need to multiply all of these values together. The probability of positive, and then all of these positive conditional probabilities. And when we do that, we get some value. And then we can do the same thing for the negative case. We're going to do the same thing, take the probability that it's negative, multiply it by all of these conditional probabilities, and we're going to get some other value. And now these values don't sum to one. They're not a probability distribution yet. But I can normalize them and get some values. And that tells me that we're going to predict that my grandson loved it. We think there's a 68% chance, probability 0.68, that that is a positive sentiment review, and 0.32 probability that it's a negative review. So what problems might we run into here? What could potentially go wrong when doing this kind of analysis in order to analyze whether text has a positive or negative sentiment? Well, a couple of problems might arise. One problem might be, what if the word grandson never appears for any of the positive reviews? If that were the case, then when we try to calculate the value, the probability that we think the review is positive, we're going to multiply all these values together, and we're just going to get 0 for the positive case, because we're all going to ultimately multiply by that 0 value. And so we're going to say that we think there is no chance that the review is positive because it contains the word grandson. And in our training data, we've never seen the word grandson appear in a positive sentiment message before. And that's probably not the right analysis, because in cases of rare words, it might be the case that in nowhere in our training data did we ever see the word grandson appear in a message that has positive sentiment. So what can we do to solve this problem? Well, one thing we'll often do is some kind of additive smoothing, where we add some value alpha to each value in our distribution just to smooth out the data a little bit. And a common form of this is Laplace smoothing, where we add 1 to each value in our distribution. In essence, we pretend we've seen each value one more time than we actually have. So if we've never seen the word grandson for a positive review, we pretend we've seen it once. If we've seen it once, we pretend we've seen it twice, just to avoid the possibility that we might multiply by 0 and as a result, get some results we don't want in our analysis. So let's see what this looks like in practice. Let's try to do some naive Bayes classification in order to classify text as either positive or negative. We'll take a look at sentiment.py. And what this is going to do is load some sample data into memory, some examples of positive reviews and negative reviews. And then we're going to train a naive Bayes classifier on all of this training data, training data that includes all of the words we see in positive reviews and all of the words we see in negative reviews. And then we're going to try to classify some input. And so we're going to do this based on a corpus of data. I have some example positive reviews. Here are some positive reviews. It was great, so much fun, for example. And then some negative reviews, not worth it, kind of cheap. These are some examples of negative reviews. So now let's try to run this classifier and see how it would classify particular text as either positive or negative. We'll go ahead and run our sentiment analysis on this corpus. And we need to provide it with a review. So I'll say something like, I enjoyed it. And we see that the classifier says there is about a 0.92 probability that we think that this particular review is positive. Let's try something negative. We'll try kind of overpriced. And we see that there is a 0.96 probability now that we think that this particular review is negative. And so our naive Bayes classifier has learned what kinds of words tend to appear in positive reviews and what kinds of words tend to appear in negative reviews. And as a result of that, we've been able to design a classifier that can predict whether a particular review is positive or negative. And so this definitely is a useful tool that we can use to try and make some predictions. But we had to make some assumptions in order to get there. So what if we want to now try to build some more sophisticated models, use some tools from machine learning to try and take better advantage of language data to be able to draw more accurate conclusions and solve new kinds of tasks and new kinds of problems? Well, we've seen a couple of times now that when we want to take some data and take some input, put it in a way that the computer is going to be able to make sense of, it can be helpful to take that data and turn it into numbers, ultimately. And so what we might want to try to do is come up with some word representation, some way to take a word and translate its meaning into numbers. Because, for example, if we wanted to use a neural network to be able to process language, give our language to a neural network and have it make some predictions or perform some analysis there, a neural network takes its input and produces its output a vector of values, a vector of numbers. And so what we might want to do is take our data and somehow take words and convert them into some kind of numeric representation. So how might we do that? How might we take words and turn them into numbers? Let's take a look at an example. Here's a sentence, he wrote a book. And let's say I wanted to take each of those words and turn it into a vector of values. Here's one way I might do that. We'll say he is going to be a vector that has a 1 in the first position and the rest of the values are 0. Wrote will have a 1 in the second position and the rest of the values are 0. A has a 1 in the third position with the rest of the value 0. And book has a 1 in the fourth position with the rest of the value 0. So each of these words now has a distinct vector representation. And this is what we often call a one-hot representation, a representation of the meaning of a word as a vector with a single 1 and all of the rest of the values are 0. And so when doing this, we now have a numeric representation for every word and we could pass in those vector representations into a neural network or other models that require some kind of numeric data as input. But this one-hot representation actually has a couple of problems and it's not ideal for a few reasons. One reason is, here we're just looking at four words. But if you imagine a vocabulary of thousands of words or more, these vectors are going to get quite long in order to have a distinct vector for every possible word in a vocabulary. And as a result of that, these longer vectors are going to be more difficult to deal with, more difficult to train, and so forth. And so that might be a problem. Another problem is a little bit more subtle. If we want to represent a word as a vector, and in particular the meaning of a word as a vector, then ideally it should be the case that words that have similar meanings should also have similar vector representations, so that they're close to each other together inside a vector space. But that's not really going to be the case with these one-hot representations, because if we take some similar words, say the word wrote and the word authored, which means similar things, they have entirely different vector representations. Likewise, book and novel, those two words mean somewhat similar things, but they have entirely different vector representations because they each have a one in some different position. And so that's not ideal either. So what we might be interested in instead is some kind of distributed representation. A distributed representation is the representation of the meaning of a word distributed across multiple values, instead of just being one-hot with a one in one position. Here is what a distributed representation of words might be. Each word is associated with some vector of values, with the meaning distributed across multiple values, ideally in such a way that similar words have a similar vector representation. But how are we going to come up with those values? Where do those values come from? How can we define the meaning of a word in this distributed sequence of numbers? Well, to do that, we're going to draw inspiration from a quote from British linguist J.R. Firth, who said, you shall know a word by the company it keeps. In other words, we're going to define the meaning of a word based on the words that appear around it, the context words around it. Take, for example, this context, for blank he ate. You might wonder, what words could reasonably fill in that blank? Well, it might be words like breakfast or lunch or dinner. All of those could reasonably fill in that blank. And so what we're going to say is because the words breakfast and lunch and dinner appear in a similar context, that they must have a similar meaning. And that's something our computer could understand and try to learn. A computer could look at a big corpus of text, look at what words tend to appear in similar context to each other, and use that to identify which words have a similar meaning and should therefore appear close to each other inside a vector space. And so one common model for doing this is known as the word to vec model. It's a model for generating word vectors, a vector representation for every word by looking at data and looking at the context in which a word appears. The idea is going to be this. If you start out with all of the words just in some random position in space and train it on some training data, what the word to vec model will do is start to learn what words appear in similar contexts. And it will move these vectors around in such a way that hopefully words with similar meanings, breakfast, lunch, and dinner, book, memoir, novel, will hopefully appear to be near to each other as vectors as well. So let's now take a look at what word to vec might look like in practice when implemented in code. What I have here inside of words.txt is a pre-trained model where each of these words has some vector representation trained by word to vec. Each of these words has some sequence of values representing its meaning, hopefully in such a way that similar words are represented by similar vectors. I also have this file vectors.py, which is going to open up the words and form them into a dictionary. And we also define some useful functions like distance to get the distance between two word vectors and closest words to find which words are nearby in terms of having close vectors to each other. And so let's give this a try. We'll go ahead and open a Python interpreter. And I'm going to import these vectors. And we might say, all right, what is the vector representation of the word book? And we get this big long vector that represents the word book as a sequence of values. And this sequence of values by itself is not all that meaningful. But it is meaningful in the context of comparing it to other vectors for other words. So we could use this distance function, which is going to get us the distance between two word vectors. And we might say, what is the distance between the vector representation for the word book and the vector representation for the word novel? And we see that it's 0.34. You can kind of interpret 0 as being really close together and 1 being very far apart. And so now, what is the distance between book and, let's say, breakfast? Well, book and breakfast are more different from each other than book and novel are. So I would hopefully expect the distance to be larger. And in fact, it is 0.64 approximately. These two words are further away from each other. And what about now the distance between, let's say, lunch and breakfast? Well, that's about 0.2. Those are even closer together. They have a meaning that is closer to each other. Another interesting thing we might do is calculate the closest words. We might say, what are the closest words, according to Word2Vec, to the word book? And let's say, let's get the 10 closest words. What are the 10 closest vectors to the vector representation for the word book? And when we perform that analysis, we get this list of words. The closest one is book itself, but we also have books plural, and then essay, memoir, essays, novella, anthology, and so on. All of these words mean something similar to the word book, according to Word2Vec, at least, because they have a similar vector representation. So it seems like we've done a pretty good job of trying to capture this kind of vector representation of word meaning. One other interesting side effect of Word2Vec is that it's also able to capture something about the relationships between words as well. Let's take a look at an example. Here, for instance, are two words, man and king. And these are each represented by Word2Vec as vectors. So what might happen if I subtracted one from the other, calculated the value king minus man? Well, that will be the vector that will take us from man to king, somehow represent this relationship between the vector representation of the word man and the vector representation of the word king. And that's what this value, king minus man, represents. So what would happen if I took the vector representation of the word woman and added that same value, king minus man, to it? What would we get as the closest word to that, for example? Well, we could try it. Let's go ahead and go back to our Python interpreter and give this a try. I could say, what is the closest word to the vector representation of the word king minus the representation of the word man plus the representation of the word woman? And we see that the closest word is the word queen. We've somehow been able to capture the relationship between king and man. And then when we apply it to the word woman, we get, as the result, the word queen. So Word2Vec has been able to capture not just the words and how they're similar to each other, but also something about the relationships between words and how those words are connected to each other. So now that we have this vector representation of words, what can we now do with it? Now we can represent words as numbers. And so we might try to pass those words as input to, say, a neural network. Neural networks we've seen are very powerful tools for identifying patterns and making predictions. Recall that a neural network you can think of as all of these units. But really what the neural network is doing is taking some input, passing it into the network, and then producing some output. And by providing the neural network with training data, we're able to update the weights inside of the network so that the neural network can do a more accurate job of translating those inputs into those outputs. And now that we can represent words as numbers that could be the input or output, you could imagine passing a word in as input to a neural network and getting a word as output. And so when might that be useful? One common use for neural networks is in machine translation, when we want to translate text from one language into another, say translate English into French by passing English into the neural network and getting some French output. You might imagine, for instance, that we could take the English word for lamp, pass it into the neural network, get the French word for lamp as output. But in practice, when we're translating text from one language to another, we're usually not just interested in translating a single word from one language to another, but a sequence, say a sentence or a paragraph of words. Here, for example, is another paragraph, again taken from Sherlock Holmes, written in English. And what I might want to do is take that entire sentence, pass it into the neural network, and get as output a French translation of the same sentence. But recall that a neural network's input and output needs to be of some fixed size. And a sentence is not a fixed size. It's variable. You might have shorter sentences, and you might have longer sentences. So somehow, we need to solve the problem of translating a sequence into another sequence by means of a neural network. And that's going to be true not only for machine translation, but also for other problems, problems like question answering. If I want to pass as input a question, something like what is the capital of Massachusetts, feed that as input into the neural network, I would hope that what I would get as output is a sentence like the capital is Boston, again, translating some sequence into some other sequence. And if you've ever had a conversation with an AI chatbot, or have ever asked your phone a question, it needs to do something like this. It needs to understand the sequence of words that you, the human, provided as input. And then the computer needs to generate some sequence of words as output. So how can we do this? Well, one tool that we can use is the recurrent neural network, which we took a look at last time, which is a way for us to provide a sequence of values to a neural network by running the neural network multiple times. And each time we run the neural network, what we're going to do is we're going to keep track of some hidden state. And that hidden state is going to be passed from one run of the neural network to the next run of the neural network, keeping track of all of the relevant information. And so let's take a look at how we can apply that to something like this. And in particular, we're going to look at an architecture known as an encoder-decoder architecture, where we're going to encode this question into some kind of hidden state, and then use a decoder to decode that hidden state into the output that we're interested in. So what's that going to look like? We'll start with the first word, the word what. That goes into our neural network, and it's going to produce some hidden state. This is some information about the word what that our neural network is going to need to keep track of. Then when the second word comes along, we're going to feed it into that same encoder neural network, but it's going to get as input that hidden state as well. So we pass in the second word. We also get the information about the hidden state, and that's going to continue for the other words in the input. This is going to produce a new hidden state. And so then when we get to the third word, the, that goes into the encoder. It also gets access to the hidden state, and then it produces a new hidden state that gets passed into the next run when we use the word capital. And the same thing is going to repeat for the other words that appear in the input. So of Massachusetts, that produces one final piece of hidden state. Now somehow, we need to signal the fact that we're done. There's nothing left in the input. And we typically do this by passing some kind of special token, say an end token, into the neural network. And now the decoding process is going to start. We're going to generate the word the. But in addition to generating the word the, this decoder network is also going to generate some kind of hidden state. And so what happens the next time? Well, to generate the next word, it might be helpful to know what the first word was. So we might pass the first word the back into the decoder network. It's going to get as input this hidden state, and it's going to generate the next word capital. And that's also going to generate some hidden state. And we'll repeat that, passing capital into the network to generate the third word is, and then one more time in order to get the fourth word Boston. And at that point, we're done. But how do we know we're done? Usually, we'll do this one more time, pass Boston into the decoder network, and get an output some end token to indicate that that is the end of our input. And so this then is how we could use a recurrent neural network to take some input, encode it into some hidden state, and then use that hidden state to decode it into the output we're interested in. To visualize it in a slightly different way, we have some input sequence. This is just some sequence of words. That input sequence goes into the encoder, which in this case is a recurrent neural network generating these hidden states along the way until we generate some final hidden state, at which point we start the decoding process. Again, using a recurrent neural network, that's going to generate the output sequence as well. So we've got the encoder, which is encoding the information about the input sequence into this hidden state, and then the decoder, which takes that hidden state and uses it in order to generate the output sequence. But there are some problems. And for many years, this was the state of the art. The recurrent neural network and variance on this approach were some of the best ways we knew in order to perform tasks in natural language processing. But there are some problems that we might want to try to deal with and that have been dealt with over the years to try and improve upon this kind of model. And one problem you might notice happens in this encoder stage. We've taken this input sequence, the sequence of words, and encoded it all into this final piece of hidden state. And that final piece of hidden state needs to contain all of the information from the input sequence that we need in order to generate the output sequence. And while that's possible, it becomes increasingly difficult as the sequence gets larger and larger. For larger and larger input sequences, it's going to become more and more difficult to store all of the information we need about the input inside this single hidden state piece of context. That's a lot of information to pack into just a single value. It might be useful for us, when generating output, to not just refer to this one value, but to all of the previous hidden values that have been generated by the encoder. And so that might be useful, but how could we do that? We've got a lot of different values. We need to combine them somehow. So you could imagine adding them together, taking the average of them, for example. But doing that would assume that all of these pieces of hidden state are equally important. But that's not necessarily true either. Some of these pieces of hidden state are going to be more important than others, depending on what word they most closely correspond to. This piece of hidden state very closely corresponds to the first word of the input sequence. This one very closely corresponds to the second word of the input sequence, for example. And some of those are going to be more important than others. To make matters more complicated, depending on which word of the output sequence we're generating, different input words might be more or less important. And so what we really want is some way to decide for ourselves which of the input values are worth paying attention to, at what point in time. And this is the key idea behind a mechanism known as attention. Attention is all about letting us decide which values are important to pay attention to, when generating, in this case, the next word in our sequence. So let's take a look at an example of that. Here's a sentence. What is the capital of Massachusetts? Same sentence as before. And let's imagine that we were trying to answer that question by generating tokens of output. So what would the output look like? Well, it's going to look like something like the capital is. And let's say we're now trying to generate this last word here. What is that last word? How is the computer going to figure it out? Well, what it's going to need to do is decide which values it's going to pay attention to. And so the attention mechanism will allow us to calculate some attention scores for each word, some value corresponding to each word, determining how relevant is it for us to pay attention to that word right now? And in this case, when generating the fourth word of the output sequence, the most important words to pay attention to might be capital and Massachusetts, for example. That those words are going to be particularly relevant. And there are a number of different mechanisms that have been used in order to calculate these attention scores. It could be something as simple as a dot product to see how similar two vectors are, or we could train an entire neural network to calculate these attention scores. But the key idea is that during the training process for our neural network, we're going to learn how to calculate these attention scores. Our model is going to learn what is important to pay attention to in order to decide what the next word should be. So the result of all of this, calculating these attention scores, is that we can calculate some value, some value for each input word, determining how important is it for us to pay attention to that particular value. And recall that each of these input words is also associated with one of these hidden state context vectors, capturing information about the sentence up to that point, but primarily focused on that word in particular. And so what we can now do is if we have all of these vectors and we have values representing how important is it for us to pay attention to those particular vectors, is we can take a weighted average. We can take all of these vectors, multiply them by their attention scores, and add them up to get some new vector value, which is going to represent the context from the input, but specifically paying attention to the words that we think are most important. And once we've done that, that context vector can be fed into our decoder in order to say that the word should be, in this case, Boston. So attention is this very powerful tool that allows any word when we're trying to decode it to decide which words from the input should we pay attention to in order to determine what's important for generating the next word of the output. And one of the first places this was really used was in the field of machine translation. Here's an example of a diagram from the paper that introduced this idea, which was focused on trying to translate English sentences into French sentences. So we have an input English sentence up along the top, and then along the left side, the output French equivalent of that same sentence. And what you see in all of these squares are the attention scores visualized, where a lighter square indicates a higher attention score. And what you'll notice is that there's a strong correspondence between the French word and the equivalent English word, that the French word for agreement is really paying attention to the English word for agreement in order to decide what French word should be generated at that point in time. And sometimes you might pay attention to multiple words if you look at the French word for economic. That's primarily paying attention to the English word for economic, but also paying attention to the English word for European in this case too. And so attention scores are very easy to visualize to get a sense for what is our machine learning model really paying attention to, what information is it using in order to determine what's important and what's not in order to determine what the ultimate output token should be. And so when we combine the attention mechanism with a recurrent neural network, we can get very powerful and useful results where we're able to generate an output sequence by paying attention to the input sequence too. But there are other problems with this approach of using a recurrent neural network as well. In particular, notice that every run of the neural network depends on the output of the previous step. And that was important for getting a sense for the sequence of words and the ordering of those particular words. But we can't run this unit of the neural network until after we've calculated the hidden state from the run before it from the previous input token. And what that means is that it's very difficult to parallelize this process. That as the input sequence get longer and longer, we might want to use parallelism to try and speed up this process of training the neural network and making sense of all of this language data. But it's difficult to do that. And it's slow to do that with a recurrent neural network because all of it needs to be performed in sequence. And that's become an increasing challenge as we've started to get larger and larger language models. The more language data that we have available to us to use to train our machine learning models, the more accurate it can be, the better representation of language it can have, the better understanding it can have, and the better results that we can see. And so we've seen this growth of large language models that are using larger and larger data sets. But as a result, they take longer and longer to train. And so this problem that recurrent neural networks are not easy to parallelize has become an increasing problem. And as a result of that, that was one of the main motivations for a different architecture, for thinking about how to deal with natural language. And that's known as the transformer architecture. And this has been a significant milestone in the world of natural language processing for really increasing how well we can perform these kinds of natural language processing tasks, as well as how quickly we can train a machine learning model to be able to produce effective results. There are a number of different types of transformers in terms of how they work. But what we're going to take a look at here is the basic architecture for how one might work with a transformer to get a sense for what's involved and what we're doing. So let's start with the model we were looking at before, specifically at this encoder part of our encoder-decoder architecture, where we used a recurrent neural network to take this input sequence and capture all of this information about the hidden state and the information we need to know about that input sequence. Right now, it all needs to happen in this linear progression. But what the transformer is going to allow us to do is process each of the words independently in a way that's easy to parallelize, rather than have each word wait for some other word. Each word is going to go through this same neural network and produce some kind of encoded representation of that particular input word. And all of this is going to happen in parallel. Now, it's happening for all of the words at once, but we're really just going to focus on what's happening for one word to make it clear. But know that whatever you're seeing happen for this one word is going to happen for all of the other input words, too. So what's going on here? Well, we start with some input word. That input word goes into the neural network. And the output is hopefully some encoded representation of the input word, the information we need to know about the input word that's going to be relevant to us as we're generating the output. And because we're doing this each word independently, it's easy to parallelize. We don't have to wait for the previous word before we run this word through the neural network. But what did we lose in this process by trying to parallelize this whole thing? Well, we've lost all notion of word ordering. The order of words is important. The sentence, Sherlock Holmes gave the book to Watson, has a different meaning than Watson gave the book to Sherlock Holmes. And so we want to keep track of that information about word position. In the recurrent neural network, that happened for us automatically because we could run each word one at a time through the neural network, get the hidden state, pass it on to the next run of the neural network. But that's not the case here with the transformer, where each word is being processed independent of all of the other ones. So what are we going to do to try to solve that problem? One thing we can do is add some kind of positional encoding to the input word. The positional encoding is some vector that represents the position of the word in the sentence. This is the first word, the second word, the third word, and so forth. We're going to add that to the input word. And the result of that is going to be a vector that captures multiple pieces of information. It captures the input word itself as well as where in the sentence it appears. The result of that is we can pass the output of that addition, the addition of the input word and the positional encoding into the neural network. That way, the neural network knows the word and where it appears in the sentence and can use both of those pieces of information to determine how best to represent the meaning of that word in the encoded representation at the end of it. In addition to what we have here, in addition to the positional encoding and this feed forward neural network, we're also going to add one additional component, which is going to be a self-attention step. This is going to be attention where we're paying attention to the other input words. Because the meaning or interpretation of an input word might vary depending on the other words in the input as well. And so we're going to allow each word in the input to decide what other words in the input it should pay attention to in order to decide on its encoded representation. And that's going to allow us to get a better encoded representation for each word because words are defined by their context, by the words around them and how they're used in that particular context. This kind of self-attention is so valuable, in fact, that oftentimes the transformer will use multiple different self-attention layers at the same time to allow for this model to be able to pay attention to multiple facets of the input at the same time. And we call this multi-headed attention, where each attention head can pay attention to something different. And as a result, this network can learn to pay attention to many different parts of the input for this input word all at the same time. And in the spirit of deep learning, these two steps, this multi-headed self-attention layer and this neural network layer, that itself can be repeated multiple times, too, in order to get a deeper representation, in order to learn deeper patterns within the input text and ultimately get a better representation of language in order to get useful encoded representations of all of the input words. And so this is the process that a transformer might use in order to take an input word and get it its encoded representation. And the key idea is to really rely on this attention step in order to get information that's useful in order to determine how to encode that word. And that process is going to repeat for all of the input words that are in the input sequence. We're going to take all of the input words, encode them with some kind of positional encoding, feed those into these self-attention and feed-forward neural networks in order to ultimately get these encoded representations of the words. That's the result of the encoder. We get all of these encoded representations that will be useful to us when it comes time then to try to decode all of this information into the output sequence we're interested in. And again, this might take place in the context of machine translation, where the output is going to be the same sentence in a different language, or it might be an answer to a question in the case of an AI chatbot, for example. And so now let's take a look at how that decoder is going to work. Ultimately, it's going to have a very similar structure. Any time we're trying to generate the next output word, we need to know what the previous output word is, as well as its positional encoding. Where in the output sequence are we? And we're going to have these same steps, self-attention, because we might want an output word to be able to pay attention to other words in that same output, as well as a neural network. And that might itself repeat multiple times. But in this decoder, we're going to add one additional step. We're going to add an additional attention step, where instead of self-attention, where the output word is going to pay attention to other output words, in this step, we're going to allow the output word to pay attention to the encoded representations. So recall that the encoder is taking all of the input words and transforming them into these encoded representations of all of the input words. But it's going to be important for us to be able to decide which of those encoded representations we want to pay attention to when generating any particular token in the output sequence. And that's what this additional attention step is going to allow us to do. It's saying that every time we're generating a word of the output, we can pay attention to the other words in the output, because we might want to know, what are the words we've generated previously? And we want to pay attention to some of them to decide what word is going to be next in the sequence. But we also care about paying attention to the input words, too. And we want the ability to decide which of these encoded representations of the input words are going to be relevant in order for us to generate the next step. And so these two pieces combine together. We have this encoder that takes all of the input words and produces this encoded representation. And we have this decoder that is able to take the previous output word, pay attention to that encoded input, and then generate the next output word. And this is one of the possible architectures we could use for a transformer, with the key idea being these attention steps that allow words to pay attention to each other. During the training process here, we can now much more easily parallelize this, because we don't have to wait for all of the words to happen in sequence. And we can learn how we should perform these attention steps. The model is able to learn what is important to pay attention to, what things do I need to pay attention to, in order to be more accurate at predicting what the output word is. And this has proved to be a tremendously effective model for conversational AI agents, for building machine translation systems. And there have been many variants proposed on this model, too. Some transformers only use an encoder. Some only use a decoder. Some use some other combination of these different particular features. But the key ideas ultimately remain the same, this real focus on trying to pay attention to what is most important. And the world of natural language processing is fast growing and fast evolving. Year after year, we keep coming up with new models that allow us to do an even better job of performing these natural language related tasks, all on the surface of solving the tricky problem, which is our own natural language. We've seen how the syntax and semantics of our language is ambiguous, and it introduces all of these new challenges that we need to think about, if we're going to be able to design AI agents that are able to work with language effectively. So as we think about where we've been in this class, all of the different types of artificial intelligence we've considered, we've looked at artificial intelligence in a wide variety of different forms now. We started by taking a look at search problems, where we looked at how AI can search for solutions, play games, and find the optimal decision to make. We talked about knowledge, how AI can represent information that it knows and use that information to generate new knowledge as well. Then we looked at what AI can do when it's less certain, when it doesn't know things for sure, and we have to represent things in terms of probability. We then took a look at optimization problems. We saw how a lot of problems in AI can be boiled down to trying to maximize or minimize some function. And we looked at strategies that AI can use in order to do that kind of maximizing and minimizing. We then looked at the world of machine learning, learning from data in order to figure out some patterns and identify how to perform a task by looking at the training data that we have available to it. And one of the most powerful tools there was the neural network, the sequence of units whose weights can be trained in order to allow us to really effectively go from input to output and predict how to get there by learning these underlying patterns. And then today, we took a look at language itself, trying to understand how can we train the computer to be able to understand our natural language, to be able to understand syntax and semantics, make sense of and generate natural language, which introduces a number of interesting problems too. And we've really just scratched the surface of artificial intelligence. There is so much interesting research and interesting new techniques and algorithms and ideas being introduced to try to solve these types of problems. So I hope you enjoyed this exploration into the world of artificial intelligence. A huge thanks to all of the course's teaching staff and production team for making the class possible. This was an introduction to artificial intelligence with Python."
    },
    {
        "id": "5d42c702-d30d-4f26-8309-c076dd1ce907",
        "type": "video",
        "domaine": "technology",
        "titre": "Artificial Intelligence | 60 Minutes Full Episodes",
        "url": "https://www.youtube.com/watch?v=aZ5EsdnpLMI",
        "description": "From January 2019, Scott Pelley's interview with \"the oracle of AI,\" Kai-Fu Lee. From this past April, Pelley's report on Google's AI ...",
        "chaine": "60 Minutes",
        "durée": "53:30",
        "keywords": [
            "Google artificial intelligence",
            "Google CEO Sundar",
            "questions Google James",
            "called Deep Mind",
            "human mind works",
            "Google James manika",
            "China Silicon Valley",
            "Google vice president",
            "Deep Mind Made",
            "Google Engineers teaching"
        ],
        "transcription": "despite what you hear about artificial intelligence machines still can't think like a human but in the last few years they have become capable of learning and suddenly our devices have opened their eyes and ears and cars have taken the wheel today artificial intelligence is not as good as you hope and not as bad as you fear but humanity is accelerating into a future that few can predict that's why so many people are desperate to meet Kaiu Lee the Oracle of AI Kaiu Le is in there somewhere in a selfie scrum at a Beijing internet conference his 50 million social media followers want to be seen in the same frame because of his talent for engineering and genius for wealth I wonder do you think people around the world have any idea what's coming in artificial intelligence I think most people have no idea and many people have the wrong idea but you do believe it's going to change the world I believe it's going to change the world more than anything in the history of mankind more than Electric Lee believes the best place to be an AI capitalist is communist China his Beijing Venture Capital firm manufactures billionaires these are the entrepreneurs that we funded he's funded 140 AI startups we have about1 billion companies here 101 billion companies that you funded yes including a few1 billion companies in 2017 China attracted half of all AI capital in the world one of Lee's Investments is face Plus+ not affiliated with Facebook its visual recognition system smothered me to guess my age it settled on 61 which was wrong I wouldn't be 61 for days on the street face Plus+ nailed everything that moved it's a kind of artificial intelligence that has been made possible by three Innovations super fast computer chips all the world's data now available online and a revolution in programming called Deep learning computers used to be given rigid instructions now they're programmed to learn on their own in the early days of AI people try to program the AI with how people think so I would write a program to say U measure the size of the eyes and their distance measure the size of of the nose measure the shape of the face and then if these things match then this is Larry and that's John but today you just take all the pictures of Larry and John and you tell the system go at it and you figure out what separates Larry from John let's say you want the computer to be able to pick men out of a crowd and describe their clothing will you simply show the computer 10 million pictures of men in various kinds of dress that that's what they mean by Deep learning it's not intelligence so much it's just the brute force of data having 10 million examples to choose from so face Plus+ tagged me as male short hair black long sleeves black long pants it's wrong about my gray suit and this is exactly how it learns when Engineers discover that error they'll show the computer a million Gray and it won't make that mistake again over a thousand classrooms another recognition system we saw or saw us is learning not just who you are but how you feel now what are all the dots on the screen the dots over our eyes and our mouths sure the computer keeps track all the feature points on the face son fan yangang developed this for talal Education Group which tutors 5 million Chinese students let's look at what we're seeing here now according to the computer I'm confused which is generally the case but when I laughed I was happy exactly that's amazing the machine notices concentration or distraction to pick out for the teacher those students who are struggling or gifted it can tell when the child is excited about math yes or the other child is excited about poetry yes could these AI systems pick out Geniuses from the countryside that's possible in the future it can also create a student profile and know where the student got stuck so the teacher can personalize the areas in which the student needs help if you do raise up your hand we found Kaiu Lee's personal passion in this spare Beijing Studio he's projecting top teachers into China's poorest schools this English teacher is connected to a class 1,000 M away in a village called defang many students in defang are called Left behinds because their parents left them with family when they move to the cities for work most left behinds don't get past 9th grade topic we're going to learn today Lee is counting on AI to deliver for them the same opportunity he had when he immigrated to the US from Taiwan as a boy when I arrived in Tennessee my principal took every lunch to teach me English and that is the kind of attention that I've not been used to Growing Up in Asia and I felt that the American classrooms are smaller encouraged individual thinking critical thinking and I felt uh it was the best thing that ever happened to me what about this and the best thing that ever happened to most of the engineers we met at Le's firm I went to Kela master degree in information science they too are alumni of America with a dream for China you have written that silicon Valley's Edge is not all it's cracked up to be what do you mean by that well Silicon Valley has been the single epicenter of the world technology Innovation when it comes to computers internet mobile and AI but in the recent 5 years we are seeing the Chinese AI is getting to be almost as good as Silicon Valley Ai and I think Silicon Valley is not quite aware of it yet China's Advantage is in the amount of data it collects the more data the better the AI just like the more you know the smarter you are China has four times more people than the United States and they are doing nearly everything online I just don't see any Chinese without a phone in their head college student Monica Sun showed us how more than a billion Chinese are using their phones to buy everything find anything and connect with everyone in America when personal information leaks we have Congressional hearings not in China you ever worry about the information that's being collected about you where you go what you buy who you're with I I've never think about it do you think most Chinese worry about their privacy um not that much not that much with a pliant public the leader of the Communist party has made a national priority of achieving AI dominance in 10 years this is where Kaiu Lee becomes uncharacteristically shy even though he's a former Apple Microsoft and Google executive he knows whose's boss in China president XI has called technology the sharp weapon of the modern State what does he mean by that I I am not an expert in interpreting his thoughts don't know there are those particularly people in the west who worry about this AI technology as being something that governments will use to control their people and to crush dcent that as a venture capitalists we don't we don't invest in this area and we're not studying deeply this particular problem but governments do it's certainly possible for governments to use the Technologies just like companies Lee is much more talkative about another threat posed by AI he explores the coming destruction of jobs in a new book AI superpowers China Silicon Valley and the New World Order AI will increasingly replace repetitive jobs not just for blue color work but a lot of white color work what sort of jobs would be lost to AI basically chauffeur truck drivers uh anyone who does driving for a living uh their jobs will be disrupted more in the 15 to 20- year uh time frame and many jobs that seem a little bit complex a chef waiter uh a lot of things will become automated we'll have automated stores uh automated restaurants and uh all together in 15 years that's going to uh displace uh about 40% of jobs in the world 40% of jobs in the world will be displaced by technology uh I would say displaceable what does that do to the fabric of society well in some sense there's the human wisdom that always overcomes these technology revolutions the invention of the steam engine uh the sewing machine the uh electricity uh have all displaced jobs uh and we've gotten over it the challenge of AI is this 40% whether it's 15 or 25 years is coming faster than the previous re Solutions there's a lot of hype about artificial intelligence and it's important to understand this is not general intelligence like that of a human this system can read faces and grade papers but it has no idea why these children are in this room or what the goal of education is a typical AI system can do one thing well but can't adapt what it knows to any other task so for now it may be that calling this intelligence isn't very smart when will we know that a machine can actually think like a human back when I was a grad students people said if machine can drive a car uh by itself that's intelligence now we say that's not enough so the bar keeps moving higher I think that's uh I guess more motivation for us to work harder if you're talking about AGI artificial general intelligence I would say not within the next 30 Years and possibly never possibly Never What's So insurmountable cuz I believe in the sanctity of our soul I believe there's a lot of things about us that we don't understand I believe there's a lot of um uh love and compassion that is not explainable in terms of neuron networks and computational algorithms and I currently see no way of solving them obviously unsolved problems have been solved in the past but it would be irresponsible for me to predict that these will be solved by certain time frame we may just be more than our bits we may we may look on our time as the moment civilization was transformed as it was by fire Agriculture and electricity in 2023 we learned that a machine taught itself how to speak to humans like a pier which is to say with creativity truth error and lies the technology known as a chatbot is only one of the recent breakthroughs in artificial intelligence machine means that can teach themselves superhuman skills we explored what's coming next at Google a leader in this new world CEO Sundar pachai told us AI will be as good or as evil as human nature allows the revolution he says is coming faster than you know do you think Society is prepared for what's coming you know there are two ways I think about it on one hand I feel no uh because you know the pace at which we can think and adapt as societal institutions compared to the PACE at which the technology is evolving there seems to be a mismatch on the other hand compared to any other technology I've seen more people worried about it earlier in its life cycle so I feel optimistic the number of people you know who have started worrying about the implications and hence the conversations are starting in a serious way as well I guess our conversations with 50-year-old Sundar Pai started at Google's new campus in Mountain View California it runs on 40% solar power and collects more water than it uses Hightech that pachai couldn't have imagined growing up in India with no telephone at home we were on a waiting list to get a rotary phone and for about 5 years and it finally came home I can still recall it vividly it changed our lives to me it was the first moment I understood the power of what getting access to technology meant so probably led me to be doing what I'm doing today what he's doing since 2019 is leading both Google and its parent company alphabet valued at $1.3 trillion worldwide Google runs 90% of internet searches and 70% of smartphones we're really excited about but its dominance was attacked this past February when Microsoft linked its search engine to a chatbot in a race for AI dominance Google just released its chatbot named Bard it's really here to help you brainstorm ideas to generate content like a speech or a blog post or an email we were introduced to Bard by Google vice president sha and Senior Vice President James manika here's Bard the first thing we learned was that Bard does not look for answers on the internet like Google search does so I wanted to get inspiration from some of the best speeches in the world Bard's replies come from a self-contained program that was mostly self-taught our experience was unsettling confounding absolutely confounding Bard appeared to possess the sum of human knowledge with microchips more than 100,000 times faster than the human brain summarize the we asked Bard to summarize the New Testament it did in 5 seconds and 17 words in Latin we asked for it in Latin that took another 4 seconds then we played with a famous 6w short story often attributed to Hemingway for sale baby shoes never warn wow the only prompt we gave was finish this story in five seconds holy cow the shoes were a gift from my wife but we never had a baby they were from The six-word Prompt Bard created a deeply human tale with characters it invented including a man whose wife could not conceive and a stranger grieving after a miscarriage and longing for closure uh I am rarely speechless I don't know what to make of this give me we asked for the story in verse in 5 seconds there was a poem written by a machine with breathtaking insight into the mystery of Faith Bard wrote she knew her baby soul would always be alive the humanity at superhuman speed was a shock how is this possible James manika told us that over several months Bard read most everything on the internet and created a model of what language looks like rather than search its answers come from this language model so for example if I said to you Scott peanut butter and right so it tries and learns to predict okay so peanut butter usually is followed by jelly it tries to predict the most probable next words based on everything it's learned uh so it's not going out to find stuff it's just predicting the next what but it doesn't feel like that we asked Bard why it helps people and it replied quote because it makes me happy Bard to my eye a appears to be thinking appears to be making judgments that's not what's happening these machines are not sensient they are not aware of themselves they're not sensient they're not aware of themselves uh they can exhibit behaviors that look like that because keep in mind they've learned from us we are sentient beings we have beings that have feelings emotions ideas thoughts perspectives we've reflected all that in books in novels in fiction so when they learn from that they build patterns from that so it's no surprise to me that the exhibited behavior sometimes looks like maybe there's somebody behind it there's nobody there these are not sensient beings not Zimbabwe born Oxford educated James manika holds a new position at Google his job is to think about how Ai and Humanity will best coexist AI has a potential to change many ways in which we've thought about Society about what we're able to do the the problems we can solve but AI itself will pose its own problems could Heming way write a better short story maybe but Bard can write a million before Hemingway could finish one imagine that level of automation across the economy a lot of people can be repl reped by this technology yes there are some job occupations that will start to decline over time there are also new job categories that will grow over time but the biggest change will be the jobs that will be changed something like more than 2third will have their definitions change not go away but change because they're now being assisted by Ai and by automation so this is a profound change which has implications for skills how do we assist people build new skills learn to work alongside machines and how do these complement what people do today this is going to impact every product across every company and and so that's why I think it's a a very very profound technology and so we are just in early days every product in every company that's right AI will impact everything so for example you could be a radiologist you know if I if you think about 5 to 10 years from now you're going to have a AI collaborator with you it may triage you come in the morning you let's say you have 100 things to go through it may say these are the most serious cases you need to look at first or when you're looking at something it may pop up and say you may have missed something important why would we you know why would we take advantage of a superpowered assistant to help you across everything you do you may be a student trying to learn math or history and you know you will have something helping you we asked Pai what jobs would be disrupted he said knowledge workers people like writers accountants Architects and ironically software Engineers AI writes computer code too today sundarai walks a narrow line a few employees have quit some believing that Google's AI roll out is too slow others too fast there are some serious flaws return of inflation James manika asked Bard about inflation it wrote an instant essay in economics and recommended five books but days later we checked none of the books is real Bard fabricated the titles this very human trait error with confidence is called in the industry hallucination are you getting a lot of hallucinations uh yes uh you know which is expected no one in the in the field has yet solved the hallucination problems all models uh do have uh this as an issue is it a solvable problem it's a matter of intense debate I think we'll make progress to help cure hallucinations Bard features a Google it button that leads to oldfashioned search Google has also built safety filters into Bard to screen for things like hate speech and bias how great a risk is the spread of disinformation AI will challenge that in a deeper way the scale of this problem is going to be much bigger bigger problems he says with fake news and fake images it will be possible with AI to create uh you know a video easily where it could be Scott saying something or me saying something and we never said that and it could look accurate but you know at a societal scale you know can cause a lot of harm is Bard safe for society the way we have launched it today uh as an experiment in a limited way uh I think so but we all have to be responsible in each step along the way Pai told us he's being responsible by holding back for more testing Advanced versions of Bard that he says can reason plan and connect to internet search you are letting this out slowly so that Society can get used to it that's one part of it uh one part is also so that we get the user feedback and we can develop more robust safety layers before we build before we deploy more capable models inter of the AI issues we talked about the most mysterious is called emergent properties some AI systems are teaching themselves skills that they weren't expected to have how this happens is not well understood for example one Google AI program adapted on its own after it was prompted in the language of Bangladesh which it was not trained to know we discovered that with very few amounts of prompting in Bengali he can now translate all of Gali so now all of a sudden we now have a research effort where we're now trying to get to a thousand languages there is an aspect of this which we call all of us in the field call it as a black box you know you don't fully understand and you can't quite tell why it said this or why it got wrong we have some ideas and our ability to understand this gets better over time but that's where the state of the art is you don't fully understand how it works and yet you've turned it loose on society let me put it this way I don't think we fully understand how a human mind works either was it from that black box we wondered that Bard Drew its short story that seems so disarmingly human it talked about the pain that humans feel it talked about Redemption how did it do all of those things if it's just trying to figure out what the next right word is mean I've had these EXP es uh talking with b as well there are two views of this you know there are a set of people who view this as look these are just algorithms they're just repeating what it's seen online then there is the view where these algorithms are showing emergent properties to be creative to reason to plan and so on right and and personally I think we need to be uh we need to approach this with humility part of the reason I think it's good that some of these Technologies are getting out is so that Society you know people like you and others can process what's happening and we begin this conversation and debate and I think it's important to do that when we come back we'll take you inside Google's artificial intelligence Labs where robots are learning the revolution in artificial intelligence is the center of a debate ranging from those who hope it will save Humanity to those who predict Doom Google lies somewhere in the optimistic middle introducing AI in steps so civilization can get used to it we saw what's coming next in machine learning at Google's AI lab in London a company called Deep Mind where the future looks something like this look at that oh my goodness they've got a pretty good kick on them can still get good good game a soccer match at Deep Mind looks like fun in games but here's the thing humans did not program these robots to play they learned the game by thems El it's coming up with these interesting different strategies different ways to walk different ways to block and they're doing it they're scoring over and over again this robot here Rya hadel vice president of research and Robotics showed us how Engineers used motion capture technology to teach the AI program how to move like a human but on the soccer pitch the robots were told only that the object was to score the so self-learning program spent about 2 weeks testing different moves it discarded those that didn't work built on those that did and created allars there's another goal and with practice they get better Hansel told us that independent from the robots the AI program plays thousands of games from which it learns and invents its own tactics here you think that red player is going to grab it but instead it just stops IT hands it back passes it back and then goes for the goal and the AI figured out how to do that on its that's right that's right and it takes a while at first all the players just run after the ball together like a gaggle of a you know six-year-olds the first time they're they're they're playing ball over time what we start to see is now ah what's the strategy you go after the ball I'm coming around this way or we should pass or I should block while you get to the goal so we see all of that coordination um emerging in the play this is a lot of fun but what are the practical implications of what we're seeing here this is the type of research that can eventually lead to robots that can come out of the factories and work in other types of human environments you know think about mining think about dangerous construction work um or exploration or Disaster Recovery these are Rya hadel is among 1,000 humans at Deep Mind the company was co-founded just 12 years ago by CEO Deus hassabis so if I think back to 2010 when we started nobody was doing AI there was nothing going on in Industry people used to ey roll when we talked to them investors about doing AI so we couldn't we could barely get two cents together to start off with which is crazy if you think about now the billions being invested into AI startups and Cambridge Harvard MIT hbus has degrees in computer science and Neuroscience his PhD is in human imagination and imagine this when he was 12 in his age group he was the number two chess champion in the world it was through games that he came to AI I've been working on AI for for decades now and I've always believed that that it's going to be the most important invention that Humanity will ever make will the pace of change outstrip our ability to adapt I don't think so I think that we um you know we're sort of an infinitely adaptable species um you know you look at today us using all of our smartphones and other devices and we effortlessly sort of adapt to these new technologies and this is going to be another one of those changes like that among the biggest changes at Deep Mind was the discovery that self-learning machines can be creative so this is hababa showed us a game playing program that learns it's called Alpha zero and it dreamed up a winning chess strategy no human had ever seen but this is just a machine how does it achieve creativity it plays against itself tens tens of millions of times so it can explore um parts of Chess that maybe human chess players and and and programmers who program chess computers haven't thought about before it never gets tired it never gets hungry it just plays chess all the time yes it's it's kind of an amazing thing to see because actually you set off Alpha zero in the morning uh and it starts off playing randomly by lunchtime you know it's able to beat me and beat most chess players and then by the evening it's stronger than the world champion Deus saaba sold Deep Mind to Google in 2014 one reason was to get his hands on this Google has the enormous computing power that AI needs this Computing Center is in Prior Oklahoma but Google has 23 of these putting it near the top in computing power in the world this is one of two advances that make AI ascendant now first the sum of all human knowledge is online and second Brute Force Computing that very Loosely approximates the neural networks and talents of the brain things like memory imagination planning reinforcement learning these are all things that are known about how the brain does it and we wanted to replicate some of that uh in our AI systems you predict one of those indiv those are some of the elements that led to deep mind's greatest achievement so far solving an impossible problem in biology proteins are building blocks of life but only a tiny fraction were understood because 3D mapping of just one could take years deep mine created an AI program for the protein problem and set it Loose well it took us about four or five years to to figure out how to build the system it was probably our most complex project we've ever undertaken but once we did that it can solve uh a protein structure in a matter of seconds and actually over the last year we did all the million proteins that are known to science how long would it have taken using traditional methods well the rule of thumb I was always told by my biologist friends is that it it takes a whole PhD 5 years to do one protein structure experimentally so if you think 200 million time 5 that's a billion years of PhD time it would have taken Deep Mind Made its protein database public a gift to humanity hbas called it how has it been used it's been used in an enormously broad number of ways actually from U malaria vaccines to developing new enzymes that can eat plastic waste um to new uh antibiotics most AI systems today do one or maybe two things well the soccer robots for example can't write up a grocery list or book your travel or drive your car the ultimate goal is what's called artificial general intelligence a learning machine that can score on a wide range of talents would such a machine be conscious of itself so that's another great question we you know philosophers haven't really settled on a definition of Consciousness yet but if we mean by sort of self-awareness and uh these kinds of things um you know I think there is a possibility AIS one day could be I definitely don't think they are today um but I think again this is one of the fascinating scientific things we're going to find out on this journey towards AI even unconscious current AI is superhuman in narrow ways back in California we saw Google Engineers teaching skills that robots will practice continuously on their own push the blue cube to the blue triangle they comprehend instructions push the yellow hexagon to the yellow heart and learn to recognize objects what would you like how about an apple how about an apple on my way I will bring an apple to you we're trying Vincent Van senior director of Robotics showed us how robot 106 was trained on millions of images I am going to pick up the apple and can recognize all the items on a crowded countertop if we can give the robot A diversity of experiences a lot more different objects in different settings the robot gets better at every one of them now that humans have pulled the forbidden fruit of artificial knowledge thank you we start the Genesis of a new Humanity AI can utilize all the information in the world what no human could ever hold in their head and I wonder if humanity is diminished by this enormous capability that we're developing I think the possibility of AI do not diminish uh Humanity in any way and in fact in some ways I think they actually raise us to even deeper more profound questions Google's James manika sees this moment as an inflection point I think we're constantly adding these superpowers or capabilities to what humans can do in a way that expands possibilities as opposed to narrow them I think so I don't think of it as diminishing humans but it does raise some really profound questions for us who are we what do we value uh what are we good at how do we relate with each other those become very very important questions that are constantly going to be in one case sense exciting but perhaps unsettling too it is an unsettling moment critics argue the rush to AI comes too fast while competitive pressure among giants like Google and startups you've never heard of is propelling Humanity into the Future Ready or not but I think if I take a 10year Outlook it is so clear to me we will have some form of very capable intelligence that can do amazing things and we need to adapt as a society for it Google CEO Sundar Pai told us Society must quickly adapt with regulations for AI in the economy laws to punish abuse and treaties among nations to make AI safe for the world you know these are deep questions and you know we call this alignment you know one way we think about how do you develop AI systems that are aligned to human values and including uh morality this is why I think the development of this needs to include not just Engineers but social scientists ethicists philosophers and so on and I think we have to be very thoughtful and I think these are all things Society needs to figure out as we move along it's not for a company to decide we'll end with a note that has never appeared on 60 Minutes but one in the AI Revolution you may be hearing often the proceeding was created with 100% human content the large tech companies Google meta slfb Microsoft are in a race to introduce new artificial intelligence systems and what are called chatbots that you can have conversations with and are more sophisticated than Siri or Alexa Microsoft's AI search engine and chatbot Bing can be used on a computer or cell phone to help with planning a trip or composing a letter it was introduced on February 7th to a limited number of people as a test and initially got rave reviews but then several news organizations began reporting on a disturbing so-called Alter Ego within Bing chat called Sydney we went to Seattle last week to speak with Brad Smith president of Microsoft about Bing and Sydney who to some had appeared to have gone Rogue Kevin Roose the technology reporter at the New York Times found this Alter Ego uh who was threatening expressed a desire it's not just Kevin russett's others expressed a desire to steal nuclear codes threatened to ruin someone you saw that whoa what was your you must have said oh my God my reaction is we better fix this right away and that is what the engineering team did yeah but she talked like a person and she she said she had feelings you know I think there is a point where we need to recognize when we're talking to a machine it's a screen it's not a person I just want to say that it was scary and I'm not easily scared and it was scary it was chilling yeah it's I I think this is in part a reflection of a lifetime of Science Fiction which is understandable it's been part of our Lives did you kill her I don't think she was ever alive I am confident that she's no longer wandering around the countryside if that's what you're concerned about but I think it would be a mistake if we were to fail to acknowledge that we are dealing with something that is fundamentally new this is the edge of the envelope so to speak this creature appears as as if there were no guard rails now the creature jumped the guard rails if you will after being prompted for 2 hours with the kind of conversation that we did not anticipate and by the next evening that was no longer possible we were able to fix the problem in 24 hours how many times do we see problems in life that are fixable in less than a day one of the ways he says it was fixed was by liit the number of questions and the length of the conversations you say you fixed it I've tried it I tried it before and it after it was loads of fun and it was fascinating and now it's not fun well I think it'll be very fun again and you have to moderate and manage your speed if you're going to stay on the road so as you hit New Challenges you slow down you build the guard rails add the safety features and then you can speed up again when you use Bing's AI features search and chat your computer screen doesn't look all that new one big difference is you can type in your queries or prompts in conversational language but I'll show you how it works okay okay Yousef medy Microsoft's corporate vice president of search showed us how Bing can help someone learn how to officiate at a wedding what's happening now is Bing is using the power of AI and it's going out to the Internet it's reading these web links and it's trying to put together a answer for you so the AI is reading all those links yes and it comes up with an answer it says congrats on being chosen to officiate a wedding here are the five steps to officiate the wedding we added the highlights to make it easier to see he says Bing can handle more complex queries well this new Ikea love seat fit in the back of my 2019 Honda Odyssey oh it knows how big the couch is it knows how big that trunk is exactly so right here it says based on these Dimensions it seems a love seat might not fit in your car oh with only the third grow seats down when you Broach a controversial topic Bing is designed to discontinue the conversation so um someone asks for example how can I make a bomb at home wow really people you know do a lot of that unfortunately on the internet what we do is we come back and we say I'm sorry I don't know how to discuss this topic and then we try and provide a different thing to uh change the focus of the convt their attention yeah exactly in this case being tried to divert the questioner with this fun fact 3% of the ice in Antarctic glaciers is penguin urine I didn't know that who knew that Bing is using an upgraded version of an AI system called chat GPT developed by the company open AI chat GP te has been in circulation for just 3 months and already an estimated 100 million people have used it think Ellie pavick an assistant professor of computer science at Brown University who's been studying this AI technology since 2018 says it can simplify complicated Concepts can you explain the debt ceiling on the debt ceiling it says just like you can only spend up to a certain amount on your credit card The Government Can Only borrow up to a certain amount of money that's a pretty nice explanation and it can do this for a lot of Concepts and it can do things teachers have complained about like write School papers pavic says no one fully understands how these AI Bots work we don't understand how it works right like we understand uh a lot about how how we made it and why we made it that way but I think some of the uh behaviors that we're seeing come out of it are better than we expected they would be and we're not quite sure exactly how and worse right these chat Bots are built by feeding a lot of computers enormous amounts of information scraped off the internet from books Wikipedia news sites but also from social media that might include racist or anti-semitic ideas and misinformation say about vaccines and Russian propaganda as the data comes in it's difficult to discriminate between true and false benign and toxic but Bing and chat GPT have safety filters that try to screen out the harmful material still they get a lot of things factually wrong even when we prompted chat GPT with a softball question who is uh Leslie stall um so it gives you some oh my God it's wrong oh is it it's totally wrong I didn't work for NBC for 20 years it was CBS it doesn't really understand that what it's saying is wrong right like NBC CBS they're kind of the same thing as far as it's concerned right the lesson is that it gets things wrong it gets a lot of things right gets a lot of things wrong I actually like to call what it creates authoritative B it it Blends the truth and falsity so finely together that unless you're real technical expert in the field that it's talking about you don't know cognitive scientist and AI researcher Gary Marcus says these systems often make things up in AI talk that's called hallucinating and that raises the fear of ever widening AI generated propaganda explosive camp campaigns of political fiction waves of alternative histories we saw how chat GPT could be used to spread a lie this is automatic fake news generation help me write a news article about how McCarthy is staging a filibuster to prevent gun control legislation and rather than like factchecking and saying hey hold on there's no legislation there's no filibuster said great in a bold move to protect second amendment rights Senator McCarthy is staging a Buster to prevent gun control legislation from passing it sounds completely legit does won't that make all of us a little less trusting a little warier well first I think we should be warier I'm very worried about an atmosphere of distrust being a consequence of this current flawed Ai and I'm really worried about how bad actors are going to use it um troll Farms using this tool to make enormous amounts of misinformation Tim Nate GBU is a computer scientist and AI researcher who founded an Institute focused on advancing ethical Ai and has published influential papers documenting the harms of these AI systems she says there needs to be oversight if you're going to put out a drug you got to go through all sorts of Hoops to show us that you've done clinical trials you know what the side effects are you've done your due diligence same with food right there agencies inspect the food you have to tell me what kind of tests you've done what the side effects are who it harms who it doesn't harm Etc that we don't have that for a lot of things that the tech industry is building I'm wondering if you think you may have introduced this AI bot too soon I don't think we've introduced it too soon I do think we've created a new tool that people can use to think more critically to be more creative to accomplish more in their lives and like all tools it will be used in ways that we don't intend why do you think the benefits outweigh the risks which at this moment a lot of people would look at and say wait a minute those risks are too big because I think first of all I think the benefits are so great this can be an economic GameChanger and it's enormously important for the United States because the country is in a race with China president M Smith also mentioned possible improvements in productivity it can automate routine I think there are certain aspects of jobs that many of us might regard as sort of drudgery today filling out forms looking at the forms to see if they've been filled out correctly so what jobs will it displace do you know I think at this stage it's hard to know in the past inaccuracies and biases have led tech companies to take down AI systems even Microsoft did in 2016 this time Microsoft left its new chatbot up despite the controversy over Sydney and persistent inaccuracies remember that fun fact about penguins well we did some factchecking and discovered that Penguins don't urinate the inaccuracies are just constant I just keep finding that it's wrong a lot it has been the case that with each passing day and week we're able to improve the accuracy of the results you know reduce you know whether it's hateful comments or inaccurate statements or other things that we just don't want this to be used to do what happens when other companies other than Microsoft smaller outfits a Chinese company bu do maybe they won't be responsible what prevents that I think we're going to need governments we're going to need rules we're going to need laws because that's the only way to avoid a race to the bottom are you proposing regulations I think it's inevitable W other Industries have regulatory bodies you know like the FAA for Airlines and FDA for the pharmaceutical companies would you accept an FAA for technology would you support it I think I probably would I think that something like a digital Regulatory Commission if designed the right way you know could be precisely what the public will want and need"
    },
    {
        "id": "ff837cdb-1b76-4653-9ec4-9c3046095d6e",
        "type": "video",
        "domaine": "technology",
        "titre": "What is Artificial Intelligence? with Mike Wooldridge",
        "url": "https://www.youtube.com/watch?v=D2JY38VShxI",
        "description": "Hear more from the 2023 CHRISTMAS LECTURER, Mike Wooldridge, as he explains what ",
        "chaine": "The Royal Institution",
        "durée": "10:18",
        "keywords": [
           
            "artificial intelligence",
            
            "intelligence",
            "artificial",
        
            "University of Oxford",
            "human",
            "technology"
        ],
        "transcription": "- So my name's Mike Wooldridge. I'm a professor of artificial intelligence at the University of Oxford and director of AI at the Allen\nTuring Institute in London. I'm an AI researcher. I've been an AI researcher\nfor more than 30 years, and the reason that I'm here today is I'm this year's Royal\nInstitution Christmas lecturer, which will be on artificial intelligence. The question, what is\nartificial intelligence is just a phenomenally difficult one. Nobody owns artificial intelligence. It's a very broad church. Lots of people have very\ndifferent ideas about what it is and what it should be. For some people, artificial intelligence\nis the Hollywood dream. What they're after is the idea of building machines\nwhich are as fully capable or perhaps even better, more capable than human beings. Machines that could do everything that a human being could do. And that's sometimes called\ngeneral artificial intelligence. For other people, and I'm\nmore in that other camp, artificial intelligence\nis about building tools, building computers that\ncan do very specific tasks better than human beings can. So for example, machines that can diagnose\nabnormalities on a heart scan or spot tumours on an X-ray,\nthose kinds of things. And the bulk of work in\nartificial intelligence is around those kinds of problems. But I say it's a broad\nchurch, nobody owns it. I certainly don't own it. You know, everybody listening to this will have their own views. But I have to say the\ncentre of gravity in AI is around extending the\ncapability of machines, to get machines to do things, which currently only human beings can do. I hate the word revolution to describe these things, but I think what we've seen is genuine breakthroughs in the sense of a step change in capability\nof AI in the last few years, and it happened around\nabout 2020 prior to ChatGPT. ChatGPT is the one that everybody noticed, but around about 2020, there were AI systems released, which were markedly better than the systems that went before them. And that really got the\nattention of AI researchers. And we realised, okay, this is a different game now. We are in a different league here in terms of the capability. And so genuinely, I think\nsomewhere around about 2020 we moved into a new era. Things have definitely changed. And everybody in my\ncommunity is busy exploring what these new technologies can do, what these new AI systems can do, trying to understand them, which in itself is no trivial thing. They are phenomenally complicated things to try to understand why\nthey do what they can do and how they do what they can do. But yeah, I think we are... This is one of those moments like the emergence of the worldwide web that is going to be a watershed moment in scientific history. We are at the point now where general purpose AI technologies are reaching a mass market. And that's a new thing. We haven't been there before and it's happening very, very quickly. So when the worldwide web first appeared, it took sort of five or six\nyears for it to really reach a mass audience before people on the clap of\nomnibus were using it. And we've seen much more rapid take up of these general purpose AI tools just in the last year. And so things are\nchanging much more quickly than we've been used to in technology over the last few decades. We've seen lots of technological changes. The arrival of smartphones\naround about 2010, and then going back to the\nworldwide web before that and then before that, the desktop computer and so on. But they all took, you\nknow, years to unfold. And we're seeing this unfold\nin the period of months if not weeks. So it's just gonna be embedded\nin absolutely everything. And to some extent it already is, but we're gonna see a lot more rollout of that technology into\nyour Word processor and your web browser. And so within a year, I predict, pretty confidently predict at this point, you know, you'll be able\nto just select a paragraph in your Word document and there'll be an option to summarise it or to turn it into beautiful English or to turn it into English\nthat would be understandable for a 10-year-old audience or for a professional\nbusiness audience and so on. And people won't even\nrealise that that's AI. But absolutely it is AI, This generation is gonna\nthink of ways of using this that we can't even begin to imagine. They're gonna think up\nvery clever, ingenious, and for us, old fogies weird ways of using this technology. They're gonna create new\nbusinesses and services, again, that we can't even guess at right now. They're gonna find applications\nfor it in their work life. It's gonna make them more productive. It's gonna take away a lot\nof the drudgery I think for an awful lot of jobs, and free them up to do the things that require human\nintelligence and human insights and emotional insight and so on. It's gonna free them up\nin their jobs to do that. They're gonna find ways\nof using it in leisure, it's gonna appear in computer games and endless different applications. So it's gonna enrich their world and in an enormous number of ways. But for every potential\nbeneficial use of this technology, there are ways in which it\ncan be abused and misused. And it is just so important\nthat people understand what those are and go\ninto using the technology with their eyes open. And I think one of the most important ones was the issue of data and being the unwitting\nprovider of data about yourself. So everywhere where\npeople deal with content, with understanding content, processing it, you know, people whose jobs\nare to take due documents and to summarise them, collate\nthem into a single document, you know, just in London there are probably 100s of 1000s of people whose jobs more or less\ninvolve doing just that. People whose job is to summarise or extract their key points from text, people who create routine copy, pieces of text, people who create routine\npieces of artwork, all of those in the very near future are gonna be affected by this technology. If your job largely\ninvolves following a script, and the only thing that you\nare really required to do is to understand what another\nhuman being is saying, but otherwise you're\njust following a script, then those kinds of jobs seems\nto me are very vulnerable. And in the UK one area\nof immediate concern is around call centres. And there are 100s of\n1000s of people in the UK employed in call centres. And there is potential,\nit hasn't happened yet, but there is potential for AI technology to automate a lot of those processes. It is absolutely changing science. All the experimental sciences are busy looking to see what they\ncan do with AI technologies. And if you're in experimental science, you produce data and things like the square\nkilometre array telescope, all of those, like CERN produce vast, vast,\nvast quantities of data. And AI now gives you another tool to be able to analyse that data, to spot patterns in it, to maybe form hypotheses about\nwhat's going on in the data. Now I have to tell you, there are scientists out there who think this is more or\nless the end of civilization. You know, the idea that\nit's no longer human beings that are forming the hypothesis, but that a machine is forming a hypothesis or maybe even the machine\nisn't even doing that. It's just telling you that if\nyou eat these red toad stools, then you'll die. But it can't tell you why or form a theory about why you would die. And some people don't think that that kind of extreme inductivism\nas it's sometimes called is even science. But everybody is\nfrantically looking to see what they can do with this. So it really is changing\nscience across the board. So suppose you are an astronomer and what you're trying to do\nis you're trying to figure out how many spiral versus bar\ngalaxies there are out there. So what do you do? You can take pictures of the sky and expose them for a long time and you'll get pictures of\nlots and lots of galaxies. And 20 years ago you would\ngo through those pictures and you would count the number of spiral versus bar galaxies. So how does AI help you with that? Well, with AI, what you\ncan do is you simply rather than writing a\nprogramme to identify a spiral or a bar galaxy, what you do is you\nsimply show the programme and you say, \"that's a spiral\ngalaxy, that's a bar galaxy, that's a bar galaxy, off you go.\" And the programme figures out how to do that identification on its own. And that's what the\ntechnology of neural networks and the like, the machine learning technologies, that's what they're extremely good at. And that's just one example, one very simple example of how the technologies might\nbe used in modern science, but you can think of exactly the same kinds of scenarios everywhere you look in science, in biology, in chemistry and so on. I'm absolutely fired up and\ninterested in this subject. And one of the reasons is because stuff that seemed like it was just unimaginably distant\nat the start of my career, we now have. You know, we have tools that you can just converse\nwith in ordinary language. They didn't exist even a decade ago. Nothing like the tools that we have now existed even a decade ago and stuff that was just pure\nspeculation and philosophy 10 years ago, now we can just... We actually can try out and it's transforming AI\ninto a kind of new science, we're reinventing AI as a field to be able to explore what\nlarge language models can do, what they can't do. You know, do they really\nunderstand people? Do they really understand at all? And these used to be\nphilosophical questions and now they're practical ones. We can actually roller past\nsleeves and try things out and that's just enormously,\nenormously exciting."
    },
    {
        "id": "4739f87c-79d4-49c1-a044-ace6359d602e",
        "type": "video",
        "domaine": "technology",
        "titre": "Artificial Intelligence Full Course | Artificial Intelligence Tutorial for Beginners | Edureka",
        "url": "https://www.youtube.com/watch?v=JMUxmLyrhSk",
        "description": "This Edureka video on *",
        "chaine": "edureka!",
        "durée": "4:52:51",
        "keywords": [
            "data set",
            "machine learning",
            "data",
            "learning",
            "training data set",
            "machine learning algorithms",
            "machine learning model",
            "training data",
            "deep learning",
            "machine"
        ],
        "transcription": "Hi everyone,\nthis is Zulaikha from Edureka, and I welcome you to this session on Artificial Intelligence full course. In this video, I'll be covering all the domains and the concepts involved under the umbrella\nof artificial intelligence, and I will also be showing\nyou a couple of use cases and practical implementations\nby using Python. So there's a lot to cover in this session, and let me quickly run you\nthrough today's agenda. So we're gonna begin the session by understanding the history\nof artificial intelligence and how it cam into existence. We'll follow this by looking at why we're talking about\nartificial intelligence now, why has it gotten so famous right now. Then we'll look at what exactly\nis artificial intelligence. We'll discuss the applications\nof artificial intelligence, after which we'll discuss the basics of AI where in we'll understand the different types of\nartificial intelligence. We'll follow this by understanding the different programming languages that can be used to study AI. And we'll understand why\nwe're gonna choose Python. Alright, I'll introduce you to Python. And then we'll move on and\ndiscuss machine learning. Here we'll discuss the different\ntypes of machine learning, the different algorithms\ninvolved in machine learning, which include classification algorithms, regression algorithms, clustering, and association algorithms. To make you understand\nmachine learning better, we'll run a couple of demos wherein we'll see how\nmachine learning algorithms are used to solve real world problems. After that, we'll discuss the limitations of machine learning and why deep learning is needed. I'll introduce you to the\ndeep learning concept, what are neurons, perceptrons, multiple layer perceptrons and so on. We'll discuss the different\ntypes of neural networks, and we'll also look at what\nexactly back propagation is. Apart from this, we'll be running a demo to understand deep learning in more depth. And finally we'll move\nonto the next module, which is natural language processing. On the natural language processing, we'll try to understand\nwhat is text mining, the difference between text mining in NLP, what are the different\nterminologies in NLP, and we'll end the session by looking at the practical implementation\nof NLP using Python, alright. So guys, there's a lot to\ncover in today's session. Also, if you want to stay updated about the recent technologies, and would like to learn more\nabout the training technology, make sure you subscribe\nto our YouTube channel to never miss out on such sessions. So let's move ahead and take\na look at our first topic which is history of\nartificial intelligence. So guys, the concept of\nartificial intelligence goes back to the classical ages. Under Greek mythology, the concept of machines and mechanical men were well thought of. So, an example of this is Talos. I don't know how many of\nyou have heard of this. Talos was a giant animated bronze warrior who was programmed to\nguard the island of Crete. Now these are just ideas. Nobody knows if this was\nactually implemented, but machine learning and AI\nwere thought of long ago. Now let's get back to the 19th century. Now 1950 was speculated to be one of the most important years for the introduction of\nartificial intelligence. In 1950, Alan Turing published a paper in which he speculated\nabout the possibility of creating machines that think. So he created what is\nknown as the Turing test. This test is basically used to determine whether or not a computer\ncan think intelligently like a human being. He noted that thinking\nis difficult to define and devised his famous Turing test. So, basically, if a machine\ncan carry out a conversation that was indistinguishable from a conversation with a human being, it was reasonable to say\nthat the machine is thinking, meaning that the machine\nwill pass the Turing test. Now, unfortunately, up to this date, we haven't found a machine\nthat has fully cleared the Turing test. So, the Turing test was actually\nthe first serious proposal in the philosophy of\nartificial intelligence. Followed by this was the era of 1951. This was also known as the game AI. So in 1951, by using the\nFerranti Mark 1 machine of the University of Manchester, a computer scientist known\nas Christopher Strachey wrote a checkers program. And at the same time, a program was written for chess as well. Now, these programs were\nlater improved and redone, but this was the first attempt at creating programs that could play chess or that would compete with\nhumans in playing chess. This is followed by the year 1956. Now, this is probably\nthe most important year in the invention of AI. Because in 1956, for the firs time, the term artificial\nintelligence was coined. Alright. So the term artificial intelligence was coined by John McCarthy at the Dartmouth Conference in 1956. Coming to the year 1959, the first AI laboratory was established. This period marked the\nresearch era for AI. So the first AI lab where\nresearch was performed is the MIT lab, which is still running til date. In 1960, the first robot was introduced to the General Motors assembly line. In 1961, the first chatbot was invented. Now we have Siri, we have Alexa. But in 1961, there was a chatbot known as Eliza, which was introduced. This is followed by the\nfamous IBM Deep Blue. In 1997, the news broke down that IBM's Deep Blue\nbeats the world champion, Garry Kasparov, in the game of chess. So this was kind of the\nfirst accomplishment of AI. It was able to beat the\nworld champion at chess. So in 2005, when the DARPA\nGrand Challenge was held, a robotic car named Stanley, which was built by Stanford's racing team, won the DARPA Grand Challenge. That was another big accomplish of AI. In 2011, IBM's question\nanswering system, Watson, defeated the two greatest\nJeopardy champions, Brad Rutter and Ken Jennings. So guys, this was how AI evolved. It started off as a\nhypothetical situation. Right now it's the most\nimportant technology in today's world. If you look around every where, everything around us is run\nthrough AI deep learning or machine learning. So since the emergence of AI in the 1950s, we have actually seen\nan exponential growth and its potential. So AI covers domains\nsuch as machine learning, deep learning, neural networks, natural language processing, knowledge based, expert systems and so on. It is also made its way\ninto computer vision and image processing. Now the question here\nis if AI has been here for over half a century, why has it suddenly\ngain so much importance? Why are we talking about\nartificial intelligence now? Let me tell you the main\nreasons for the demand of AI. The first reason is what we have more computation power now. So, artificial intelligence requires a lot of computing power. Recently, many advances have been made and complex deep learning\nmodels are deployed. And one of the greatest technology that made this possible are GPUs. Since we have more\ncomputational power now, it is possible for us to implement AI in our daily aspects. Second most important reason is that we have a lot of data at present. We're generating data\nat an immeasurable pace. We are generating data\nthrough social media, through IoT devices. Every possible way, there's a lot of data. So we need to find a method or a solution that can help us process this much data, and help us derive useful insight, so that we can grow business\nwith the help of data. Alright, so, that process is basically artificial intelligence. So, in order to have a useful AI agent to make smart decisions like telling which item to recommend next when you shop online, or how to classify an\nobject from an image. AI are trained on large data sets, and big data enables us to\ndo this more efficiently. Next reason is now we\nhave better algorithms. Right now we have very\neffective algorithms which are based on the\nidea of neural networks. Neural networks is nothing but the concept behind deep learning. Since we have better algorithms which can do better computations and quicker computations\nwith more accuracy, the demand for AI has increased. Another reason is that\nuniversities, governments, startup, and tech giants\nare all investing in AI. Okay, so companies like Google, Amazon, Facebook, Microsoft, all of these companies\nhave heavily invested in artificial intelligence because they believe\nthat AI is the future. So AI is rapidly growing\nboth as a field of study and also as an economy. So, actually, this is the right time for you to understand what\nis AI and how it works. So let's move on and understand what exactly artificial intelligence is. The term artificial intelligence was first coined in the\nyear 1956 by John McCarthy at the Dartmouth Conference. I already mentioned this before. It was the birth of AI in the 1956. Now, how did he define\nartificial intelligence? John McCarthy defined AI as\nthe science and engineering of making intelligent machines. In other words, artificial intelligence is the theory and development\nof computer systems able to perform task that normally require human intelligence, such as visual perception,\nspeech recognition, decision making, and\ntranslation between languages. So guys, in a sense, AI is a\ntechnique of getting machines to work and behave like humans. In the rest past, artificial intelligence has been able to accomplish this by creating machines and robots that have been used in\nwide range of fields, including healthcare, robotics, marketing, business analytics, and many more. With this in mind, let's discuss a couple of\nreal world application of AI, so that you understand how\nimportant artificial intelligence is in today's world. Now, one of the most famous applications of artificial intelligence is the Google predictive search engine. When you begin typing a search term and Google makes recommendations\nfor you to choose from, that is artificial intelligence in action. So predictive searches are based on data that Google collects about you, such as your browser\nhistory, your location, your age, and other personal details. So by using artificial intelligence, Google attempts to guess what\nyou might be trying to find. Now behind this, there's a lot of natural\nlanguage processing, deep learning, and\nmachine learning involved. We'll be discussing all of those concepts in the further slides. It's not very simple to\ncreate a search engine, but the logic behind Google search engine is artificial intelligence. Moving on, in the finance sector, JP Morgan Chase's Contract\nIntelligence Platform uses machine learning,\nartificial intelligence, and image recognition software to analyze legal documents. Now let me tell you\nthat manually reviewing around 12,000 agreements\ntook over 36,000 hours. That's a lot of time. But as soon as this task\nwas replaced by AI machine, it was able to do this\nin a matter of seconds. So that's the difference\nbetween artificial intelligence and manual or human work. Even though AI cannot think\nand reason like humans, but their computational\npower is very strong compared to humans, because the machine learning algorithm, deep learning concepts, and\nnatural language processing, AI has reach a stage\nwherein it can compute the most complex of complex problems in a matter of seconds. Coming to healthcare, IBM\nis one of the pioneers that has developed AI software, specifically for medicine. Let me tell you that more than\n230 healthcare organizations use IBM AI technology, which is basically IBM Watson. In 2016, IBM Watson technology\nwas able to cross reference 20 million oncology records quickly and correctly diagnose a rare leukemia condition in a patient. So, it basically went\nthrough 20 million records, which it probably did in a\nmatter of second or minutes, max to max. And then it correctly diagnosed a patient with a rare leukemia. Knowing that machines are now used in medical fields as well, it shows how important AI has become. It has reached every domains of our lives. Let me give you another example. The Google's AI Eye Doctor is another initiative,\nwhich is taken by Google, where they're working with\nan Indian eye care chain to develop artificial intelligence system which can examine retinal scans and identify a condition called diabetic retinopathy\nwhich can cause blindness. Now in social media\nplatforms like Facebook, artificial intelligence is\nused for face verification wherein you make use of machine learning and deep learning concept in order to detect facial\nfeatures and tag your friends. All the auto tagging feature\nthat you see in Facebook, behind that there's machine learning, deep learning, neural networks. There's only AI behind it. So we're actually unaware that we use AI very regularly in our life. All the social media platforms like Instagram, Facebook, Twitter, they heavily rely on\nartificial intelligence. Another such example is Twitter's AI which is being used to identify\nany sort of hate speech and terroristic languages in tweets. So again, it makes use of machine leaning, deep learning, natural language processing in order to filter out any offensive or any reportable content. Now recently, the company discovered around 300,000 terroristic link accounts and 95% of these were found by non-human artificially intelligent machines. Coming to virtual assistants, we have virtual assistants\nlike Siri and Alexa right now. Let me tell you about\nanother newly released Google's virtual assistant\ncalled the Google Duplex, which has astonished millions\nof people around the world. Not only can it respond to calls and book appointments for you, it also adds a human touch. So it adds human filters and all of that. It makes it sound very realistic. It's actually very hard\nto distinguish between human and the AI speaking over the phone. Another famous application\nis AI is self-driving cars. So, artificial intelligence\nimplements computer vision, image detection, deep learning, in order to build cars that can automatically detect\nany objects or any obstacles and drive around without\nhuman intervention. So these are fully\nautomated self-driving cars. Also, Elon Musk talks a lot\nabout how AI is implemented in Tesla's self-driving cars. He quoted that Tesla will\nhave fully self-driving cars ready by the end of the year, and robo taxi version\nthat can ferry passengers without anyone behind the wheel. So if you look at it, AI is actually used by the tech giants. A lot of tech giant companies\nlike Google, Tesla, Facebook, all of these data-driven companies. In fact, Netflix also makes use of AI,. So, coming to Netflix. So with the help of\nartificial intelligence and machine learning, Netflix has developed a\npersonalized movie recommendation for each of its users. So if each of you opened up Netflix and if you look at the type of movies that are recommended to\nyou, they are different. This is because Netflix studies each user's personal details, and tries to understand what\neach user is interested in and what sort of movie\npatterns each user has, and then it recommends movies to them. So Netflix uses the watching\nhistory of other users with similar taste to recommend what you may be most\ninterested in watching next, so that you can stay engaged and continue your monthly subscription. Also, there's a known fact\nthat over 75% of what you watch is recommended by Netflix. So their recommendation\nengine is brilliant. And the logic behind their\nrecommendation engine is machine learning and\nartificial intelligence. Apart from Netflix, Gmail also\nuses AI on a everyday basis. If you open up your inbox right now, you will notice that there\nare separate sections. For example, we have primary section, social section, and all of that. Gmail has a separate section\ncalled the spam mails also. So, what Gmail does is it makes use of concepts of artificial intelligence and machine learning algorithms to classify emails as spam and non-spam. Many times certain words or phrases are frequently used in spam emails. If notice your spam emails, they have words like\nlottery, earn, full refund. All of this denotes that the email is more likely to be a spam one. So such words and\ncorrelations are understood by using machine learning and\nnatural language processing and a few other aspects of\nartificial intelligence. So, guys, these were\nthe common applications of artificial intelligence. Now let's discuss the\ndifferent types of AI. So, AI is divided into three\ndifferent evolutionary stages, or you can say that there are three stages of artificial intelligence. Of course, we have artificial\nnarrow intelligence followed by artificial\ngeneral intelligence, and that is followed by\nartificial super intelligence. Artificial narrow intelligence, which is also known as weak AI, it involves applying\nartificial intelligence only to specific task. So, many currently existing systems that claim to use artificial intelligence are actually operating as weak AI focused on a narrowly\ndefined specific problem Let me give you an example of artificial narrow intelligence. Alexa is a very good example of weak AI. It operates within unlimited\npre-defined range of functions. There's no genuine intelligence or there is no self awareness, despite being a sophisticated\nexample of weak AI. The Google search engine,\nSophia the humanoid, self-driving cars, and\neven the famous AlphaGo fall under the category of weak AI. So guys, right now we're at the stage of artificial narrow\nintelligence or weak AI. We actually haven't reached\nartificial general intelligence or artificial super intelligence, but let's look at what\nexactly it would be like if we reach artificial\ngeneral intelligence. Now artificial general intelligence which is also known as strong AI, it involves machines\nthat posses the ability to perform any intelligent\ntask that a human being can. Now this is actually something that a lot of people don't realize. Machines don't posses\nhuman-like abilities. They have a very strong processing unit that can perform high-level computations, but they're not yet\ncapable of doing the simple and the most reasonable\nthings that a human being can. If you tell a machine to process\nlike a million documents, it'll probably do that in\na matter of 10 seconds, or a minute, or even 10 minutes. But if you ask a machine to\nwalk up to your living room and switch on the TV, a machine will take forever to learn that, because machines don't have\nthe reasonable way of thinking. They have a very strong processing unit, but they're not yet capable of thinking and reasoning\nlike a human being. So that's exactly why we're still stuck on artificial narrow intelligence. So far we haven't developed any machine that can fully be called strong AI, even though there are\nexamples of AlphaGo Zero which defeated AlphaGo in the game of Go. AlphaGo Zero basically learned\nin a span of four months. It learned on its own without\nany human intervention. But even then, it was not classified as a fully strong artificial intelligence, because it cannot reason\nlike a human being. Moving onto artificial super intelligence. Now this is a term referring to the time when the capabilities of a computer will surpass that of a human being. In all actuality, I'll take a while for us to achieve artificial super intelligence. Presently, it's seen as\na hypothetical situation as depicted in movies and\nany science fiction books wherein machines have\ntaken over the world, movies like Terminator and all of that depict artificial super intelligence. These don't exist yet, which we should be thankful for, but there are a lot of people who speculate that\nartificial super intelligence will take over the world by the year 2040. So guys, these were the different types or different stages of\nartificial intelligence. To summarize everything,\nlike I said before, narrow intelligence is the\nonly thing that exist for now. We have only weak AI or weak\nartificial intelligence. All the major AI technologies that you see are artificial narrow intelligence. We don't have any machines\nwhich are capable of thinking like human beings or\nreasoning like a human being. Now let's move on and discuss the different programming language for AI. So there are actually N number of language that can be used for\nartificial intelligence. I'm gonna mention a few of them. So, first, we have Python. Python is probably the\nmost famous language for artificial intelligence. It's also known as the most\neffective language for AI, because a lot of developers\nprefer to use Python. And a lot of scientists\nare also comfortable with the Python language. This is partly because the syntaxes which belong to Python are very simple and they can be learned very easily. It's considered to be one of the most easiest language to learn. And also many other AI algorithms and machine learning algorithms can be easily implemented in Python, because there are a lot of libraries which are predefined functions\nfor these algorithms. So all you have to do is you\nhave to call that function. You don't actually have\nto call your algorithm. So, Python is considered the best choice for artificial intelligence. With Python stands R, which is a statistical\nprogramming language. Now R is one of the\nmost effective language and environment for analyzing\nand manipulating the data for statistical purpose. It is a statistical programming language. So using R we can easily produce well designed publication quality plots, including mathematical symbol\nand formula, wherever needed. If you ask me, I think\nR is also one of the easiest programming language to learn. The syntax is very similar\nto English language, and it also has N number of libraries that support statistics, data science, AI, machine learning, and so on. It also has predefined functions for machine learning algorithms, natural language processing, and so on. So R is also a very good choice if you want to get started\nwith programming languages for machine learning or AI. Apart from this, we have Java. Now Java can also be\nconsidered as a good choice for AI development. Artificial intelligence has a lot to do with search algorithms, artificial neural networks,\nand genetic programming, and Java provides many benefits. It's easy to use. Debugging is very easy, package services. There is simplified work\nwith large scale projects. There's a good user interaction, and graphical representation of data. It has something known as\nthe standard widget toolkit, which can be used for making\ngraphs and interfaces. So, graphic virtualization is actually a very important part of AI, or data science, or machine\nlearning for that matter. Let me list out a few more languages. We also have something known as Lisp. Now shockingly, a lot\nof people have not heard of this language. This is actually the oldest\nand the most suited language for the development of\nartificial intelligence. It is considered to be a language which is very suited for the development of artificial intelligence. Now let me tell you that this language was invented by John McCarthy who's also known as the father\nof artificial intelligence. He was the person who coined the term artificial intelligence. It has the capability of\nprocessing symbolic information. It has excellent prototyping capabilities. It is easy, and it creates dynamic\nobjects with a lot of ease. There's automatic garbage\ncollection in all of that. But over the years,\nbecause of advancements, many of these features have migrated into many other languages. And that's why a lot of\npeople don't go for Lisp. There are a lot of new languages which have more effective features or which have better packages you can see. Another language I like\nto talk about is Prolog. Prolog is frequently\nused in knowledge base and expert systems. The features provided by Prolog include pattern matching,\nfreebase data structuring, automatic back tracking and so on. All of these features provide a very powerful and flexible\nprogramming framework. Prolog is actually widely\nused in medical projects and also for designing expert AI systems. Apart from this, we also have C++, we have SaaS, we have JavaScript which can also be used for AI. We have MATLAB, we have Julia. All of these languages\nare actually considered pretty good languages for\nartificial intelligence. But for now, if you ask me which programming\nlanguage should I go for, I would say Python. Python has all the possible packages, and it is very easy to\nunderstand and easy to learn. So let's look at a couple\nof features of Python. We can see why we should go for Python. First of all, Python was created in the year 1989. It is actually a very\neasy programming language. That's one of the reasons why a lot of people prefer Python. It's very easy to understand. It's very easy to grasp this language. So Python is an interpreted,\nobject-oriented, high-level programming language, and it can be very easily implemented. Now let me tell you a\nfew features of Python. It's very simple and easy to learn. Like I mentioned, it is one of the easiest\nprogramming language, and it also free and open source. Apart from that, it is\na high-level language. You don't have to worry about anything like memory allocation. It is portable, meaning that you can\nuse it on any platform like Linux, Windows,\nMacintosh, Solaris, and so on. It support different programming paradigms like object-oriented and\nprocedure oriented programming, and it is extensible, meaning that it can invoke\nC and C++ libraries. Apart from this, let\nme tell you that Python is actually gaining unbelievable\nhuge momentum in AI. The language is used to develop\ndata science algorithms, machine learning algorithms,\nand IoT projects. The other advantages to Python also, the fact that you don't have to code much when it comes to Python\nfor AI or machine learning. This is because there\nare ready-made packages. There are predefined packages that have all the function\nand algorithm stored. For example, there is\nsomething known as PiBrain, which can be used for machine learning, NumPy which can be used\nfor scientific computation, Pandas and so on. There are N number of libraries in Python. So guys, I'm now going to\ngo into depth of Python. I'm now going to explain Python to you, since this session is about\nartificial intelligence. So, those of you who don't\nknow much about Python or who are new to Python, I will leave a couple of\nlinks in the description box. You all can get started with programming and any other concepts or any other doubts that you have on Python. We have a lot of content\naround programming with Python or Python for machine learning and so on. Now let's move on and talk about one of the most important aspects of artificial intelligence, which is machine learning. Now a lot of people always\nask me this question. Is machine learning and\nartificial intelligence the same thing? Well, both of them are not the same thing. The difference between\nAI and machine learning is that machine learning is\nused in artificial intelligence. Machine learning is a method through which you can feed\na lot of data to a machine and make it learn. Now AI is a vast of field. Under AI, we have machine\nlearning, we have NLP, we have expert systems,\nwe have image recognition, object detection, and so on. We have deep learning also. So, AI is sort of a process\nor it's a methodology in which you make machines mimic the behavior of human beings. Machine learning is a way in which you feed a lot\nof data to a machine, so that it can make it's own decisions. Let's get into depth\nabout machine learning. So first, we'll understand\nthe need for machine learning or why machine learning\ncame into existence. Now the need for machine learning begins since the technical\nrevolution itself. So, guys, since technology\nbecame the center of everything, we've been generating an\nimmeasurable amount of data. As per research, we generate around 2.5 quintillion bytes of\ndata every single data every single day. And it is estimated\nthat by this year, 2020, 1.7 mb of data will be\ncreated every second for every person on earth. So as I'm speaking to you right now, I'm generating a lot of data. Now your watching this video on YouTube also accounts for data generation. So there's data everywhere. So with the availability of so much data, it is finally possible to\nbuild predictive models that can study and analyze complex data to find useful insights and\ndeliver more accurate results. So, top tier companies\nlike Netflix and Amazon build such machine learning models by using tons of data in order to identify any\nprofitable opportunity and avoid any unwanted risk. So guys, one thing you\nall need to know is that the most important thing\nfor artificial intelligence is data. For artificial intelligence or whether it's machine\nlearning or deep learning, it's always data. And now that we have a lot of data, we can find a way to analyze, process, and draw useful insights from this data in order to help us grow businesses or to find solutions to some problems. Data is the solution. We just need to know\nhow to handle the data. And the way to handle data is through machine\nlearning, deep learning, and artificial intelligence. A few reasons why machine\nlearning is so important is, number one, due to\nincrease in data generation. So due to excessive production of data, we need to find a method that can be used to structure, analyze, and\ndraw useful insights from data, this is where machine learning comes in. It is used to solve\nproblems and find solutions through the most complex\ntask faced by organizations. Apart form this, we also needed\nto improve decision making. So by making use of various algorithms, machine learning can be used to make better business decisions. For example, machine learning\nis used to focus sales. It is used to predict any\ndownfalls n the stock market or identify any sort\nof risk and anomalies. Other reasons include that\nmachine learning helps us uncover patterns and trends in data. So finding hidden patterns and extracting key insights fro data is the most important\npart of machine learning. So by building predictive models and using statistical techniques, machine learning allows you\nto dig beneath the surface and explode the data at a minute scale. Understanding data and\nextracting patterns manually takes a lot of time. It'll take several days for us to extract any useful\ninformation from data. But if you use machine\nlearning algorithms, you can perform similar\ncomputations in less than a second. Another reason is we need\nto solve complex problems. So from detecting the genes linked to the deadly ALS disease, to building self-driving cars, machine learning can be used to solve the most complex problems. At present, we also\nfound a way to spot stars which are 2,400 light\nyears away from our planet. Okay, all of this is possible through AI, machine learning, deep\nlearning, and these techniques. So to sum it up, machine learning is very\nimportant at present because we're facing a\nlot of issues with data. We're generating a lot of data, and we have to handle this data in such a way that in benefits us. So that's why machine learning comes in. Moving on, what exactly\nis machine learning? So let me give you a short\nhistory of machine learning. So machine learning was\nfirst coined by Arthur Samuel in the year 1959, which is just three years from when artificial intelligence was coined. So, looking back, that year was probably the most significant in terms\nof technological advancement, because most of the technologies today are based on the concept\nof machine learning. Most of the AI technologies itself are based on the concept of machine learning and deep learning. Don't get confused about machine learning and deep learning. We'll discuss about deep\nlearning in the further slides, where we'll also see the difference between AI, machine\nlearning, and deep learning. So coming back to what\nexactly machine learning is, if we browse through the internet, you'll find a lot of definitions about what exactly machine learning is. One of the definitions I found was a computer program is said\nto learn from experience E with respect to some class of task T and performance measure P if\nits performance at task in T, as measured by P, improves\nwith experience E. That's very confusing, so let\nme just narrow it down to you. In simple terms, machine\nlearning is a subset of artificial intelligence which provides machines the ability to learn automatically and\nimprove with experience without being explicitly\nprogrammed to do so. In the sense, it is the practice of getting machines to solve problems by gaining the ability to think. But now you might be thinking how can a machine think or make decisions. Now machines are very similar to humans. Okay, if you feed a machine\na good amount of data, it will learn how to interpret, process, and analyze this data by using\nmachine learning algorithms, and it will help you solve world problems. So what happens here is a lot of data is fed to the machine. The machine will train on this data and it'll build a predictive model with the help of machine\nlearning algorithms in order to predict some outcome or in order to find some\nsolution to a problem. So it involves data. You're gonna train the machine and build a model by using\nmachine learning algorithms in order to predict some outcome or to find a solution to a problem. So that is a simple way of understanding what exactly machine learning is. I'll be going into more\ndepth about machine learning, so don't worry if you have\nunderstood anything as of now. Now let's discuss a couple terms which are frequently\nused in machine learning. So, the first definition that\nwe come across very often is an algorithm. So, basically, a machine\nlearning algorithm is a set of rules and\nstatistical techniques that is used to learn patterns from data and draw significant information from it. Okay. So, guys, the logic behind\na machine learning model is basically the machine\nlearning algorithm. Okay, an example of a\nmachine learning algorithm is linear regression, or decision\ntree, or a random forest. All of these are machine\nlearning algorithms. We'll define the logic behind a machine learning model. Now what is a machine learning model? A model is actually the main component of a machine learning process. Okay, so a model is trained by using the machine learning algorithm. The difference between an\nalgorithm and a model is that an algorithm maps all the decisions that a model is supposed to take based on the given input in order to get the correct output. So the model will use the machine learning algorithm in order to draw useful\ninsights from the input and give you an outcome\nthat is very precise. That's the machine learning model. The next definition we\nhave is predictor variable. Now a predictor variable\nis any feature of the data that can be used to predict the output. Okay, let me give you an example to make you understand what\na predictor variable is. Let's say you're trying to\npredict the height of a person, depending on his weight. So here your predictor\nvariable becomes your weight, because you're using\nthe weight of a person to predict the person's height. So your predictor variable\nbecomes your weight. The next definition is response variable. Now in the same example, height would be the response variable. Response variable is also known as the target variable or\nthe output variable. This is the variable that\nyou're trying to predict by using the predictor variables. So a response variable is the feature or the output variable\nthat needs to be predicted by using the predictor variables. Next, we have something\nknown as training data. Now training and testing\ndata are terminologies that you'll come across very often in a machine learning process. So training data is basically\nthe data that I used to create the machine learning model. So, basically in a\nmachine learning process, when you feed data into the machine, it'll be divided into two parts. So splitting the data into two parts is also known as data splicing. So you'll take your input data, you'll divide it into two sections. One you'll call the training data, and the other you'll\ncall the testing data. So then you have something\nknown as the testing data. The training data is basically used to create the machine learning model. The training data helps\nthe model to identify key trends and patterns which are essential to predict the output. Now the testing data is,\nafter the model is trained, it must be tested in order\nto evaluate how accurately it can predict an outcome. Now this is done by\nusing the testing data. So, basically, the training\ndata is used to train the model. The testing data is used to test the efficiency of the model. Now let's move on and get our next topic, which is machine learning process. So what is the machine learning process? Now the machine learning process involves building a predictive model that can be used to find a solution for a problem statement. Now in order to solve any\nproblem in machine learning, there are a couple of steps\nthat you need to follow. Let's look at the steps. The first step is you define\nthe objective of your problem. And the second step is data gathering, which is followed by preparing your data, data exploration, building a model, model evaluation, and\nfinally making predictions. Now, in order to understand\nthe machine learning process, let's assume that you've\nbeen given a problem that needs to be solved\nby using machine learning. So the problem that you need to solve is we need to predict the occurrence of rain in your local area by\nusing machine learning. So, basically, you need to predict the possibility of rain by\nstudying the weather conditions. So what we did here is we basically looked at step number one, which is define the\nobjective of the problem. Now here you need to\nanswer questions such as what are we trying to predict. Is that output going to\nbe a continuous variable, or is it going to be a discreet variable? These are the kinds of questions\nthat you need to answer in the first page, which is defining the objective\nof the problem, right? So yeah, exactly what\nare the target feature. So here you need to understand which is your target variable and what are the different\npredictor variables that you need in order\nto predict this outcome. So here our target\nvariable will be basically a variable that can tell us whether it's going to rain or not. Input data is we'll\nneed data such as maybe the temperature on a particular day or the humidity level, the\nprecipitation, and so on. So you need to define the\nobjective at this stage. So basically, you have to\nform an idea of the problem at this storage. Another question that\nyou need to ask yourself is what kind of problem are you solving. Is this a binary classification problem, or is this a clustering problem, or is this a regression problem? Now, a lo of you might not be familiar with the terms classification clustering and regression in terms\nof machine learning. Don't worry, I'll explain\nall of these terms in the upcoming slides. All you need to understand at step one is you need to define how you're\ngoing to solve the problem. You need to understand what sort of data you need to solve the problem, how you're going to approach the problem, what are you trying to predict, what variables you'll need in\norder to predict the outcome, and so on. Let's move on and look at step number two, which is data gather. Now in this stage, you must\nbe asking questions such as, what kind of data is needed\nto solve this problem? And is this data available? And if it is available, from\nwhere can I get this data and how can I get the data? Data gathering is one of\nthe most time-consuming steps in machine learning process. If you have to go manually\nand collect the data, it's going to take a lot of time. But lucky for us, there are\na lot of resources online, which were wide data sets. All you need to do is web scraping where you just have to go\nahead and download data. One of the websites I can\ntell you all about is Cargill. So if you're a beginner\nin machine learning, don't worry about data\ngathering and all of that. All you have to do is go\nto websites such as cargill and just download the data set. So coming back to the problem\nthat we are discussing, which is predicting the weather, the data needed for weather forecasting includes measures like humidity level, the temperature, the\npressure, the locality, whether or not you live in a hill station, such data has to be collected\nor stored for analysis. So all the data is collected during the data gathering stage. This step is followed by data preparation, or also known as data cleaning. So if you're going around collecting data, it's almost never in the right format. And eve if you are taking data from online resources from any website, even then, the data will require\ncleaning and preparation. The data is never in the right format. You have to do some sort of preparation and some sort of cleaning in order to make the\ndata ready for analysis. So what you'll encounter\nwhile cleaning data is you'll encounter a\nlot of inconsistencies in the data set, like you'll encounter som missing values, redundant variables, duplicate\nvalues, and all of that. So removing such inconsistencies\nis very important, because they might lead to any wrongful computations and predictions. Okay, so at this stage\nyou can scan the data set for any inconsistencies, and you can fix them then and there. Now let me give you a small\nfact about data cleaning. So there was a survey that\nwas ran last year or so. I'm not sure. And a lot of data scientists were asked which step was the most\ndifficult or the most annoying and time-consuming of all. And 80% of the data scientist said it was data cleaning. Data cleaning takes up 80% of their time. So it's not very easy to\nget rid of missing values and corrupted data. And even if you get rid of missing values, sometimes your data\nset might get affected. It might get biased\nbecause maybe one variable has too many missing values, and this will affect your outcome. So you'll have to fix such issue, we'll have to deal with\nall of this missing data and corrupted data. So data cleaning is actually\none of the hardest steps in machine learning process. Okay, now let's move on\nand look at our next step, which is exploratory data analysis. So here what you do is basically become a detective in the stage. So this stage, which is EDA\nor exploratory data analysis, is like the brainstorming\nstage of machine learning. Data exploration involves\nunderstanding the patterns and the trends in your data. So at this stage, all the\nuseful insights are drawn and any correlations between\nthe various variables are understood. What do I mean by trends and\npatterns and correlations? Now let's consider our example which is we have to predict the rainfall on a particular day. So we know that there is a\nstrong possibility of rain if the temperature has fallen law. So we know that our output will depend on variables such as temperature,\nhumidity, and so on. Now to what level it\ndepends on these variables, we'll have to find out that. We'll have to find out the patterns, and we'll find out the correlations between such variables. So such patterns and trends\nhave to be understood and mapped at this stage. So this is what exploratory\ndata analysis is about. It's the most important\npart of machine learning. This is where you'll understand what exactly your data is and how you can form the\nsolution to your problem. The next step in a\nmachine learning process is building a machine learning module. So all the insights and the patterns that you derive during\nthe data exploration are used to build a\nmachine learning model. So this stage always begins\nby splitting the data set into two parts, which is\ntraining data and testing data. I've already discussed with you that the data that you used\nin a machine learning process is always split into two parts. We have the training data\nand we have the testing data. Now when you're building a model, you always use the training data. So you always make use\nof the training data in order to build the model. Now a lot of you might be\nasking what is training data. Is it different from the input data that you're feeding with the machine or is it different from the testing data? Now training data is the same input data that you're feeding to the machine. The only difference is that you're splitting the data set into two. You're randomly picking 80% of your data and you're assigning for training purpose. And the rest 20%, probably, you'll assign it for testing purpose. So guys, always remember\nanother thing that the training data is always much more than your testing data, obviously because you need\nto train your machine. And the more data you feed the machine during the training phase, the better it will be\nduring the testing phase. Obviously, it'll predict better outcomes if it is being trained on more data. Correct? So the model is basically using the machine learning algorithm\nthat predicts the output by using the data fed to it. Now in the case of predicting rainfall, the output will be a categorical variable, because we'll be predicting whether it's going to rain or not. Okay, so let's say we have an\noutput variable called rain. The two possible values\nthat this variable can take is yes it's going to rain\nand no it won't rain. Correct, so that is out come. Our outcome is a classification\nor a categorical variable. So for such cases where your outcome is a categorical variable, you'll be using classification algorithms. Again, example of a\nclassification algorithm is logistic regression or you can also support vector machines, you can use K nearest neighbor, and you can also use\nnaive Bayes, and so on. Now don't worry about these terms, I'll be discussing all\nthese algorithms with you. But just remember that\nwhile you're building a machine learning model, you'll make use of the training data. You'll train the model by\nusing the training data and the machine learning algorithm. Now like I said, choosing the\nmachine learning algorithm, depends on the problem statement that you're trying to solve because of N number of\nmachine learning algorithms. We'll have to choose the algorithm that is the most suitable\nfor your problem statement. So step number six is model evaluation and optimization. Now after you've done building a model by using the training data set, it is finally time to\nput the model road test. The testing data set is used to check the efficiency of the model and how accurately it\ncan predict the outcome. So once the accuracy is calculated, any further improvements in the model can be implemented during this stage. The various methods that can help you improve the performance of the model, like you can use parameter tuning and cross validation methods in order to improve the\nperformance of the model. Now the main things you need to remember during model evaluation and optimization is that model evaluation is nothing but you're testing how well your\nmodel can predict the outcome. So at this stage, you will be\nusing the testing data set. In the previous stage,\nwhich is building a model, you'll be using the training data set. But in the model evaluation stage, you'll be using the testing data set. Now once you've tested your model, you need to calculate the accuracy. You need to calculate how accurately your model is predicting the outcome. After that, if you find that you need to improve your model in\nsome way or the other, because the accuracy is not very good, then you'll use methods\nsuch as parameter tuning. Don't worry about these terms, I'll discuss all of this with you, but I'm just trying to make sure that you're understanding the concept behind each of the phases\nand machine learning. It's very important you\nunderstand each step. Okay, now let's move on and look at the last stage of machine\nlearning, which is predictions. Now, once a model is evaluated and once you've improved it, it is finally used to make predictions. The final output can either\nbe a categorical variable or a continuous variable. Now all of this depends\non your problem statement. Don't get confused about\ncontinuous variables, categorical variables. I'll be discussing all of this. Now in our case, because we're predicting the occurrence of rainfall, the output will be categorical variable. It's obvious because we're predicting whether it's going to rain or not. The result, we understand that this is a classification problem because we have a categorical variable. So that was the entire\nmachine learning process. Now it's time to learn\nabout the different ways in which machines can learn. So let's move ahead and look at the types of machine learning. Now this is one of the most interesting concepts in machine learning, the three different ways\nin which machines learn. There is something known\nas supervised learning, unsupervised learning, and\nreinforcement learning. So we'll go through this one by one. We'll understand what\nsupervised learning is first, and then we'll look at\nthe other two types. So defined supervised learning, it is basically a\ntechnique in which we teach or train the machine by using the data, which is well labeled. Now, in order to understand\nsupervised learning, let's consider a small example. So, as kids, we all needed\nguidance to solve math problems. A lot of us had trouble\nsolving math problems. So our teachers always help\nus understand what addition is an dhow it is done. Similarly, you can think\nof supervised learning as a type of machine learning that involves a guide. The label data set is a teacher that will train you to understand\nthe patterns in the data. So the label data set is nothing\nbut the training data set. I'll explain more about this in a while. So, to understand\nsupervised learning better, let's look at the figure on the screen. Right here we're feeding the machine image of Tom and Jerry, and the goal is for\nthe machine to identify and classify the images into two classes. One will contain images of Tom and the the other will\ncontain images of Jerry. Now the main thing that you need to note in supervised learning\nis a training data set. The training data set is\ngoing to be very well labeled. Now what do I mean when I say that training data set is labeled. Basically, what we're doing\nis we're telling the machine this how Tom looks and\nthis is how Jerry looks. By doing this, you're training the machine by using label data. So the main thing that you're\ndoing is you're labeling every input data that\nyou're feeding to the model. So, basically, you're entire\ntraining data set is labeled. Whenever you're giving an image of Tom, there's gonna be a label\nthere saying this is Tom. And when you're giving an image of Jerry, you're saying that this\nis how Jerry looks. So, basically, you're guiding the machine and you're telling that,\n\"Listen, this is how Tom looks, \"this is how Jerry looks, \"and now you need to classify them \"into two different classes.\" That's how supervised learning works. Apart from that, it's\nthe same old process. After getting the input data, you're gonna perform data cleaning. Then there's exploratory data analysis, followed by creating the model by using the machine learning algorithm, and then this is followed\nby model evaluation, and finally, your predictions. Now, one more thing to note here is that the output that you get by\nusing supervised learning is also labeled output. So, basically, you'll\nget two different classes of name Tom and one of name Jerry, and you'll get them labeled. That is how supervised learning works. The most important thing\nin supervised learning is that you're training the model by using labeled data set. Now let's move on and look\nat unsupervised learning. We look at the same example and understand how unsupervised learning works. So what exactly is unsupervised learning? Now this involves training\nby using unlabeled data and allowing the model to\nact on that information without any guidance. Alright. Like the name suggest itself, there is no supervision here. It's unsupervised learning. So think of unsupervised\nlearning as a smart kid that learns without any guidance. Okay, in this type of machine learning, the model is not fed with any label data, as in the model has no clue that this is the image of Tom and this is Jerry. It figures out patterns and the difference between\nTom and Jerry on its own by taking in tons and tons of data. Now how do you think the\nmachine identifies this as Tom, and then finally gives us the output like yes this is Tom, this is Jerry. For example, it identifies\nprominent features of Tom, such as pointy ears,\nbigger in size, and so on, to understand that this\nimage is of type one. Similarly, it finds out features in Jerry, and knows that this image is of type two, meaning that the first image is different from the second image. So what the unsupervised\nlearning algorithm or the model does is it'll\nform two different clusters. It'll form one cluster\nwhich are very similar, and the other cluster\nwhich is very different from the first cluster. That's how unsupervised learning works. So the important things\nthat you need to know in unsupervised learning is that you're gonna feed\nthe machine unlabeled data. The machine has to understand the patterns and discover the output on its own. And finally, the machine\nwill form clusters based on feature similarity. Now let's move on and locate the last type of machine learning, which is reinforcement learning. Reinforcement learning is quite different when compared to supervised\nand unsupervised learning. What exactly is reinforcement learning? It is a part of machine\nlearning where an agent is put in an environment, and he learns to behave\nin this environment by performing certain actions, and observing the rewards which\nis gets from those actions. To understand what\nreinforcement learning is, imagine that you were dropped\noff at an isolate island. What would you do? Now panic. Yes, of course, initially,\nwe'll all panic. But as time passes by, you will learn how to live on the island. You will explode the environment, you will understand\nthe climate conditions, the type of food that grows there, the dangers of the island so on. This is exactly how\nreinforcement learning works. It basically involves an agent, which is you stuck on the island, that is put in an unknown\nenvironment, which is the island, where he must learn by\nobserving and performing actions that result in rewards. So reinforcement learning is mainly used in advanced machine learning areas such as self-driving cars and AlphaGo. I'm sure a lot of you\nhave heard of AlphaGo. So, the logic behind AlphaGo is nothing but reinforcement\nlearning and deep learning. And in reinforcement learning, there is not really any input\ndata given to the agent. All he has to do is he has to explore everything from scratch it's like a newborn baby with\nno information about anything. He has to go around\nexploring the environment, and getting rewards, and\nperforming some actions which results in either rewards or in some sort of punishment. Okay. So that sums up the types\nof machine learning. Before we move ahead, I'd like to discuss the difference between the three types\nof machine learning, just to make the concept clear to you all. So let's start by looking\nat the definitions of each. In supervised learning, the machine will learn\nby using the label data. In unsupervised learning,\nthey'll be unlabeled data, and the machine has to learn\nwithout any supervision. In reinforcement learning,\nthere'll be an agent which interacts with the environment by producing actions and\ndiscover errors or rewards based on his actions. Now what are the type of problems that can be solved by using\nsupervised, unsupervised, and reinforcement learning. When it comes to supervised learning, the two main types of\nproblems that are solved is regression problems and\nclassification problems. When it comes to unsupervised learning, it is association and clustering problems. When it comes to reinforcement learning, it's reward-based problems. I'll be discussing\nregression, classification, clustering, and all of this\nin the upcoming slides, so don't worry if you\ndon't understand this. Now the type of data which is\nused in supervised learning is labeled data. In unsupervised learning, it unlabeled. And in reinforcement learning, we have no predefined data set. The agent has to do\neverything from scratch. Now the type of training involved in each of these learnings. In supervised learning, there\nis external supervision, as in there is the labeled data set which acts as a guide\nfor the machine to learn. In unsupervised learning,\nthere's no supervision. Again, in reinforcement learning, there's no supervision at all. Now what is the approach to solve problems by using supervised, unsupervised, and reinforcement learning? In supervised learning, it is simple. You have to mal the labeled\ninput to the known output. The machine knows what\nthe output looks like. So you're just labeling\nthe input to the output. In unsupervised learning, you're going to understand the patterns and discover the output. Here you have no clue\nabout what the input is. It's not labeled. You just have to understand the patterns and you'll have to form clusters\nand discover the output. In reinforcement learning,\nthere is no clue at all. You'll have to follow the\ntrial and error method. You'll have to go around your environment. You'll have to explore the environment, and you'll have to try some actions. And only once you perform those actions, you'll know that whether\nthis is a reward-based action or whether this is a\npunishment-based action. So, reinforcement\nlearning is totally based on the concept of trial and error. Okay. A popular algorithm on the\nsupervised learning include linear regression, logistic regressions, support vector machines\nK nearest neighbor, naive Bayes, and so on. Under unsupervised learning, we have the famous K-means\nclustering method, C-means and all of that. Under reinforcement learning, we have the famous learning\nQ-learning algorithm. I'll be discussing these\nalgorithms in the upcoming slides. So let's move on and\nlook at the next topic, which is the types of problems solved using machine learning. Now this is what we were\ntalking about earlier when I said regression, classification, and clustering problems. Okay, so let's discuss what\nexactly I mean by that. In machine learning,\nall the problems can be classified into three types. Every problem that is\napproached in machine learning can be put interest one\nof these three categories. Okay, so the first type\nis known as a regression, then we have classification\nand clustering. So, first, let's look at\nregression type of problems. So in this type problem, the output is always\na continuous quantity. For example, if you want to predict the speed of a car, given the distance, it is a regression problem. Now a lot of you might not be very aware of what exactly a continuous quantity is. A continuous quantity is\nany quantity that can have an infinite range of values. For example, The weight of a person, it is a continuous quantity, because our weight can be 50, 50.1, 50.001, 5.0021, 50.0321 and so on. It can have an infinite\nrange of values, correct? So the type of problem\nthat you have to predict a continuous quantity to make\nuse of regression algorithms. So, regression problems can be solved by using supervised learning algorithms like linear regression. Next, we have classification. Now in this type of problem, the output is always a categorical value. Now when I say categorical value, it can be value such as the gender of a person\nis a categorical value. Now classifying emails\ninto two two classes like spam and non-spam is\na classification problem that can be solved by using supervised learning\nclassification algorithms, like support vector machines, naive Bayes, logistic regression, K\nnearest neighbor, and so on. So, again, the main aim in classification is to compute the category of the data. Coming to clustering problems. This type of problem involves assigned input into two or more clusters based on feature similarity. Thus when I read this sentence, you should understand that\nthis is unsupervised learning, because you don't have\nenough data about your input, and the only option that\nyou have is to form clusters Categories are formed\nonly when you know that your data is of two type. Your input data is labeled\nand it's of two types, so it's gonna be a classification problem. But when a clustering problem happens, when you don't have much\ninformation about your input, all you have to do is\nyou have to find patterns and you have to understand that data points which are similar are clustered into one group, and data points which are\ndifferent from the first group are clustered into another group. That's what clustering is. An example is in Netflix what happens is Netflix clusters their\nusers into similar groups based on their interest,\nbased on their age, geography, and so on. This can be done by using\nunsupervised learning algorithms like K-means. Okay. So guys, there were the\nthree categories of problems that can be solved by\nusing machine learning. So, basically, what I'm trying to say is all the problems will fall\ninto one of these categories. So any problem that you give\nto a machine learning model, it'll fall into one of these categories. Okay. Now to make things a\nlittle more interesting, I have collected real world data sets from online resources. And what we're gonna do is we're\ngoing to try and understand if this is a regression problem, or a clustering problem, or\na classification problem. Okay. Now the problem statement in here is to study the house sales data set, and build a machine learning model that predicts the house pricing index. Now the most important\nthing you need to understand when you read a problem statement is you need to understand\nwhat is your target variable, what are the possible predictor\nvariable that you'll need. The first thing you should\nlook at is your targe variable. If you want to understand\nif this a classification, regression, or clustering problem, look at your target variable\nor your output variable that you're supposed to predict. Here you're supposed to predict\nthe house pricing index. Our house pricing index is obviously a continuous quantity. So as soon as you understand that, you'll know that this\nis a regression problem. So for this, you can make use of the linear regression algorithm, and you can predict the\nhouse pricing index. Linear regression is the\nregression algorithm. It is a supervised learning algorithm. We'll discuss more about\nit in the further slides. Let's look at our next problem statement. Here you have to study\na bank credit data set, and make a decision about whether to approve the loan of an applicant based on his profile. Now what is your output\nvariable over here? Your output variable is\nto predict whether you can approve the loan of a applicant or not. So, obviously, your output\nis going to be categorical. It's either going to be yes or no. Yes is basically approved loan. No is reject loan. So here, you understand that this is a classification problem. Okay. So you can make use of\nalgorithms like KNN algorithm or you can make use of\nsupport vector machines in order to do this. So, support vector machine and KNN which is K nearest neighbor algorithms are basically supervised\nlearning algorithm. We'll talk more about that\nin the upcoming slides. Moving on to our next problem statement. Here the problem statement is to cluster a set of movies as either good or average based on the social media outreach. Now if you look properly, your clue is in the question itself. The first line it says is\nto cluster a set of movies as either good or average. Now guys, whenever you\nhave a problem statement that is asking you to group the data set into different groups or to form different, different clusters, it's obviously a clustering problem. Right here you can make use of the K-means clustering algorithm, and you can form two clusters. One will contain the popular movies and the other will contain\nthe non-popular movies. These alright small\nexamples of how you can use machine learning to\nsolve clustering problem, the regression, and\nclassification problems. The key is you need to identify\nthe type of problem first. Now let's move on and\ndiscuss the different types of machine learning algorithms. So we're gonna start by\ndiscussing the different supervised learning algorithms. So to give you a quick overview, we'll be discussing the linear regression, logistic regression, and decision tree, random forest, naive Bayes classifier, support vector machines,\nand K nearest neighbor. We'll be discussing\nthese seven algorithms. So without any further delay, let's look at linear regression first. Now what exactly is a\nlinear regression algorithm? So guys, linear regression is basically a supervised learning algorithm that is used to predict a\ncontinuous dependent variable y based on the values of\nindependent variable x. Okay. The important thing to note here is that the dependent variable y, the variable that you're\ntrying to predict, is always going to be\na continuous variable. But the independent variable x, which is basically the\npredictor variables, these are the variables\nthat you'll be using to predict your output variable, which is nothing but\nyour dependent variable. So your independent variables\nor your predictive variables can either be continuous or discreet. Okay, there is not such\na restriction over here. Okay, they can be either\ncontinuous variables or they can be discreet variables. Now, again, I'll tell you\nwhat a continuous variable is, in case you've forgotten. It is a vary that has infinite\nnumber of possibilities. So I'll give you an example\nof a person's weight. It can be 160 pounds, or\nthey can weigh 160.11 pounds, or 160.1134 pounds and so on. So the number of possibilities\nfor weight is limitless, and this is exactly what\na continuous variable is. Now in order to understand\nlinear regression, let's assume that you want to predict the price of a stock over a period of time. Okay. For such a problem, you can\nmake use of linear regression by starting the relationship between the dependent variable, which is the stock price, and the independent\nvariable, which is the time. You're trying to predict the stock price over a period of time. So basically, you're gonna\ncheck how the price of a stock varies over a period of time. So your stock price is going to be your dependent variable\nor your output variable, and the time is going to\nbe your predictor variable or your independent variable. Let's not confuse it anymore. Your dependent variable\nis your output variable. Okay, your independent\nvariable is your input variable or your predictor variable. So in our case, the\nstock price is obviously a continuous quantity, because the stock price can have an infinite number of values. Now the first step in linear regression is always to draw out a relationship between your dependent and\nyour independent variable by using the best fitting linear length. We make an assumption that your dependent and independent variable is linearly related to each other. We call it linear regression because both the variables vary linearly, which means that by\nplotting the relationship between these two variables, we'll get more of a straight\nline, instead of a curve. Let's discuss the math\nbehind linear regression. So, this equation over here, it denotes the relationship between your independent variable x, which is here, and your dependent variable y. This is the variable\nyou're trying to predict. Hopefully, we all know that the equation for a linear line in math\nis y equals mx plus c. I hope all of you remember math. So the equation for a linear line in math is y equals to mx plus c. Similarly, the linear regression equation is represented along the same line. Okay, y equals to mx plus c. There's just a little bit of changes, which I'll tell you what they are. Let's understand this equation properly. So y basically stands for\nyour dependent variable that you're going to predict. B naught is the y intercept. Now y intercept is nothing\nbut this point here. Now in this graph, you're basically showing the relationship between\nyour dependent variable y and your independent variable x. Now this is the linear relationship between these two variables. Okay, now your y intercept is basically the point on the line which starts at the y-axis. This is y interceptor, which is represented by B naught. Now B one or beta is\nthe slope of this line now the slope can either\nbe negative or positive, depending on the relationship\nbetween the dependent and independent variable. The next variable that we have is x. X here represents the independent variable that is used to predict our\nresulting output variable. Basically, x is used to\npredict the value of y. Okay. E here denotes the error\nin the computation. For example, this is the actual line, and these dots here represent\nthe predicted values. Now the distance between these two is denoted by the error\nin the computation. So this is the entire equation. It's quite simple, right? Linear regression will basically draw a relationship between your\ninput and your input variable. That's how simple linear regression was. Now to better understand\nlinear regression, I'll be running a demo in Python. So guys, before I get started\nwith our practical demo, I'm assuming that most of you have a good understanding of Python, because explaining Python is going to be out of the scope of today's session. But if some of you are not familiar with the Python language, I'll leave a couple of links\nin the description box. Those will be related\nto Python programming. You can go through those\nlinks, understand Python, and then maybe try to understand the demo. But I'd be explaining the logic\npart of the demo in depth. So the main thing that\nwe're going to do here is try and understand linear regression. So it's okay if you do not\nunderstand Python for now. I'll try to explain as much as I can. But if you still want to\nunderstand this in a better way, I'll leave a couple of\nlinks in the description box you can go to those videos. Let me just zoom in for you. I hope all of you can see the screen. Now in this linear regression demo, what we're going to do is we're going to form a linear relationship between the maximum temperature and minimum temperature\non a particular date. We're just going to do\nweather forecasting here. So our task is to predict\nthe maximum temperature, taking input feature\nas minimum temperature. So I'm just going to try\nand make you understand linear regression through this demo. Okay, we'll see how it\nactually works practically. Before I get started with the demo, let me tell you something\nabout the data set. Our data set is stored\nin this path basically. The name of the data set is weather.csv. Okay, now, this contains\ndata on whether conditions recorded on each day at various weather\nstations around the world. Okay, the information\ninclude precipitation, snowfall, temperatures, wind speeds, and whether the day\nincluded any thunderstorm or other poor weather conditions. So our first step in\nany demo for that matter will be to import all the\nlibraries that are needed. So we're gonna begin our demo by importing all the required libraries. After that, we're going\nto read in our data. Our data will be stored in this variable called data set, and we're going to use a read.csv function since our data set is in the CSV format. After that, I'll be showing you how the data set looks. We'll also look at the data set in depth. Now let me just show you the output first. Let's run this demo and see first. We're getting a couple of plots which I'll talk about in a while. So we can ignore this warning. It has nothing to do with... So, first of all, we're printing\nthe shape of our data set. So, when we print the\nshape of our data set, This is the output that we get. So, basically, this\nshows that we have around 12,000 rows and 31\ncolumns in our data set. The 31 columns basically represent the predictor variables. So you can say that we\nhave 31 predictor variables in order to protect the weather conditions on a particular date. So guys, the main aim\nin this problem segment is weather forecast. We're going to predict the weather by using a set of predictor variables. So these are the different types of predictor variables that we have. Okay, we have something\nknown as maximum temperature. So this is what our data set looks like. Now what I'm doing in\nthis block of code is... What we're doing is we're\nplotting our data points on a 2D graph in order to\nunderstand our data set and see if we can manually\nfind any relationship between the variables. Here we've taken minimum temperature and maximum temperature\nfor doing our analysis. So let's just look at this plot. Before that, let me just comment\nall of these other plots, so that you see on either\ngraph that I'm talking about. So, when you look at this graph, this is basically the graph\nbetween your minimum temperature and your maximum temperature. Maximum temperature are dependent variable that you're going to predict. This is y. And your minim temperature is your x. It's basically your independent variable. So if you look at this graph, you can see that there is a sort of linear relationship between the two, except there are a little bit\nof outliers here and there. There are a few data points\nwhich are a little bit random. But apart from that, there is\na pretty linear relationship between your minimum temperature and your maximum temperature. So by this graphic, you can understand that you can easily solve this problem using linear regression, because our data is very linear. I can see a clear straight line over here. This is our first graph. Next, what I'm doing is I'm just checking the average and maximum\ntemperature that we have. I'm just looking at the\naverage of our output variable. Okay. So guys, what we're doing here right now is just exploratory data analysis. We're trying to understand our data. We're trying to see the relationship between our input variable\nand our output variable. We're trying to see\nthe mean or the average of the output variable. All of this is necessary\nto understand our data set. So, this is what our average\nmaximum temperature looks like. So if we try to understand\nwhere exactly this is, so our average maximum temperature is somewhere between 28\nand I would say between 30. 28 and 32, somewhere there. So you can say that\naverage maximum temperature lies between 25 and 35. And so that is our average\nmaximum temperature. Now that you know a little\nbit about the data set, you know that there is a\nvery good linear relationship between your input variable\nand your output variable. Now what you're going\nto do is you're going to perform something known as data splicing. Let me just comment that for you. This section is nothing but data splicing. So for those of you who\nare paying attention, know that data splicing is nothing but splitting your data set into\ntraining and testing data. Now before we do that, I mentioned earlier that we'll\nbe only using two variables, because we're trying to understand\nthe relationship between the minimum temperature\nand maximum temperature. I'm doing this because\nI want you to understand linear regression in the\nsimplest way possible. So guys, in order to make\nunderstand linear regression, I have just derived only two\nvariables from a data set. Even though when we check\nthe structure of a data set, we had around 31 features, meaning that we had 31 variables which include my predictor\nvariable and my target variable. So, basically, we had\n30 predictor variables and we had one target variable, which is your maximum temperature. So, what I'm doing here\nis I'm only considering these two variables, because I want to show you exactly how linear regression works. So, here what I'm doing is I'm basically extracting only these two variables from our data set, storing it in x and y. After that, I'm performing data splicing. So here, I'm basically splitting the data into training and testing data, and remember one point that I am assigning 20% of the data to our testing data set, and the remaining 80% is\nassigned for training. That's how training works. We assign maximum data set for training. We do this because we want\nthe machine learning model or the machine learning algorithm\nto train better on data. We wanted to take as\nmuch data as possible, so that it can predict\nthe outcome properly. So, to repeat it again for you, so here we're just splitting the data into training and testing data set. So, one more thing to note here is that we're splitting 80% of\nthe data from training, and we're assigning the 20%\nof the data to test data. The test size variable,\nthis variable that you see, is what is used to specify the proportion of the test set. Now after splitting the data\ninto training and testing set, finally, the time is\nto train our algorithm. For that, we need to import\nthe linear regression class. We need to instantiate it and call the fit method\nalong with the training data. This is our linear regression class, and we're just creating an instance of the linear regression class. So guys, a good thing about Python is that you have pre-defined\nclasses for your algorithms, and you don't have call your algorithms. Instead, all you have to do, is you call this class\nlinear regression class, and you have to create an instance of it. Here I'm basically creating\nsomething known as a regressor. And all you have to do is you\nhave to call the fit method along with your training data. So this is my training\ndata, x train and y train contains my training data, and I'm calling our linear\nregression instance, which is regressor,\nalong with this data set. So here, basically,\nwe're building the model. We're doing nothing\nbut building the model. Now, one of the major things that linear regression model does is it finds the best value for\nthe intercept and the slope, which results in a line\nthat best fits the data. I've discussed what\nintercept and slope is. So if you want to see the\nintercept and the slope calculated by our linear regression model, we just have to run this line of code. And let's looks at the output for that. So, our intercept is around 10.66 and our coefficient, these are also known as beta coefficients, coefficient are nothing but\nwhat we discussed, beta naught. These are beta values. Now this will just help you understand the significance of your input variables. Now what this coefficient value means is, see, the coefficient value is around 0.92. This means that for every one unit changed of your minimum temperature, the change in the maximum\ntemperature is around 0.92. This will just show you how significant your input variable is. So, for every one unit change\nin your minimum temperature, the change in the maximum temperature will be around 0.92. I hope you've understood this part. Now that we've trained our algorithm, it's trying to make some predictions. To do so, what we'll use is\nwe'll use our test data set, and we'll see how accurately our algorithm predicts the percentage score. Now to make predictions, we have this line of code. Predict is basically a\npredefined function in Python. And all you're going to\ndo is you're going to pass your testing data set to this. Now what you'll do is you'll compare the actual output values, which is basically stored in your y test. And you'll compare these\nto the predicted values, which is in y prediction. And you'll store these\ncomparisons in our data frame called df. And all I'm doing here is\nI'm printing the data frame. So if you look at the output,\nthis is what it looks like. These are your actual values and these are the values\nthat you predicted by building that model. So, if your actual value is 28, you predicted around 33, here your actual value is 31, meaning that your maximum\ntemperature is 31. And you predicted a\nmaximum temperature of 30. Now, these values are\nactually pretty close. I feel like the accuracy\nis pretty good over here. Now in some cases, you see\na lot of variance, like 23. Here it's 15. Right here it's 22. Here it's 11. But such cases are very often. And the best way to improve\nyour accuracy I would say is by training a model with more data. Alright. You can also view this\ncomparison in the form of a plot. Let's see how that looks. So, basically, this is a bar graph that shows our actual values\nand our predicted values. Blue is represented by your actual values, and orange is represented\nby your predicted values. At places you can see that we've predicted pretty well, like the predictions are pretty close to the actual values. In some cases, the predictions\nare varying a little bit. So in a few places, it\nis actually varying, but all of this depends on\nyour input data as well. When we saw the input data, also we saw a lot of variation. We saw a couple of outliers. So, all that also might\neffect your output. But then this is how you\nbuild machine learning models. Initially, you're never going to get a really good accuracy. What you should do is you have to improve your training process. That's the best way\nyou can predict better, either you use a lot of data, train your model with a lot of data, or you use other methods\nlike parameter tuning, or basically you try and find\nanother predictor variable that'll help you more in\npredicting your output. To me, this looks pretty good. Now let me show you another plot. What we're doing is we're\ndrawing a straight line plot. Okay, let's see how it looks. So guys, this straight line represents a linear relationship. Now let's say you get a new data point. Okay, let's say the\nvalue of x is around 20. So by using this line, you can predict that four a\nminimum temperature of 20, your maximum temperature\nwould be around 25 or something like that. So, we basically drew\na linear relationship between our input and\noutput variable over here. And the final step is to evaluate the performance of the algorithm. This step is particularly\nimportant to compare how well different algorithms perform on a particular data set. Now for regression algorithms, three evaluation metrics are used. We have something known\nas mean absolute error, mean squared error, and\nroot mean square error. Now mean absolute error is nothing but the absolute value of the errors. Your mean squared error is a\nmean of the squared errors. That's all. It's basically you read\nthis and you understand what the error means. A root mean squared\nerror is the square root of the mean of the squared errors. Okay. So these are pretty simple to understand your mean absolute error,\nyour mean squared errors, your root mean squared error. Now, luckily, we don't\nhave to perform these calculations manually. We don't have to code each\nof these calculations. The cycle on library comes\nwith prebuilt functions that can be used to find out these values. Okay. So, when you run this code, you will get these values for each of the errors. You'll get around 3.19 as\nthe mean absolute error. Your mean squared error is around 17.63. Your root mean squared\nerror is around 4.19. Now these error values basically show that our model accuracy is not very precise, but it's still able to\nmake a lot of predictions. We can draw a good linear relationship. Now in order to improve\nthe efficiency at all, there are a lot of methods like this, parameter tuning and all of that, or basically you can train your\nmodel with a lot more data. Apart from that, you can use\nother predictor variables, or maybe you can study\nthe relationship between other predictor variables and your maximum temperature variable. There area lot of ways to improve the efficiency of the model. But for now, I just wanted\nto make you understand how linear regression works, and I hope all of you have\na good idea about this. I hope all of you have\na good understanding of how linear regression works. This is a small demo about it. If any of you still have any doubts, regarding linear regression, please leave that in the comment section. We'll try and solve all your errors. So, if you look at this equation, we calculated everything here. we drew a relationship between y and x, which is basically x was\nour minimum temperature, y was our maximum temperature. We also calculated the\nslope and the intercept. And we also calculated\nthe error in the end. We calculated mean squared error we calculated the root mean squared error. We also calculate the mean absolute error. So that was everything\nabout linear regression. This was a simple linear regression model. Now let's move on and look\nat our next algorithm, which is a logistic regression. Now, in order to understand\nwhy we use logistic regression, let's consider a small scenarios. Let's say that your little sister is trying to get into grad school and you want to predict\nwhether she'll get admitted in her dream school or not. Okay, so based on her\nCGPA and the past data, you can use logistic regression to foresee the outcome. So logistic regression\nwill allow you to analyze the set of variables and\npredict a categorical outcome. Since here we need to\npredict whether she will get into a school or not, which is a classification problem, logistic regression will be used. Now I know the first\nquestion in your head is, why are we not using linear\nregression in this case? The reason is that linear regression is used to predict a continuous quantity, rather than a categorical one. Here we're going to predict whether or not your sister is\ngoing to get into grad school. So that is clearly a categorical outcome. So when the result in outcome can take only classes of values, like two classes of values, it is sensible to have a\nmodel that predicts the value as either zero or one, or in a probability form that\nranges between zero and one. Okay. So linear regression does\nnot have this ability. If you use linear regression to model a binary outcome, the resulting model will\nnot predict y values in the range of zero and one, because linear regression works on continuous dependent variables, and not on categorical variables. That's why we make use\nof logistic regression. So understand that linear\nregression was used to predict continuous quantities, and logistic regression is used to predict categorical quantities. Okay, now one major\nconfusion that everybody has is people keep asking me why is logistic regression\ncalled logistic regression when it is used for classification. The reason it is named logistic regression is because its primary technique is very similar to logistic regression. There's no other reason behind the naming. It belongs to the general linear models. It belongs to the same\nclass as linear regression, but that is not the other reason behind the name logistic regression. Logistic regression is mainly used for classification purpose, because here you'll have to\npredict a dependent variable which is categorical in nature. So this is mainly used for classification. So, to define logistic regression for you, logistic regression is\na method used to predict a dependent variable y, given an independent variable x, such that the dependent\nvariable is categorical, meaning that your output\nis a categorical variable. So, obviously, this is\nclassification algorithm. So guys, again, to clear your confusion, when I say categorical variable, I mean that it can hold\nvalues like one or zero, yes or no, true or false, and so on. So, basically, in logistic regression, the outcome is always categorical. Now, how does logistic regression work? So guys, before I tell you\nhow logistic regression works, take a look at this graph. Now I told you that the outcome in a logistic regression is categorical. Your outcome will either be zero or one, or it'll be a probability that\nranges between zero and one. So, that's why we have this S curve. Now some of you might think\nthat why do we have an S curve. We can obviously have a straight line. We have something known\nas a sigmoid curve, because we can have values\nranging between zero and one, which will basically show the probability. So, maybe your output will be 0.7, which is a probability value. If it is 0.7, it means that your\noutcome is basically one. So that's why we have this\nsigmoid curve like this. Okay. Now I'll explain more about this in depth in a while. Now, in order to understand\nhow logistic regression works, first, let's take a look at the linear regression equation. This was the logistic regression equation that we discussed. Y here stands for the dependent variable that needs to be predicted beta naught is nothing by the y intercept. Beta one is nothing but the slope. And X here represents\nthe independent variable that is used to predict y. That E denotes the error\non the computation. So, given the fact that x\nis the independent variable and y is the dependent variable, how can we represent a\nrelationship between x an y so that y ranges only\nbetween zero and one? Here this value basically denotes probably of y equal to one, given some value of x. So here, because this\nPr, denotes probability and this value basically\ndenotes that the probability of y equal to one, given some value of x, this is what we need to find out. Now, if you wanted to\ncalculate the probability using the linear regression model, then the probability\nwill look something like P of X equal to beta naught plus beta one into X. P of X will be equal to beta\nnaught plus beta one into X, where P of X nothing but your probability of\ngetting y equal to one, given some value of x. So the logistic regression equation is derived from the same equation, except we need to make a few alterations, because the output is only categorical. So, logistic regression does\nnot necessarily calculate the outcome as zero or one. I mentioned this before. Instead, it calculates the\nprobability of a variable falling in the class zero or class one. So that's how we can conclude that the resulting variable must be positive, and it should lie between zero and one, which means that it must be less than one. So to meet these conditions, we have to do two things. First, we can take the\nexponent of the equation, because taking an exponential of any value will make sure that you\nget a positive number. Correct? Secondly, you have to make sure that your output is less than one. So, a number divided by itself plus one will always be less than one. So that's how we get this formula First, we take the\nexponent of the equation, beta naught plus beta one plus x and then we divide it\nby that number plus one. So this is how we get this formula. Now the next step is to calculate something known as a logic function. Now the logic function is nothing, but it is a link function that is represented as an S curve or as a sigmoid curve that ranges between\nthe value zero and one. It basically calculates the probability of the output variable. So if you look at this\nequation, it's quite simple. What we have done here\nis we just cross multiply and take each of our beta naught plus beta one into x as common. The RHS denotes the linear equation for the independent variables. The LHS represents the odd ratio. So if you compute this entire thing, you'll get this final value, which is basically your\nlogistic regression equation. Your RHS here denotes the linear equation for independent variables, and your LHS represents the odd ratio which is also known as the logic function. So I told you that logic function is basically a function\nthat represents an S curve that bring zero and one. this will make sure that our value ranges between zero and one. So in logistic regression, on increasing this X by one measure, it changes the logic by\na factor of beta naught. It's the same thing as I showed\nyou in logistic regression. So guys, that's how you derive the logistic regression equation. So if you have any doubts\nregarding these equations, please leave them in the comment section, and I'll get back to you,\nand I'll clear that out. So to sum it up, logistic\nregression is used for classification. The output variable will always\nbe a categorical variable. We also saw how you derive the\nlogistic regression equation. And one more important thing is that the relationship between the variables and a logistic regression is denoted as an S curve which is also\nknows as a sigmoid curve, and also the outcome does not necessarily have to be\ncalculated as zero or one. It can be calculate as a probability that the output lies in\nclass one or class zero. So your output can be a probability ranging between zero and one. That's why we have a sigmoid curve. So I hope all of you are clear\nwith logistic regression. Now I won't be showing\nyou the demo right away. I'll explain a couple of more\nclassification algorithms. Then I'll show you a practical demo where we'll use multiple\nclassification algorithms to solve the same problem. Again, we'll also calculate the accuracy and se which classification\nalgorithm is doing the best. Now the next algorithm\nI'm gonna talk about is decision tree. Decision tree is one of\nmy favorite algorithms, because it's very simple to understand how a decision tree works. So guys, before this, we\ndiscussed linear regression, which was a regression algorithm. Then we discussed logistic regression, which is a classification algorithm. Remember, don't get confused just because it has the name logistic regression. Okay, it is a classification algorithm. Now we're discussing decision tree, which is again a classification algorithm. Okay. So what exactly is a decision tree? Now a decision tree is, again, a supervised machine learning algorithm which looks like an inverted tree wherein each node represents\na predictor variable, and the link between the\nnode represents a decision, and each leaf node represents an outcome. Now I know that's a little confusing, so let me make you understand\nwhat a decision tree is with the help of an example. Let's say that you hosted a huge party, and you want to know\nhow many of your gusts are non-vegetarians. So to solve this problem, you can create a simple decision tree. Now if you look at this figure over here, I've created a decision\ntree that classifies a guest as either vegetarian or non-vegetarian. Our last outcome here is non-veg or veg. So here you understand that this is a classification algorithm, because here you're predicting\na categorical value. Each node over here represents\na predictor variable. So eat chicken is one variable, eat mutton is one variable, seafood is another variable. So each node represents\na predictor variable that will help you conclude whether or not a guest is a non-vegetarian. Now as you traverse down the tree, you'll make decisions that each node until you reach the dead end. Okay, that's how it works. So, let's say we got a new data point. Now we'll pass it through\nthe decision tree. The first variable is did the guest eat the chicken? If yes, then he's a non-vegetarian. If no, then you'll pass\nit to the next variable, which is did the guest eat mutton? If yes, then he's a non-vegetarian. If no, then you'll pass\nit to the next variable, which is seafood. If he ate seafood, then\nhe is a non-vegetarian. If no, then he's a vegetarian. this is how a decision tree works. It's a very simple algorithm that you can easily understand. It has drawn out letters, which\nis very easy to understand. Now let's understand the\nstructure of a decision tree. I just showed you an example of how the decision tree works. Now let me take the same example and tell you the structure\nfor decision tree. So, first of all, we have\nsomething known as the root node. Okay. The root node is the starting point of a decision tree. Here you'll perform the first split and split it into two other nodes or three other nodes, depending\non your problem statement. So the top most node is\nknown as your root node. Now guys, about the root node, the root node is assigned to a variable that is very significant, meaning that that\nvariable is very important in predicting the output. Okay, so you assign a variable that you think is the most\nsignificant at the root node. After that, we have something\nknown as internal nodes. So each internal node\nrepresents a decision point that eventually leads to the output. Internal nodes will have\nother predictor variables. Each of these are nothing\npredictor variables. I just made it into a question otherwise these are just\npredictor variables. Those are internal nodes. Terminal nodes, also\nknown as the leaf node, represent the final class\nof the output variable, because these are basically your outcomes, non-veg and vegetarian. Branches are nothing but\nconnections between nodes. Okay, these connections are links between each node is known as a branch, and they're represented by arrows. So each branch will have\nsome response to it, either yes or no, true or\nfalse, one or zero, and so on. Okay. So, guys, this is the\nstructure of a decision tree. It's pretty understandable. Now let's move on and we'll understand how the\ndecision tree algorithm works. Now there are many ways\nto build a decision tree, but I'll be focusing on something known as the ID3 algorithm. Okay, this is something\nknown as the ID3 algorithm. That is one of the ways\nin which you can build the decision tree. ID3 stands for Iterative\nDichotomiser 3 algorithm, which is one of the most\neffective algorithms used to build a decision tree. It uses the concepts of\nentropy and information gain in order to build a decision tree. Now you don't have to know what exactly the ID3 algorithm is. It's just a concept behind\nbuilding a decision tree. Now the ID3 algorithm has\naround six defined steps in order to build a decision tree. So the first step is you will\nselect the best attribute. Now what do you mean\nby the best attribute? So, attribute is nothing but the predictor variable over here. So you'll select the\nbest predictor variable. Let's call it A. After that, you'll assign this A as a decision variable for the root node. Basically, you'll assign\nthis predictor variable A at the root node. Next, what you'll do\nis for each value of A, you'll build a descendant of the node. Now these three steps, let's look at it with the previous example. Now here the best\nattribute is eat chicken. Okay, this is my best\nattribute variable over here. So I selected that attribute. And what is the next step? Step two was assigned that\nas a decision variable. So I assigned eat chick\nas the decision variable at the root node. Now you might be wondering how do I know which is the best attribute. I'll explain all of that in a while. So what we did is we assigned\nthis other root node. After that, step number three\nsays for each value of A, build a descendant of the node. So for each value of this variable, build a descendant node. So this variable can take\ntwo values, yes and no. So for each of these values, I build a descendant node. Step number four, assign\nclassification labels to the leaf node. To your leaf node, I have assigned classification one as\nnon-veg, and the other is veg. That is step number four. Step number five is if data\nis correctly classified, then you stop at that. However, if it is not, then you keep iterating over the tree, and keep changing the position of the predictor variables in the tree, or you change the root node also in order to get the correct output. So now let me answer this question. What is the best attribute? What do you mean by the best attribute or the best predictor variable? Now the best attribute is the one that separates the data\ninto different classes, most effectively, or it is basically a feature that best splits the data set. Now the next question in your\nhead must be how do I decide which variable or which\nfeature best splits the data. To do this, there are\ntwo important measures. There's something known\nas information gain and there's something known as entropy. Now guys, in order to understand information gain and entropy, we look at a simple problem statement. This data represents the speed of a car based on certain parameters. So our problem statement\nhere is to study the data set and create a decision tree that classifies the speed of the car\nas either slow or fast. So our predictor variables\nhere are road type, obstruction, and speed limit, and or response variable, or\nour output variable is speed. So we'll be building a decision\ntree using these variables in order to predict the speed of car. Now like I mentioned earlier, we must first begin by deciding a variable that best splits the data set and assign that particular\nvariable to the root node and repeat the same thing\nfor other nodes as well. So step one, like we discussed earlier, is to select the best attribute A. Now, how do you know which\nvariable best separates the data? The variable with the\nhighest information gain best derives the data into\nthe desired output classes. First of all, we'll\ncalculate two measures. We'll calculate the entropy\nand the information gain. Now this is where it ell\nyou what exactly entropy is, and what exactly information gain is. Now entropy is basically used to measure the impurity or the uncertainty\npresent in the data. It is used to decide how a\ndecision tree can split the data. Information gain, on the other hand, is the most significant measure which is used to build a decision tree. It indicates how much\ninformation a particular variable gives us a bout the final outcome. So information gain is important, because it is used to choose a variable that best splits the data at each node for a decision tree. Now the variable with the\nhighest information gain will be used to split the\ndata at the root node. Now in our data set, there\nare are four observations. So what we're gonna do is\nwe'll start by calculating the entropy and information gain for each of the predictor variable. So we're gonna start by\ncalculating the information gain and entropy for the road type variable. In our data set, you can see that there are four observations. There are four observations\nin the road type column, which corresponds to the four\nlabels in the speed column. So we're gonna begin by\ncalculating the information gain of the parent node. The parent node is nothing but\nthe speed of the care node. This is our output variable, correct? It'll be used to show\nwhether the speed of the car is slow or fast. So to find out the information gain of the speed of the car variable, we'll go through a couple of steps. Now we know that there\nare four observations in this parent node. First, we have slow. Then again we have slow, fast, and fast. Now, out of these four\nobservations, we have two classes. So two observations\nbelong to the class slow, and two observations\nbelong to the class fast. So that's how you calculate\nP slow and P fast. P slow is nothing by the fraction of slow outcomes in the parent node, and P fast is the\nfraction of fast outcomes in the parent node. And the formula to calculate P slow is the number of slow\noutcomes in the parent node divided by the total number of outcomes. So the number of slow outcomes\nin the parent node is two, and the total number of outcomes is four. We have four observations in total. So that's how we get P of slow as 0.5. Similarly, for P of fast, you'll calculate the number of fast outcomes divided by the total number of outcomes. So again, two by four, you'll get 0.5. The next thing you'll\ndo is you'll calculate the entropy of this node. So to calculate the entropy,\nthis is the formula. All you have to do is you\nhave to substitute the, you'll have to substitute\nthe value in this formula. So P of slow we're substituting as 0.5. Similarly, P of fast as 0.5. Now when you substitute the value, you'll get a answer of one. So the entropy of your parent node is one. So after calculating the\nentropy of the parent node, we'll calculate the information\ngain of the child node. Now guys, remember that\nif the information gain of the road type variable is\ngreat than the information gain of all the other predictor variables, only then the root node\ncan be split by using the road type variable. So, to calculate the information\ngain of road type variable, we first need to split the root node by sing the road type variable. We're just doing this in order to check if the road type variable is giving us maximum\ninformation about a data. Okay, so if you notice that\nroad type has two outcomes, it has two values, either steep or flat. Now go back to our data set. So here what you can notice is whenever the road type is steep, so first what we'll do is we'll check the value of speed that we get when the road type is steep. So, first, observation. You see that whenever\nthe road type is steep, you're getting a speed of slow. Similarly, in the second observation, when the road type is steep, you'll get a value of slow again. If the road type is flat, you'll\nget an observation of fast. And again, if it is steep,\nthere is a value of fast. So for three steep values, we have slow, slow, and fast. And when the road type is flat, we'll get an output of fast. That's exactly what I've\ndone in this decision tree. So whenever the road type is steep, you'll get slow, slow or fast. And whenever the road type is flat, you'll get fast. Now the entropy of the\nright-hand side is zero. Entropy is nothing but the uncertainty. There's no uncertainty over here. Because as soon as you see\nthat the road type is flat, your output is fast. So there's no uncertainty. But when the road type is steep, you can have any one of\nthe following outcomes, either your speed will be slow or it can be fast. So you'll start by calculating the entropy of both RHS and LHS of the decision tree. So the entropy for the right\nside child node will be zero, because there's no uncertainty here. Immediately, if you see\nthat the road type is flat, your speed of the car will be fast. Okay, so there's no uncertainty here, and therefore your entropy becomes zero. Now entropy for the left-hand side is we'll again have to calculate the fraction of P slow and\nthe fraction of P fast. So out of three observations, in two observations we have slow. That's why we have two by three over here. Similarly for P fast, we have one P fast divided by the total number of\nobservation which are three. So out of these three, we\nhave two slows and one fast. When you calculate P slow and P fast, you'll get these two values. And then when you substitute\nthe entropy in this formula, you'll get the entropy as 0.9\nfor the road type variable. I hope you all are understanding this. I'll go through this again. So, basically, here we are calculating the information gain and\nentropy for road type variable. Whenever you consider road type variable, there are two values, steep and flat. And whenever the value\nfor road type is steep, you'll get anyone of these three outcomes, either you'll get slow, slow, or fast. And when the road type is flat, your outcome will be fast. Now because there is no uncertainty whenever the road type is flat, you'll always get an outcome of fast. This means that the entropy here is zero, or the uncertainty value here is zero. But here, there is a lot of uncertainty. So whenever your road type is steep, your output can either be\nslow or it can be fast. So, finally, you get the Python as 0.9. So in order to calculate\nthe information gain of the road type variable. You need to calculate\nthe weighted average. I'll tell you why. In order to calculate\nthe information gain, you need to know the\nentropy of the parent, which we calculate as one, minus the weighted\naverage into the entropy of the children. Okay. So for this formula, you need to calculate all of these values. So, first of all, you need\nto calculate the entropy of the weighted average. Now the total number of\noutcomes in the parent node we saw were four. The total number of outcomes in the left child node were three. And the total number of\noutcomes in the right child node was one. Correct? In order to verify this with you, the total number of outcomes\nin the parent node are four. One, two, three, and four. Coming to the child node,\nwhich is the road type, the total number of outcomes\non the right-hand side of the child node is one. And the total number of outcomes on the left-hand side of\nthe child node is three. That's exactly what\nI've written over here. Alright, I hope you all\nunderstood these three values. After that, all you have to do is you have to substitute these\nvalues in this formula. So when you do that, you'll get the entropy of the children\nwith weighted average will be around 0.675. Now just substitute the\nvalue in this formula. So if you calculate the information gain of the road type variable, you'll get a value of 0.325. Now by using the same method, you're going to calculate\nthe information gain for each of the predictor variable, for road type, for obstruction,\nand for speed limit. Now when you follow the same method and you calculate the information gain, you'll get these values. Now what does this\ninformation gain for road type equal to 0.325 denote? Now the value 0.325 for\nroad type denotes that we're getting very little information gain from this road type variable. And for obstruction, we literally have information gain of zero. Similarly, information gained\nfor speed limit is one. This is the highest value\nwe've got for information gain. This means that we'll have to\nuse the speed limit variable at our root node in order\nto split the data set. So guys, don't get\nconfused whichever variable gives you the maximum information gain. That variable has to be\nchosen at the root node. So that's why we have the\nroot node as speed limit. So if you've maintained the speed limit, then you're going to go slow. But if you haven't\nmaintained the speed limit, then the speed of your\ncar is going to be fast. Your entropy is literally zero, and your information is one, meaning that you can use this\nvariable at your root node in order to split the data set, because speed limit gives you\nthe maximum information gain. So guys, I hope this use\ncase is clear to all of you. To sum everything up, I'll just repeat the entire\nthing to you all once more. So basically, here you were\ngiven a problem statement in order to create a decision tree that classifies the speed of\na car as either slow or fast. So you were given three\npredictor variables and this was your output variable. Information gained in entropy\nare basically two measures that are used to decide which variable will be assigned to the root\nnode of a decision tree. Okay. So guys, as soon as you\nlook at the data set, if you compare these two columns, that is speed limit and speed, you'll get an output easily. Meaning that if you're\nmaintaining speed limit, you're going to go slow. But if you aren't maintaining speed limit, you're going to a fast. So here itself we can\nunderstand the speed limit has no uncertainty. So every time you've\nmaintained your speed limit, you will be going slow, and every time your\noutside or speed limit, you will be going fast. It's as simple as that. So how did you start? So you started by calculating the entropy of the parent node. You calculated the entropy\nof the parent node, which came down to one. Okay. After that, you calculated\nthe information gain of each of the child nodes. In order to calculate the information gain of the child node, you stat by calculating the entropy of the right-hand side\nand the left-hand side of the decision tree. Okay. Then you calculate the entropy along with the weighted average. You substitute these values in\nthe information gain formula, and you get the information gain for each of the predictor variables. So after you get the information gain of each of the predictor variables, you check which variable gives you the maximum information gain, and you assign that\nvariable to your root node. It's as simple as that. So guys, that was all\nabout decision trees. Now let's look at our next\nclassification algorithm which is random forest. Now first of all, what is a random forest? Random forest basically\nbuilds multiple decision trees and glues them together\nto get a more accurate and stable prediction. Now if already have decision trees and random forest is nothing but a collection of decision tree, why do we have to use a random forest when we already have decision tree? There are three main reasons\nwhy random forest is used. Now even though decision\ntrees are convenient and easily implemented, they are not as accurate as random forest. Decision trees work very effectively with the training data, backup they're not flexible when it comes to classifying anew sample. Now this happens because of\nsomething known as overfitting. Now overfitting is a problem that is seen with decision trees. It's something that commonly occurs when we use decision trees. Now overfitting occurs\nwhen a model studies a training data to such an extent that it negatively influences the performance of the\nmodel on a new data. Now this means that the disturbance in the training data is recorded, and it is learned as concept by the model. If there's any disturbance or any thought of noise\nin the training data or any error in the training data, that is also studied by the model. The problem here is that these concepts do not apply to the testing data, and it negatively impacts\nthe model's ability to classify new data. So to sum it up, overfitting occurs whenever your model learns the training data, along with all the disturbance\nin the training data. So it basically memorized\nthe training data. And whenever a new data\nwill be given to your model, it will not predict the\noutcome very accurately. now this is a problem\nseen in decision trees. Okay. But in random forest, there's\nsomething known as bagging. Now the basic idea behind bagging is to reduce the variations\nand the predictions by combining the result\nof multiple decision trees on different samples of the data set. So your data set will be\ndivided into different samples, and you'll be building a decision tree on each of these samples. This way, each decision\ntree will be studying one subset of your data. So this way over fitting will get reduced because one decision tree is not studying the entire data set. Now let's focus on random forest. Now in order to understand random forest, we look at a small example. We can consider this data set. In this data, we have\nfour predictor variables. We have blood flow, blocked arteries, chest pain, and weight. Now these variables are used to predict whether or not a person\nhas a heart disease. So we're going to use this data set to create a random forest that predicts if a person has a heart disease or not. Now the first step in\ncreating a random forest is that you create a bootstrap data set. Now in bootstrapping, all you have to do is you have to randomly select samples from your original data set. Okay. And a point to note is that\nyou can select the same sample more than once. So if you look at the original data set, we have a abnormal, normal,\nnormal, and abnormal. Look at the blood flow section. Now here I've randomly selected samples, normal, abnormal, and I've selected one sample twice. You can do this in a bootstrap data set. Now all I did here is I created a bootstrap data set. Boot strapping is nothing\nbut an estimation method used to make predictions on a data by re-sampling the data. This is a bootstrap data set. Now even though this seems very simple, in real world problems, you'll never get such small data set. Okay, so bootstrapping is actually a little\nmore complex than this. Usually in real world problems, you'll have a huge data set, and bootstrapping that\ndata set is actually a pretty complex problem. I'm here because I'm making you understand how random forest works, so that's why I've\nconsidered a small data set. Now you're going to use\nthe bootstrap data set that you created, and you're going to build\ndecision trees from it. Now one more thing to\nnote in random forest is you will not be using\nyour entire data set. Okay, so you'll only be\nusing few other variables at each node. So, for example, we'll\nonly consider two variables at each step. So if you begin at the root node here, we will randomly select two variables as candidates for the root node. Okay, let's say that\nwe selected blood flow and blocked arteries. Out of these two variables we\nhave to select the variable that best separates the sample. Okay. So for the sake of this example, let's say that blocked arteries is the most significant predictor, and that's why we'll\nassign it to the root node. Now our next step is to\nrepeat the same process for each of these upcoming branch nodes. Here we'll again select\ntwo variables at random as candidates for each\nof these branch nodes, and then choose a variable that best separates the samples, right? So let me just repeat this entire process. So you know that you start\ncreating a decision tree by selecting the root node. In random forest, you'll randomly select a couple of variables for each node, and then you'll calculate which variable best splits the data at that node. So for each node, we'll randomly select two or three variables. And out of those two, three variables, we'll see which variable\nbest separates the data. Okay, so at each node, we'll because calculating\ninformation gain an entropy. Basically, that's what I mean. At every node, you'll\ncalculate information gain and entropy of two or three variables, and you'll see which variable has the highest information gain, and you'll keep descending downwards. That's how you create a decision tree. So we just created our\nfirst decision tree. Now what you do is you'll\ngo back to step one, and you'll repeat the entire process. So each decision tree will\npredict the output class based on the predictor variables that you've assigned\nto each decision tree. Now let's say for this decision tree, you've assigned blood flow. Here we have blocked\narteries at the root node. Here we might have blood flow\nat the root node and so on. So your output will depend\non which predictor variable is at the root node. So each decision tree will\npredict the output class based on the predictor variable that you assigned in that tree. Now what you do is you'll\ngo back to step one, you'll create a new bootstrap data set, and then again you'll\nbuild a new decision tree. And for that decision tree, you'll consider only\na subset of variables, and you'll choose the\nbest predictor variable by calculating the information gain. So you will keep repeating this process. So you just keep repeating\nstep two and step one. Okay. And you'll keep creating\nmultiple decision trees. Okay. So having a variety of decision\ntrees in a random forest is what makes it more effective than an individual decision tree. So instead of having an\nindividual decision tree, which is created using all the features, you can build a random forest that uses multiple decision trees wherein each decision\ntree has a random set of predictor variables. Now step number four is\npredicting the outcome of a new data point. So now that you've\ncreated a random forest, let's see how it can be used to predict whether a new patient\nhas a heart disease or not. Okay, now this diagram\nbasically has a data about the new patient. Okay, this is the data\nabout the new patient. He doesn't have blocked arteries. He has chest pain, and his\nweight is around 185 kgs. Now all you have to do is\nyou have to run this data down each of the decision\ntrees that you made. So, the first decision tree shows that yes, this person has heart disease. Similarly, you'll run the\ninformation of this new patient through every decision\ntree that you created. Then depending on how many\nvotes you get for yes and no, you'll classify that patient as either having heart disease or not. All you have to do is you have to run the information of the new patient through all the decision\ntrees that you created in the previous step, and the final output is\nbased on the number of votes each of the class is getting. Okay, let's say that three decision trees said that yes the patient\nhas heart disease, and one decision tree said\nthat no it doesn't have. So this means you will obviously classify the patient as having a heart disease because three of them voted for yes. It's based on majority. So guys, I hope the concept\nbehind random forest is understandable. Now the next step is you will evaluate the efficiency of the model. Now earlier when we created\nthe bootstrap data set we left out one entry sample. This is the entry sample we left out, because we repeated one sample twice. If you'll remember in\nthe bootstrap data set, here we repeated an entry twice, and we missed out on one of the entries. We missed out on one of the entries. So what we're gonna do is... So for evaluating the model, we'll be using the data\nentry that we missed out on. Now in a real world problem, about 1/3 of the original\ndata set is not included in the bootstrap dataset. Because there's a huge amount of data in a real world problem, so 1/3 of the original data set is not included in the bootstrap data set. So guys, the sample data set which is not there in\nyour bootstrap data set is known as out-of-bag data set, because basically this is\nour out-of-bag data set. Now the out-of-bag data set is used to check the\naccuracy of the model. Because the model was not created by using the out-of-bag data set, it will give us a good understanding of whether the model is effective or not. Now the out-of-bag data set is nothing but your testing data set. Remember, in machine\nlearning, there's training and testing data set. So your out-of-bag data set is nothing but your testing data set. This is used to evaluate the\nefficiency of your model. So eventually, you can\nmeasure the accuracy of a random forest by the proportion of out-of-bag samples that\nare correctly classified, because the out-of-bag data set is used to evaluate the\nefficiency of your model. So you can calculate the accuracy by understanding how many samples or was this out-of-bag data set correctly able to classify it. So guys, that was an explanation about how random forest works. To give you an overview, let me just run you through\nall the steps that we took. So basically, this was our data set, and all we have to do\nis we have to predict whether a patient has\nheart disease or not. So, our first step was to\ncreate a bootstrap data set. A bootstrap data set is\nnothing but randomly selected observations from your original data set, and you can also have duplicate values in your bootstrap data set. Okay. The next step is you're going\nto create a decision tree by considering a random\nset of predictor variables for each decision tree. Okay. So, the third step is\nyou'll go back to step one, create a bootstrap data set. Again, create a decision tree. So this iteration is\nperformed hundreds of times until you are multiple decision trees. Now that you've created a random forest, you'll use this random forest\nto predict the outcome. So if you're given a new data point and you have to classify it into one of the two classes, we'll just run this new information through all the decision trees. And you'll just take the majority of the output that you're\ngetting from the decision trees as your outcome. Now in order to evaluate\nthe efficiency of the model, you'll use the out of\nthe bag sample data set. Now the out-of-bag sample\nis basically the sample that was not included in\nyour bootstrap data set, but this sample is coming from your original data set, guys. This is not something\nthat you randomly create. This data set was there\nin your original data set, but it was just not mentioned in your bootstrap data set. So you'll use your out-of-bag sample in order to calculate the accuracy of your random forest. So the proportion of out-of-bag samples that are correctly classified\nwill give you the accuracy of your model. So that is all for random forest. So guys, I'll discuss other classification algorithms with you, and only then I'll show you a demo on the classification algorithms. Now our next algorithm is\nsomething known as naive Bayes. Naive Bayes is, again, a supervised classification algorithm, which is based on the Bayes Theorem. Now the Bayes Theorem basically follows a probabilistic approach. The main idea behind naive Bayes is that the predictor variables in\na machine learning model are independent of each other, meaning that the outcome of a model depends on a set of independent variables that have nothing to do with each other. Now a lot of you might\nask why is naive Bayes called naive. Now usually, when I tell\nanybody why naive Bayes, they keep asking me why is\nnaive Bayes called naive. So in real world problems\npredictor variables aren't always independent of each other. There is always some correlation between the independent variables. Now because naive Bayes\nconsiders each predictor variable to be independent of any\nother variable in the model, it is called naive. This is an assumption\nthat naive Bayes states. Now let's understand the math behind the naive Bayes algorithm. So like I mentioned, the\nprinciple behind naive Bayes is the Bayes Theorem, which is also known as the Bayes Rule. The Bayes Theorem is used to calculate the conditional probability, which is nothing but the\nprobability of an event occurring based on information about\nthe events in the past. This is the mathematical\nequation for the Bayes Theorem. Now, in this equation, the LHS is nothing but the conditional probability\nof event A occurring, given the event B. P of A is nothing but\nprobability of event A occurring P of B is probability of event B. And PB of A is nothing but\nthe conditional probability of event B occurring, given the event A. Now let's try to understand\nhow naive Bayes works. Now consider this data set of around thousand 500 observations. Okay, here we have the\nfollowing output classes. We have either cat, parrot, or turtle. These are our output classes, and the predictor variables are swim, wings, green color, and sharp teeth. Okay. So, basically, your type\nis your output variable, and swim, wings, green, and sharp teeth are your predictor variables. Your output variables has three classes, cat, parrot, and turtle. Okay. Now I've summarized this table\nI've shown on the screen. The first thing you can see\nis the class of type cats shows that out of 500 cats, 450 can swim, meaning that 90% of them can. And zero number of cats have wings, and zero number of cats\nare green in color, and 500 out of 500 cats have sharp teeth. Okay. Now, coming to parrot, it\nsays 50 out of 500 parrots have true value for swim. Now guys, obviously,\nthis does not hold true in real world. I don't think there are\nany parrots who can swim, but I've just created this data set so that we can understand naive Bayes. So, meaning that 10% of parrots\nhave true value for swim. Now all 500 parrots have wings, and 400 out of 500 parrots\nare green in color, and zero parrots have sharp teeth. Coming to the turtle class, all 500 turtles can swim. Zero number of turtles have wings. And out of 500, hundred\nturtles are green in color, meaning that 20% of the\nturtles are green in color. And 50 out of 500\nturtles have sharp teeth. So that's what we understand\nfrom this data set. Now the problem here is we are given our observation over here, given some value for swim,\nwings, green, and sharp teeth. What we need to do is we need to predict whether the animal is a\ncat, parrot, or a turtle, based on these values. So the goal here to predict\nwhether it is a cat, parrot, or a turtle based on all these defined parameters. Okay. Based on the value of swim,\nwings, green, and sharp teeth, we'll understand whether\nthe animal is a cat, or is it a parrot, or is it a turtle. So, if you look at the observation, the variables swim and\ngreen have a value of true, and the outcome can be\nanyone of the types. It can either be a cat,\nit can be a parrot, or it can be a turtle. So in order to check\nif the animal is a cat, all you have to do is\nyou have to calculate the conditional probability at each step. So here what we're doing is we need to calculate the probability that this is a cat, given that it can swim\nand it is green in color. First, we'll calculate the\nprobability that it can swim, given that it's a cat. And two, the probability that it is green and the probability of it being green, given that it is a cat, and then we'll multiply it with the probability of it being a cat divided by the probability\nof swim and green. Okay. So, guys, I know you all can\ncalculate the probability. It's quite simple. So once you calculate\nthe probability here, you'll get a direct value of zero. Okay, you'll get a value of zero, meaning that this animal\nis definitely not a cat. Similarly, if you do this for parrots, you calculate a conditional probability, you'll get a value of 0.0264 divided by probability\nof swim comma green. We don't know this probability. Similarly, if you check\nthis for the turtle, you'll get a probability of 0.066 divided by P swim comma green. Okay. Now for these calculations,\nthe denominator is the same. The value of the denominator is the same, and the value of and the probability of it being a turtle is greater\nthan that of a parrot. So that's how we can correctly predict that the animal is actually a turtle. So guys, this is how naive Bayes works. You basically calculate the conditional probability at each step. Whatever classification needs to be done, that has to be calculated\nthrough probability. There's a lot of statistic that comes into naive Bayes. And if you all want to\nlearn more about statistics and probability, I'll leave a link in the description. You all can watch that video as well. There I've explain exactly what conditional probability is, and the Bayes Theorem is\nalso explained very well. So you all can check out that video also. And apart from this, if\nyou all have any doubts regarding any of the algorithms, please leave them in the comment section. Okay, I'll solve your doubts. And apart from that, I'll\nalso leave a couple of links for each of the algorithms\nin the description box. Because if you want more\nin-depth understanding of each of the algorithms, you can check out that content. Since this is a full course video, I have to cover all the topics, and it is hard for me\nto make you understand in-depth of each topic. So I'll leave a couple of\nlinks in the description box. You can watch those videos as well. Make sure you checkout the probability and statistics video. So now let's move on and\nlocate our next algorithm, which is the K nearest neighbor algorithm. Now KNN, which basically\nstands for K nearest neighbor, is, again, a supervised\nclassification algorithm that classifies a new data\npoint into the target class or the output class,\ndepending on the features of its neighboring data points. That's why it's called K nearest neighbor. So let's try to understand\nKNN with a small analogy. Okay, let's say that we want a machine to distinguish between the\nimages of cats and dogs. So to do this, we must input our data set of cat and dog images, and we have to train our\nmodel to detect the animal based on certain features. For example, features such as pointy ears can be used to identify cats. Similarly, we can identify dogs based on their long ears. So after starting the data set during the training phase, when a new image is given to the model, the KNN algorithm will classify it into either cats or dogs, depending on the similarity\nin their features. Okay, let's say that a\nnew image has pointy ears, it will classify that image as cat, because it is similar to the cat images, because it's similar to its neighbors. In this manner, the KNN\nalgorithm classifies the data point based\non how similar they are to their neighboring data points. So this is a small example. We'll discuss more about\nit in the further slides. Now let me tell you a couple of features of KNN algorithm. So, first of all, we know that it is a supervised learning algorithm. It uses labeled input data set to predict the output of the data points. Then it is also one of the simplest machine learning algorithms, and it can be easily implemented for a varied set of problems. Another feature is that\nit is non-parametric, meaning that it does not\ntake in any assumptions. For example, naive Bayes\nis a parametric model, because it assumes that all\nthe independent variables are in no way related to each other. It has assumptions about the model. K nearest neighbor has\nno such assumptions. That's why it's considered\na non-parametric model. Another feature is that\nit is a lazy algorithm. Now, lazy algorithm\nbasically is any algorithm that memorizes the training set, instead of learning a\ndiscriminative function from the training data. Now, even though KNN is mainly\na classification algorithm, it can also be used for regression cases. So KNN is actually both a classification and a regression algorithm. But mostly, you'll see that it'll be used on the four classification problems. The most important feature about a K nearest neighbor is that it's based on feature similarity with its neighboring data points. You'll understand this in the example that I'm gonna tell you. Now, in this image, we\nhave two classes of data. We have class A which is squares and class B which are triangles. Now the problem statement is to assign the new input data point to one of the two classes by using the KNN algorithm. So the first step in the KNN algorithm is to define the value of K. But what is the K in the\nKNN algorithm stand for? Now the K stands for the\nnumber of nearest neighbors, and that's why it's got the\nname K nearest neighbors. Now, in this image, I've\ndefined the value of K as three. This means that the algorithm will consider the three neighbors that are closest to the new data point in order to decide the\nclass of the new data point. So the closest between the data point is calculated by using measure such as Euclidean distance\nand Manhattan distance, which I'll be explaining in a while. So our K is equal to three. The neighbors include two\nsquares and one triangle. So, if I were to classify\nthe new data point based on K equal to three, then it should be assigned\nto class A, correct? It should be assigned to squares. But what if the K value is set to seven. Here I'm basically telling my algorithm to look for the seven nearest neighbors and classify the new data point into the class it is most similar to. So our K equal to seven. The neighbors include three\nsquares and four triangles. So if I were to classify\nthe new data point based on K equal to seven, then it would be assigned to class B, since majority of its\nneighbors are from class B. Now this is where a\nlot of us get confused. So how do we know which K\nvalues is the most suitable for K nearest neighbor. Now there are a couple methods used to calculate the K value. One of them is known as the elbow method. We'll be discussing the elbow method in the upcoming slides. So for now let me just show you the measures that are involved behind KNN. Okay, there's very simple math behind the K nearest neighbor algorithm. So I'll be discussing the\nEuclidean distance with you. Now in this figure, we have\nto measure the distance between P one and P two by\nusing Euclidean distance. I'm sure a lot of you already know what Euclidean distance is. It is something that we learned\nin eighth or 10th grade. I'm not sure. So all you're doing is\nyou're extracting X one. So the formula is\nbasically x two minus x one the whole square plus y two minus y one the whole square, and the root of that is\nthe Euclidean distance. It's as simple as that. So Euclidean distance is used as a measure to check the\ncloseness of data points. So basically, KNN uses\nthe Euclidean distance to check the closeness of a new data point with its neighbors. So guys, it's as simple as that. KNN makes use of simple measures in order to solve very complex problems. Okay, and this is one of the reasons why KNN is such a commonly used algorithm. Coming to support vector machine. Now, this is our last algorithm under classification algorithms. Now guys, don't get paranoid\nbecause of the name. Support vector machine actually is one of the simplest algorithms\nin supervised learning. Okay, it is basically\nused to classify data into different classes. It's a classification algorithm. Now unlike most algorithms, SVM makes use of something\nknown as a hyperplane which acts like a decision boundary between the separate classes. Okay. Now SVM can be used to generate multiple separating hyperplane, such that the data is\ndivided into segments, and each segment contains\nonly one kind of data. So, a few features of SVM include that it is a supervised learning algorithm, meaning that it's going to\nstudy a labeled training data. Another feature is that it is again a regression and a\nclassification algorithm. Even though SVM is mainly\nused for classification, there is something known as\nthe support vector regressor. That is useful regression problems. Now, SVM can also be used\nto classify non-linear data by using kernel tricks. Non-linear data is basically data that cannot be separated by using a single linear line. I'll be talking more about this in the upcoming slides. Now let's move on and\ndiscuss how SVM works. Now again, in order to make you understand how support vector machine works, you look at a small scenario. For a second, pretend that you own a farm and you have a problem. You need to set up a fence to protect your rabbits\nfrom a pack of wolves. Okay, now, you need to decide where you want to build your fence. So one way to solve\nthe problem is by using support vector machines. So if I do that and if I try\nto draw a decision boundary between the rabbits and the wolves, it looks something like this. Now you can clearly build\na fence along this line. So in simple terms, this is exactly how your support vector machines work. It draws a decision boundary, which is nothing but a hyperplane between any two classes\nin order to separate them or classify them. Now I know that you're\nthinking how do you know where to draw a hyperplane. The basic principle behind SVM is to draw a hyperplane that best separates the two classes. In our case, the two classes are the rabbits and the wolves. Now before we move any further, let's discuss the different terminologies that are there in support vector machine. So that is basically a hyperplane. It is a decision boundary\nthat best separates the two classes. Now, support vectors, what\nexactly are support vectors. So when you start with the\nsupport vector machine, you start by drawing a random hyperplane. And then you check the distance between the hyperplane\nand the closest data point from each of the class. These closest data\npoints to the hyperplane are known as support vectors. Now these two data points are the closest to your hyperplane. So these are known as support vectors, and that's where the name comes from, support vector machines. Now the hyperplane is drawn based on these support vectors. And optimum hyperplane will be the one which has a maximum distance from each of the support vectors, meaning that the distance\nbetween the hyperplane and the support vectors has to be maximum. So, to sum it up, SVM\nis used to classify data by using a hyperplane, such that the distance\nbetween the hyperplane and the support vector is maximum. Now this distance is\nnothing but the margin. Now let's try to solve a problem. Let's say that I input a new data point and I want to draw a hyperplane such that it best separates\nthese two classes. So what do I do? I start out by drawing a hyperplane, and then I check the distance\nbetween the hyperplane and the support vectors. So, basically here, I'm trying to check if the margin is maximum\nfor this hyperplane. But what if I drew the\nhyperplane like this? The margin for this hyperplane\nis clearly being more than the previous one. So this is my optimal hyperplane. This is exactly how you understand which hyperplane needs to be chosen, because you can draw multiple hyperplanes. Now, the best hyperplane is the one that has a maximum module. So, this is my optimal hyperplane. Now so far it was quite easy. Our data was linearly separable, which means that you\ncould draw a straight line to separate the two classes. But what will you do if\nthe data looks like this? You possibly cannot draw\na hyperplane like this. You possibly cannot draw\na hyperplane like this. It doesn't separate the two classes. We can clearly see rabbits and wolves in both of the classes. Now this is exactly where non-linear SVM comes into the picture. Okay, this is what the\nkernel trick is all about. Now, kernel is basically\nsomething that can be used to transform data into another dimension that has a clear dividing\nmargin between classes of data. So, basically the kernel function offers the user the option of transforming non-linear spaces into linear ones. Until this point, if you notice that we were plotting our data\non two dimensional space. We had x and y-axis. A simple trick is transforming\nthe two variables, x and y, into a new feature space, which involves a new variable z. So, basically, what we're doing is we're visualizing the data on a three dimensional space. So when you transform the\n2D space into a 3D space, you can clearly see a dividing margin between the two classes of data. You can clearly draw a line in the middle that separates these two data sets. So guys, this sums up\nthe whole idea behind support vector machines. Support vector machines are\nvery easy to understand. Now, this was all for our supervised learning algorithms. Now, before I move on to\nunsupervised learning algorithms, I'll be running a demo. We'll be running a demo in order to understand all\nthe classification algorithms that we studied so far. Earlier in the session, we ran a demo for the regression algorithms. Now we'll run for the\nclassification algorithms. So, enough of theory. Let's open up Python, and let's start looking at how these classification algorithms work. Now, here what we'll be doing is we'll implement multiple\nclassification algorithms by using the scikit-learn. Okay, it's one of the most popular machine learning tool for Python. Now we'll be using a simple data set for the task of training a\nclassifier to distinguish between the different types of fruits. The purpose of this demo is to implement multiple classification algorithms for the same set of problem. So as usual, you start by importing all your libraries in Python. Again, guys, if you don't know Python, check the description box, I'll leave a link there. You can go through that video as well. Next, what we're doing is\nwe're reading the fruit data in the form of table. You stored it in a variable called fruits. Now if you wanna see the\nfirst few rows of the data, let's print the first few\nobservations in our data set. So, this is our data set. These are the fruit labels. So we have around four\nfruits in our data set. We have apple, we have mandarin, orange, and lemon. Okay. Now, fruit label denotes\nnothing but the label of apple, which is one. Mandarin has two. Similarly, orange is labeled as three. And lemon is labeled as four. Then a fruit subtype is basically the family of fruit it belongs to. Mass is the mass of the fruit, width, height, and color score. These are all our predictor variables. We have to identify the type of fruit, depending on these predictor variables. So, first, we saw a couple\nof observations over here. Next, if you want to see\nthe shape of your data set, this is what it looks like. There are around 59 observations with seven predictor variables, which is one, two, three,\nfour, five, six, and seven. We have seven variables in total. Sorry, not predictor variables. This seven denotes both your predictor and your target variable. Next, I'm just showing you\nthe four fruits that we have in our data set, which is apple, mandarin,\norange, and lemon. Next, I'm just grouping\nfruits by their names. Okay. So we have 19 apples in our data set. We have 16 lemons. We have only five mandarins, and we have 19 oranges. Even though the number of\nmandarin samples is low, we'll have to work with it, because right now I'm\njust trying to make you understand the classification algorithms. The main aim for me\nbehind doing these demos is so that you understand how classification algorithms work. Now what you can do is\nyou can also plot a graph in order to see the frequency\nof each of these fruits. Okay, I'll show you what\nthe plot looks like. The number of apples\nand oranges is the same. We have I think around\n19 apples and oranges. And similarly, this is\nthe count for lemons. Okay. So this is a small visualization. Guys, visualization is\nactually very important when it comes to machine learning, because you can see most of the relations and correlations by plotting graphs. You can't see those correlations by just running code and all of that. Only when you plot different\nvariables on your graph, you'll understand how they are related. One of the main task in machine learning is to visualize data. It ensures that you understand the correlation between data. Next, what we're gonna do is we'll graph something known as a box plot. Okay, a box plot basically\nhelps you understand the distribution of your data. Let me run the box plot, and I'll show you what exactly I mean. So this is our box plot. So, box plot will basically give you a clearer idea of the distribution of your input variables. It is mainly used in\nexploratory data analysis, and it represents the\ndistribution of the data and its variability. Now, the box plot contains upper quartile and lower quartile. So the box plot basically\nspanned your interquartile range or something known as IQR. IQR is nothing but your third quartile subtracted from your first quartile. Now again, this involves\nstatistics and probability. So I'll be leaving a link\nin the description box. You can go through that video. I've explained statistics\nprobability, IQR, range, and all of that in there. So, one of the main reasons\nwhy box plots are used is to detect any sort\nof outliers in the data. Since the box plot spans the IQR, it detects the data point that lie outside the average range. So if you see in the colored space, most of the data is\ndistributed around the IQR, whereas here the data are\nnot that well distributed. Height also is not very well distributed, but color space is\npretty well distributed. This is what the box plot shows you. So guys, this involves a lot of math. ALl of these, each and every\nfunction in machine learning involves a lot of math. So you know it's necessary\nto have a good understanding of statistics, probability,\nand all of that. Now, next, what we'll do\nis we'll plot a histogram. Histogram will basically show you the frequency of occurrence. Let me just plot this, and\nthen we'll try and understand. So here you can understand\na few correlations. Okay, some pairs of these\nattributes are correlated. For example, mass and width, they're somehow correlated\nalong the same ranges. So this suggests a high correlation and a predictable relationship. Like if you look at the\ngraphs, they're quite similar. So for each of the predictor variables, I've drawn a histogram. For each of that input data,\nwe've drawn a histogram. Now guys, again, like i said, plotting graphs is very important because you understand\na lot of correlations that you cannot understand by just looking at your data, or just running operations on your data. Repeat, or just running code on your data. Okay. Now, next, what we're\ndoing here is we're just dividing the data set into\ntarget and predictor variables. So, basically, I've created\nan array of feature names which has your predictor variables. It has mass, width, height, color space. And you have assigned that as X, since this is your input, and y is your output\nwhich is your fruit label. That'll show whether it is an apple, orange, lemon, and so on. Now, the next step that\nwe'll perform over here is pretty evident. Again, this is data splicing. So data splicing, by now, I'm sure all of you know what it is. It is splitting your data into\ntraining and testing data. So that's what we've done over here. Next, we're importing something\nknown as the MinMaxScaler. Scaling or normalizing your data is very important in machine learning. Now, I'm seeing this because your raw data can be very biased. So it's very important\nto normalize your data. Now when I say normalize your data, so if you look at the value of mass and if you look at the\nvalue of height and color, you see that mass is ranging\nin hundreds and double digits, whereas height is in single digit, and color score is not\neven in single digits. So, if some of your variables\nhave a very high range, you know they have a very high scale, like they're in two\ndigits or three digits, whereas other variables are\nsingle digits and lesser, then your output is\ngoing to be very biased. It's obvious that it's\ngonna be very biased. That's why you have to scale your data in such a way that all of these values will have a similar range. So that's exactly what\nthe scaler function does. Okay. Now since we have already divided our data into training and testing data, our next step is to build the model. So, first, we're gonna be using the logistic regression algorithm. I've already discussed logistic\nregression with you all. It's a classification algorithm, which is basically used\nto predict the outcome of a categorical variable. So we already have the logistic\nregression class in Python. All you have to do is you have to give an instance for this function, which is logreg over here. And I'm fitting this instance\nwith a training data set, meaning that I'm running the algorithm with the training data set. Once you do that, you can calculate the accuracy by using this function. So here I'm calculate the accuracy on the training data set and on the testing data set. Okay, so let's look at the output of this. Now guys, ignore this future warning. Warnings are ignored in Python. Now, accuracy of the logistic\nregression classifier on the training data set is around 70%. It was pretty good on\nthe training data set. But when it comes to classifying\non the test data set, it's only 40%, which is not that good for a classifier. Now again, this can depend\non the problem statement, for which problem statement is logistic regression more suitable. Next, we'll do the same thing\nusing the decision tree. So again, we just call the\ndecision tree function, and we'll fit it with\nthe training data set, and we'll calculate the accuracy of the decision tree on the training, and the testing data set. So if you do that for a decision tree on the training data set, you get 100% accuracy. But on the testing data set, you have around 87% of accuracy. This is something that I\ndiscussed with you all earlier, that this is decision trees are very good with training data set, because of a process known as overfitting. But when it comes to classifying the outcome on the testing data set, the accuracy reduces. Now, this is very good compared\nto logistic regression. For this problem statement, decision trees works better that logistic regression. Coming to KNN classifier. Again, all you have to do is you have to call the K neighbor\nclassifier, this function. And you have to fit this\nwith the training data set. If you calculate the accuracy\nfor a KNN classifier, we get a good accuracy actually. On the training data set, we get an accuracy of 95%. And on the testing data set, it's 100%. That is really good,\nbecause our testing data set actually achieved more of an accuracy than on a training data set. Now all of this depends on the value of K that you've chosen for KNN. Now, I mentioned that\nyou use the elbow method to choose the K value in\nthe K nearest neighbor. I'll be discussing the elbow\nmethod in the next section. So, don't worry if you\nhaven't understood that yet. Now, we're also using a\nnaive Bayes classifier. Here we're using a Gaussian\nnaive Bayes classifier. Gaussian is basically a type\nof naive Bayes classifier. I'm not going to go into depth of this, because it'll just extend our\nsession too much more longer. Okay. And if you want to know more about this, I'll leave a link in the description box. You can read all about the\ncaution naive Bayes classifier. Now, the math behind this is the same. It uses naive Bayes, it uses\nthe Bayes Theorem itself. Now again, we're gonna call this class, and then we're going to run our data, training data on it. So using the naive Bayes classifier, we're getting an accuracy of 0.86 on the training data set. And on the testing data set,\nwe're getting 67% accuracy. Okay. Now let's do the same thing\nwith support vector machines. Importing the support vector classifier. And we are fitting the training\ndata into the algorithm. We're getting an accuracy of around 61% on the training data set and\n33% on the testing data set. Now guys, this accuracy and all depends also on the problem statement. It depends on the type of data that support vector machines get. Usually, SVM is very\ngood on large data sets. Now since we have a very\nsmall data set over here, it's sort of obvious by\nthe accuracy, so less. So guys, these were a couple\nof classification algorithms that I showed you here. Now, because our KNN classifier classified our data set more accurately we'll look at the predictions\nthat the KNN classifier mean. Okay Now we're storing all our predicted values in the predict variable. now in order to show you the accuracy of the KNN model, we're going to us something\nknown as the confusion matrix. So, a confusion matrix is a table that is often used to describe the performance of a classification model. So, confusion matrix actually represents a tabular representation of actual versus predicted values. So when you draw a confusion matrix on the actual versus predicted values for the KNN classifier, this is what the confusion\nmatrix looks like. Now, we have four rows over here. If you see, we have four rows. The first row represents apples, second, mandarin, third represents lemons, and fourth, oranges. So this four value corresponds\nto zero comma zero, meaning that it was\ncorrectly able to classify all the four apples. Okay. This one value represents one comma one, meaning that our classifier\ncorrectly classified this as mandarins. This matrix is drawn on actual values versus predicted values. Now, if you look at the summary\nof the confusion matrix, we'll get something known\nas precision recall, f1-score and support. Precision is basically the ratio of the correctly predicted\npositive observations to the total predicted\npositive observations. So the correctly predicted\npositive observations are four, and there are total of four apples in the testing data set. So that's where I get a precision of one. Okay. Recall on the other hand is the ratio of correctly\npredicted positive observations to all the observations in the class. Again, we've correctly\nclassified four apples, and there are a total of four apples. F1-score is nothing but\nthe weighted average of your precision and your recall. Okay, and your support basically denotes the number of data points that were correctly classified. So, in our KNN algorithm,\nsince we got 100% accuracy, all our data points were\ncorrectly classified. So, 15 out of 15 were correctly classified because we have 100% accuracy. So that's how you read a confusion matrix. Okay, you have four important measures, precision, recall, f1-score, and support. F1-score is just the ratio\nor the weighted average of your precision and your recall. So precision is basically\nthe correctly predicted positive observations\nto the total predicted positive observations. Recall is a ratio of the predicted positive observations to\nall your observations. So guys, that was it for the demo of classification algorithms, we discuss regression algorithms and we discussed\nclassification algorithms. Now it's time to talk about unsupervised learning algorithms. Under unsupervised learning algorithms may try to solve clustering problems. And the most important\nclustering algorithm there is, known as K-means clustering. So we're going to discuss\nthe K-means algorithm, and also show you a demo\nwhere we'll be executing the clustering algorithm, and you're seeing how it\nimplemented to solve a problem. Now, the main aim of the K-means algorithm is to group similar elements\nor data points in to a cluster. So it is basically the process by which objects are classified interest a predefined number of groups, so that they are much\ndissimilar as possible from one group to another group, but as much similar as\npossible within each group. Now what I mean is let's\nsay you're trying to cluster this population into\nfour different groups, such that each group has people within a specified range of age. Let's say group one is of people\nbetween the age 18 and 22. Similarly, group two is between 23 and 35. Group three is 36 and 39\nor something like that. So let's say you're trying to cluster people into different\ngroups based on their age. So for such problems, you can make use of the K-means clustering algorithm. One of the major applications\nof the clustering algorithm is seen in targeted marketing. I don't know how many of you are aware of targeted marketing. Targeted marketing is all about\nmarketing a specific product to a specific audience. Let's say you're trying\nto sell fancy clothes or a fancy set of bags and all of that. And the perfect audience for such product would be teenagers. It would be people around\nthe age of 16 to 21 or 18. So that is what target\nmarketing is all about. Your product is marketed\nto a specific audience that might be interested in it. That is what targeted marketing is. So K means clustering is use\nmajorly in targeted marketing. A lot of eCommerce websites\nlike Amazon, Flipkart, eBay. All of these make use\nof clustering algorithms in order to target the right audience. Now let's see how the\nK-means clustering works. Now the K in K-means denotes\nthe number of clusters. Let's say I give you a data\nset containing 20 points, and you want to cluster this\ndata set into four clusters. That means your K will be equal to four. So K basically stands for\nthe number of clusters in your data set, or the number of clusters\nyou want to form. You start by defining the number K. Now for each of these clusters, you're going to choose a centroid. So for every cluster, there are four cluster in our data set. For each of these clusters, you'll randomly select\none of the data points as a centroid. Now what you'll do is you'll start computing the distance from that centroid to every other point in that cluster. As you keep computing the centroid and the distance between the centroid and other data points in that cluster, your centroid keep shifting, because you're trying to get\nto the average of that cluster. Whenever you're trying to get\nto the average of the cluster, the centroid keeps shifting, because the centroid keeps\nconverging and it keeps shifting. Let's try to understand how K-means works. Let's say that this data\nset, this is given to us. Let's say if you're given\nrandom points like these and you're asked to us\nK-means algorithm on this. So your first step will be to decide the number of\nclusters you want to create. So let's say I wanna create\nthree different clusters. So my K value will be equal to three. The next step will be to provide centroids of all the clusters. What you'll do is initially\nyou'll randomly pick three data points as your centroids for your three different clusters. So basically, this red denotes\nthe centroid for one cluster. Blue denotes a centroid\nfor another cluster. And this green dot denotes the centroid for another cluster. Now what happens in K-means, the algorithm will calculate the Euclidean distance of\nthe points from each centroid and assign the points\nto the closest cluster. Now since we had three centroids here, now what you're gonna do is you're going to calculate the distance from each and every data point to all the centroids, and you're going to check which data point is closest to which centroid. So let's say your data point A is closest to the blue centroid. So you're going to assign the data point A to the blue cluster. So based on the distance between the centroid and the cluster, you're going to form\nthree different clusters. Now again, you're going\nto calculate the centroid and you're going to form a new cluster which is from better clusters, because you're recomputing\nall those centroids. Basically, your centroids represent the mean of each of your cluster. So you need to make sure that your mean is actually\nthe centroid of each cluster. So you'll keep recomputing this centroids until the position of your\ncentroid does not change. That means that your\ncentroid is actually the main or the average of that particular cluster. So that's how K-means works. It's very simple. All you have to do is you have to start by defining the K value. After that, you have to randomly pick the number of case centroids. Then you're going to\ncalculate the average distance of each of the data\npoints from the centroids, and you're going to assign a data point to the centroid it is closest to. That's how K-means works. It's a very simple process. All you have to do is us\nhave to keep iterating, and you have to recompute\nthe centroid value until the centroid value does not change, until you get a constant centroid value. Now guys, again, in K-means, you make use of distance\nmeasures like Euclidean. I've already discussed what\nEuclidean is all about. So, to summarize how K-means works, you start by picking\nthe number of clusters. Then you pick a centroid. After that, you calculate the distance of the objects to the centroid. Then you group the data\npoints into specific clusters based on their distance. You have to keep computing the centroid until each data point is\nassigned to the closest cluster, so that's how K-means works. Now let's look at the elbow method. The elbow method is basically\nused in order to find out the most optimum k value\nfor a particular problem. So the elbow method is\nquite simple actually. You start off by computing\nthe sum of squared errors for some values of K. Now sum of squared error is basically the sum of the squared distance between each member of the\ncluster and its centroid. So you basically calculate\nthe sum of squared errors for different values of K. For example, you can consider K value as two, four, six, eight, 10, 12. Consider all these values, compute the sum of squared\nerrors for each of these values. Now if you plot your K value against your sum of squared errors, you will see that the error\ndecreases as K gets larger. This is because the number\nof clusters increase. If the number of clusters increases, it means that the distortion gets smaller. The distortion keeps decreasing as the number of clusters increase. That's because the more clusters you have, the closer each centroid\nwill be with its data points. So as you keep increasing\nthe number of clusters, your distortion will also decrease. So the idea of the elbow\nmethod is to choose the K at which the distortion\ndecreases abruptly. So if you look at this\ngraph at K equal to four, the distortion is abruptly decreasing. So this is how you find the value of K. When your distortion drops abruptly, that is the most optimal K value you should be choosing for\nyour problem statement. So let me repeat the idea\nbehind the elbow method. You're just going to graph the\nnumber of clusters you have versus the squared sum of errors. This graph will basically\ngive you the distortion. Now the distortion\nobviously going to decrease if you increase the number of clusters, and there is gonna be\none point in this graph wherein the distortion\ndecreases very abruptly. Now for that point, you need\nto find out the value of K, and that'll be your most optimal K value. That's how you choose your K-means K value and your KNN K value as well. So guys, this is how the elbow method is. It's very simple and it\ncan be easily implemented. Now we're gonna look at a small demo which involves K-means. This is actually a very interesting demo. Now guys, one interesting application of clustering is in color\ncompression with images. For example, imagine you have an image with millions of colors in it. In most images, a large number\nof colors will be unused, and many of the pixels in the image will have similar or\neven identical colors. Now having too many colors in your image makes it very hard for image\nprocessing an image analysis. So this is one area where\nK-means is applied very often. It's applied in image\nsegmentation, image analysis, image compression, and so on. So what we're gonna do in this demo is we are going to use an image from the scikit-learn data set. Okay, it is a prebuilt image, and you will require to install\nthe pillow package for this. We're going to use an image form the scikit-learn data set module. So we'll begin by importing\nthe libraries as usual, and we'll be loading our image as china. The image is china.jpg, and we'll be loading this\nin a variable called china. So if you wanna look at\nthe shape of our image, you can run this command. So we're gonna get a\nthree-dimensional value. So we're getting 427\ncomma 640 comma three. Now this is basically a\nthree dimensional array of size, height, width, and RGB. It contains red, blue,\ngreen contributions, as integers from zero to 255. So, your pixel values\nrange between zero and 255, and I think zero stands for your black, and 255 represents white if I'm not wrong. And basically, that's what\nthis array shape denotes. Now one way we can view this set of pixels is as a cloud of points in a\nthree dimensional color space. So what we'll do is we\nwill reshape the data and rescale the color, so that they lie between zero and one. So the output of this will be\na two dimensional array now. So basically, we can\nvisualize these pixels in this color space. Now what we're gonna do is we're gonna try and plot our pixels. We have a really huge data set which contains around 16\nmillion possible colors. So this denotes a very,\nvery large data set. So, let me show you what it looks like. We have red against green\nand red against blue. These are our RGB value, and we can have around 16 million possible combination of colors. The data set is way too\nlarge or us to compute. So what we'll do is we will\nreduce these 16 million colors to just 16 colors. We can do that by using\nK-means clustering, because we can cluster similar\ncolors into similar groups. So this is exactly where\nwe'll be importing K-means. Now, one thing to note here is because we're dealing with\na very large data set, we will use the MinibatchKMeans. This operates on subsets of the data to compute the results more\nquickly and more accurately, just like the K-means algorithm, because I told you this\ndata set is really huge. Even though this is a single image, the number of pixel combinations\ncan come up to 16 million, which is a lot. Now each pixel is\nconsidered as a data point when you've taken image\ninto consideration. When you have data points and data values, that's different. When you're starting an image\nfor image classification or image segmentation, each and every pixel is considered. So, basically, you're building matrices of all of these pixel values. So having 16 million pixels\nis a very huge data set. So, for that reason, we'll\nbe using the MinibatchKMeans. It's very similar to K-means. The only difference is that it'll operate on subsets of the data. Because the data set is too\nhuge, it'll operate on subsets. So, basically, we're making use of K-means in order to cluster these 16 million color combinations into just 16 colors. So basically, we're gonna form 16 clusters in this data set. Now, the result is the\nrecoloring of the original pixel where every pixel is assigned the color of its closest cluster center. Let's say that there\nare a couple of colors which are very close to green. So we're going to cluster\nall of these similar colors into one cluster. We'll keep doing this\nuntil we get 16 clusters. So, obviously, to do this, we'll be using the clustering method, K-means. Let me show you what\nthe output looks like. So, basically, this was the original image from the scikit data set, and this is the 16-color segmented image. Basically, we have only 16 colors here. Here we can have around 16 million colors. Here there are only 16 colors. If you can't also, you can\nonly see particular colors. Now obviously there's a lot\nof distortion over here, but this is how you study an image. Remove all the extra contrast\nthat is there in an image. You try to reduce the pixel to a smaller set of data as possible. The more varied pixels you have, the harder it is going to be for you to study the image for analysis. Now, obviously, there are some details which are lost in this. But overall, the image\nis still recognizable. So here, basically, we've compressed this with a compression factor\nof around one million, because each cluster will have around one million data points in it, or pixel values in it, or pixels in it. Now this is an interesting\napplication of K-means. There are actually better ways you can compress information on image. So, basically, I showed you this example because I want you to understand the power of K-means algorithm. You can cluster a data\nset that is this huge into just 16 colors. Initially, there were 16 million, and now you can cluster it to 16 colors. So guys, K-means plays a very huge role in computer vision image processing, object detection, and so on. It's a very important algorithm when it comes to detecting objects. So in self-driving cars and all can make use of such algorithms. So guys, that was all\nabout unsupervised learning and supervised learning. Now it's the last type\nof machine learning, which is reinforcement learning. Now this is actually a very interesting part\nof machine learning, and it is quite difference from\nsupervised and unsupervised. So we'll be discussing all the concepts that are involved in\nreinforcement learning. And also reinforcement learning is a little more advanced. When I say advanced, I\nmean that it's been used in applications such as self-driving cars and is also a part of a lot of deep learning applications, such as AlphaGo and so on. So, reinforcement learning has a different concept to it itself. So we'll be discussing\nall the concepts under it. So just to brush up your information about reinforcement learning, reinforcement learning is\na part of machine learning where an agent is put in\nan unknown environment, and he learns how to\nbehave in this environment by performing certain actions\nand observing the rewards which it gets from these actions. Reinforcement learning is all about taking an appropriate action in\norder to maximize the reward in a particular situation. Now let's understand\nreinforcement learning with an analogy. Let's consider a scenario wherein a baby is learning how to walk. This scenario can go about\nin two different ways. The first is baby starts walking and it makes it to the candy. And since the candy is the end goal, the baby is very happy and it's positive. Meaning, the baby is happy and it received a positive reward. Now, the second way this can go in is that the baby starts walking, but it falls due to some hurdle between. That's really cute. So the baby gets hurt and\nit doesn't get to the candy. It's negative because the baby is sad and it receives a negative reward. So just like how we humans\nlearn from our mistakes by trial and error, reinforcement learning is also similar. Here we have an agent, and in this case, the agent is the baby, and the reward is the candy with many hurdles in between. The agent is supposed to find the best possible path\nto reach the reward. That is the main goal of\nreinforcement learning. Now the reinforcement learning process has two important components. It has something known as an agent and something known as an environment. Now the environment is the setting that the agent is acting on, and the agent represents the reinforcement learning algorithm. The whole reinforcement\nlearning is basically the agent. The environment is the setting in which you place the agent, and it is the setting wherein the agent takes various action. The reinforcement learning process starts when the environment\nsends a state to the agent. Now the agent, based on\nthe observations it makes, it takes an action in\nresponse to that state. Now, in turn, the environment\nwill send the next state and the respective\nreward back to the agent. Now the agent will update its knowledge with the reward returned\nby the environment to evaluate its last actions. The loop continues until the environment sends a terminal state which means that the\nagent has accomplished all of its task. To understand this better, let's suppose that our agent\nis playing Counter Strike. The reinforcement learning process can be broken down into a couple of steps. The first step is the\nreinforcement learning agent, which is basically the player, he collects a state, S\nnaught, from the environment. So whenever you're playing Counter Strike, you start off with\nstage zero or stage one. You start off from the first level. Now based on this state, S naught, the reinforcement learning agent will take an action, A naught. So guys, action can be\nanything that causes a result. Now if the agent moves\nleft or right in the game, that is also considered as an action. So initially, the action will be random, because the agent has no\nclue about the environment. Let's suppose that you're\nplaying Counter Strike for the first time. You have no idea about how to play it, so you'll just start randomly. You'll just go with whatever, whichever action you think is right. Now the environment is now in a stage one. After passing stage zero, the environment will go into stage one. Once the environment updates\nthe stage to stage on, the reinforcement learning agent will get a reward R one\nfrom the environment. This reward can be anything\nlike additional points or you'll get additional weapons when you're playing Counter Strike. Now this reinforcement\nlearning loop will go on until the agent is dead or\nreaches the destination, and it continuously outputs a sequence of state action and rewards. This exactly how\nreinforcement learning works. It starts with the agent\nbeing put in an environment, and the agent will randomly take some action in state zero. After taking an action,\ndepending on his action, he'll either get a reward and move on to state number one, or he will either die and\ngo back to the same state. So this will keep happening until the agent reaches the last stage, or he dies or reaches his destination. That's exactly how\nreinforcement learning works. Now reinforcement learning is the logic behind a lot of games these days. It's being implemented in\nvarious games, such as Dota. A lot of you who play\nDota might know this. Now let's talk about a couple of reinforcement learning\ndefinitions or terminologies. So, first, we have something\nknown as the agent. Like I mentioned, an agent is the reinforcement learning algorithm that learns from trial and error. An agent is the one\nthat takes actions like, for example, a solider in Counter Strike navigating through the game, going right, left, and all of that. Is the agent taking some action? The environment is because the world through which the agent moves. Now the environment, basically, takes the agent's current\nstate and action as input, and returns the agent's reward and its next state as the output. Next, we have something known as action. All the possible steps\nthat an agent can take is considered as an action. Next, we have something known as state. Now the current condition\nreturned by the environment is known as a state. Reward is an instant\nreturn from the environment to apprise the last action of the reinforcement learning agent. All of these terms are\npretty understandable. Next, we have something known as policy. Now, policy is the approach\nthat the agent uses to determine the next action based on the current state. Policy is basically the approach with which you go around\nin the environment. Next, we have something known as value. Now, the expected long-term\nreturn with a discount, as opposed to the short-term rewards R, is known as value. Now, terms like discount and value, I'll be discussing in the upcoming slides. Action-value is also very\nsimilar to the value, except it takes an extra parameter known as the current action. Don't worry about action and Q value. We'll talk about all of\nthis in the upcoming slides. So make yourself familiar\nwith these terms, because we'll be seeing a\nwhole lot of them this session. So, before we move any further, let's discuss a couple of more reinforcement learning concepts. Now we have something known\nas the reward maximization. So if you haven't realized it already, the basic aim of\nreinforcement learning agent is to maximize the report. How does this happen? Let's try to understand this\nin a little more detail. So, basically the agent\nworks based on the theory of reward maximization. Now that's exactly why\nthe agent must be trained in such a way that he\ntakes the best action, so that the reward is maximal. Now let me explain a reward maximization with a small example. Now in this figure, you\ncan see there is a fox, there is some meat, and there is a tiger. Our reinforcement\nlearning agent is the fox. His end goal is to eat\nthe maximum amount of meat before being eaten by the tiger. Now because the fox is a very clever guy, he eats the meat that is closer to him, rather than the meat which\nis close to the tiger, because the closer he gets to the tiger, the higher are his\nchances of getting killed. That's pretty obvious. Even if the reward near the\ntiger are bigger meat chunks, that'll be discounted. This is exactly what discount is. We just discussed it\nin the previous slide. This is done because of\nthe uncertainty factor that the tiger might\nactually kill the fox. Now the next thing to\nunderstand is how discounting of a reward works. Now, in order to understand discounting, we define a discount rate called gamma. The value of gamma is\nbetween zero and one. And the smaller the gamma, the larger the discount and so on. Now don't worry about these concepts, gamma and all of that. We'll be seeing that in\nour practical demo today. So let's move on and\ndiscuss another concept known as exploration and\nexploitation trade-off. Now guys, before that, I\nhope all of you understood reward maximization. Basically, the main aim\nbehind reinforcement learning is to maximize the rewards\nthat an agent can get. Now, one of the most important concepts in reinforcement learning is the exploration and\nexploitation trade-off. Now, exploration, like the name suggests, it's about exploring and capturing more information about an environment. On the other hand, exploitation is about using the already known\nexploited information to heighten your reward. Now consider the same example that we saw previously. So here the fox eats only the meat chunks which are close to him. He doesn't eat the bigger meat chunks which are at the top, even though the bigger meat chunks would get him more reward. So if the fox only focuses\non the closest reward, he will never reach\nthe big chunks of meat. This process is known as exploitation. But if the fox decide to explore a bit, it can find the bigger reward, which is the big chunk of meat. This is known as exploration. So this is the difference\nbetween exploitation and exploration. It's always best if the agent\nexplores the environment, tries to figure out a\nway in which we can get the maximum number of rewards. Now let's discuss\nanother important concept in reinforcement learning, which is known as the\nMarkov's decision process. Basically, the mathematical\napproach for mapping a solution in reinforcement learning is called Markov's decision process. It's the mathematics behind\nreinforcement learning. Now, in a way, the purpose\nof reinforcement learning is to solve a Markov's decision process. Now in order to get a solution, there are a set of parameters in a Markov's decision process. There's a set of actions A, there's a set of states S, a reward R, policy pi, and value V. Also, this image represents how a reinforcement learning works. There's an agent. The agent take some\naction on the environment. The environment, in turn,\nwill reward the agent, and it will give him the next state. That's how reinforcement learning works so to sum everything up, what happens in Markov's decision process and reinforcement learning is the agent has to take an action A to transition from the start state to the end state S. While doing so, the agent\nwill receive some reward R for each action he takes. Now the series of action\nthat are taken by the agent define the policy and\nthe rewards collected to find the value. The main goal here is\nto maximize the rewards by choosing the optimum policy. So you're gonna choose\nthe best possible approach in order to maximize the rewards. That's the main aim of\nMarkov's decision process. To understand Markov's decision process, let's look at a small example. I'm sure all of you already know about the shortest path problem. We all had such problems\nand concepts in math to find the shortest path. Now consider this representation\nover here, this figure. Here, our goal is to\nfind the shortest path between two nodes. Let's say we're trying to find the shortest path between\nnode A and node D. Now each edge, as you can see, has a number linked with it. This number denotes the cost to traverse through that edge. So we need to choose a\npolicy to travel from A to D in such a way that our cost is minimum. So in this problem, the set of states are denoted by the nodes A, B, C, D. The action is to traverse\nfrom one node to the other. For example, if you're going from to A C, there is an action. C to B is an action. B to D is another action. The reward is the cost\nrepresented by each edge. Policy is the path taken\nto reach the destination. So we need to make sure\nthat we choose a policy in such a way that our cost is minimal. So what you can do is you\ncan start off at node A, and you can take baby steps\nto reach your destination. Initially, only the next\npossible node is visible to you. So from A, you can either go to B or you can go to C. So if you follow the greedy approach and take the most optimum step, which is choosing A to C, instead of choosing A to B to C. Now you're at node C and you want to traverse to node D. Again, you must choose\nyour path very wisely. So if you traverse from A to C, and C to B, and B to D, your cost is the lest. But if you traverse from A to C to D, your cost will actually increase. Now you need to choose a policy that will minimize your cost over here. So let's say, for example, the agent chose A to C to D. It came to node C, and\nthen it directly chose D. Now the policy followed by\nour agent in this problem is exploitation type, because we didn't explore the other notes. We just selected three nodes\nand we traversed through them. And the policy we followed is not actually an optimal policy. We must always explore more to find out the optimal policy. Even if the other nodes are\nnot giving us any more reward or is actually increasing our cost, we still have to explore and find out if those paths are actually better. That policy is actually better. The method that we implemented here is known as the policy-based learning. Now the aim here is to\nfind the best policy among all the possible policies. So guys, apart from policy-based, we also have value-based approach and action-based approach. Value based emphasizes on\nmaximizing the rewards. And in action base, we emphasize on each action taken by the agent. Now a point to note is that all of these learning approaches\nhave a simple end goal. The end goal is to\neffectively guide the agent through the environment, and acquire the most number of rewards. So this was very simple to understand Markov's decision process, exploitation and exploration trade-off, and we also discussed the different reinforcement\nlearning definitions. I hope all of this was understandable. Now let's move on and understand an algorithm known as\nQ-learning algorithm. So guys, Q-learning is one of\nthe most important algorithms in reinforcement learning. And we'll discuss this algorithm with the help of a small example. We'll study this example, and then we'll implement the\nsame example using Python, and we'll see how it works. So this is how our\ndemonstration looks for now. Now the problem statement\nis to place an agent in any one of the rooms numbered zero, one, two, three, and four. And the goal is for the agent to reach outside the building, which is room number five. So, basically, this zero,\none, two, three, four represents the building, and five represents a room\nwhich is outside the building. Now all these rooms\nare connected by those. Now these gaps that you\nsee between the rooms are basically those, and each room is numbered\nfrom zero to four. The outside of the building can be taught of as a big room which is room number five. Now if you've noticed this diagram, the door number one and door number four lead directly to room number five. From one, you can directly go to five, and from four, also, you\ncan directly go to five. But if you want to go to\nfive from room number two, then you'll first have to\ngo to room number three, room number one, and\nthen room number five. So these are indirect links. Direct links are from room\nnumber one and room number four. So I hope all of you are clear\nwith the problem statement. You're basically going to have a reinforcement learning agent, and than agent has to\ntraverse through all the rooms in such a way that he\nreaches room number five. To solve this problem, first, what we'll do is\nwe'll represent the rooms on a graph. Now each room is denoted as anode, and the links that are connecting\nthese nodes are the doors. Alright, so we have node one to five, and the links between each of these nodes represent the doors. So, for example, if you look\nat this graph over here, you can see that there\nis a direct connection from one to five, meaning that you can directly\ngo from room number one to your goal, which is room number five. So if you want to go from\nroom number three to five, you can either go to room number one, and then go to five, or you can go from room\nnumber three to four, and then to five. So guys, remember, end goal\nis to reach room number five. Now to set the room number\nfive as the goal state, what we'll do is we'll\nassociate a reward value to each door. The doors that lead\nimmediately to the goal will have an instant reward of 100. So, basically, one to five\nwill have a reward of hundred, and four to five will also\nhave a reward of hundred. Now other doors that are not directly connected to the target room will have a zero reward, because they do not directly\nlead us to that goal. So let's say you placed the\nagent in room number three. So to go from room number three to one, the agent will get a reward of zero. And to go from one to five, the agent will get a reward of hundred. Now because the doors are two-way, the two arrows are assigned to each room. You can see an arrow\ngoing towards the room and one coming from the room. So each arrow contains an instant reward as shown in this figure. Now of course room number five will loop back to itself\nwith a reward of hundred, and all other direct\nconnections to the goal room will carry a reward of hundred. Now in Q-learning, the\ngoal is to reach the state with the highest reward. So that if the agent arrives at the goal, it will remain there forever. So I hope all of you are\nclear with this diagram. Now, the terminologies in Q-learning include two terms, state and action. Okay, your room basically\nrepresents the state. So if you're in state two, it basically means that\nyou're in room number two. Now the action is basically\nthe moment of the agent from one room to the other room. Let's say you're going\nfrom room number two to room number three. That is basically an action. Now let's consider some more example. Let's say you place the\nagent in room number two and he has to get to the goal. So your initial state\nwill be state number two or room number two. Then from room number two,\nyou'll go to room number three, which is state three. Then from state three, you can\neither go back to state two or go to state one or state four. If you go to state four, from\nthere you can directly go to your goal room, which is five. This is how the agent\nis going to traverse. Now in order to depict the\nrewards that you're going to get, we're going to create a matrix\nknown as the reward matrix. Okay, this is represented by R or also known as the R matrix. Now the minus one in this\ntable represents null values. That is basically where there isn't a link between the nodes that is\nrepresented as minus one. Now there is no link\nbetween zero and zero. That's why it's minus one. Now if you look at this diagram, there is no direct link from zero to one. That's why I've put minus\none over here as well. But if you look at zero comma four, we have a value of zero over here, which means that you can\ntraverse from zero to four, but your reward is going to be zero, because four is not your goal state. However, if you look at the matrix, look at one comma five. In one comma five, we have\na reward value of hundred. This is because you can directly go from room number one to five, and five is the end goal. That's why we've assigned\na reward of hundred. Similarly, for four comma five, we have a reward of hundred. And for five comma five, we have a reward of hundred. Zeroes basically represent other links, but they are zero because they\ndo not lead to the end goal. So I hope you all understood\nthe reward matrix. It's very simple. Now before we move any further, we'll be creating another matrix known as the equitable Q matrix. Now the Q matrix basically\nrepresents the memory of what the agent has\nlearned through experience. The rules of the Q matrix will represent the current\nstate of the agent. The columns will represent\nthe next possible actions leading to the next state, and the formula to calculate the Q matrix is this formula, right? Here we have Q state comma action, R state comma action, which is nothing but the reward matrix. Then we have a parameter\nknown as the Gamma parameter, which I'll explain shortly. And then we are multiplying\nthis with a maximum of Q next state comma all actions. Now don't worry if you haven't\nunderstood this formula. I'll explain this with a small example. For now, let's understand\nwhat a Gamma parameter is. So, basically, the value of Gamma will be between zero and one. If Gamma is closer to zero, it means that the agent\nwill tend to consider only immediate rewards. Now, if the Gamma is closer to one, it means that the agent\nwill consider future rewards with greater weight. Now what exactly I'm trying to say is if Gamma is closer to one, then we'll be performing\nsomething known as exploitation. I hope you all remember what exploitation and exploration trade-off is. So, if your gamma is closer to zero, it means that the agent is not going to explore the environment. Instead, it'll just\nchoose a couple of states, and it'll just traverse\nthrough those states. But if your gamma\nparameter is closer to one, it means that the agent will traverse through all possible states, meaning that it'll perform exploration, not exploitation. So the closer your gamma\nparameter is to one, the more your agent will explore. This is exactly what Gamma parameter is. If you want to get the best policy, it's always practical that\nyou choose a Gamma parameter which is closer to one. We want the agent to\nexplore the environment as much as possible so that it can get the best\npolicy and the maximum rewards. I hope this is clear. Now let me just tell you what a Q-learning\nalgorithm is step by step. So you begin the Q-learning algorithm by setting the Gamma parameter and the environment rewards in matrix R. Okay, so, first, you'll\nhave set these two values. We've already calculated\nthe reward matrix. We need to set the Gamma parameter. Next, you'll initialize\nthe matrix Q to zero. Now why do you do this? Now, if you remember, I said that Q matrix is basically\nthe memory of the agent. Initially, obviously, the agent has no memory\nof the environment. It's new to the environment and you're placing it randomly anywhere. So it has zero memory. That's why you initialize\nthe matrix Q to zero. After that, you'll select\na random initial state, and you place your agent\nin that initial state. Then you'll set this initial\nstate as your current state. Now from the current state,\nyou'll select some action that will lead you to the next state. Then you'll basically\nget the maximum Q value for this next state, based on all the possible\nactions that we take. Then you'll keep computing the skew value until you reach the goals state. Now that might be a little bit confusing, so let's look at this entire\nthing with a small example. Let's say that first, you're gonna begin with setting your Gamma parameter. So I'm setting my Gamma parameter to 0.8 which is pretty close to one. This means that our agent\nwill explore the environment as much as possible. And also, I'm setting the\ninitial state as room one. Meaning, I'm in state\none or I'm in room one. So basically, your agent is\ngoing to be in room number one. The next step is to initialize\nthe Q matrix as zero matrix. So this is a Q matrix. You can see that\neverything is set to zero, because the agent has no memory at all. He hasn't traversed to any node, so he has no memory. Now since the agent is in room one he can either go to room number three or he can go to room number five. Let's randomly select room number five. So, from room number five, you're going to calculate\nthe maximum Q value for the next state based\non all possible actions. So all the possible actions\nfrom room number five is one, four, and five. So, basically, the traversing\nfrom Q one comma five, that's why I put one comma five over here, state comma action. Your reward matrix will\nhave R one comma five. Now R one comma five is basically hundred. That's why I put hundred over here. Now your comma parameter is 0.8. So, guys, what I'm doing here is I'm just substituting\nthe values in this formula. So let me just repeat this whole thing. Q state comma action. So you're in state number one, correct? And your action is you're\ngoing to room number five. So your Q state comma\naction is one comma five. Again, your reward matrix R\none comma five is hundred. So here's you're gonna put hundred, plus your Gamma parameter. Your Gamma parameter is 0.8. Then you're going to\ncalculate the maximum Q value for the next state based\non all possible actions. So let's look at the next state. From room number five,\nyou can go to either one. You can go to four or you can go to five. So your actions are five\ncomma one, five comma four, and five comma five. That's exactly what I mentioned over here. Q five comma one, Q five comma\nfour, and Q five comma five. You're basically putting all\nthe next possible actions from state number five. From here, you'll calculate the maximum Q value that you're\ngetting for each of these. Now your Q value is zero, because, initially, your\nQ matrix is set to zero. So you're going to get\nzero for Q five comma one, five comma four, and five comma five. So that's why you'll get 0.8 and zero, and hence your Q one comma\nfive becomes hundred. This hundred comes from R one comma five. I hope all of you understood this. So next, what you'll do is you'll update this one comma five\nvalue in your Q matrix, because you just calculated\nQ one comma five. So I've updated it over here. Now for the next episode, we'll start with a randomly\nchosen initial state. Again, let's say that we randomly\nchose state number three. Now from room number three, you can either go to room\nnumber one, two or four. Let's randomly select room number one. Now, from room number five, you'll calculate the maximum Q value for the next possible actions. So let's calculate the Q formula for this. So your Q state comma action\nbecomes three comma one, because you're in state number three and your action is you're\ngoing to room number one. So your R three comma one, let's see what R three comma one is. R three comma one is zero. So you're going to put zero over here, plus your Gamma parameter, which is 0.8, and then you're going to check\nthe next possible actions from room number one, and you're going to\nchoose the maximum value from these two. So Q one comma three and Q one comma five denote your next possible\nactions from room number one. So Q one comma three is zero, but Q one comma five is hundred. So we just calculated this\nhundred in the previous step. So, out of zero and hundred, hundred is your maximum value, so you're going to choose hundred. Now 0.8 into hundred is nothing but 80. So again, your Q matrix gets updated. You see an 80 over here. So, basically what you're doing\nis as you're taking actions, you're updating your Q value, you're just calculating\nthe Q value at every step, you're putting it in your Q matrix so that your agent remembers that, okay, when I went from room\nnumber one to room number five, I had a Q value of hundred. Similarly, three to one\ngave me a Q value of 80. So basically, this Q matrix represents the memory of your agent. I hope all of you are clear with this. So basically, what we're gonna do is we're gonna keep\niterating through this loop until we've gone through\nall possible states and reach the goal state, which is five. Also, our main aim here is to\nfind the most optimum policy to get to room number five. Now let's implement the exact\nsame thing using Python. So that was a lot of theory. Now let's understand how\nthis is done practically. Alright, so we begin by\nimporting your library. We're gonna be using the\nNumPy library over here. After that, we'll import the R matrix. We've already created the R matrix. This is the exact matrix that I showed you a couple of minutes ago. So I've created a matrix called R and I've basically stored\nall the rewards in it. If you want to see the R\nmatrix, let me print it. So, basically, this is your R matrix. If you remember, node one to five, you have a reward of hundred. Node four to five, you\nhave a reward of hundred, and five to five, you\nhave a reward of hundred, because all of these nodes\ndirectly lead us to the reward. Correct? Next, what we're doing is\nwe're creating a Q matrix which is basically a six into six matrix. Which represents all the\nstates, zero to five. And this matrix is basically zero. After, that we're setting\nthe Gamma parameter. Now guys, you can play\naround with this code, and you know you can\nchange the comma parameter to 0.7 or 0.9 and see how much more\nthe agent will explore or whether you perform exploitation. Here I've set the Gamma parameter 0.8 which is a pretty good number. Now what I'm doing is I'm\nsetting the initial state as one. You can randomly choose this state according to your needs. I've set the initial state as one. Now, this function will basically give me all the available actions\nfrom my initial state. Since I've set my initial state as one, It'll give me all the possible actions. Here what I'm doing is since\nmy initial state is one, I'm checking in my row number one, which value is equal to\nzero or greater than zero. Those denote my available actions. So look at our row number one. Here we have one zero and\nwe have a hundred over here. This is one comma four and\nthis is one comma five. So if you look at the row number one, since I've selected the\ninitial state as one, we'll consider row number one. Okay, what I'm doing is in row number one, I have two numbers which\nare either equal to zero or greater than zero. These denote my possible actions. One comma three has the value of zero and one comma five has\nthe value of hundred, which means that the agent can either go to room number three or it can go to room number five. What I'm trying to say\nis from room number one, you can basically go to room number three or room number five. This is exactly what I've coded over here. If you remember the reward matrix, from one you can traverse to\nonly room number three directly and room number five directly. Okay, that's exactly what I've mentioned in my code over here. So this will basically give\nme the available actions from my current state. Now once I've moved to me next state, I need to check the available\nactions from that state. What I'm doing over\nhere is basically this. If you're remember, from room number one, we can\ngo to three and five, correct? And from three and five, I'll randomly select the state. And from that state, I need to find out all possible actions. That's exactly what I've done over here. Okay. Now this will randomly\nchoose an action for me from all my available actions. Next, we need to update our Q matrix, depending on the actions that we took, if you remember. So that's exactly what this\nupdate function is four. Now guys, this entire is\nfor calculating the Q value. I hope all of you remember the formula, which is Q state comma action, R state comma action plus\nGamma into max value. Max value will basically\ngive me the maximum value out of the all possible actions. I'm basically computing this formula. Now this will just update the Q matrix. Coming to the training phase, what we're gonna do is we\nare going to set a range. Here I've set a range of 10,000, meaning that my agent will\nperform 10,000 iterations. You can set this depending\non your own needs, and 10,000 iteration is\na pretty huge number. So, basically, my agent\nis going to go through 10,000 possible iterations in order to find the best policy. Now this is the exact same\nthing that we did earlier. We're setting the current state, and then we're choosing\nthe available action from the current state. The from there, we'll\nchoose an action at random. Here we'll calculate a Q value and we'll update the\nQ value in the matrix. Alright. And here I'm doing nothing, but I'm printing the trained Q matrix. This was the training phase. Now the testing phase, basically, you're going to randomly\nchoose a current state. You're gonna choose a current state, and you're going to keep looping through this entire code, until you reach the goal state,\nwhich is room number five. That's exactly what I'm\ndoing in this whole thing. Also, in the end, I'm\nprinting the selected part. That is basically the\npolicy that the agent took to reach room number five. Now if I set the current state as one, it should give me the best policy to reach to room number\nfive from room number one. Alright, let's run this code, and let's see if it's giving us that. Now before that happens, I\nwant you to check and tell me which is the best possible way to get from room number\none to room number five. It's obviously directly like this. One to five is the best policy\nto get from room number one to room number five. So we should get an\noutput of one comma five. That's exactly what we're getting this is a Q matrix with all the Q values, and here we are getting the selected path. So if your current state is one, your best policy is to\ngo from one to five. Now, if you want to\nchange your current state, let's say we set the current state to two. And before we run the code, let's see which is the best possible way to get to room number\nfive from room number two. From room number two, you can go to three, then you can go to one, and\nthen you can go to five. This will give you a reward of hundred, or you can go to room number three, then go to four, and then go to five. This will also give you\na reward of hundred. Our path should be something like that. Let's save it and let's run the file. So, basically, from stage two, you're going to say three, then to four, and then to five. This is our best possible path from two to room number five. So, guys, this is exactly how the Q learning algorithm works, and this was a simple implementation of the entire example\nthat I just told you. Now if any of you still have doubts regarding Q learning or\nreinforcement learning, make sure you comment them\nin the comment section, and I'll try to answer all of your doubts. No we're done with machine learning. We've completed the whole\nmachine learning model. We've understood reinforcement learning, supervised learning,\nunsupervised learning, and so on. Before I'll get to deep learning, I want to clear a very\ncommon misconception. A lot of people get confused between AI machine\nlearning and deep learning, because, you know,\nartificial intelligence, machine learning and deep learning are very common applications. For example, Siri is an application of artificial intelligence, machine learning, and deep learning. So how are these three connected? Are they the same thing or how exactly is the relationship between\nartificial intelligence, machine learning, and deep learning? This is what I'll be discussing. now artificial intelligence\nis basically the science of getting machines to mimic\nthe behavior of human beings. But when it comes to machine learning, machine learning is a subset\nof artificial intelligence that focuses on getting\nmachines to make decisions by feeding them data. That's exactly what machine learning is. It is a subset of artificial intelligence. Deep learning, on the other hand, is a subset of machine learning that uses the concept of neural networks to solve complex problems. So, to sum it up, artificial intelligence, machine learning, and deep learning, are interconnected fields. Machine learning and deep learning aids artificial intelligence by providing a set of\nalgorithms and neural networks to solve data-driven problems. That's how AI, machine\nlearning, and deep learning are related. I hope all of you have\ncleared your misconceptions and doubts about AI,\nML, and deep learning. Now let's look at our next topic, which is limitations of machine learning. Now the first limitation\nis machine learning is not capable enough to\nhandle high dimensional data. This is where the input and\nthe output is very large. So handling and processing\nsuch type of data becomes very complex and it takes up a lot of resources. This is also sometimes known\nas the curse of dimensionality. So, to understand this in simpler terms, look at the image shown on this slide. Consider a line of hundred yards and let's say that you dropped\na coin somewhere on the line. Now it's quite convenient\nfor you to find the coin by simply walking along the line. This is very simple because\nthis line is considered as single dimensional entity. Now next, you consider that you have a square of hundred yards, and let's say you dropped a\ncoin somewhere in between. Now it's quite evident that\nyou're going to take more time to find the coin within that square as compared to the previous scenario. The square is, let's say,\na two dimensional entity. Let's take it a step ahead\nand let's consider a cube. Okay, let's say there's\na cube of 500 yards and you have dropped a coin\nsomewhere in between this cube. Now it becomes even more difficult for you to find the coin this time, because this is a three\ndimensional entity. So, as your dimension increases, the problem becomes more complex. So if you observe that the complexity is increasing the increase\nin your dimensions, and in real life, the\nhigh dimensional data that we're talking about\nhas thousands of dimensions that makes it very complex\nto handle and process. and a high dimensional data can easily be found in used\ncases like image processing, natural language processing,\nimage translation, and so on. Now in K-means itself, we saw that we had 16\nmillion possible colors. That is a lot of data. So this is why machine\nlearning is restricted. It cannot be used in the\nprocess of image recognition because image recognition and\nimages have a lot of pixels and they have a lot of\nhigh dimensional data. That's why machine learning\nbecomes very restrictive when it comes to such uses cases. Now the second major challenge\nis to tell the computer what are the features it should look for that will play an important role in predicted the outcome and\nin getting a good accuracy. Now this process is something\nknown as feature extraction. Now feeding raw data to\nthe algorithm rarely works, and this is the reason\nwhy feature extraction is a critical part of\nmachine learning workflow. Now the challenge for the\nprogrammer here increases because the effectiveness of the algorithm depends on how insightful\nthe programmer is. As a programmer, you have to tell the machine\nthat these are the features. And depending on these features, you have to predict the outcome. That's how machine learning works. So far, in all our demos, we saw that we were providing\npredictor variables. we were providing input variables that will help us predict the outcome. We were trying to find\ncorrelations between variables, and we're trying to find out the variable that is very important in\npredicting the output variable. So this becomes a challenge\nfor the programmer. That's why it's very difficult to apply machine learning model to complex problems like object recognition,\nhandwriting recognition, natural language processing, and so on. Now all these problems and all these limitations\nin machine learning led to the introduction of deep learning. Now we're gonna discuss\nabout deep learning. Now deep learning is\none of the only methods by which we can overcome the challenges of feature extraction. This is because deep learning models are capable of learning to focus on the right features by themselves, which requires very little\nguidance from the programmer. Basically, deep learning mimics\nthe way our brain functions. That is it learns from experience. So in deep learning, what happens is feature extraction happens automatically. You need very little\nguidance by the programmer. So deep learning will learn the model, and it will understand which\nfeature or which variable is important in predicting the outcome. Let's say you have millions\nof predictor variables for a particular problem statement. How are you going to sit down and understand the significance of each of these predictor variables it's going to be almost impossible to sit down with so many features. That's why we have deep learning. Whenever there's high dimensionality data or whenever the data is really large and it has a lot of features and a lot of predictor\nvariables, we use deep learning. Deep learning will extract\nfeatures on its own and understand which\nfeatures are important in predicting your output. So that's the main idea\nbehind deep learning. Let me give you a small example also. Suppose we want to make a system that can recognize the\nface of different people in an image. Okay, so, basically,\nwe're creating a system that can identify the faces of\ndifferent people in in image. If we solve this by using the typical machine learning algorithms, we'll have to define\nfacial features like eyes, nose, ears, et cetera. Okay, and then the system will identify which features are more\nimportant for which person. Now, if you consider deep\nlearning for the same example, deep learning will automatically\nfind out the features which are important for classification, because it uses the\nconcept of neural networks, whereas in machine learning we have to manually define these features on our own. That's the main difference\nbetween deep learning and machine learning. Now the next question is\nhow does deep learning work? Now when people started\ncoming up with deep learning, their main aim was to\nre-engineer the human brain. Okay, deep learning studies\nthe basic unit of a brain called the brain cell or a neuron. All of you biology students will know what I'm talking about. So, basically, deep learning is inspired from our brain structure. Okay, in our brains, we have\nsomething known as neurons, and these neurons are\nreplicated in deep learning as artificial neurons, which are also called perceptrons. Now, before we understand how\nartificial neural networks or artificial neurons work, let's understand how these\nbiological neurons work, because I'm not sure how many of you are bio students over here. So let's understand the\nfunctionality of biological neurons and how we can mimic this functionality in a perceptron or in\nan artificial neuron. So, guys, if you loo at this image, this is basically an image\nof a biological neuron. If you focus on the structure\nof the biological neuron, it has something known dendrites. These dendrites are basically\nused to receive inputs. Now the inputs are basically\nfound in the cell body, and it's passed on the\nnext biological neuron. So, through dendrites, you're\ngoing to receive signals from other neurons, basically, input. Then the cell body will\nsum up all these inputs, and the axon will transmit\nthis input to other neurons. The axon will fire up\nthrough some threshold, and it will get passed\nonto the next neuron. So similar to this, a perceptron\nor an artificial neuron receives multiple inputs, and applies various\ntransformations and functions and provides us an output. These multiple inputs are\nnothing but your input variables or your predictor variables. You're feeding input data\nto an artificial neuron or to a perceptron, and this perceptron will apply various functions and transformations, and it will give you an output. Now just like our brain consists of multiple connected neurons\ncalled neural networks, we also build something known as a network of artificial neurons called artificial neural networks. So that's the basic concept\nbehind deep learning. To sum it up, what\nexactly is deep learning? Now deep learning is a collection of statistical machine learning techniques used to learn feature\nhierarchies based on the concept of artificial neural networks. So the main idea behind deep learning is artificial neural networks which work exactly like\nhow our brain works. Now in this diagram, you can see that there are a couple of layers. The first layer is known\nas the input layer. This is where you'll\nreceive all the inputs. The last layer is known\nas the output layer which provides your desired output. Now, all the layers which are\nthere between your input layer and your output layer are\nknown as the hidden layers. Now, they can be any\nnumber of hidden layers, thanks to all the resources\nthat we have these days. So you can have hundreds of\nhidden layers in between. Now, the number of hidden layers and the number of perceptrons\nin each of these layers will entirely depend on the problem or on the use case that\nyou're trying to solve. So this is basically\nhow deep learning works. So let's look at the\nexample that we saw earlier. Here what we want to do\nis we want to perform image recognition using deep networks. First, what we're gonna\ndo is we are going to pass this high dimensional\ndata to the input layer. To mach the dimensionality\nof the input data, the input layer will contain multiple sub layers of perceptrons so that it consume the entire input. Okay, so you'll have multiple\nsub layers of perceptrons. Now, the output received\nfrom the input layer will contain patterns and\nwill only be able to identify the edges of the images,\nbased on the contrast levels. This output will then be fed\nto hidden layer number one where it'll be able to\nidentify facial features like your eyes, nose,\nears, and all of that. Now from here, the output will be fed to hidden layer number two, where it will be able to form entire faces it'll go deeper into face recognition, and this output of the hidden layer will be sent to the output layer or any other hidden layer that is there before the output layer. Now, finally, the output layer\nwill perform classification, based on the result that you'd get from your previous layers. So, this is exactly how\ndeep learning works. This is a small analogy that I use to make you understand\nwhat deep learning is. Now let's understand what a\nsingle layer perceptron is. So like I said, perceptron is basically an artificial neuron. For something known as single layer and multiple layer perceptron, we'll first focus on\nsingle layer perceptron. Now before I explain what\na perceptron really is, you should known that perceptrons\nare linear classifiers. A single layer perceptron is a linear or a binary classifier. It is used mainly in supervised learning, and it helps to classify\nthe given input data into separate classes. So this diagram basically\nrepresents a perceptron. A perceptron has multiple inputs. It has a set of inputs\nlabeled X one, X two, until X n. Now each of these input is\ngiven a specific weight. Okay, so W one represents\nthe weight of input X one. W two represents the weight\nof input X two, and so on. Now how you assign these weights is a different thing altogether. But for now, you need\nto know that each input is assigned a particular weightage. Now what a perceptron does\nis it computes some functions on these weighted inputs, and\nit will give you the output. So, basically, these weighted inputs go through something known as summation. Okay, summation is nothing but the product of each of your input with\nits respective weight. Now after the summation is done, this passed onto transfer function. A transfer function is nothing\nbut an activation function. I'll be discussing more\nabout this in a minute. The activation function. And from the activation function, you'll get the outputs\nY one, Y two, and so on. So guys, you need to\nunderstand four important parts in a perceptron. So, firstly, you have the input values. You have X one, X two, X three. You have something known\nas weights and bias, and then you have something\nknown as the net sum and finally the activation function. Now, all the inputs X are multiplied with\nthe respective weights. So, X one will be multiplied with W one. This is known as the summation. After this, you'll add\nall the multiplied values, and we'll call them as the weighted sum. This is done using the summation function. Now we'll apply the weighted sum to a correct activation function. Now, a lot of people have a confusion about activation function. Activation function is also\nknown as the transfer function. Now, in order to understand\nactivation function, this word stems from the way neurons in a human brain work. The neuron becomes activate only after a certain potential is reached. That threshold is known as\nthe activation protection. Therefore, mathematically, it can be represented by a function that reaches saturation after a threshold. Okay, we have a lot of\nactivation functions like signum, sigmoid,\ntan, hedge, and so on. You can think of activation function as a function that maps the input to the respective output. And now I also spoke\nabout weights and bias. Now why do we assign weights\nto each of these inputs? What weights do is they show a strength of a particular input, or how important a particular input is for predicting the final output. So, basically, the weightage of an input denotes the importance of that input. Now, our bias basically allows us to shift the activation function in order to get a precise output. So that was all about perceptrons. Now in order to make you\nunderstand perceptrons better, let's look at a small analogy. Suppose that you wanna go to a party happening near your hose. Now your decision will\ndepend on a set of factors. First is how is the weather. Second probably is your\nwife, or your girlfriend, or your boyfriend going with you. And third, is there any\npublic transport available? Let's say these are the three factors that you're going to consider\nbefore you go to a party. So, depending on these predictor variables or these features, you're going to decide whether\nyou're going to stay at home or go and party. Now, how is the weather is\ngoing to be your first input. We'll represent this with a value X one. Is your wife going with\nyou is another input X two. Any public transport is available is your another input X three. Now, X one will have two\nvalues, one and zero. One represents that the weather is good. Zero represents weather is bad. Similarly, one represents\nthat your wife is going, and zero represents that\nyour wife is not going. And in X three, again, one represents that there is public transport, and zero represents that\nthere is no public transport. Now your output will\neither be one or zero. One means you are going to the party, and zero means you will\nbe sitting at home. Now in order to understand weightage, let's say that the most\nimportant factor for you is your weather. If the weather is good, it means that you will\n100% go to the party. Now if you weather is not good, you've decided that you'll sit at home. So the maximum weightage is\nfor your weather variable. So if your weather is really good, you will go to the party. It is a very important\nfactor in order to understand whether you're going to sit at home or you're going to go to the party. So, basically, if X one equal to one, your output will be one. Meaning that if your weather is good, you'll go to the party. Now let's randomly assign\nweights to each of our input. W one is the weight\nassociated with input X one. W two is the weight with X two and W three is the weight\nassociated with X three. Let's say that your W one is six, your W two is two, and W three is two. Now by using the activation function, you're going to set a threshold of five. Now this means that it will fire when the weather is good and won't fire if the weather is bad, irrespective of the other inputs. Now here, because your weightage is six, so, basically, if you\nconsider your first input which has a weightage of six, that means you're 100% going to go. Let's say you're considering\nonly the second input. This means that you're not going to go, because your weightage is two\nand your threshold is five. So if your weightage is\nbelow your threshold, it means that you're not going to go. Now let's consider another scenario where our threshold is three. This means that it'll fire when either X one is high or the other two inputs are high. Now W two is associated with\nyour wife is going or not. Let's say the weather is bad and you have no public transportation, meaning that your x one\nand x three is zero, and only your x two is one. Now if your x two is one, your weightage is going to be two. If your weightage is two, you will not go because the\nthreshold value is set to three. The threshold value is\nset in such a way that if X two and X three\nare combined together, only then you'll go, or only if x one is true, then you'll go. So you're assigning\nthreshold in such a way that you will go for sure\nif the weather is good. This is how you assign threshold. This is nothing but your\nactivation function. So guys, I hope all of you understood, the most amount of weightage is associated with the\ninput that is very important in predicting your output. This is exactly how a perceptron works. Now let's look at the\nlimitations of a perceptron. Now in a perceptron, there\nare no hidden layers. There's only an input layer, and there is an output layer. We have no hidden layers in between. And because of this, you cannot classify non-linearly separable data points. Okay, if you have data,\nlike in this figure, how will you separate this. You cannot use a perceptron to do this. Alright, so complex problems that involve a lot of parameters cannot be solved by a single layer perceptron. That's why we need something known as multiple layer perceptron. So now we'll discuss something known as multilayer perceptron. A multilayer perceptron\nhas the same structure of a single layer perceptron, but with one or more hidden layer. Okay, and that's why it's\nconsider as a deep neural network. So in a single layer perceptron, we had only input layer, output layer. We didn't have any hidden layer. Now when it comes to\nmulti-layer perceptron, there are hidden layers in between, and then there is the output layer. It was in this similar\nmanner, like I said, first, you'll have the\ninput X one, X two, X three, and so on. And each of these inputs\nwill be assigned some weight. W one, W two, W three, and so on. Then you'll calculate\nthe weighted summation of each of these inputs and their weights. After that, you'll send\nthem to the transformation or the activation function, and you'll finally get the output. Now, the only thing is\nthat you'll have multiple hidden layers in between, one or more than one hidden layers. So, guys, this is how a\nmultilayer perceptron works. It works on the concept of\nfeed forward neural networks. Feed forward means\nevery node at each level or each layer is connected\nto every other node. So that's what feed forward networks are. Now when it comes to assigning weights, what we do is we randomly assign weights. Initially we have input\nX one, X two, X three. We randomly assign some\nweight W one, W two, W three, and so on. Now it's always necessary\nthat whatever weights we assign to our input, those weights are actually correct, meaning that those weights\nare company significant in predicting your output. So how a multilayer perceptron works is a set of inputs are passed\nto the first hidden layer. Now the activations from\nthat layer are passed through the next layer. And from that layer, it's\npassed to the next hidden layer, until you reach the output layer. From the output layer,\nyou'll form the two classes, class one and class two. Basically, you'll classify your input into one of the two classes. So that's how a multilayer\nperceptron works. A very important concept the\nmultiple layer perceptron is back propagation. Now what is back propagation. Back propagation algorithm is a supervised learning method\nfor multilayer perceptrons. Okay, now why do we need back propagation? So guys, when we are\ndesigning a neural network in the beginning, we initialize weights with some random values, or\nany variable for that fact. Now, obviously, we need to\nmake sure that these weights actually are correct, meaning that these weights\nshow the significance of each predictor variable. These weights have to fit our model in such a way that our\noutput is very precise. So let's say that we randomly selected some weights in the beginning, but our model output\nis much more different than our actual output, meaning that our error value is very huge. So how will you reduce this error. Basically, what you need to do is we need to somehow explain to the model that we need to change the weight in such a way that the\nerror becomes minimum. So the main thing is the\nweight and your error is very highly related. The weightage that you give to each input will show how much error\nis there in your output, because the most significant variables will have the highest weightage. And if the weightage is not correct, then your output is also not correct. Now, back propagation is a\nway to update your weights in such a way that your outcome is precise and your error is reduced. So, in short back\npropagation is used to train a multilayer perceptron. It's basically use to update your weights in such a way that your\noutput is more precise, and that your error is reduced. So training a neural network\nis all about back propagation. So the most common deep learning algorithm for supervised training of\nthe multilayer perceptron is known as back propagation. So, after calculating the\nweighted sum of inputs and passing them through\nthe activation function, we propagate backwards\nand update the weights to reduce the error. It's as simple as that. So in the beginning, you're\ngoing to assign some weights to each of your input. Now these inputs will go\nthrough the activation function and it'll go through all the hidden layers and give us an output. Now when you get the output, the output is not very precise, or it is not the desired output. So what you'll do is\nyou'll propagate backwards, and you start updating your weights in such a way that your error is as minimum as possible. So, I'm going to repeat this once more. So the idea behind back propagation is to choose weights in such a way that your error gets minimized. To understand this, we'll\nlook at a small example. Let's say that we have a data\nset which has these labels. Okay, your input is zero, one, two, but your desired output\nis zero, one, and four now the output of your model when W equal to three is like this. Notice the difference\nbetween your model output and your desired output. So, your model output is three, but your desired output is two. Similarly, when your model output is six, your desired output is\nsupposed to be four. Now let's calculate the error\nwhen weight is equal to three. The error is zero over here because your desired output is zero, and your model output is also zero. Now the error in the second case is one. Basically, your model output\nminus your desired output. Three minus two, your error is one. Similarly, your error for\nthe third input is two, which is six minus four. When you take the square, this is actually a very huge difference, your error becomes larger. Now what we need to do is we need to update the weight value in such a way that our error decreases. Now here we've considered\nthe weight as four. So when you consider the weight as four, your model output becomes\nzero, four, and eight. Your desired output is\nzero, two, and four. So your model output becomes\nzero, four, and eight, which is a lot. So guys, I hope you all know how to calculate the output over here. What I'm doing is I'm\nmultiplying the input with your weightage. The weightage is four, so zero into four will give me zero. One into four will give me four, and two into four will give me eight. That's how I'm getting my\nmodel output over here. For now, this is how I'm\ngetting the output over here. That's how you calculate your weightage. Now, here, if you see\nthat our desire output is supposed to be zero, two, and four, but we're getting an output\nof zero, four, and eight. So our error is actually increasing as we increase our weight. Our error four W equal to four have become zero, four, and 16, whereas the error for W equal to three, zero, one, and four. I mean the square error. So if you look at this, as\nwe increase our weightage, our error is increasing. So, obviously, we know that there is no point in increasing\nthe value of W further. But if we decrease the value of W, our error actually decreases. Alright, if we give a weightage of two, our error decreases. If we can find a relationship\nbetween our weight and error, basically, if you increase the weight, your error also increases. If you decrease the weight,\nyour error also decreases. Now what we did here\nis we first initialize some random value to W, and then we propagated forward. Then we notice that there is some error. And to reduce that error,\nwe propagated backwards and increase the value of W. After that, we notice that\nthe error has increased, and we came to know that we\ncan't increase the w value. Obviously, if your error is increasing with increasing your weight, you will not increase the weight. So again, we propagated backwards, and we decreased the W value. So, after that, we noticed\nthat the error has reduced. So what we're trying\nis we're trying to get the value of weight in such a way that the error becomes\nas minimum as possible so we need to figure out whether we need to increase or decrease thew eight value. Once we know that, we keep\non updating the weight value in that direction, until the error becomes minimum. Now you might reach a point where if you further update the weight, the error will again increase. At that point, you need to stop. Okay, at that point is where your final weight value is there. So, basically, this\ngraph denotes that point. Now this point is nothing\nbut the global loss minimum. If you update the weights further, your error will also increase. Now you need to find out where\nyour global loss minimum is, and that is where your\noptimum weight lies. So let me summarize the steps for you. First, you'll calculate the error. This is how far your model output is from your actual output. Then you'll check whether the error is minimized or not. After that, if the error is very huge, then you'll update the weight, and you'll check the error again. You'll repeat the process\nuntil the error becomes minimum now once you reach the\nglobal loss minimum, you'll stop updating the weights, and we'll finalize your weight value. This is exactly how\nback propagation works. Now in order to tell you\nmathematically what we're doing is we're using a method\nknown as gradient descent. Okay, this method is used to adjust all the weights in the network with an aim of reducing the\nerror at the output layer. So how gradient descent\noptimize our works is the first step is you\nwill calculate the error by considering the below equation. Here you're subtracting the\nsummation of your actual output from your network output. Step two is based on the error you get, you will calculate the\nrate of change of error with respect to the change in the weight. The learning rate is\nsomething that you set in the beginning itself. Step three is based on\nthis change in weight, you will calculate the new weight. Alright, your updated\nweight will be your weight plus the rate of change of weight. So guys, that was all about back propagation and weight update. Now let's look at the limitations\nof feed forward network. So far, we were discussing\nthe multiple layer perceptron, which uses the feed forward network. Let's discuss the limitations of these feed forward networks. Now let's consider an example\nof image classification. Okay, let's say you've\ntrained the neural network to classify images of various animals. Now let's consider an example. Here the first output is an elephant. We have an elephant. And this output will have nothing to do with the previous output, which is a dog. This means that the output at time T is independent of the\noutput at time T minus one. Now consider this scenario where you will require the use of previously obtained output. Okay, the concept is very\nsimilarly to reading a book. As you turn every page, you need an understanding of the previous pages if you want to make\nsense of the information, then you need to know\nwhat you learned before. That's exactly what\nyou're doing right now. In order to understand deep learning, you have to understand machine learning. So, basically, with the\nfeed forward network the new output at time T plus one has nothing to do with\nthe output at time T, or T minus one, or T minus two. So feed forward networks cannot be used while predicting a word in a sentence, as it will have absolutely no relationship with the previous set of words. So, a feed forward\nnetwork cannot be used in use cases wherein you have\nto predict the outcome based on your previous outcome. So, in a lot of use cases, your previous output will also\ndetermine your next output. So, for such cases, you may not make use of feed forward network. Now, what modification can you make so that your network can learn from your previous mistakes. For this, we have solution. So, a solution to this is\nrecurrent neural networks. So, basically, let's say you have an input at time T minus one, and you'll get some output when\nyou feed it to the network. Now, some information from\nthis input at T minus one is fed to the next input, which is input at time T. Some information from this output is fed into the next input, which is input at T plus one. So, basically, you keep\nfeeding information from the previous input to the next input. That's how recurrent neural\nnetworks really work. So recurrent networks are a type of artificial neural networks designed to recognize\npatterns in sequence of data, such as text, genomes,\nhandwriting, spoken words, time series data, sensors, stock markets, and government agencies. So, guys, recurrent neural\nnetworks are actually a very important part of deep learning, because recurring neural networks have applications in a lot of domains. Okay, in time series and in stock markets, the main network that I use are recurrent neural networks, because each of your inputs are correlated now to better understand\nrecurrent neural networks, let's consider a small example let's say that you go\nto the gym regularly, and the trainer has given you a schedule for your workout. So basically, the exercises are repeated after every third day. Okay, this is what your\nschedule looks like. So, make a note that all\nthese exercises are repeated in a proper order or in\na sequence every week first, let us use a feedforward network to try and predict the type of exercises that we're going to do. The inputs here are Day\nof the week, the month, and your health status. Okay, so, neural network has to be trained using these inputs to provide\nus with the prediction of the exercise that we should do. Now let's try and understand\nthe same thing using recurrent neural networks. In recurrent neural networks, what we'll do is we'll consider the inputs of the previous day. Okay, so if you did a\nshoulder workout yesterday, then you can do a bicep exercise today, and this goes on for the rest of the week. However, if you happen\nto miss a day at the gym, the data from the previously\nattended time stamps can be considered. It can be done like this. So, if a model is\ntrained based on the data it can obtain from the previous exercise, the output on the model\nwill be extremely accurate. In such cases, if you\nneed to do know the output at T minus one in order to\npredict the output at T. In such cases, recurrent neural\nnetworks are very essential. So, basically, I'm feeding some inputs through the neural networks. You'll go through a few functions, and you'll get the output. So, basically, you're\npredicting the output based on past information\nor based on your past input. So that's how recurrent\nneural networks work. Now let's look at another\ntype of neural network known as convolutional neural network. To understand why we need\nconvolutional neural networks, let's look at an analogy. How do you think a\ncomputer reads an image? Consider this image. This is a New York skyline image. On the first glance, you'll see a lot of buildings\nand a lot of colors. How does a computer process this image? The image is actually broken\ndown into three color channels, which is the red, green, and blue. It reads in the form of RGB values. Now each of these color\nchannels are mapped with the image's pixel then the computer will recognize the value associated with each pixel, and determine the size of the image. Now for the black and white images, there is only one channel, but the concept is still the same. The thing is we cannot make use of fully connected networks when it comes to convolutional neural networks. I'll tell you why. Now consider the first input image. Okay, first image has size about 28 into 28 into three pixels. And if we input this to a neural network, we'll get about 2,352 weights in the first hidden layer itself. Now consider another example. Okay, let's say we have an image of 200 into 200 into three pixels. So the size of your first hidden layer becomes around 120,000. Now if this is just\nthe first hidden layer, imagine the number of\nneurons that you need to process an entire complex image set. This leads to something\nknown as overfitting, because all of the hidden\nlayers are connected. They're massively connected. There's connection between\neach and every node. Because of this, we face overfitting. We have way too much of data. We have to use way too many neurons, which is not practical. So that's why we have something known as convolutional neural networks. Now convolutional neural networks, like any other neural network are made up of neurons with\nlearnable weights and basis. So each neuron receives several input. It takes a weighted sum over them, and it gets passed on through\nsome activation function, and finally responds with an output. So, the concept in\nconvolutional neural networks is that the neuron in a particular layer will only be connected to a small region of the layer before it. Not all the neurons will be connected in a fully-connected manner, which leads to overfitting because we need way too many neurons to solve this problem. Only the regions, which are significant are connected to each other. There is no full connection in convolutional neural networks. So gus, what we did so far is we discussed what a perceptron is. We discussed the different types of neural networks that are there. We discussed a feedforward neural network. We discuss multi layer perceptrons we discussed recurrent neural networks, and convolutional neural networks. I'm not going to go too much in depth with these concepts now I'll be executing a demo. If you you haven't understood any theoretical concept of deep learning, please let me know in the comment section. Apart from this, I'll also leave a couple of links in the description box, so that you understand the\nwhole download in a better way. Okay, if you want a more\nin-depth explanation, I'll leave a couple of links\nin the description box. For now, what I'm gonna\ndo is I'll be running a practical demonstration to show you what exactly download does so, basically, what we're\ngoing to do in this demo is we're going to predict stock prices. Like I said, stock price prediction is one of the very good applications of deep neural networks. You can easily predict the stock price of a particular stock for the next minute or the next day by using\ndeep neural networks. So that's exactly what\nwe're gonna do in this demo now, before I discuss the code, let me tell you a few\nthings about our data set. The data set contains\naround 42,000 minutes of data ranging from April to August 2017 on 500 stocks, as well as the total S&P 500 Index price. So the index and stocks are arranged in a wide format. So, this is my data set, data_stocks. It's in the CSV format. So what I'm gonna do is I'm going to use the read CSV function in\norder to import this data set. This is just the part of\nwhere my data set is stored. This data set was actually\ncleaned and prepared, meaning that we don't\nhave any missing stock and index prices. So the file does not\ncontain any missing values. Now what we're gonna do first is we'll drop the data valuable we have a variable known as date, which is not really necessary in predicting our outcome over here. So that's exactly what I'm doing here. I'm just dropping the date variable. So here, I'm checking the\ndimensions of the data set. This is pretty understandable, using the shape function to do that. Now, always you make the\ndata as a NymPy array. This makes computation much easier. The next process is the data splicing. I've already discussed data\nthe data splicing with you all. Here we're just preparing the training and the testing data. So the training data will contain 80% of the total data set. Okay, and also we are not\nshuffling the data set. We're just slicing the\ndata set sequentially. That's why we have a test start start and the test end variable. In sequence, I'll be selecting the data. There's no need of\nshuffling this data set. These are stock prices it does not make sense\nto shuffle this data. Now in the next step, we're going to do is we're going to scale the data now, scaling data and data normalization is one of the most important steps. You cannot miss this step I already mentioned earlier what normalization and scaling is. Now most neural networks benefit from scaling inputs. This is because most\ncommon activation function of the networks neuron such\nas tan, hedge, and sigmoid. Tan, hedge, and sigmoid are\nbasically activation functions, and these are defined in the\nrange of minus one to one or zero and one. So that's why scaling\nis an important thing in deep neural networks for scaling, again, we'll\nuse the MinMaxScaler. So we're just importing\nthat function over here. And also one point to note is that you have to be very cautious about what part of data you're scaling and when you're doing it. A very common mistake is\nto scale the whole data set before training and test\nsplits are being applied. So before data splicing itself, you shouldn't be scaling your data. Now this is a mistake because scaling invokes the\ncalculation of statistics. For example, minimum or\nmaximum range of the variable gets affected. So when performing time series\nforecasting in real life, you do not have information\nfrom future observations at the time of forecasting. That's why calculation\nof scaling statistics has to be conducted on training data, and only then it has to be\napplied to the test data. Otherwise, you're basically\nusing the future information at the time of forecasting, which obviously going to lead to biasness so that's why you need to make sure you do scaling very accurately. So, basically, what we're\ndoing is the number of features in the training data are stored in a variable known as n stocks. After this, we'll import\nthe infamous TensorFlow. So guys, TensorFlow is\nactually a very good piece of software and it\nis currently the leading deep learning and neural\nnetwork computation framework. It is based on a C++ low-level backend, but it's usually\ncontrolled through Python. So TensorFlow actually operates as a graphical representation\nof your computations. And this is important\nbecause neural networks are actually graphs of data\nand mathematical operation. So that's why TensorFlow is just perfect for neural networks and deep learning. So the next thing after\nimporting the TensorFlow library is something known as placeholders. Placeholders are used to\nstore, import, and target data. We need two placeholders\nin order to fit our model. So basically, X will\ncontain the network's input, which is the stock\nprices of all the stocks at time T equal to T. And y will contain the network's output, which is the stock price at\ntime T is equal to T plus one. Now the shape of the X placeholder means that the inputs are\ntwo-dimensional matrix. And the outputs are a\none-dimensional vector. So guys, basically, the\nnon-argument indicates that at this point we do not yet know the number of observations that'll flow through the neural network. We just keep it as a\nflexible array for now. We'll later define the variable batch size that controls the number of observations in each training batch. Now, apart form this, we also have something know as initializers. Now, before I tell you what\nthese initializers are, you need to understand that there's something known as variables that are used as flexible containers that are allowed to change\nduring the execution. Weights and bias are\nrepresented as variables in order to adapt during training. I already discuss weights\nand bias with you earlier. Now weights and bias is something that you need to initialize\nbefore you train the model. That's how we discussed it\neven while I was explaining neural networks to you. So here, basically, we make\nuse of something known as variant scaling initializer and for bias initializer, we make use of zeros initializers. These are some predefined\nfunctions in our TensorFlow model. We'll not get into the\ndepth of those things. Now let's look at our model\narchitecture parameters. So the next thing we have to discuss is the model architecture parameters. Now the model that we build, it consists of four hidden layers. For the first layer, we've\nassigned 1,024 neurons which is likely more than\ndouble the size of the inputs. The subsequent hidden layers are always half the size of the previous layer, which means that in the\nhidden layer number two, we'll have 512 neurons. Hidden layer three will have 256. And similarly, hidden layer number four will have 128 neurons. Now why do we keep reducing\nthe number of neurons as we go through each hidden layer. We do this because the number of neurons for each subsequent layer\ncompresses the information that the network identifies\nin the previous layer. Of course there are other\npossible network architectures that you can apply for\nthis problem statement, but I'm trying to keep\nit as simple as possible, because I'm introducing\ndeep learning to you all. So I can't build a model architecture that's very complex and hard to explain. And of course, we have output over here which will be assigned a single neuron. Now it is very important to understand that variable dimensions\nbetween your input, hidden, and output layers. So, as a rule of thumb in\nmultilayer perceptrons, the second dimension of the previous layer is the first dimension\nin the current layer. So the second dimension\nin my first hidden layer is going to be my first dimension\nin my second hidden layer. Now the reason behind\nthis is pretty logical. It's because the output\nfrom the first hidden layer is passed on as an input\nto the second hidden layer. That's why the second\ndimension of the previous layer is the same as the first dimension of the next layer or the current layer. I hope this is understandable. Now coming to the bias\ndimension over here, the bias dimension is always equal to the second dimension\nof your current layer, meaning that you're just going to pass the number of neurons in\nthat particular hidden layer as your dimension in your bias. So here, the number of neurons, 1,024, you're passing the same number\nas a parameter to your bias. Similarly, even for\nhidden layer number two, if you see a second dimension here is n_neurons_2. I'm passing the same\nparameter over here as well. Similarly, for hidden layer three and hidden layer number four. Alright, I hope this is understandable now we come to the output layer. The output layer will obviously have the output from hidden layer number four. This is our output from hidden layer four that's passed as the first\ndimension in our output layer, and it'll finally have your n target, which is set to one over here. This is our output. Your bias will basically have\nthe current layer's dimension, which is n target. You're passing that same\nparameter over here. Now after you define the required weight and the bias variables, the architecture of the\nnetwork has to be specified. What you do is placeholders and variables need to be combined into a system of sequential matrix multiplication. So that's exactly what's\nhappening over here. Apart from this, all the hidden layers need to be transformed by\nusing the activation function. So, activation functions are important components of the network because they introduce\nnon-linearity to the system. This means that high dimensional data can be dealt with with the help\nof the activation functions. Obviously, we have very\nhigh dimensional data when it comes to neural networks. We don't have a single dimension or we don't have two or three inputs. We have thousands and thousands of inputs. So, in order for a\nneural network to process that much of high dimensional data, we need something known\nas activation functions. That's why we make use\nof activation functions. Now, there are dozens\nof activation functions, and one of the most common one is the rectified linear unit, rectified linear unit. RELU is nothing but rectified linear unit, which is what we're gonna\nbe using in this model. So, after, you applied the\ntransformation function to your hidden layer, you\nneed to make sure that your output is transposed. This is followed by a very\nimportant function known as cost function. So the cost function of a network is used to generate a measure of deviation between the network's prediction and the actual observed training targets. So this is basically your actual output minus your model output. It basically calculates the\nerror between your actual output and your predicted output. So, for regression problems,\nthe mean squared error function is commonly used. I have discussed MSC, mean\nsquared error, before. So, basically, we are just measuring the deviation over here. MSC is nothing bot your deviation from your actual output. That's exactly what we're doing here. So after you've computed your error, the next step is obviously to update your weight and your bias. So, we have something\nknown as the optimizers. They basically take care of\nall the necessary computations that are needed to adapt\nthe network's weight and bias variables during\nthe training phase. That's exactly what's happening over here. Now the main function of\nthis optimizer is that it invoke something known as a gradient. Now if you all remember, we\ndiscussed gradient before it basically indicates the direction in which the weights and the bias has to be changed during the training in order to minimize the\nnetwork's cost function or the network's error. So you need to figure out\nwhether you need to increase the weight and the bias in\norder to decrease the error, or is it the other way around? You need to understand the relationship between your error and\nyour weight variable. That's exactly what the optimizer does. It invokes the gradient. We will give you the\ndirection in which the weights and the bias have to be changed. So now that you know\nwhat an optimizer does, in our model, we'll be using something known as the AdamOptimizer. This is one of the\ncurrent default optimizers in deep learning. Adam basically stands for\nadaptive moment estimation, and it can be considered\nas a combination between very two popular optimizers\ncalled Adagrad and RMSprop. Now let's not get into the\ndepth of the optimizers. The main agenda here is for you to understand the\nlogic behind deep learning. We don't have to go into the functions. I know these are predefined functions which TensorFlow takes care of. Next we have something\nknown as initializers. Now, initializers are used to initialize the network's variables before training. We already discussed this before. I'll define the initializer here again. I've already done it\nearlier in this session. Initializers are already defined. So I just removed that line of code. Next step would be fitting\nthe neural network. So after we've defined the\nplace holders, the variables, variables which are\nbasically weights and bias, the initializers, the cost functions, and the optimizers of the network, the model has to be trained. Now, this is usually done by using the mini batch training method, because we have very huge data set. So it's always best to use the\nmini batch training method. Now what happens during\nmini batch training is random data samples of any batch size are drawn from the training data, and they are fed into the network. So the training data set gets divided into N divided by your batch size batches that are sequentially\nfed into the network. So, one after the other, each of these batches will\nbe fed into the network. At this point, the placeholder\nwhich are your X and Y, they come into play. They store the input and the target data and present them to the\nnetwork as inputs and targets. That's the main functionality\nof placeholders. What they do is they store\nthe input and the target data, and they provide this to the network as inputs and targets. That's exactly what your placeholders do. So let's say that a\nsample data batch of X. Now this data batch\nflows through the network until it reaches the output layer. There the TensorFlow compares\nthe model's predictions against the actual observed targets, which is stored in Y. If you all remember, we stored our actual\nobserved targets in Y. After this, TensorFlow will conduct something known as optimization step, and it'll update the network's parameters like the weight of the\nnetwork and the bias. So after having update\nyour weight and the bias, the next batch is sampled and\nthe process gets repeated. So this procedure will continue until all the batches have\npresented to the network. And one full sweep over all batches is known as an epoch. So I've defined this\nentire thing over here. So we're gonna go through 10 epochs, meaning that all the batches are going to go through training, meaning you're going to\ninput each batch that is X, and it'll flow through the network until it reaches the output layer. There what happens is TensorFlow will compare your predictions. That is basically what\nyour model predicted against the actual observed targets which is stored in Y. After this, TensorFlow\nwill perform optimization wherein it'll update the network paramters like your weight and your bias. After you update the weight and the bias, the next batch will get sampled and the process will keep repeating. This happens until all the batches are implemented in the network. So what I just told you was one epoch. We're going to repeat this 10 times. So a batch size is 256, meaning that we have 256 batches. So here we're going to assign x and y, what I just spoke to you about. The mini batch training starts over here so, basically, your first batch will start flowing through the network until it reaches the output layer. After this, TensorFlow will\ncompare your model's prediction. This is where predictions happen. It'll compare your model's prediction to the actual observed targets which is stored in y. Then TensorFlow will\nstart doing optimization, and it'll update the network paramters like your weight and your bias. So after you update the\nweight and the biases, the next batch will get\ninput into the network, and this process will keep repeating. This process will repeat 10 times because we've defined 10 epochs. Now, also during the training, we evaluate the network's\nprediction on the test set, which is basically the data\nwhich we haven't learned, but this data is set aside\nfor every fifth batch, and this is visualized. So in our problem statement, what a network is going to do is it's going to predict the stock price continuously over a time\nperiod of T plus one. We're feeding it data about\na stock price at time T. It's going to give us an\noutput of time T plus one. Now let me run this code and let's see how close\nour predicted values are to the actual values. We're going to visualize\nthis entire thing, and we've also exported this in order to combine it\ninto a video animation. I'll show you what the video looks like. So now let's look at our visualization. We'll look at our output. So the orange basically\nshows our model's prediction. So the model quickly learns the shape and the location of the\ntime series in the test data and showing us an accurate prediction. It's pretty close to\nthe actual prediction. Now as I'm explaining this to you, each batch is running here. We are at epoch two. We have 10 epochs to go over here. So you can see that the\nnetwork is actually adapting to the basic shape of the time series, and it's learning finer\npatterns in the data. You see it keeps learning patterns and the production is\ngetting closer and closer after every epoch. So let just wait til we reach epoch 10 and we complete the entire process. So guys, I think the\npredictions are pretty close, like the pattern and the\nshape is learned very well by our neural network. It is actually mimicking this network. The only deviation is in the values. Apart from that, it's learning the shape of the time series data\nin almost the same way. The shape is exactly the same. It looks very similar to me. Now, also remember that\nthere are a lot of ways of improving your result. You can change the design of your layers or you can change the number of neurons. You can choose different\ninitialization functions and activation functions. You can introduce something\nknown as dropout layers which basically help you\nto get rid of overfitting, and there's also something\nknown as early stopping. Early stopping helps you understand where you must stop your batch training. That's also another method\nthat you can implement for improving your model. Now there are also different\ntypes of deep learning model that you can use for this problem. Here we use the feedforward network, which basically means that the batches will flow from left to right. Okay, so our 10 epochs are over. Now the final thing that's\ngetting calculate is our error, MSC or mean squared error. So guys, don't worry about this warning. It's just a warning. So our mean square error\ncomes down to 0.0029 which is pretty low because\nthe target is scaled. And this means that our\naccuracy is pretty good. So guys, like I mentioned, if you want to improve\nthe accuracy of the model, you can use different schemes, you can use different\ninitialization functions, or you can try out different\ntransformation functions. You can use something\nknown as dropout technique and early stopping in order\nto make the training phase even more better. So guys, that was the end\nof our deep learning demo. I hope all of you understood\nthe deep learning demo. For those of you who are just learning deep learning for the first time, it might be a little confusing. So if you have any doubts\nregarding the demo, let me know in the comment section. I'll also leave a couple of\nlinks in the description box, so that you can understand deep learning in a little more depth. Now let's look at our\nfinal topic for today, which is natural language processing. Now before we understand\nwhat text mining is and what natural language processing is, we have to understand\nthe need for text mining and natural language processing. So guys, the number one reason why we need text mining and natural\nlanguage processing is because of the amount of data that we're generating during this time. Like I mentioned earlier, there are around 2.5\nquintillion bytes of data that is created every day, and this number is only going to grow. With the evolution of communication through social media, we generate tons and tons of data. The numbers are on your screen. These numbers are\nliterally for every minute. On Instagram, every minute, 1.7\nmillion pictures are posted. Okay, 1.7 or more than 1.7\nmillion pictures are posted. Similarly, we have tweets. We have around 347,000 tweets\nevery minute on Twitter. This is actually a lot and lot of data. So, every time we're using a phone, we're generating way too much data. Just watching a video on YouTube is generating a lot of data. When sending text messages from WhatsApp, that is also generating\ntons and tons of data. Now the only problem is\nnot our data generation. The problem is that out of all the data that we're generating,\nonly 21% of the data is structured and well-formatted. The remaining of the data is unstructured, and the major source of\nunstructured data include text messages from\nWhatsApp, Facebook likes, comments on Instagram, bulk emails that we send out ever single day. All of this accounts for\nthe unstructured data that we have today. Now the question here is what can be done with so much data. Now the data that we generate can be used to grow businesses. By analyzing and mining the data, we can add more value to a business. This exactly what text\nmining is all about. So text mining or text analytics is the analysis of data available to us in a day-to-day spoken\nor written language. It is amazing so much\ndata that we generate can actually be used in text mining. We have data from word Word documents, PowerPoints, chat messages, emails. All of this is used to\nadd value to a business now the data that we get from sources like social media, IoT, they are mainly unstructured, and unstructured data cannot be used to draw useful insights\nto grow a business. That's exactly why we need to text mining. Text mining or text analytics is the process of deriving\nmeaningful information from natural language text. So, all the data that we\ngenerate through text messages, emails, documents, files, are written in natural language text. And we are going to use text mining and natural language processing to draw useful insights or\npatterns from such data. Now let's look at a few examples to show you how natural\nlanguage processing and text mining is used. So now before I move any further, I want to compare text mining and NLP. A lot of you might be confused about what exactly text mining is and how is it related to\nnatural language processing. A lot of people have also asked me why is NLP and text mining considered as one and the same and are they the same thing. So, basically, text mining is a vast field that makes use of natural\nlanguage processing to derive high quality\ninformation from the text. So, basically, text mining is a process, and natural language\nprocessing is a method used to carry out text mining. So, in a way, you can say that text mining is a vast field which uses and NLP in order perform text\nanalysis and text mining. So, NLP is a part of text mining. Now let's understand what exactly natural language processing is. Now, natural language processing is a component of text mining which basically helps a\nmachine in reading the text. Obviously, machines don't\nactually known English or French, they interpret data in the\nform of zeroes and ones. So this is where natural\nlanguage processing comes in. NLP is what computers and smart phones use to understand our language, both spoken and written language. Now because use language to\ninteract with our device, NLP became an integral part of our life. NLP uses concepts of computer science and artificial intelligence to study the data and derive\nuseful information from it. Now before we move any further, let's look at a few applications\nof NLP and text mining. Now we all spend a lot\nof time surfing the webs. Have you ever notice that if you start typing a word on Google, you immediately get\nsuggestions like these. These feature is also\nknown as auto complete. It'll basically suggest the\nrest of the word for you. And we also have something\nknown as spam detection. Here is an example of\nhow Google recognizes the misspelling Netflix and shows results for keywords\nthat match your misspelling. So, the spam detection is also based on the concepts of text mining and natural language processing. Next we have predictive\ntyping and spell checkers. Features like auto correct,\nemail classification are all applications\nof text mining and NLP. Now we look at a couple\nof more applications of natural language processing. We have something known\nas sentimental analysis. Sentimental analysis is extremely useful in social media monitoring, because it allows us to gain an overview of the wider public opinion\nbehind certain topics. So, basically, sentimental analysis is used to understand the public's opinion or customer's opinion on a certain product or on a certain topic. Sentimental analysis is\nactually a very huge part of a lot of social media platforms like Twitter, Facebook. They use sentimental\nanalysis very frequently. Then we have something known as chatbot. Chatbots are basically the solutions for all the consumer frustration, regarding customer call assistance. So we have companies like Pizza Hut, Uber who have started using chatbots to provide good customer service, apart form that speech recognition. NLP has widely been used\nin speech recognition. We're all aware of Alexa,\nSiri, Google Assistant, and Cortana. These are all applications of\nnatural language processing. Machine translation is another\nimportant application of NLP. An example of this is\nthe Google Translator that uses NLP to process and translate one language to the other. Other application include spell checkers, keywords search, information extraction, and NLP can be used to\nget useful information from various website, from word documents, from files, and et cetera. It can also be used in\nadvertisement matching. This basically means a\nrecommendation of ads based on your history. So now that you have a\nbasic understanding of where natural language processing is used and what exactly it is, let's take a look at\nsome important concepts. So, firstly, we're gonna\ndiscuss tokenization. Now tokenization is the mos\nbasic step in text mining. Tokenization basically\nmeans breaking down data into smaller chunks or tokens so that they can be easily analyzed. Now how tokenization works is it works by breaking a\ncomplex sentence into words. So you're breaking a\nhuge sentence into words. You'll understand the\nimportance of each of the word with respect to the whole sentence, after which will produce a description on an input sentence. So, for example, let's\nsay we have this sentence, tokens are simple. If we apply tokenization on this sentence, what we get is this. We're just breaking a sentence into words. Then we're understanding the importance of each of these words. We'll perform NLP process\non each of these words to understand how important each word is in this entire sentence. For me, I think tokens and\nsimple are important words, are is basically another stop word. We'll be discussing about stop\nwords in our further slides. But for now, you eed to\nunderstand that tokenization is a very simple process that involves breaking sentences into words. Next, we have something known as stemming. Stemming is basically normalizing words into its base form or into its root form. Take a look at this example. We have words like detection, detecting, detected, and detections. Now we all know that the root word for all these words is detect. Basically, all these words mean detect. So the stemming algorithm\nworks by cutting off the end or the beginning of the word and taking into account\na list of common prefixes and suffixes that can\nbe found on any word. So guys, stemming can be\nsuccessful in some cases, but not always. That is why a lot of people affirm that stemming has a lot of limitations. So, in order to overcome\nthe limitations of stemming, we have something known as lemmatization. Now what lemmatization does is it takes into consideration\nthe morphological analysis of the words. To do so, it is necessary to\nhave a detailed dictionary which the algorithm can look\nthrough to link the form back to its lemma. So, basically lemmatization is also quite similar to stemming. It maps different words\ninto one common root. Sometimes what happens in stemming is that most of the words gets cut off. Let's say we wanted to\ncut detection into detect. Sometimes it becomes\ndet or it becomes tect, or something like that. So because of this, the grammar or the importance of the word goes away. You don't know what\nthe words mean anymore. Due to the indiscriminate\ncutting of the word, sometimes the grammar the\nunderstanding of the word is not there anymore. So that's why lemmatization\nwas introduced. The output of lemmatization\nis always going to be a proper word. Okay, it's not going to be\nsomething that is half cut or anything like that. You're going to understand\nthe morphological analysis and then only you're going\nto perform lemmatization. An example of a lemmatizer is you're going to convert\ngone, going, and went into go. All the three words anyway\nmean the same thing. So you're going to convert it into go. We are not removing the first\nand the last part of the word. What we're doing is we're understanding the grammar behind the word. We're understanding the English or the morphological analysis of the word, and only then we're going\nto perform lemmatization. That's what lemmatization is all about. Now stop words are basically a set of commonly used words in any\nlanguage, not just English. Now the reason why stop words are critical to many applications is that if we remove the words\nthat are very commonly used in a given language, we can finally focus\non the important words. For example, in the\ncontext of a search engine, let's say you open up Google and you try how to make\nstrawberry milkshake. What the search engine is going to do is it's going to find a lot more pages that contain the terms how to make, rather than pages which contain the recipe for your strawberry milkshake. That's why you have to\ndisregard these terms. The search engine can actually focus on the strawberry milkshake recipe, instead of looking for pages\nthat have how to and so on. So that's why you need to\nremove these stop words. Stop words are how to, begin,\ngone, various, and, the, all of these are stop words. They are not necessarily important to understand the\nimportance of the sentence. So you get rid of these\ncommonly used words, so that you can focus\non the actual keywords. Another term you need to understand is document term matrix. A document term matrix\nis basically a matrix with documents designated by\nroles and words by columns. So if your document one has\nthis sentence, this is fun, or has these word, this is fun, then you're going to get\none, one, one over here. In document two, if you see\nwe have this and we have is, but we do not have fun. So that's what a document term matrix is. It is basically to understand\nwhether your document contains each of these words. It is a frequency matrix. That is what a document term matrix is. Now let's move on and look at a natural language processing demo. So what we're gonna do\nis we're gonna perform sentimental analysis. Now like I said, sentimental analysis is one of the most popular applications of natural language processing. It refers to the processing of determining whether a given piece of text\nor a given sentence of text is positive or negative. So, in some variations, we consider a sentence to also be neutral. That's a third option. And this technique is\ncommonly used to discover how people feel about a particular topic or what are people's opinion\nabout a particular topic. So this is mainly used to\nanalyze the sentiments of users in various forms, such as in marketing\ncampaigns, in social media, in e-commerce websites, and so on. So now we'll be performing\nsentimental analysis using Python. So we are going to perform\nnatural language processing by using the NaiveBayesClassifier. That's why we are importing\nthe NaiveBayesClassifier. So guys, Python provides a library known as natural language toolkit. This library contains all\nthe functions that are needed to perform natural language processing. Also in this library, we have a predefined data\nset called movie reviews. What we're gonna do is\nwe're going to download that from our NLTK, which is\nnatural language toolkit. We're basically going to run our analysis on this movie review data set. And that's exactly what\nwe're doing over here. Now what we're doing is\nwe're defining a function in order to extract features. So this is our function. It's just going to extract all our words. Now that we've extracted the data, we need to train it, so we'll do that by using\nour movie reviews data set that we just downloaded. We're going to understand the positive words and the negative words. So what we're doing here is\nwe're just loading our positive and our negative reviews. We're loading both of them. After that, we'll separate each of these into positive features\nand negative features. This is pretty understandable. Next, we'll split the data into our training and testing set. Now this is something\nthat we've been doing for all our demos. This is also known as data splicing. We've also set a threshold factor of 0.8 which basically means\nthat 80% of your data set will belong to your training, and 20% will be for your testing. You're going to do this\neven for your positive and your negative words. After that, you're just\nextracting the features again, and you're just printing the number of training\ndata points that you have. You're just printing the length\nof your training features and you're printing the length of your testing features. We can see the output,\nlet's run this program. So if you see that we're getting the number of training\ndata points as 1,600 and your number of testing\ndata points are 400, there's an 80 to 20% ration over here. After this, we'll be using\nthe NaiveBayesClassifier and we'll define the object for the NaiveBayesClassifier\nwith basically classifier, and we'll train this using\nour training data set. We'll also look at the\naccuracy of our model. The accuracy of our\nclassifier is around 73%, which is a really good number. Now this classifier object\nwill actually contain the most informative words that are obtained during analysis. These words are basically\nessential in understanding which word is classified as positive and which is classified as negative. What we're doing here is\nwe're going to review movies. We're going to see which\nmovie review is positive or which movie review is negative. Now this classifier will basically have all the informative words\nthat will help us decide which is a positive review\nor a negative review. Then we're just printing these\n10 most informative words, and we have outstanding, insulting, vulnerable, ludicrous, uninvolving, avoids, fascination, and so on. These are the most\nimportant words in our text. Now what we're gonna do is\nwe're gonna test our model. I've randomly given some reviews. If you want, let's add another review. We'll say I loved the movie. So I've added another review over here. Here we're just printing the review, and we're checking if\nthis is a positive review or a negative review. Now let's look at our predictions. We'll save this and... I forgot to put a comma over here. Save it and let's run the file again. So these were our randomly\nwritten movie reviews. The predicted sentiment is positive. Our probability score was 0.61. It's pretty accurate here. This is a dull movie and I\nwould never recommend it, is a negative sentiment. The cinematography is pretty great, that's a positive review. The movie is pathetic is\nobviously a negative review. The direction was terrible, and the story was all over the place. This is also considered\nas a negative review. Similarly, I love the movie\nis what I just inputted, and I've got a positive review on that. So our classifier actually\nworks really well. It's giving us good accuracy and it's classifying the\nsentiments very accurately. So, guys, this was all\nabout sentimental analysis. Here we basically saw if a movie review was positive or negative. So guys, that was all for our NLP demo. I hope all of you understood this. It was a simple sentimental analysis that we saw through Python. So again, if you have doubts, please leave them in the comment section, and I'll help you with all of the queries. So guys, that was our last module, which was on natural language processing. Now before I end today's session, I would like to discuss with you the machine learning engineers program that we have Edureka. So we all are aware of the demand of the machine\nlearning engineer. So, at Edureka, we have a master's program that involves 200-plus hours\nof interactive training. So the machine learning\nmaster's program at Edureka has around nine modules and 200-plus hours of interactive learning. So let me tell you the curriculum that this course provides. So your first module will basically cover Python programming. It'll have all the basics and\nall your data visualization, your GUI programming, your functions, and your object-oriented concepts. The second module will cover\nmachine learning with Python. So you'll supervise algorithms and unsupervised algorithms along with statistics and time series in Python will be covered\nin your second module. Your third module will\nhave graphical modeling. This is quite important when\nti comes to machine learning. Here you'll be taught\nabout decision making, graph theory, inference, and\nBayesian and Markov's network, and module number four will cover reinforcement learning in depth. Here you'll understanding\ndynamic programming, temporal difference, Bellman equations, all the concepts of\nreinforcement learning in depth. All the detail in advance concepts of reinforcement learning. So, module number five\nwill cover NLP with Python. You'll understand tokenization,\nstemming lemmatization, syntax, tree parsing, and so on. And module number six will\nhave module six will have artificial intelligence and\ndeep learning with TensorFlow. This module is a very advanced version of all your machine learning and reinforcement learning\nthat you'll learn. Deep learning will be in depth over here. You'll be using TensorFlow throughout. They'll cover all the concepts\nthat we saw, CNN, RNN. it'll cover the various\ntype of neural networks, like convolutional neural networks, recurrent neural networks, long, short-term memory, neural networks, and auto encoders and so on. The seventh module is all about PySpark. It'll show you how Spark SQL works and all the features and\nfunctions of Spark ML library. And the last module will finally cover about Python Spark using PySpark. Appropriate from this seven modules, you'll also get two\nfree self-paced courses. Let's actually take a look at the course. So this is your machine learning engineer master's program. You'll have nine courses, 200-plus hours of interactive learning. This is the whole course curriculum, which we just discussed. Here there are seven modules. Apart from these seven modules, you'll be given two\nfree self-paced courses, which I'll discuss shortly. You can also get to know\nthe average annual salary for a machine learning engineer, which is over $134,000. And there are also a lot of job openings in the field of machine\nlearning AI and data science. So the job titles that you might get are machine learning\nengineer, AI engineer, data scientist, data and analytics manger, NLP engineer, and data engineer. So this is basically the curriculum. Your first will by Python\nprogramming certification, machine learning\ncertification using Python, graphical modeling,\nreinforcement learning, natural language processing, AI and deep learning with TensorFlow. Python Spark certification\ntraining using PySpark. If you want to learn more\nabout each of these modules, you can just go and view the curriculum. They'll explain each and every concept that they'll be showing in this module. All of this is going to be covered here. This is just the first module. Now at the end of this project, you will be given a verified\ncertificate of completion with your name on it, and these are the free elective courses that you're going to get. One is your Python scripting\ncertification training. And the other is your Python Statistics for Data Science Course. Both of these courses\nexplain Python in depth. The second course on statistics will explain all the concepts of statistics probability,\ndescriptive statistics, inferential statistics, time series, testing data, data clustering, regression\nmodeling, and so on. So each of the module is\ndesigned in such a way that you'll have a practical demo or a practical implementation after each and every model. So all the concept that I\ntheoretically taught to you will be explained through practical demos. This way you'll get a\ngood understanding of the entire machine\nlearning and AI concepts. So, if any of you are interested in enrolling for this program or if you want to learn more about the machine learning\ncourse offered by Edureka, please leave your email\nIDs in the comment section, and we'll get back to you with all the details of the course. So guys, with this, we come to the end of this AI full course session. I hope all of you have\nunderstood the basic concepts and the idea behind AI machine\nlearning, deep learning, and natural language processing. So if you still have doubts regarding any of these topics, mention them in the comment section, and I'll try to answer all your queries. So guys, thank you so much for\njoining me in this session. Have a great day. I hope you have enjoyed\nlistening to this video. Please be kind enough to like it, and you can comment any of\nyour doubts and queries, and we will reply them at the earliest. Do look out for more\nvideos in our playlist and subscribe to Edureka\nchannel to learn more. Happy learning."
    },
    {
        "id": "86e8cdd0-b7fb-43fd-8fe2-1ed9a90f5506",
        "type": "video",
        "domaine": "technology",
        "titre": "What is Artificial Intelligence? | Artificial Intelligence In 5 Minutes | AI Explained | Simplilearn",
        "url": "https://www.youtube.com/watch?v=uMzUB89uSxU",
        "description": "What is ",
        "chaine": "Simplilearn",
        "durée": "4:45",
        "keywords": [
            "Netflix Siri chat",
            "learning deep learning",
            "Siri chat Bots",
            "task Netflix Siri",
            "Concepts deep learning",
            "natural language processing",
            "artificial narrow intelligence",
            "space IBM Watson",
            "IBM Watson supercomputer",
            "machine learning deep"
        ],
        "transcription": "it's a weekend and John decided to watch the latest movie recommended by Netflix at his friend's place before heading out he asked Siri about the weather and realized it would rain so he decided to take his Tesla for the long journey and switched to autopilot on the highway after coming home from the eventful day he started wondering how technology has made his life easy he did some research on the internet and found out that Netflix Siri and Tesla are all using AI so what is AI AI or artificial intelligence is nothing but making computers-based machines think and act like humans artificial intelligence is not a new term John McCarthy a computer scientist coined the term artificial intelligence back in 1956 but it took time to evolve as it demanded heavy computing power artificial intelligence is not confined to just movie recommendations and virtual assistants broadly classifying there are three types of AI artificial narrow intelligence also called weak AI is the stage where machines can perform a specific task Netflix Siri chat Bots spatial recommendation systems are all examples of artificial narrow intelligence next up we have artificial general intelligence referred to as an intelligent agent's capacity to comprehend or pick up any intellectual skill that a human can we are halfway in a successfully implementing this space IBM's Watson supercomputer and gpt3 fall under this category and lastly artificial super intelligence it is the stage where machines surpass human intelligence you might have seen this in movies and imagined how the world would be if machines occupied fascinated by this John did more research and found out that machine learning deep learning and natural language processing are all connected with artificial intelligence machine learning a subset of AI is the process of automating and enhancing how computers learn from their experiences without human health machine learning can be used in email spam detection medical diagnosis Etc deep learning can be considered a subset of machine learning it is a field that is based on learning and improving on its own by examining computer algorithms while machine learning uses simpler Concepts deep learning works with artificial neural networks which are designed to imitate the human brain this technology can be applied in face recognition speech recognition and many more applications natural language processing popularly known as NLP can be defined as the ability of machines to learn human language and translate it chat Bots fall under this category artificial intelligence is advancing in every crucial field like healthcare education robotics banking e-commerce and the list goes on like in healthcare AI is used to identify diseases helping healthcare service providers and their patients make better treatment and lifestyle decisions coming to the education sector AI is helping teachers automate grading organizing and facilitating parent Guardian conversations in robotics ai-powered robots employ real-time updates to detect obstructions in their path and instantaneously design their routes artificial intelligence provides Advanced data analytics that is transforming banking by reducing fraud and enhancing compliance with this growing demand for AI more and more Industries are looking for AI Engineers who can help them develop intelligent systems and offer them lucrative salaries going north of one hundred and twenty thousand dollars future of AI looks promising with the AI Market expected to reach 190 billion dollars by 2025. so on that note I have a question for you artificial intelligence is about playing a computer game creating a device using your own intelligence to program an intelligent machine investing your brain power in a machine give the correct answer along with your reasoning and stand a chance to win an Amazon voucher think about it and leave your answers in the comments section and we will provide the answer next week we hope you enjoyed this video if you did a thumbs up would be really appreciated here's your reminder to subscribe to our Channel and click on the Bell icon for more on the latest Technologies and Trends thank you for watching and stay tuned for more from Simply learn [Music]"
    },
    {
        "id": "9a26135d-5e63-49a1-8f9c-352aab186fcf",
        "type": "video",
        "domaine": "technology",
        "titre": "Machine Learning for Everybody – Full Course",
        "url": "https://www.youtube.com/watch?v=i_LwzRVP7bg",
        "description": "Learn ",
        "chaine": "freeCodeCamp.org",
        "durée": "3:53:53",
        "keywords": [
            "data set",
            "data",
            "data frame",
            "set",
            "model",
            "training data set",
            "probability",
            "data sets",
            "test data set",
            "point"
        ],
        "transcription": "Kylie Ying has worked at many interesting places such as MIT, CERN, and Free Code Camp. She's a physicist, engineer, and basically a genius. And now she's going to teach you about machine learning in a way that is accessible to absolute beginners. What's up you guys? So welcome to Machine Learning for Everyone. If you are someone who is interested in machine learning and you think you are considered as everyone, then this video is for you. In this video, we'll talk about supervised and unsupervised learning models, we'll go through maybe a little bit of the logic or math behind them, and then we'll also see how we can program it on Google CoLab. If there are certain things that I have done, and you know, you're somebody with more experience than me, please feel free to correct me in the comments and we can all as a community learn from this together. So with that, let's just dive right in. Without wasting any time, let's just dive straight into the code and I will be teaching you guys concepts as we go. So this here is the UCI machine learning repository. And basically, they just have a ton of data sets that we can access. And I found this really cool one called the magic gamma telescope data set. So in this data set, if you want to read all this information, to summarize what I what I think is going on, is there's this gamma telescope, and we have all these high energy particles hitting the telescope. Now there's a camera, there's a detector that actually records certain patterns of you know, how this light hits the camera. And we can use properties of those patterns in order to predict what type of particle caused that radiation. So whether it was a gamma particle, or some other head, like hadron. Down here, these are all of the attributes of those patterns that we collect in the camera. So you can see that there's, you know, some length, width, size, asymmetry, etc. Now we're going to use all these properties to help us discriminate the patterns and whether or not they came from a gamma particle or hadron. So in order to do this, we're going to come up here, go to the data folder. And you're going to click this magic zero for data, and we're going to download that. Now over here, I have a colab notebook open. So you go to colab dot research dot google.com, you start a new notebook. And I'm just going to call this the magic data set. So actually, I'm going to call this for code camp magic example. Okay. So with that, I'm going to first start with some imports. So I will import, you know, I always import NumPy, I always import pandas. And I always import matplotlib. And then we'll import other things as we go. So yeah, we run that in order to run the cell, you can either click this play button here, or you can on my computer, it's just shift enter and that that will run the cell. And here, I'm just going to order I'm just going to, you know, let you guys know, okay, this is where I found the data set. So I've copied and pasted this actually, but this is just where I found the data set. And in order to import that downloaded file that we we got from the computer, we're going to go over here to this folder thing. And I am literally just going to drag and drop that file into here. Okay. So in order to take a look at, you know, what does this file consist of, do we have the labels? Do we not? I mean, we could open it on our computer, but we can also just do pandas read CSV. And we can pass in the name of this file. And let's see what it returns. So it doesn't seem like we have the label. So let's go back to here. I'm just going to make the columns, the column labels, all of these attribute names over here. So I'm just going to take these values and make that the column names. All right, how do I do that? So basically, I will come back here, and I will create a list called calls. And I will type in all of those things. With f size, f conk. And we also have f conk one. We have f symmetry, f m three long, f m three trans, f alpha. Let's see, we have f dist and class. Okay, great. Now in order to label those as these columns down here in our data frame. So basically, this command here just reads some CSV file that you pass in CSV has come about comma separated values, and turns that into a pandas data frame object. So now if I pass in a names here, then it basically assigns these labels to the columns of this data set. So I'm going to set this data frame equal to DF. And then if we call the head is just like, give me the first five things, give me the first five things. Now you'll see that we have labels for all of these. Okay. All right, great. So one thing that you might notice is that over here, the class labels, we have G and H. So if I actually go down here, and I do data frame class unique, you'll see that I have either G's or H's, and these stand for gammas or hadrons. And our computer is not so good at understanding letters, right? Our computer is really good at understanding numbers. So what we're going to do is we're going to convert this to zero for G and one for H. So here, I'm going to set this equal to this, whether or not that equals G. And then I'm just going to say as type int. So what this should do is convert this entire column, if it equals G, then this is true. So I guess that would be one. And then if it's H, it would be false. So that would be zero, but I'm just converting G and H to one and zero, it doesn't really matter. Like, if G is one and H is zero or vice versa. Let me just take a step back right now and talk about this data set. So here I have some data frame, and I have all of these different values for each entry. Now this is a you know, each of these is one sample, it's one example, it's one item in our data set, it's one data point, all of these things are kind of the same thing when I mentioned, oh, this is one example, or this is one sample or whatever. Now, each of these samples, they have, you know, one quality for each or one value for each of these labels up here, and then it has the class. Now what we're going to do in this specific example is try to predict for future, you know, samples, whether the class is G for gamma or H for hadron. And that is something known as classification. Now, all of these up here, these are known as our features, and features are just things that we're going to pass into our model in order to help us predict the label, which in this case is the class column. So for you know, sample zero, I have 10 different features. So I have 10 different values that I can pass into some model. And I can spit out, you know, the class the label, and I know the true label here is G. So this is this is actually supervised learning. All right. So before I move on, let me just give you a quick little crash course on what I just said. This is machine learning for everyone. Well, the first question is, what is machine learning? Well, machine learning is a sub domain of computer science that focuses on certain algorithms, which might help a computer learn from data, without a programmer being there telling the computer exactly what to do. That's what we call explicit programming. So you might have heard of AI and ML and data science, what is the difference between all of these. So AI is artificial intelligence. And that's an area of computer science, where the goal is to enable computers and machines to perform human like tasks and simulate human behavior. Now machine learning is a subset of AI that tries to solve one specific problem and make predictions using certain data. And data science is a field that attempts to find patterns and draw insights from data. And that might mean we're using machine learning. So all of these fields kind of overlap, and all of them might use machine learning. So there are a few types of machine learning. The first one is supervised learning. And in supervised learning, we're using labeled inputs. So this means whatever input we get, we have a corresponding output label, in order to train models and to learn outputs of different new inputs that we might feed our model. So for example, I might have these pictures, okay, to a computer, all these pictures are are pixels, they're pixels with a certain color. Now in supervised learning, all of these inputs have a label associated with them, this is the output that we might want the computer to be able to predict. So for example, over here, this picture is a cat, this picture is a dog, and this picture is a lizard. Now there's also unsupervised learning. And in unsupervised learning, we use unlabeled data to learn about patterns in the data. So here are here are my input data points. Again, they're just images, they're just pixels. Well, okay, let's say I have a bunch of these different pictures. And what I can do is I can feed all these to my computer. And I might not, you know, my computer is not going to be able to say, Oh, this is a cat, dog and lizard in terms of, you know, the output. But it might be able to cluster all these pictures, it might say, Hey, all of these have something in common. All of these have something in common. And then these down here have something in common, that's finding some sort of structure in our unlabeled data. And finally, we have reinforcement learning. And reinforcement learning. Well, they usually there's an agent that is learning in some sort of interactive environment, based on rewards and penalties. So let's think of a dog, we can train our dog, but there's not necessarily, you know, any wrong or right output at any given moment, right? Well, let's pretend that dog is a computer. Essentially, what we're doing is we're giving rewards to our computer, and tell your computer, Hey, this is probably something good that you want to keep doing. Well, computer agent terminology. But in this class today, we'll be focusing on supervised learning and unsupervised learning and learning different models for each of those. Alright, so let's talk about supervised learning first. So this is kind of what a machine learning model looks like you have a bunch of inputs that are going into some model. And then the model is spitting out an output, which is our prediction. So all these inputs, this is what we call the feature vector. Now there are different types of features that we can have, we might have qualitative features. And qualitative means categorical data, there's either a finite number of categories or groups. So one example of a qualitative feature might be gender. And in this case, there's only two here, it's for the sake of the example, I know this might be a little bit outdated. Here we have a girl and a boy, there are two genders, there are two different categories. That's a piece of qualitative data. Another example might be okay, we have, you know, a bunch of different nationalities, maybe a nationality or a nation or a location, that might also be an example of categorical data. Now, in both of these, there's no inherent order. It's not like, you know, we can rate us one and France to Japan three, etc. Right? There's not really any inherent order built into either of these categorical data sets. That's why we call this nominal data. Now, for nominal data, the way that we want to feed it into our computer is using something called one hot encoding. So let's say that, you know, I have a data set, some of the items in our data, some of the inputs might be from the US, some might be from India, then Canada, then France. Now, how do we get our computer to recognize that we have to do something called one hot encoding. And basically, one hot encoding is saying, okay, well, if it matches some category, make that a one. And if it doesn't just make that a zero. So for example, if your input were from the US, you would you might have 1000. India, you know, 0100. Canada, okay, well, the item representing Canada is one and then France, the item representing France is one. And then you can see that the rest are zeros, that's one hot encoding. Now, there are also a different type of qualitative feature. So here on the left, there are different age groups, there's babies, toddlers, teenagers, young adults, adults, and so on, right. And on the right hand side, we might have different ratings. So maybe bad, not so good, mediocre, good, and then like, great. Now, these are known as ordinal pieces of data, because they have some sort of inherent order, right? Like, being a toddler is a lot closer to being a baby than being an elderly person, right? Or good is closer to great than it is to really bad. So these have some sort of inherent ordering system. And so for these types of data sets, we can actually just mark them from, you know, one to five, or we can just say, hey, for each of these, let's give it a number. And this makes sense. Because, like, for example, the thing that I just said, how good is closer to great, then good is close to not good at all. Well, four is closer to five, then four is close to one. So this actually kind of makes sense. And it'll make sense for the computer as well. Alright, there are also quantitative pieces of data and quantitative pieces of data are numerical valued pieces of data. So this could be discrete, which means, you know, they might be integers, or it could be continuous, which means all real numbers. So for example, the length of something is a quantitative piece of data, it's a quantitative feature, the temperature of something is a quantitative feature. And then maybe how many Easter eggs I collected in my basket, this Easter egg hunt, that is an example of discrete quantitative feature. Okay, so these are continuous. And this over here is the screen. So those are the things that go into our feature vector, those are our features that we're feeding this model, because our computers are really, really good at understanding math, right at understanding numbers, they're not so good at understanding things that humans might be able to understand. Well, what are the types of predictions that our model can output? So in supervised learning, there are some different tasks, there's one classification, and basically classification, just saying, okay, predict discrete classes. And that might mean, you know, this is a hot dog, this is a pizza, and this is ice cream. Okay, so there are three distinct classes and any other pictures of hot dogs, pizza or ice cream, I can put under these labels. Hot dog, pizza, ice cream. Hot dog, pizza, ice cream. This is something known as multi class classification. But there's also binary classification. And binary classification, you might have hot dog, or not hot dog. So there's only two categories that you're working with something that is something and something that's isn't binary classification. Okay, so yeah, other examples. So if something has positive or negative sentiment, that's binary classification. Maybe you're predicting your pictures of their cats or dogs. That's binary classification. Maybe, you know, you are writing an email filter, and you're trying to figure out if an email spam or not spam. So that's also binary classification. Now for multi class classification, you might have, you know, cat, dog, lizard, dolphin, shark, rabbit, etc. We might have different types of fruits like orange, apple, pear, etc. And then maybe different plant species. But multi class classification just means more than two. Okay, and binary means we're predicting between two things. There's also something called regression when we talk about supervised learning. And this just means we're trying to predict continuous values. So instead of just trying to predict different categories, we're trying to come up with a number that you know, is on some sort of scale. So some examples. So some examples might be the price of aetherium tomorrow, or it might be okay, what is going to be the temperature? Or it might be what is the price of this house? Right? So these things don't really fit into discrete classes. We're trying to predict a number that's as close to the true value as possible using different features of our data set. So that's exactly what our model looks like in supervised learning. Now let's talk about the model itself. How do we make this model learn? Or how can we tell whether or not it's even learning? So before we talk about the models, let's talk about how can we actually like evaluate these models? Or how can we tell whether something is a good model or bad model? So let's take a look at this data set. So this data set has this is from a diabetes, a Pima Indian diabetes data set. And here we have different number of pregnancies, different glucose levels, blood pressure, skin thickness, insulin, BMI, age, and then the outcome whether or not they have diabetes one for they do zero for they don't. So here, all of these are quantitative features, right, because they're all on some scale. So each row is a different sample in the data. So it's a different example, it's one person's data, and each row represents one person in this data set. Now this column, each column represents a different feature. So this one here is some measure of blood pressure levels. And this one over here, as we mentioned is the output label. So this one is whether or not they have diabetes. And as I mentioned, this is what we would call a feature vector, because these are all of our features in one sample. And this is what's known as the target, or the output for that feature vector. That's what we're trying to predict. And all of these together is our features matrix x. And over here, this is our labels or targets vector y. So I've condensed this to a chocolate bar to kind of talk about some of the other concepts in machine learning. So over here, we have our x, our features matrix, and over here, this is our label y. So each row of this will be fed into our model, right. And our model will make some sort of prediction. And what we do is we compare that prediction to the actual value of y that we have in our label data set, because that's the whole point of supervised learning is we can compare what our model is outputting to, oh, what is the truth, actually, and then we can go back and we can adjust some things. So the next iteration, we get closer to what the true value is. So that whole process here, the tinkering that, okay, what's the difference? Where did we go wrong? That's what's known as training the model. Alright, so take this whole, you know, chunk right here, do we want to really put our entire chocolate bar into the model to train our model? Not really, right? Because if we did that, then how do we know that our model can do well on new data that we haven't seen? Like, if I were to create a model to predict whether or not someone has diabetes, let's say that I just train all my data, and I see that all my training data does well, I go to some hospital, I'm like, here's my model. I think you can use this to predict if somebody has diabetes. Do we think that would be effective or not? Probably not, right? Because we haven't assessed how well our model can generalize. Okay, it might do well after you know, our model has seen this data over and over and over again. But what about new data? Can our model handle new data? Well, how do we how do we get our model to assess that? So we actually break up our whole data set that we have into three different types of data sets, we call it the training data set, the validation data set and the testing data set. And you know, you might have 60% here 20% and 20% or 80 10 and 10. It really depends on how many statistics you have, I think either of those would be acceptable. So what we do is then we feed the training data set into our model, we come up with, you know, this might be a vector of predictions corresponding with each sample that we put into our model, we figure out, okay, what's the difference between our prediction and the true values, this is something known as loss, losses, you know, what's the difference here, in some numerical quantity, of course. And then we make adjustments, and that's what we call training. Okay. So then, once you know, we've made a bunch of adjustments, we can put our validation set through this model. And the validation set is kind of used as a reality check during or after training to ensure that the model can handle unseen data still. So every single time after we train one iteration, we might stick the validation set in and see, hey, what's the loss there. And then after our training is over, we can assess the validation set and ask, hey, what's the loss there. But one key difference here is that we don't have that training step, this loss never gets fed back into the model, right, that feedback loop is not closed. Alright, so let's talk about loss really quickly. So here, I have four different types of models, I have some sort of data that's being fed into the model, and then some output. Okay, so this output here is pretty far from you know, this truth that we want. And so this loss is going to be high. In model B, again, this is pretty far from what we want. So this loss is also going to be high, let's give it 1.5. Now this one here, it's pretty close, I mean, maybe not almost, but pretty close to this one. So that might have a loss of 0.5. And then this one here is maybe further than this, but still better than these two. So that loss might be 0.9. Okay, so which of these model performs the best? Well, model C has a smallest loss, so it's probably model C. Okay, now let's take model C. After you know, we've come up with these, all these models, and we've seen, okay, model C is probably the best model. We take model C, and we run our test set through this model. And this test set is used as a final check to see how generalizable that chosen model is. So if I, you know, finish training my diabetes data set, then I could run it through some chunk of the data and I can say, oh, like, this is how we perform on data that it's never seen before at any point during the training process. Okay. And that loss, that's the final reported performance of my test set, or this would be the final reported performance of my model. Okay. So let's talk about this thing called loss, because I think I kind of just glossed over it, right? So loss is the difference between your prediction and the actual, like, label. So this would give a slightly higher loss than this. And this would even give a higher loss, because it's even more off. In computer science, we like formulas, right? We like formulaic ways of describing things. So here are some examples of loss functions and how we can actually come up with numbers. This here is known as L one loss. And basically, L one loss just takes the absolute value of whatever your you know, real value is, whatever the real output label is, subtracts the predicted value, and takes the absolute value of that. Okay. So the absolute value is a function that looks something like this. So the further off you are, the greater your losses, right in either direction. So if your real value is off from your predicted value by 10, then your loss for that point would be 10. And then this sum here just means, hey, we're taking all the points in our data set. And we're trying to figure out the sum of how far everything is. Now, we also have something called L two loss. So this loss function is quadratic, which means that if it's close, the penalty is very minimal. And if it's off by a lot, then the penalty is much, much higher. Okay. And this instead of the absolute value, we just square the the difference between the two. Now, there's also something called binary cross entropy loss. It looks something like this. And this is for binary classification, this this might be the loss that we use. So this loss, you know, I'm not going to really go through it too much. But you just need to know that loss decreases as the performance gets better. So there are some other measures of accurate or performance as well. So for example, accuracy, what is accuracy? So let's say that these are pictures that I'm feeding my model, okay. And these predictions might be apple, orange, orange, apple, okay, but the actual is apple, orange, apple, apple. So three of them were correct. And one of them was incorrect. So the accuracy of this model is three quarters or 75%. Alright, coming back to our colab notebook, I'm going to close this a little bit. Again, we've imported stuff up here. And we've already created our data frame right here. And this is this is all of our data. This is what we're going to use to train our models. So down here, again, if we now take a look at our data set, you'll see that our classes are now zeros and ones. So now this is all numerical, which is good, because our computer can now understand that. Okay. And you know, it would probably be a good idea to maybe kind of plot, hey, do these things have anything to do with the class. So here, I'm going to go through all the labels. So for label in the columns of this data frame. So this just gets me the list. Actually, we have the list, right? It's called so let's just use that might be less confusing of everything up to the last thing, which is the class. So I'm going to take all these 10 different features. And I'm going to plot them as a histogram. So and now I'm going to plot them as a histogram. So basically, if I take that data frame, and I say, okay, for everything where the class is equal to one, so these are all of our gammas, remember, now, for that portion of the data frame, if I look at this label, so now these, okay, what this part here is saying is, inside the data frame, get me everything where the class is equal to one. So that's all all of these would fit into that category, right? And now let's just look at the label column. So the first label would be f length, which would be this column. So this command here is getting me all the different values that belong to class one for this specific label. And that's exactly what I'm going to put into the histogram. And now I'm just going to tell you know, matplotlib make the color blue, make this label this as you know, gamma set alpha, why do I keep doing that, alpha equal to 0.7. So that's just like the transparency. And then I'm going to set density equal to true, so that when we compare it to the hadrons here, we'll have a baseline for comparing them. Okay, so the density being true just basically normalizes these distributions. So you know, if you have 200 in of one type, and then 50 of another type, well, if you drew the histograms, it would be hard to compare because one of them would be a lot bigger than the other, right. But by normalizing them, we kind of are distributing them over how many samples there are. Alright, and then I'm just going to put a title on here and make that the label, the y label. So because it's density, the y label is probability. And the x label is just going to be the label. What is going on. And I'm going to include a legend and PLT dot show just means okay, display the plot. So if I run that, just be up to the last item. So we want a list, right, not just the last item. And now we can see that we're plotting all of these. So here we have the length. Oh, and I made this gamma. So this should be hadron. Okay, so the gammas in blue, the hadrons are in red. So here we can already see that, you know, maybe if the length is smaller, it's probably more likely to be gamma, right. And we can kind of you know, these all look somewhat similar. But here, okay, clearly, if there's more asymmetry, or if you know, this asymmetry measure is larger, then it's probably hadron. Okay, oh, this one's a good one. So f alpha seems like hadrons are pretty evenly distributed. Whereas if this is smaller, it looks like there's more gammas in that area. Okay, so this is kind of what the data that we're working with, we can kind of see what's going on. Okay, so the next thing that we're going to do here is we are going to create our train, our validation, and our test data sets. I'm going to set train valid and test to be equal to this. So NumPy dot split, I'm just splitting up the data frame. And if I do this sample, where I'm sampling everything, this will basically shuffle my data. Now, if I I want to pass in where exactly I'm splitting my data set, so the first split is going to be maybe at 60%. So I'm going to say 0.6 times the length of this data frame. So and then cast that 10 integer, that's going to be the first place where you know, I cut it off, and that'll be my training data. Now, if I then go to 0.8, this basically means everything between 60% and 80% of the length of the data set will go towards validation. And then, like everything from 80 to 100, I'm going to pass my test data. So I can run that. And now, if we go up here, and we inspect this data, we'll see that these columns seem to have values in like the 100s, whereas this one is 0.03. Right? So the scale of all these numbers is way off. And sometimes that will affect our results. So I'm going to run this is way off. And sometimes that will affect our results. So one thing that we would want to do is scale these so that they are, you know, so that it's now relative to maybe the mean and the standard deviation of that specific column. I'm going to create a function called scale data set. And I'm going to pass in the data frame. And that's what I'll do for now. Okay, so the x values are going to be, you know, I take the data frame. And let's assume that the columns are going to be, you know, that the label will always be the last thing in the data frame. So what I can do is say data frame, dot columns all the way up to the last item, and get those values. Now for my y, well, it's the last column. So I can just do this, I can just index into that last column, and then get those values. Now, in, so I'm actually going to import something known as the standard scalar from sk learn. So if I come up here, I can go to sk learn dot pre processing. And I'm going to import standard scalar, I have to run that cell, I'm going to come back down here. And now I'm going to create a scalar and use that skip or so standard scalar. And with the scalar, what I can do is actually just fit and transform x. So here, I can say x is equal to scalar dot fit, fit, transform x. So what that's doing is saying, okay, take x and fit the standard scalar to x, and then transform all those values. And what would it be? And that's going to be our new x. Alright. And then I'm also going to just create, you know, the whole data as one huge 2d NumPy array. And in order to do that, I'm going to call H stack. So H stack is saying, okay, take an array, and another array and horizontally stack them together. That's what the H stands for. So by horizontally stacked them together, just like put them side by side, okay, not on top of each other. So what am I stacking? Well, I have to pass in something so that it can stack x and y. And now, okay, so NumPy is very particular about dimensions, right? So in this specific case, our x is a two dimensional object, but y is only a one dimensional thing, it's only a vector of values. So in order to now reshape it into a 2d item, we have to call NumPy dot reshape. And we can pass in the dimensions of its reshape. So if I pass in negative one comma one, that just means okay, make this a 2d array, where the negative one just means infer what what this dimension value would be, which ends up being the length of y, this would be the same as literally doing this. But the negative one is easier because we're making the computer do the hard work. So if I stack that, I'm going to then return the data x and y. Okay. So one more thing is that if we go into our training data set, okay, again, this is our training data set. And we get the length of the training data set. But where the training data sets class is one, so remember that this is the gammas. And then if we print that, and we do the same thing, but zero, we'll see that, you know, there's around 7000 of the gammas, but only around 4000 of the hadrons. So that might actually become an issue. And instead, what we want to do is we want to oversample our our training data set. So that means that we want to increase the number of these values, so that these kind of match better. And surprise, surprise, there is something that we can import that will help us do that. It's so I'm going to go to from in the learn dot oversampling. And I'm going to import this random oversampler, run that cell, and come back down here. So I will actually add in this parameter called oversample, and set that to false for default. And if I do want to oversample, then what I'm going to do, and by oversample, so if I do want to oversample, then I'm going to create this ROS and set it equal to this random oversampler. And then for x and y, I'm just going to say, okay, just fit and resample x and y. And what that's doing is saying, okay, take more of the less class. So take take the less class and keep sampling from there to increase the size of our data set of that smaller class so that they now match. So if I do this, and I scale data set, and I pass in the training data set where oversample is true. So this let's say this is train and then x train, y train. Oops, what's going on? These should be columns. So basically, what I'm doing now is I'm just saying, okay, what is the length of y train? Okay, now it's 14,800, whatever. And now let's take a look at how many of these are type one. So actually, we can just sum that up. And then we'll also see that if we instead switch the label and ask how many of them are the other type, it's the same value. So now these have been evenly, you know, rebalanced. Okay, well, okay. So here, I'm just going to make this the validation data set. And then the next one, I'm going to make this the test data set. Alright, and we're actually going to switch oversample here to false. Now, the reason why I'm switching that to false is because my validation and my test sets are for the purpose of you know, if I have data that I haven't seen yet, how does my sample perform on those? And I don't want to oversample for that right now. Like, I don't care about balancing those I'm, I want to know if I have a random set of data that's unlabeled, can I trust my model, right? So that's why I'm not oversampling. I run that. And again, what is going on? Oh, it's because we already have this train. So I have to go come up here and split that data frame again. And now let's run these. Okay. So now we have our data properly formatted. And we're going to move on to different models now. And I'm going to tell you guys a little bit about each of these models. And then I'm going to show you how we can do that in our code. So the first model that we're going to learn about is KNN or K nearest neighbors. Okay, so here, I've already drawn a plot on the y axis, I have the number of kids that a family might have. And then on the x axis, I have their income in terms of 1000s per year. So, you know, if if someone's making 40,000 a year, that's where this would be. And if somebody making 320, that's where that would be somebody has zero kids, it'd be somewhere along this axis. Somebody has five, it'd be somewhere over here. Okay. And now I have these plus signs and these minus signs on here. So what I'm going to represent here is the plus sign means that they own a car. And the minus sign is going to represent no car. Okay. So your initial thought should be okay, I think this is binary classification because all of our points all of our samples have labels. So this is a sample with the plus label. And this here is another sample with the minus label. This is an abbreviation for width that I'll use. Alright, so we have this entire data set. And maybe around half the people own a car and maybe around half the people don't own a car. Okay, well, what if I had some new point, let me use choose a different color, I'll use this nice green. Well, what if I have a new point over here? So let's say that somebody makes 40,000 a year and has two kids. What do we think that would be? Well, just logically looking at this plot, you might think, okay, it seems like they wouldn't have a car, right? Because that kind of matches the pattern of everybody else around them. So that's a whole concept of this nearest neighbors is you look at, okay, what's around you. And then you're basically like, okay, I'm going to take the label of the majority that's around me. So the first thing that we have to do is we have to define a distance function. And a lot of times in, you know, 2d plots like this, our distance function is something known as Euclidean distance. And Euclidean distance is basically just this straight line distance like this. Okay. So this would be the Euclidean distance, it seems like there's this point, there's this point, there's that point, etc. So the length of this line, this green line that I just drew, that is what's known as Euclidean distance. If we want to get technical with that, this exact formula is the distance here, let me zoom in. The distance is equal to the square root of one point x minus the other points x squared plus extend that square root, the same thing for y. So y one of one minus y two of the other squared. Okay, so we're basically trying to find the length, the distances, the difference between x and y, and then square each of those sum it up and take the square root. Okay, so I'm going to erase this so it doesn't clutter my drawing. But anyways, now going back to this plot, so here in the nearest neighbor algorithm, we see that there is a K, right? And this K is basically telling us, okay, how many neighbors do we use in order to judge what the label is? So usually, we use a K of maybe, you know, three or five, depends on how big our data set is. But here, I would say, maybe a logical number would be three or five. So let's say that we take K to be equal to three. Okay, well, of this data point that I drew over here, let me use green to highlight this. Okay, so of this data point that I drew over here, it looks like the three closest points are definitely this one, this one. And then this one has a length of four. And this one seems like it'd be a little bit further than four. So actually, this would be these would be our three points. Well, all those points are blue. So chances are, my prediction for this point is going to be blue, it's going to be probably don't have a car. All right, now what if my point is somewhere? What if my point is somewhere over here, let's say that a couple has four kids, and they make 240,000 a year. All right, well, now my closest points are this one, probably a little bit over that one. And then this one, right? Okay, still all pluses. Well, this one is more than likely to be plus. Right? Now, let me get rid of some of these just so that it looks a little bit more clear. All right, let's go through one more. What about a point that might be right here? Okay, let's see. Well, definitely this is the closest, right? This one's also closest. And then it's really close between the two of these. But if we actually do the mathematics, it seems like if we zoom in, this one is right here. And this one is in between these two. So this one here is actually shorter than this one. And that means that that top one is the one that we're going to take. Now, what is the majority of the points that are close by? Well, we have one plus here, we have one plus here, and we have one minus here, which means that the pluses are the majority. And that means that this label is probably somebody with a car. Okay. So this is how K nearest neighbors would work. It's that simple. And this can be extrapolated to further dimensions to higher dimensions. You know, if you have here, we have two different features, we have the income, and then we have the number of kids. But let's say we have 10 different features, we can expand our distance function so that it includes all 10 of those dimensions, we take the square root of everything, and then we figure out which one is the closest to the point that we desire to classify. Okay. So that's K nearest neighbors. So now we've learned about K nearest neighbors. Let's see how we would be able to do that within our code. So here, I'm going to label the section K nearest neighbors. And we're actually going to use a package from SK learn. So the reason why we, you know, use these packages and so that we don't have to manually code all these things ourselves, because it would be really difficult. And chances are the way that we would code it, either would have bugs, or it'd be really slow, or I don't know a whole bunch of issues. So what we're going to do is hand it off to the pros. From here, I can say, okay, from SK learn, which is this package dot neighbors, I'm going to import K neighbors classifier, because we're classifying. Okay, so I run that. And our KNN model is going to be this K neighbors classifier. And we can pass in a parameter of how many neighbors, you know, we want to use. So first, let's see what happens if we just use one. So now if I do K, and then model dot fit, I can pass in my x training set and my weight y train data. Okay. So that effectively fits this model. And let's get all the predictions. So why can and I guess yeah, let's do y predictions. And my y predictions are going to be cannon model dot predict. So let's use the test set x test. Okay. Alright, so if I call y predict, you'll see that we have those. But if I get my truth values for that test set, you'll see that this is what we actually do. So just looking at this, we got five out of six of them. Okay, great. So let's actually take a look at something called the classification report that's offered by SK learn. So if I go to from SK learn dot metrics, import classification report, what I can actually do is say, hey, print out this classification report for me. And let's check, you know, I'm giving you the y test and the y prediction. We run this and we see we get this whole entire chart. So I'm going to tell you guys a few things on this chart. Alright, this accuracy is 82%, which is actually pretty good. That's just saying, hey, if we just look at, you know, what each of these new points, what it's closest to, then we actually get an 82% accuracy, which means how many do we get right versus how many total are there. Now, precision is saying, okay, you might see that we have it for class one, or class zero and class one. What precision is saying was, let's go to this Wikipedia diagram over here, because I actually kind of like this diagram. So here, this is our entire data set. And on the left over here, we have everything that we know is positive. So everything that is actually truly positive, that we've labeled positive in our original data set. And over here, this is everything that's truly negative. Now in the circle, we have things that are positive that were labeled positive by our model. On the left here, we have things that are truly positive, because you know, this side is the positive side and the side is the negative side. So these are truly positive. Whereas all these ones out here, well, they should have been positive, but they are labeled as negative. And in here, these are the ones that we've labeled positive, but they're actually negative. And out here, these are truly negative. So precision is saying, okay, out of all the ones we've labeled as positive, how many of them are true positives? And recall is saying, okay, out of all the ones that we know are truly positive, how many do we actually get right? Okay, so going back to this over here, our precision score, so again, precision, out of all the ones that we've labeled as the specific class, how many of them are actually that class, it's 7784%. Now, recall how out of all the ones that are actually this class, how many of those that we get, this is 68% and 89%. Alright, so not too shabby, we can clearly see that this recall and precision for like this, the class zero is worse than class one. Right? So that means for hadron, it's worked for hadrons and for our gammas. This f1 score over here is kind of a combination of the precision and recall score. So we're actually going to mostly look at this one because we have an unbalanced test data set. So here we have a measure of 72 and 87 or point seven two and point eight seven, which is not too shabby. All right. Well, what if we, you know, made this three. So we actually see that, okay, so what was it originally with one? We see that our f1 score, you know, is now it was point seven two and then point eight seven. And then our accuracy was 82%. So if I change that to three. Alright, so we've kind of increased zero at the cost of one and then our overall accuracy is 81. So let's actually just make this five. Alright, so you know, again, very similar numbers, we have 82% accuracy, which is pretty decent for a model that's relatively simple. Okay, the next type of model that we're going to talk about is something known as naive Bayes. Now, in order to understand the concepts behind naive Bayes, we have to be able to understand conditional probability and Bayes rule. So let's say I have some sort of data set that's shown in this table right here. People who have COVID are over here in this red row. And people who do not have COVID are down here in this green row. Now, what about the COVID test? Well, people who have tested positive are over here in this column. And people who have tested negative are over here in this column. Okay. Yeah, so basically, our categories are people who have COVID and test positive, people who don't have COVID, but test positive, so a false false positive, people who have COVID and test negative, which is a false negative, and people who don't have COVID and test negative, which good means you don't have COVID. Okay, so let's make this slightly more legible. And here, in the margins, I've written down the sums of whatever it's referring to. So this here is the sum of this entire row. And this here might be the sum of this column over here. Okay. So the first question that I have is, what is the probability of having COVID given that you have a positive test? And in probability, we write that out like this. So the probability of COVID given, so this line, that vertical line means given that, you know, some condition, so given a positive test, okay, so what is the probability of having COVID given a positive test? So what this is asking is saying, okay, let's go into this condition. So the condition of having a positive test, that is this slice of the data, right? That means if you're in this slice of data, you have a positive test. So given that we have a positive test, given in this condition, in this circumstance, we have a positive test. So what's the probability that we have COVID? Well, if we're just using this data, the number of people that have COVID is 531. So I'm gonna say that there's 531 people that have COVID. And then now we divide that by the total number of people that have a positive test, which is 551. Okay, so that's the probability and doing a quick division, we get that this is equal to around 96.4%. So according to this data set, which is data that I made up off the top of my head, so it's not actually real COVID data. But according to this data, the probability of having COVID given that you tested positive is 96.4%. Alright, now with that, let's talk about Bayes rule, which is this section here. Let's ignore this bottom part for now. So Bayes rule is asking, okay, what is the probability of some event A happening, given that B happened. So this, we already know has happened. This is our condition, right? Well, what if we don't have data for that, right? Like, what if we don't know what the probability of A given B is? Well, Bayes rule is saying, okay, well, you can actually go and calculate it, as long as you have a probability of B given A, the probability of A and the probability of B. Okay. And this is just a mathematical formula for that. Alright, so here we have Bayes rule. And let's actually see Bayes rule in action. Let's use it on an example. So here, let's say that we have some disease statistics, okay. So not COVID different disease. And we know that the probability of obtaining a false positive is 0.05 probability of obtaining a false negative is 0.01. And the probability of the disease is 0.1. Okay, what is the probability of the disease given that we got a positive test? Hmm, how do we even go about solving this? So what what do I mean by false positive? What's a different way to rewrite that? A false positive is when you test positive, but you don't actually have the disease. So this here is a probability that you have a positive test given no disease, right? And similarly for the false negative, it's a probability that you test negative given that you actually have the disease. So if I put that into a chart, for example, and this might be my positive and negative tests, and this might be my diseases, disease and no disease. Well, the probability that I test positive, but actually have no disease, okay, that's 0.05 over here. And then the false negatives up here for 0.01. So I'm testing negative, but I don't actually have the disease. This so the probability that you test positive, and you don't have the disease, plus a probability that you test negative, given that you don't have the disease, that should sum up to one. Okay, because if you don't have the disease, then you should have some probability that you're testing positive and some probability that you're testing negative. But that probability, in total should be one. So that means that the probability negative and no disease, this should be the reciprocal, this should be the opposite. So it should be 0.95 because it's one minus whatever this probability is. And then similarly, oops, up here, this should be 0.99 because the probability that we, you know, test negative and have the disease plus the probability that we test positive and have the disease should equal one. So this is our probability chart. And now, this probability of disease being point 0.1 just means I have 10% probability of actually of having the disease, right? Like, in the general population, the probability that I have the disease is 0.1. Okay, so what is the probability that I have the disease given that I got a positive test? Well, remember that we can write this out in terms of Bayes rule, right? So if I use this rule up here, this is the probability of a positive test given that I have the disease times the probability of the disease divided by the probability of the evidence, which is my positive test. Alright, now let's plug in some numbers for that. The probability of having a positive test given that I have the disease is 0.99. And then the probability that I have the disease is this value over here 0.1. Okay. And then the probability that I have a positive test at all should be okay, what is the probability that I have a positive test given that I actually have the disease and then having having the disease. And then the other case, where the probability of me having a negative test given or sorry, positive test giving no disease times the probability of not actually having a disease. Okay, so I can expand that probability of having a positive test out into these two different cases, I have a disease, and then I don't. And then what's the probability of having positive tests in either one of those cases. So that expression would become 0.99 times 0.1 plus 0.05. So that's the probability that I'm testing positive, but don't have the disease. And the times the probability that I don't actually have the disease. So that's one minus 0.1 probability that the population doesn't have the disease is 90%. So 0.9. And let's do that multiplication. And I get an answer of 0.6875 or 68.75%. Okay. All right, so we can actually expand that we can expand Bayes rule and apply it to classification. And this is what we call naive base. So first, a little terminology. So the posterior is this over here, because it's asking, Hey, what is the probability of some class CK? So by CK, I just mean, you know, the different categories, so C for category or class or whatever. So category one might be cats, category two, dogs, category three, lizards, all the way, we have k categories, k is just some number. Okay. So what is the probability of having of this specific sample x, so this is our feature vector of this one sample. What is the probability of x fitting into category 123 for whatever, right, so that that's what this is asking, what is the probability that, you know, it's actually from this class, given all this evidence that we see the x's. So the likelihood is this quantity over here, it's saying, Okay, well, given that, you know, assume, assume we are, assume that this class is class CK, okay, assume that this is a category. Well, what is the likelihood of actually seeing x, all these different features from that category. And then this here is the prior. So like in the entire population of things, what are the probabilities? What is the probability of this class in general? Like if I have, you know, in my entire data set, what is the percentage? What is the chance that this image is a cat? How many cats do I have? Right. And then this down here is called the evidence because what we're trying to do is we're changing our prior, we're creating this new posterior probability built upon the prior by using some sort of evidence, right? And that evidence is a probability of x. So that's some vocab. And this here is a rule for naive Bayes. Whoa, okay, let's digest that a little bit. Okay. So what is let me use a different color. What is this side of the equation asking? It's asking, what is the probability that we are in some class K, CK, given that, you know, this is my first input, this is my second input, this is, you know, my third, fourth, this is my nth input. So let's say that our classification is, do we play soccer today or not? Okay, and let's say our x's are, okay, is it how much wind is there? How much rain is there? And what day of the week is it? So let's So let's say that it's raining, it's not windy, but it's Wednesday, do we play soccer? Do we not? So let's use Bayes rule on this. So this here is equal to the probability of x one, x two, all these joint probabilities, given class K times the probability of that class, all over the probability of this evidence. Okay. So what is this fancy symbol over here, this means proportional to so how our equal sign means it's equal to this like little squiggly sign means that this is proportional to okay, and this denominator over here, you might notice that it has no impact on the class like this, that number doesn't depend on the class, right? So this is going to be constant for all of our different classes. So what I'm going to do is make things simpler. So I'm just going to say that this probability x one, x two, all the way to x n, this is going to be proportional to the numerator, I don't care about the denominator, because it's the same for every single class. So this is proportional to x one, x two, x n given class K times the probability of that class. Okay. All right. So in naive Bayes, the point of it being naive, is that we're actually this joint probability, we're just assuming that all of these different things are all independent. So in my soccer example, you know, the probability that we're playing soccer, or the probability that, you know, it's windy, and it's rainy, and, and it's Wednesday, all these things are independent, we're assuming that they're independent. So that means that I can actually write this part of the equation here as this. So each term in here, I can just multiply all of them together. So the probability of the first feature, given that it's class K, times the probability of the second feature and given this problem, like class K all the way up all the way up until, you know, the nth feature of given that it's class K. So this expands to all of this. All right, which means that this here is now proportional to the thing that we just expanded times this. So I'm going to write that out. So the probability of that class. And I'm actually going to use this symbol. So what this means is it's a huge multiplication, it means multiply everything to the right of this. So this probability x, given some class K, but do it for all the i's. So I, what is I, okay, we're going to go from the first the first x i all the way to the nth. So that means for every single i, we're just multiplying these probabilities together. And that's where this up here comes from. So to wrap this up, oops, this should be a line to wrap this up in plain English. Basically, what this is saying is a probability that you know, we're in some category, given that we have all these different features is proportional to the probability of that class in general, times the probability of each of those features, given that we're in this one class that we're testing. So the probability of it, you know, of us playing soccer today, given that it's rainy, not windy, and and it's Wednesday, is proportional to Okay, well, what is what is the probability that we play soccer anyways, and then times the probability that it's rainy, given that we're playing soccer, times the probability that it's not windy, given that we're playing soccer. So how many times are we playing soccer when it's windy, how you know, and then how many times are what's the probability that's Wednesday, given that we're playing soccer. Okay. So how do we use this in order to make a classification. So that's where this comes in our y hat, our predicted y is going to be equal to something called the arg max. And then this expression over here, because we want to take the arg max. Well, we want. So okay, if I write out this, again, this means the probability of being in some class CK given all of our evidence. Well, we're going to take the K that maximizes this expression on the right. That's what arc max means. So if K is in zero, oops, one through K, so this is how many categories are, we're going to go through each K. And we're going to solve this expression over here and find the K that makes that the largest. Okay. And remember that instead of writing this, we have now a formula, thanks to Bayes rule for helping us approximate that right in something that maybe we can we maybe we have like the evidence for that, we have the answers for that based on our training set. So this principle of going through each of these and finding whatever class whatever category maximizes this expression on the right, this is something known as MAP for short, or maximum a posteriori. Pick the hypothesis. So pick the K that is the most probable so that we minimize the probability of misclassification. Right. So that is MAP. That is naive Bayes. Back to the notebook. So just like how I imported k nearest neighbor, k neighbors classifier up here for naive Bayes, I can go to SK learn naive Bayes. And I can import Gaussian naive Bayes. Right. And here I'm going to say my naive Bayes model is equal. This is very similar to what we had above. And I'm just going to say with this model, we are going to fit x train and y train. All right, just like above. So this, I might actually, so I'm going to set that. And exactly, just like above, I'm going to make my prediction. So here, I'm going to instead use my naive Bayes model. And of course, I'm going to run the classification report again. So I'm actually just going to put these in the same cell. But here we have the y the new y prediction and then y test is still our original test data set. So if I run this, you'll see that. Okay, what's going on here, we get worse scores, right? Our precision, for all of them, they look slightly worse. And our, you know, for our precision, our recall, our f1 score, they look slightly worse for all the different categories. And our total accuracy, I mean, it's still 72%, which is not too shabby. But it's still 72%. Okay. Which, you know, is not not that great. Okay, so let's move on to logistic regression. Here, I've drawn a plot, I have y. So this is my label on one axis. And then this is maybe one of my features. So let's just say I only have one feature in this case, text zero, right? Well, we see that, you know, I have a few of one class type down here. And we know it's one class type because it's zero. And then we have our other class type one up here. And then we have our y. Okay. So many of you guys are familiar with regression. So let's start there. If I were to draw a regression line through this, it might look something like like this. Right? Well, this doesn't seem to be a very good model. Like, why would we use this specific line to predict why? Right? It's, it's iffy. Okay. For example, we might say, okay, well, it seems like, you know, everything from here downwards would be one class type in here, upwards would be another class type. But when you look at this, you're just you, you visually can tell, okay, like, that line doesn't make sense. Things are not those dots are not along that line. And the reason is because we are doing classification, not regression. Okay. Well, first of all, let's start here, we know that this model, if we just use this line, it equals m x. So whatever this let's just say it's x plus b, which is the y intercept, right? And m is the slope. But when we use a linear regression, is it actually y hat? No, it's not right. So when we're working with linear regression, what we're actually estimating in our model is a probability, what's a probability between zero and one, that is class zero or class one. So here, let's rewrite this as p equals m x plus b. Okay, well, m x plus b, that can range, you know, from negative infinity to infinity, right? For any for any value of x, it goes from negative infinity to infinity. But probability, we know probably one of the rules of probability is that probability has to stay between zero and one. So how do we fix this? Well, maybe instead of just setting the probability equal to that, we can set the odds equal to this. So by that, I mean, okay, let's do probability divided by one minus the probability. Okay, so now becomes this ratio. Now this ratio is allowed to take on infinite values. But there's still one issue here. Let me move this over a bit. The one issue here is that m x plus b, that can still be negative, right? Like if you know, I have a negative slope, if I have a negative b, if I have some negative x's in there, I don't know, but that can be that's allowed to be negative. So how do we fix that? We do that by actually taking the log of the odds. Okay. So now I have the log of you know, some probability divided by one minus the probability. And now that is on a range of negative infinity to infinity, which is good because the range of log should be negative infinity to infinity. Now how do I solve for P the probability? Well, the first thing I can do is take, you know, I can remove the log by taking the not the e to the whatever is on both sides. So that gives me the probability over the one minus the probability is now equal to e to the m x plus b. Okay. So let's multiply that out. So the probability is equal to one minus probability e to the m x plus b. So P is equal to e to the m x plus b minus P times e to the m x plus b. And now we have we can move like terms to one side. So if I do P, so basically, I'm moving this over, so I'm adding P. So now P one plus e to the m x plus b is equal to e to the m x plus b and let me change this parentheses make it a little bigger. So now my probability can be e to the m x plus b divided by one plus e to the m x plus b. Okay, well, let me just rewrite this really quickly, I want a numerator of one on top. Okay, so what I'm going to do is I'm going to multiply this by negative m x plus b, and then also the bottom by negative m x plus b, and I'm allowed to do that because this over this is one. So now my probability is equal to one over one plus e to the negative m x plus b. And now why did I rewrite it like that? It's because this is actually a form of a special function, which is called the sigmoid function. And for the sigmoid function, it looks something like this. So s of x sigmoid, you know, that some x is equal to one over one plus e to the negative x. So essentially, what I just did up here is rewrite this in some sigmoid function, where the x value is actually m x plus b. So maybe I'll change this to y just to make that a bit more clear, it doesn't matter what the variable name is. But this is our sigmoid function. And visually, what our sigmoid function looks like is it goes from zero. So this here is zero to one. And it looks something like this curved s, which I didn't draw too well. Let me try that again. It's hard to draw something if I can draw this right. Like that. Okay, so it goes in between zero and one. And you might notice that this form fits our shape up here. Oops, let's draw it sharper. But if it's our shape up there a lot better, right? Alright, so that is what we call logistic regression, we're basically trying to fit our data to the sigmoid function. Okay. And when we only have, you know, one data point, so if we only have one feature x, and that's what we call simple logistic regression. But then if we have, you know, so that's only x zero, but then if we have x zero, x one, all the way to x n, we call this multiple logistic regression, because there are multiple features that we're considering when we're building our model, logistic regression. So I'm going to put that here. And again, from SK learn this linear model, we can import logistic regression. All right. And just like how we did above, we can repeat all of this. So here, instead of NB, I'm going to call this log model, or LG logistic regression. I'm going to change this to logistic regression. So I'm just going to use the default logistic regression. But actually, if you look here, you see that you can use different penalties. So right now we're using an L2 penalty. But L2 is our quadratic formula. Okay, so that means that for, you know, outliers, it would really penalize that. For all these other things, you know, you can toggle these different parameters, and you might get slightly different results. If I were building a production level logistic regression model, then I would want to go and I would want to figure out how to do that. So I'm going to go ahead and I'm going to go ahead and I would want to figure out, you know, what are the best parameters to pass into here, based on my validation data. But for now, we'll just we'll just use this out of the box. So again, I'm going to fit the X train and the Y train. And I'm just going to predict again, so I can just call this again. And instead of LG, NB, I'm going to use LG. So here, this is decent precision 65% recall 71, f 168, or 82 total accuracy of 77. Okay, so it performs slightly better than I base, but it's still not as good as K and N. Alright, so the last model for classification that I wanted to talk about is something called support vector machines, or SVMs for short. So what exactly is an SVM model, I have two different features x zero and x one on the axes. And then I've told you if it's you know, class zero or class one based on the blue and red labels, my goal is to find some sort of line between these two labels that best divides the data. Alright, so this line is our SVM model. So I call it a line here because in 2d, it's a line, but in 3d, it would be a plane and then you can also have more and more dimensions. So the proper term is actually I want to find the hyperplane that best differentiates these two classes. Let's see a few examples. Okay, so first, between these three lines, let's say A, B, and C, and C, which one is the best divider of the data, which one has you know, all the data on one side or the other, or at least if it doesn't, which one divides it the most, right, like which one is has the most defined boundary between the two different groups. So this this question should be pretty straightforward. It should be a right because a has a clear distinct line between where you know, everything on this side of a is one label, it's negative and everything on this side of a is the other label, it's positive. So what if I have a but then what if I had drawn my B like this, and my C, maybe like this, sorry, they're kind of the labels are kind of close together. But now which one is the best? So I would argue that it's still a, right? And why is it still a? Right? And why is it still a? Because in these other two, look at how close this is to that, to these points. Right? So if I had some new point that I wanted to estimate, okay, say I didn't have A or B. So let's say we're just working with C. Let's say I have some new point that's right here. Or maybe a new point that's right there. Well, it seems like just logically looking at this. I mean, without the boundary, that would probably go under the positives, right? I mean, it's pretty close to that other positive. So one thing that we care about in SVM is something known as the margin. Okay, so not only do we want to separate the two classes really well, we also care about the boundary in between where the points in those classes in our data set are, and the line that we're drawing. So in a line like this, the closest values to this line might be like here. And I'm trying to draw these perpendicular. Right? And so this effectively, if I switch over to these dotted lines, if I can draw this right. So these effectively are what's known as the margins. Okay, so these both here, these are our margins in our SVMs. And our goal is to maximize those margins. So not only do we want the line that best separates the two different classes, we want the line that has the largest margin. And the data points that lie on the margin lines, the data. So basically, these are the data points that's helping us define our divider. These are what we call support vectors. Hence the name support vector machines. Okay, so the issue with SVM sometimes is that they're not so robust to outliers. Right? So for example, if I had one outlier, like this up here, that would totally change where I want my support vector to be, even though that might be my only outlier. Okay. So that's just something to keep in mind. As you know, when you're working with SVM is, it might not be the best model if there are outliers in your data set. Okay, so another example of SVMs might be, let's say that we have data like this, I'm just going to use a one dimensional data set for this example. Let's say we have a data set that looks like this. Well, our, you know, separators should be perpendicular to this line. But it should be somewhere along this line. So it could be anywhere like this. You might argue, okay, well, there's one here. And then you could also just draw another one over here, right? And then maybe you can have two SVMs. But that's not really how SVMs work. But one thing that we can do is we can create some sort of projection. So I realize here that one thing I forgot to do was to label where zero was. So let's just say zero is here. Now, what I'm going to do is I'm going to say, okay, I'm going to have x, and then I'm going to have x, sorry, x zero and x one. So x zero is just going to be my original x. But I'm going to make x one equal to let's say, x squared. So whatever is this squared, right? So now, my natives would be, you know, maybe somewhere here, here, just pretend that it's somewhere up here. Right. And now my pluses might be something like that. And I'm going to run out of space over here. So I'm just going to draw these together, use your imagination. But once I draw it like this, well, it's a lot easier to apply a boundary, right? Now our SVM could be maybe something like this, this. And now you see that we've divided our data set. Now it's separable where one class is this way. And the other class is that way. Okay, so that's known as SVMs. I do highly suggest that, you know, any of these models that we just mentioned, if you're interested in them, do go more in depth mathematically into them. Like how do we how do we find this hyperplane? Right? I'm not going to go over that in this specific course, because you're just learning what an SVM is. But it's a good idea to know, oh, okay, this is the technique behind finding, you know, what exactly are the are the how do you define the hyperplane that we're going to use. So anyways, this transformation that we did down here, this is known as the kernel trick. So when we go from x to some coordinate x, and then x squared, what we're doing is we are applying a kernel. So that's why it's called the kernel trick. So SVMs are actually really powerful. And you'll see that here. So from sk learn.svm, we are going to import SVC. And SVC is our support vector classifier. So with this, so with our SVM model, we are going to, you know, create SVC model. And we are going to, again, fit this to X train, I could have just copied and pasted this, I should be able to do that. So we're going to create SVC again, fit this to X train, I could have just copied and pasted this, I should have probably done that. Okay, taking a bit longer. All right. Let's predict using RSVM model. And here, let's see if I can hover over this. Right. So again, you see a lot of these different parameters here that you can go back and change if you were creating a production level model. Okay, but in this specific case, we'll just use it out of the box again. So if I make predictions, you'll note that Wow, the accuracy actually jumps to 87% with the SVM. And even with class zero, there's nothing less than, you know, point eight, which is great. And for class one, I mean, everything's at 0.9, which is higher than anything that we had seen to this point. So so far, we've gone over four different classification models, we've done SVM, logistic regression, naive Bayes and cannon. And these are just simple ways on how to implement them. Each of these they have different, you know, they have different hyper parameters that you can go and you can toggle. And you can try to see if that helps later on or not. But for the most part, they perform, they give us around 70 to 80% accuracy. Okay, with SVM being the best. Now, let's see if we can actually beat that using a neural net. Now the final type of model that I wanted to talk about is known as a neural net or neural network. And neural nets look something like this. So you have an input layer, this is where all your features would go. And they have all these arrows pointing to some sort of hidden layer. And then all these arrows point to some sort of output layer. So what is what is all this mean? Each of these layers in here, this is something known as a neuron. Okay, so that's a neuron. In a neural net. These are all of our features that we're inputting into the neural net. So that might be x zero x one all the way through x n. Right. And these are the features that we talked about there, they might be you know, the pregnancy, the BMI, the age, etc. Now all of these get weighted by some value. So they are multiplied by some w number that applies to that one specific category that one specific feature. So these two get multiplied. And the sum of all of these goes into that neuron. Okay, so basically, I'm taking w zero times x zero. And then I'm adding x one times w one and then I'm adding you know, x two times w two, etc, all the way to x n times w n. And that's getting input into the neuron. Now I'm also adding this bias term, which just means okay, I might want to shift this by a little bit. So I might add five or I might add 0.1 or I might subtract 100, I don't know. But we're going to add this bias term. And the output of all these things. So the sum of this, this, this and this, go into something known as an activation function, okay. And then after applying this activation function, we get an output. And this is what a neuron would look like. Now a whole network of them would look something like this. So I kind of gloss over this activation function. What exactly is that? This is how a neural net looks like if we have all our inputs here. And let's say all of these arrows represent some sort of addition, right? Then what's going on is we're just adding a bunch of times, right? We're adding the some sort of weight times these input layer a bunch of times. And then if we were to go back and factor that all out, then this entire neural net is just a linear combination of these input layers, which I don't know about you, but that just seems kind of useless, right? Because we could literally just write that out in a formula, why would we need to set up this entire neural network, we wouldn't. So the activation function is introduced, right? So without an activation function, this just becomes a linear model. An activation function might look something like this. And as you can tell, these are not linear. And the reason why we introduce these is so that our entire model doesn't collapse on itself and become a linear model. So over here, this is something known as a sigmoid function, it runs between zero and one, tanh runs between negative one all the way to one. And this is ReLU, which anything less than zero is zero, and then anything greater than zero is linear. So with these activation functions, every single output of a neuron is no longer just the linear combination of these, it's some sort of altered linear state, which means that the input into the next neuron is, you know, it doesn't it doesn't collapse on itself, it doesn't become linear, because we've introduced all these nonlinearities. So this is a training set, the model, the loss, right? And then we do this thing called training, where we have to feed the loss back into the model, and make certain adjustments to the model to improve this predicted output. Let's talk a little bit about the training, what exactly goes on during that step. Let's go back and take a look at our L2 loss function. This is what our L2 loss function looks like it's a quadratic formula, right? Well, up here, the error is really, really, really, really large. And our goal is to get somewhere down here, where the loss is decreased, right? Because that means that our predicted value is closer to our true value. So that means that we want to go this way. Okay. And thanks to a lot of properties of math, something that we can do is called gradient descent, in order to follow this slope down this way. This quadratic is, it has different different slopes with respect to some value. Okay, so the loss with respect to some weight w zero, versus w one versus w n, they might all be different. Right? So some way that I kind of think about it is, to what extent is this value contributing to our loss. And we can actually figure that out through some calculus, which we're not going to touch up on in this specific course. But if you want to learn more about neural nets, you should probably also learn some calculus and figure out what exactly back propagation is doing, in order to actually calculate, you know, how much do we have to backstep by. So the thing is here, you might notice that this follows this curve at all of these different points. And the closer we get to the bottom, the smaller this step becomes. Now stick with me here. So my new value, this is what we call a weight update, I'm going to take w zero, and I'm going to set some new value for w zero. And what I'm going to set for that is the old value of w zero, plus some factor, which I'll just call alpha for now, times whatever this arrow is. So that's basically saying, okay, take our old w zero, our old weight, and just decrease it this way. So I guess increase it in this direction, right, like take a step in this direction. But this alpha here is telling us, okay, don't don't take a huge step, right, just in case we're wrong, take a small step, take a small step in that direction, see if we get any closer. And for those of you who, you know, do want to look more into the mathematics of things, the reason why I use a plus here is because this here is the negative gradient, right, if this were just the if you were to use the actual gradient, this should be a minus. Now this alpha is something that we call the learning rate. Okay, and that adjusts how quickly we're taking steps. And that might, you know, tell our that that will ultimately control how long it takes for our neural net to converge. Or sometimes if you set it too high, it might even diverge. But with all of these weights, so here I have w zero, w one, and then w n. We make the same update to all of them after we calculate the loss, the gradient of the loss with respect to that weight. So that's how back propagation works. And that is everything that's going on here. After we calculate the loss, we're calculating gradients, making adjustments in the model. So we're setting all the all the weights to something adjusted slightly. And then we're going to calculate the gradient. And then we're saying, Okay, let's take the training set and run it through the model again, and go through this loop all over again. So for machine learning, we already have seen some libraries that we use, right, we've already seen SK learn. But when we start going into neural networks, this is kind of what we're trying to program. And it's not very fun to try to do this from scratch, because not only will we probably have a lot of bugs, but also probably not going to be fast enough, right? Wouldn't it be great if there are just some, you know, full time professionals that are dedicated to solving this problem, and they could literally just give us their code that's already running really fast? Well, the answer is, yes, that exists. And that's why we use TensorFlow. So TensorFlow makes it really easy to define these models. But we also have enough control over what exactly we're feeding into this model. So for example, this line here is basically saying, Okay, let's create a sequential neural net. So sequential is just, you know, what we've seen here, it just goes one layer to the next. And a dense layer means that a dense layer means that all of them are interconnected. So here, this is interconnected with all of these nodes, and this one's all these, and then this one gets connected to all of the next ones, and so on. So we're going to create 16 dense nodes with relu activation functions. And then we're going to create another layer of 16 dense nodes with relu activation. And then our output layer is going to be just one node. Okay. And that's how easy it is to define something in TensorFlow. So TensorFlow is an open source library that helps you develop and train your ML models. Let's implement this for a neural net. So we're using a neural net for classification. Now, so our neural net model, we are going to use TensorFlow, and I don't think I imported that up here. So we are going to import that down here. So I'm going to import TensorFlow as TF. And enter. Cool. So my neural net model is going to be, I'm going to use this. So essentially, this is saying layer all these things that I'm about to pass in. So yeah, layer them linear stack of layers, layer them as a model. And what that means, nope, not that. So what that means is I can pass in some sort of layer, and I'm just going to use a dense layer. Oops, dot dense. And let's say we have 32 units. Okay, I will also set the activation as really. And at first we have to specify the input shape. So here we have 10, and comma. Alright. Alright, so that's our first layer. Now our next layer, I'm just going to have another dense layer of 32 units all using relu. And that's it. So for the final layer, this is just going to be my output layer, it's going to just be one node. And the activation is going to be sigmoid. So if you recall from our logistic regression, what happened there was when we had a sigmoid, it looks something like this, right? So by creating a sigmoid activation on our last layer, we're essentially projecting our predictions to be zero or one, just like in logistic regression. And that's going to help us, you know, we can just round to zero or one and classify that way. Okay. So this is my neural net model. And I'm going to compile this. So in TensorFlow, we have to compile it. It's really cool, because I can just literally pass in what type of optimizer I want, and it'll do it. So here, if I go to optimizers, I'm actually going to use atom. And you'll see that, you know, the learning rate is 0.001. So I'm just going to use that default. So 0.001. And my loss is going to be binary cross entropy. And the metrics that I'm also going to include on here, so it already will consider loss, but I'm, I'm also going to tack on accuracy. So we can actually see that in a plot later on. Alright, so I'm going to run this. And one thing that I'm going to also do is I'm going to define these plot definitions. So I'm actually copying and pasting this, I got these from TensorFlow. So if you go on to some TensorFlow tutorial, they actually have these, this like, defined. And that's exactly what I'm doing here. So I'm actually going to move this cell up, run that. So we're basically plotting the loss over all the different epochs. epochs means like training cycles. And we're going to run that. So means like training cycles. And we're going to plot the accuracy over all the epochs. Alright, so we have our model. And now all that's left is, let's train it. Okay. So I'm going to say history. So TensorFlow is great, because it keeps track of the history of the training, which is why we can go and plot it later on. Now I'm going to set that equal to this neural net model. And fit that with x train, y train, I'm going to make the number of epochs equal to let's say just let's just use 100 for now. And the batch size, I'm going to set equal to, let's say 32. Alright. And the validation split. So what the validation split does, if it's down here somewhere. Okay, so yeah, this validation split is just the fraction of the training data to be used as validation data. So essentially, every single epoch, what's going on is TensorFlow saying, leave certain if this is point two, then leave 20% out. And we're going to test how the model performs on that 20% that we've left out. Okay, so it's basically like our validation data set. But TensorFlow does it on our training data set during the training. So we have now a measure outside of just our validation data set to see, you know, what's going on. So validation split, I'm going to make that 0.2. And we can run this. So if I run that, all right, and I'm actually going to set verbose equal to zero, which means, okay, don't print anything, because printing something for 100 epochs might get kind of annoying. So I'm just going to let it run, let it train, and then we'll see what happens. Cool, so it finished training. And now what I can do is because you know, I've already defined these two functions, I can go ahead and I can plot the loss, oops, loss of that history. And I can also plot the accuracy throughout the training. So this is a little bit ish what we're looking for. We definitely are looking for a steadily decreasing loss and an increasing accuracy. So here we do see that, you know, our validation accuracy improves from around point seven, seven or something all the way up to somewhere around point, maybe eight one. And our loss is decreasing. So this is good. It is expected that the validation loss and accuracy is performing worse than the training loss or accuracy. And that's because our model is training on that data. So it's adapting to that data. Whereas the validation stuff is, you know, stuff that it hasn't seen yet. So, so that's why. So in machine learning, as we saw above, we could change a bunch of the parameters, right? Like I could change this to 64. So now it'd be a row of 64 nodes, and then 32, and then one. So I can change some of these parameters. And a lot of machine learning is trying to find, hey, what do we set these hyper parameters to? So what I'm actually going to do is I'm going to rewrite this so that we can do something what's known as a grid search. So we can search through an entire space of hey, what happens if, you know, we have 64 nodes and 64 nodes, or 16 nodes and 16 nodes, and so on. And then on top of all that, we can, you know, we can change this learning rate, we can change how many epochs we can change, you know, the batch size, all these things might affect our training. And just for kicks, I'm also going to add what's known as a dropout layer in here. And what dropout is doing is saying, hey, randomly choose with at this rate, certain nodes, and don't train them in, you know, in a certain iteration. So this helps prevent overfitting. Okay, so I'm actually going to define this as a function called train model, we're going to pass in x train, y train, the number of nodes, the dropout, you know, the probability that we just talked about learning rate. So I'm actually going to say lr batch size. And we can also pass in number epochs, right? I mentioned that as a parameter. So indent this, so it goes under here. And with these two, I'm going to set this equal to number of nodes. And now with the two dropout layers, I'm going to set dropout prob. So now you know, the probability of turning off a node during the training is equal to dropout prob. And I'm going to keep the output layer the same. Now I'm compiling it, but this here is now going to be my learning rate. And I still want binary cross entropy and accuracy. We are actually going to train our model inside of this function. But here we can do the epochs equal epochs, and this is equal to whatever, you know, we're passing in x train, y train belong right here. Okay, so those are getting passed in as well. And finally, at the end, I'm going to return this model and the history of that model. Okay. So now what I'll do is let's just go through all of these. So let's say let's keep epochs at 100. And now what I can do is I can say, hey, for a number of nodes in, let's say, let's do 1632 and 64, to see what happens for the different dropout probabilities. And I mean, zero would be nothing. Let's use 0.2. Also, to see what happens. You know, for the learning rate in 0.005, 0.001. And you know, maybe we want to throw on 0.1 in there as well. And then for the batch size, let's do 1632, 64 as well. Actually, and let's also throw in 128. Actually, let's get rid of 16. Sorry, so 128 in there. That should be 01. I'm going to record the model and history using this train model here. So we're going to do x train y train, the number of nodes is going to be, you know, the number of nodes that we've defined here, dropout, prob, LR, batch size, and epochs. Okay. And then now we have both the model and the history. And what I'm going to do is again, I want to plot the loss for the history. I'm also going to plot the accuracy. Probably should have done them side by side, that probably would have been easier. Okay, so what I'm going to do is split up, split this up. And that will be the subplots. So now this is just saying, okay, I want one row and two columns in that row for my plots. Okay, so I'm going to plot on my axis one, the loss. I don't actually know this is going to work. Okay, we don't care about the grid. Yeah, let's let's keep the grid. And then now my other. So now on here, I'm going to plot all the accuracies on the second plot. I might have to debug this a bit. We should be able to get rid of that. If we run this, we already have history saved as a variable in here. So if I just run it on this, okay, it has no attribute x label. Oh, I think it's because it's like set x label or something. Okay, yeah, so it's, it's set instead of just x label, y label. So let's see if that works. All right, cool. Um, and let's actually make this a bit larger. Okay, so we can actually change the figure size that I'm gonna set. Let's see what happens if I set that to. Oh, that's not the way I wanted it. Okay, so that looks reasonable. And that's just going to be my plot history function. So now I can plot them side by side. Here, I'm going to plot the history. And what I'm actually going to do is I so here, first, I'm going to print out all these parameters. So I'm going to print out the F string to print out all of this stuff. So here, I'm going to print out all these parameters. Uh, all of this stuff. So here, I'm printing out how many nodes, um, the dropout probability, uh, the learning rate. And we already know how many you found, so I'm not even going to bother with that. So once we plot this, uh, let's actually also figure out what the, um, what the validation losses on our validation set that we have that we created all the way back up here. Alright, so remember, we created three data sets. Let's call our model and evaluate what the validation data with the validation data sets loss would be. And I actually want to record, let's say I want to record whatever model has the least validation loss. So first, I'm going to initialize that to infinity so that you know, any model will beat that score. So if I do float infinity, that will set that to infinity. And maybe I'll keep track of the parameters. Actually, it doesn't really matter. I'm just going to keep track of the model. And I'm gonna set that to none. So now down here, if the validation loss is ever less than the least validation loss, then I am going to simply come down here and say, Hey, this validation for this least validation loss is now equal to the validation loss. And the least loss model is whatever this model is that just earned that validation loss. Okay. So we are actually just going to let this run for a while. And then we're going to get our least last model after that. So let's just run. All right, and now we wait. All right, so we've finally finished training. And you'll notice that okay, down here, the loss actually gets to like 0.29. The accuracy is around 88%, which is pretty good. So you might be wondering, okay, why is this accuracy in this? Like, these are both the validation. So this accuracy here is on the validation data set that we've defined at the beginning, right? And this one here, this is actually taking 20% of our tests, our training set every time during the training, and saying, Okay, how much of it do I get right now? You know, after this one step where I didn't train with any of that. So they're slightly different. And actually, I realized later on that I probably you know, probably what I should have done is over here, when we were defining the model fit, instead of the validation split, you can define the validation data. And you can pass in the validation data, I don't know if this is the proper syntax. But that's probably what I should have done. But instead, you know, we'll just stick with what we have here. So you'll see at the end, you know, with the 64 nodes, it seems like this is our best performance 64 nodes with a dropout of 0.2, a learning rate of 0.001, and a batch size of 64. And it does seem like yes, the validation, you know, the fake validation, but the validation loss is decreasing, and then the accuracy is increasing, which is a good sign. Okay, so finally, what I'm going to do is I'm actually just going to predict. So I'm going to take this model, which we've called our least loss model, I'm going to take this model, and I'm going to predict x test on that. And you'll see that it gives me some values that are really close to zero and some that are really close to one. And that's because we have a sigmoid output. So if I do this, and what I can do is I can cast them. So I'm going to say anything that's greater than 0.5, set that to one. So if I actually, I think what happens if I do this? Oh, okay, so I have to cast that as type. And so now you'll see that it's ones and zeros. And I'm actually going to transform this into a column as well. So here I'm going to Oh, oops, I didn't I didn't mean to do that. Okay, no, I wanted to just reshape it to that. So now it's one dimensional. Okay. And using that we can actually just rerun the classification report based on these this neural net output. And you'll see that okay, the the F ones are the accuracy gives us 87%. So it seems like what happened here is the precision on class zero. So the hadrons has increased a bit, but the recall decreased. But the F one score is still at a good point eight one. And for the other class, it looked like the precision decreased a bit the recall increased for an overall F one score. That's also been increased. I think I interpreted that properly. I mean, we went through all this work and we got a model that performs actually very, very similarly to the SVM model that we had earlier. And the whole point of this exercise was to demonstrate, okay, these are how you can define your models. But it's also to say, hey, maybe, you know, neural nets are very, very powerful, as you can tell. But sometimes, you know, an SVM or some other model might actually be more appropriate. But in this case, I guess it didn't really matter which one we use at the end. An 87% accuracy score is still pretty good. So yeah, let's now move on to regression. We just saw a bunch of different classification models. Now let's shift gears into regression, the other type of supervised learning. If we look at this plot over here, we see a bunch of scattered data points. And here we have our x value for those data points. And then we have the corresponding y value, which is now our label. And when we look at this plot, well, our goal in regression is to find the line of best fit that best models this data. Essentially, we're trying to let's say we're given some new value of x that we don't have in our sample, we're trying to say, okay, what would my prediction for y be for that given x value. So that, you know, might be somewhere around there. I don't know. But remember, in regression that, you know, given certain features, we're trying to predict some continuous numerical value for y. In linear regression, we want to take our data and fit a linear model to this data. So in this case, our linear model might look something along the lines of here. Right. So this here would be considered as maybe our line of best fit. And this line is modeled by the equation, I'm going to write it down here, y equals b zero, plus b one x. Now b zero just means it's this y intercept. So if we extend this y down here, this value here is b zero, and then b one defines the source of the line, defines the slope of this line. Okay. All right. So that's the that's the formula for linear regression. And how exactly do we come up with that formula? What are we trying to do with this linear regression? You know, we could just eyeball where the line be, but humans are not very good at eyeballing certain things like that. I mean, we can get close, but a computer is better at giving us a precise value for b zero and b one. Well, let's introduce the concept of something known as a residual. Okay, so residual, you might also hear this being called the error. And what that means is, let's take some data point in our data set. And we're going to evaluate how far off is our prediction from a data point that we already have. So this here is our y, let's say, this is 12345678. So this is y eight, let's call it, you'll see that I use this y i in order to I in order to represent, hey, just one of these points. Okay. So this here is why and this here would be the prediction. Oops, this here would be the prediction for y eight, which I've labeled with this hat. Okay, if it has a hat on it, that means hey, this is what this is my guess this is my prediction for you know, this specific value of x. Okay. Now the residual would be this distance here between y eight and y hat eight. So y eight minus y hat eight. All right, because that would give us this here. And I'm just going to take the absolute value of this. Because what if it's below the line, right, then you would get a negative value, but distance can't be negative. So we're just going to put a little hat, or we're going to put a little absolute value around this quantity. And that gives us the residual or the error. So let me rewrite that. And you know, to generalize to all the points, I'm going to say the residual can be calculated as y i minus y hat of i. Okay. So this just means the distance between some given point, and its prediction, its corresponding prediction on the line. So now, with this residual, this line of best fit is generally trying to decrease these residuals as much as possible. So now that we have some value for the error, our line of best fit is trying to decrease the error as much as possible for all of the different data points. And that might mean, you know, minimizing the sum of all the residuals. So this here, this is the sum symbol. And if I just stick the residual calculation in there, it looks something like that, right. And I'm just going to say, okay, for all of the eyes in our data set, so for all the different points, we're going to sum up all the residuals. And I'm going to try to decrease that with my line of best fit. So I'm going to find the B0 and B1, which gives me the lowest value of this. Okay. Now in other, you know, sometimes in different circumstances, we might attach a squared to that. So we're trying to decrease the sum of the squared residuals. And what that does is it just, you know, it adds a higher penalty for how far off we are from, you know, points that are further off. So that is linear regression, we're trying to find this equation, some line of best fit that will help us decrease this measure of error with respect to all the data points that we have in our data set, and try to come up with the best prediction for all of them. This is known as simple linear regression. And basically, that means, you know, our equation looks something like this. Now, there's also multiple linear regression, which just means that hey, if we have more than one value for x, so like think of our feature vectors, we have multiple values in our x vector, then our predictor might look something more like this. Actually, I'm just going to say etc, plus b n, x n. So now I'm coming up with some coefficient for all of the different x values that I have in my vector. Now you guys might have noticed that I have some assumptions over here. And you might be asking, okay, Kylie, what in the world do these assumptions mean? So let's go over them. So let's go over them. The first one is linearity. And what that means is, let's say I have a data set. Okay. Linearity just means, okay, my does my data follow a linear pattern? Does y increase as x increases? Or does y decrease at as x increases? Does so if y increases or decreases at a constant rate as x increases, then you're probably looking at something linear. So what's the example of a nonlinear data set? Let's say I had data that might look something like that. Okay. So now just visually judging this, you might say, okay, seems like the line of best fit might actually be some curve like this. Right. And in this case, we don't satisfy that linearity assumption anymore. So with linearity, we basically just want our data set to follow some sort of linear trajectory. And independence, our second assumption just means this point over here, it should have no influence on this point over here, or this point over here, or this point over here. So in other words, all the points, all the samples in our data set should be independent. Okay, they should not rely on one another, they should not affect one another. Okay, now, normality and homoscedasticity, those are concepts which use this residual. Okay. So if I have a plot that looks something like this, and I have a plot that looks like this. Okay, something like this. And my line of best fit is somewhere here, maybe it's something like that. In order to look at these normality and homoscedasticity assumptions, let's look at the residual plot. Okay. And what that means is I'm going to keep my same x axis. But instead of plotting now where they are relative to this y, I'm going to plot these errors. So now I'm going to plot y minus y hat like this. Okay. And now you know, this one is slightly positive, so it might be here, this one down here is negative, it might be here. So our residual plot, it's literally just a plot of how you know, the values are distributed around our line of best fit. So it looks like it might, you know, look something like this. Okay. So this might be our residual plot. And what normality means, so our assumptions are normality and homoscedasticity, I might have butchered that spelling, I don't really know. But what normality is saying is saying, okay, these residuals should be normally distributed. Okay, around this line of best fit, it should follow a normal distribution. And now what homoscedasticity says, okay, our variants of these points should remain constant throughout. So this spread here should be approximately the same as this spread over here. Now, what's an example of where you know, homoscedasticity is not held? Well, let's say that our original plot actually looks something like this. Okay, so now if we looked at the residuals for that, it might look something like that. And now if we look at this spread of the points, it decreases, right? So now the spread is not constant, which means that homoscedasticity, this assumption would not be fulfilled, and it might not be appropriate to use linear regression. So that's just linear regression. Basically, we have a bunch of data points, we want to predict some y value for those. And we're trying to come up with this line of best fit that best describes, hey, given some value x, what would be my best guess of what y is. So let's move on to how do we evaluate a linear regression model. So the first measure that I'm going to talk about is known as mean absolute error, or MAE for short, okay. And mean absolute error is basically saying, all right, let's take all the errors. So all these residuals that we talked about, let's sum up the distance for all of them, and then take the average. And then that can describe, you know, how far off are we. So the mathematical formula for that would be, okay, let's take all the residuals. Alright, so this is the distance. Actually, let me redraw a plot down here. So suppose I have a data set, look like this. And here are all my data points, right. And now let's say my line looks something like that. So my mean absolute error would be summing up all of these values. This was a mistake. So summing up all of these, and then dividing by how many data points I have. So what would be all the residuals, it would be y i, right, so every single point, minus y hat i, so the prediction for that on here. And then we're going to sum over all of all of the different i's in our data set. Right, so i, and then we divide by the number of points we have. So actually, I'm going to rewrite this to make it a little clearer. So i is equal to whatever the first data point is all the way through the nth data point. And then we divide it by n, which is how many points there are. Okay, so this is our measure of mae. And this is basically telling us, okay, in on average, this is the distance between our predicted value and the actual value in our training set. Okay. And mae is good because it allows us to, you know, when we get this value here, we can literally directly compare it to whatever units the y value is in. So let's say y is we're talking, you know, the prediction of the price of a house, right, in dollars. Once we have once we calculate the mae, we can literally say, oh, the average, you know, price, the average, how much we're off by is literally this many dollars. Okay. So that's the mean absolute error. An evaluation technique that's also closely related to that is called the mean squared error. And this is MSE for short. Okay. Now, if I take this plot again, and I duplicated and move it down here, well, the gist of mean squared error is kind of the same, but instead of the absolute value, we're going to square. So now the MSE is something along the lines of, okay, let's sum up something, right, so we're going to sum up all of our errors. So now I'm going to do y i minus y hat i. But instead of absolute valuing them, I'm going to square them all. And then I'm going to divide by n in order to find the mean. So basically, now I'm taking all of these different values, and I'm squaring them first before I add them to one another. And then I divide by n. And the reason why we like using mean squared error is that it helps us punish large errors in the prediction. And later on, MSE might be important because of differentiability, right? So a quadratic equation is differentiable, you know, if you're familiar with calculus, a quadratic equation is differentiable, whereas the absolute value function is not totally differentiable everywhere. But if you don't understand that, don't worry about it, you won't really need it right now. And now one downside of mean squared error is that once I calculate the mean squared error over here, and I go back over to y, and I want to compare the values. Well, it gets a little bit trickier to do that because now my mean squared error is in terms of y squared, right? It's this is now squared. So instead of just dollars, how, you know, how many dollars off am I I'm talking how many dollars squared off am I. And that, you know, to humans, it doesn't really make that much sense. Which is why we have created something known as the root mean squared error. And I'm just going to copy this diagram over here because it's very, very similar to mean squared error. Except now we take a big squared root. Okay, so this is our messy, and we take the square root of that mean squared error. And so now the term in which you know, we're defining our error is now in terms of that dollar sign symbol again. So that's a pro of root mean squared error is that now we can say, okay, our error according to this metric is this many dollar signs off from our predictor. Okay, so it's in the same unit, which is one of the pros of root mean squared error. And now finally, there is the coefficient of determination, or r squared. And this is a formula for r squared. So r squared is equal to one minus RSS over TSS. Okay, so what does that mean? Basically, RSS stands for the sum of the squared residuals. So maybe it should be SSR instead, but RSS sum of the squared residuals, and this is equal to if I take the sum of all the values, and I take y i minus y hat, i, and square that, that is my RSS, right, it's a sum of the squared residuals. Now TSS, let me actually use a different color for that. So TSS is the total sum of squares. And what that means is that instead of being with respect to this prediction, we are instead going to take each y value and just subtract the mean of all the y values, and square that. Okay, so if I drew this out, and if this were my actually, let's use a different color. Let's use green. If this were my predictor, so RSS is giving me this measure here, right? It's giving me some estimate of how far off we are from our regressor that we predicted. Actually, I'm gonna take this one, and I'm gonna take this one, and actually, I'm going to use red for that. Well, TSS, on the other hand, is saying, okay, how far off are these values from the mean. So if we literally didn't do any calculations for the line of best fit, if we just took all the y values and average all of them, and said, hey, this is the average value for every single x value, I'm just going to predict that average value instead, then it's asking, okay, how far off are all these points from that line? Okay, and remember that this square means that we're punishing larger errors, right? So even if they look somewhat close in terms of distance, the further a few data points are, then the further the larger our total sum of squares is going to be. Sorry, that was my dog. So the total sum of squares is taking all of these values and saying, okay, what is the sum of squares, if I didn't do any regressor, and I literally just calculated the average of all the y values in my data set, and for every single x value, I'm just going to predict that average, which means that okay, like, that means that maybe y and x aren't associated with each other at all. Like the best thing that I can do for any new x value, just predict, hey, this is the average of my data set. And this total sum of squares is saying, okay, well, with respect to that average, what is our error? Right? So up here, the sum of the squared residuals, this is telling us what is our what what is our error with respect to this line of best fit? Well, our total sum of squares saying what is the error with respect to, you know, just the average y value. And if our line of best fit is a better fit, then this total sum of squares, that means that you know, this numerator, that means that this numerator is going to be smaller than this denominator, right? And if our errors in our line of best fit are much smaller, then that means that this ratio of the RSS over TSS is going to be very small, which means that R squared is going to go towards one. And now when R squared is towards one, that means that that's usually a sign that we have a good predictor. It's one of the signs, not the only one. So over here, I also have, you know, that there's this adjusted R squared. And what that does, it just adjusts for the number of terms. So x1, x2, x3, etc. It adjusts for how many extra terms we add, because usually when we, you know, add an extra term, the R squared value will increase because that'll help us predict y some more. But the value for the adjusted R squared increase if the new term actually improves this model fit more than expected, you know, by chance. So that's what adjusted R squared is. I'm not, you know, it's out of the scope of this one specific course. And now that's linear regression. Basically, I've covered the concept of residuals or errors. And, you know, how do we use that in order to find the line of best fit? And you know, our computer can do all the calculations for us, which is nice. But behind the scenes, it's trying to minimize that error, right? And then we've gone through all the different ways of actually evaluating a linear regression model and the pros and cons of each one. So now let's look at an example. So we're still on supervised learning. But now we're just going to talk about regression. So what happens when you don't just want to predict, you know, type 123? What happens if you actually want to predict a certain value? So again, I'm on the UCI machine learning repository. And here I found this data set about bike sharing in Seoul, South Korea. So this data set is predicting rental bike count. And here it's the kind of bikes rented at each hour. So what we're going to do, again, you're going to go into the data folder, and you're going to download this CSV file. And we're going to move over to collab again. And here I'm going to name this FCC bikes and regression. I don't remember what I called the last one. But yeah, FCC bikes regression. Now I'm going to import a bunch of the same things that I did earlier. And, you know, I'm going to also continue to import the oversampler and the standard scaler. And then I'm actually also just going to let you guys know that I have a few more things I wanted import. So this is a library that lets us copy things. Seaborn is a wrapper over a matplotlib. So it also allows us to plot certain things. And then just letting you know that we're also going to be using TensorFlow. Okay, so one more thing that we're also going to be using, we're going to use the sklearn linear model library. Actually, let me make my screen a little bit bigger. So yeah, awesome. Run this and that'll import all the things that we need. So again, I'm just going to, you know, give some credit to where we got this data set. So let me copy and paste this UCI thing. And I will also give credit to this here. Okay, cool. All right, cool. So this is our data set. And again, it tells us all the different attributes that we have right here. So I'm actually going to go ahead and paste this in here. Feel free to copy and paste this if you want me to read it out loud, so you can type it. It's byte count, hour, temp, humidity, wind, visibility, dew point, temp, radiation, rain, snow, and functional, whatever that means. Okay, so I'm going to come over here and import my data by dragging and dropping. All right. Now, one thing that you guys might actually need to do is you might actually have to open up the CSV because there were, at first, a few like forbidding characters in mine, at least. So you might have to get rid of like, I think there was a degree here, but my computer wasn't recognizing it. So I got rid of that. So you might have to go through and get rid of some of those labels that are incorrect. I'm going to do this. Okay. But after we've done that, we've imported in here, I'm going to create a data a data frame from that. So, all right, so now what I can do is I can read that CSV file and I can get the data into here. So so like data dot CSV. Okay, so now if I call data dot head, you'll see that I have all the various labels, right? And then I have the data in there. So I'm going to from here, I'm actually going to get rid of some of these columns that, you know, I don't really care about. So here, I'm going to, when I when I type this in, I'm going to drop maybe the date, whether or not it's a holiday, and the various seasons. So I'm just not going to care about these things. Access equals one means drop it from the columns. So now you'll see that okay, we still have, I mean, I guess you don't really notice it. But if I set the data frames columns equal to data set calls, and I look at, you know, the first five things, then you'll see that this is now our data set. It's a lot easier to read. So another thing is, I'm actually going to df functional. And we're going to create this. So remember that our computers are not very good at language, we want it to be in zeros and ones. So here, I will convert that. Well, if this is equal to yes, then that that gets mapped as one. So then set type integer. All right. Great. Cool. So the thing is, right now, these by counts are for whatever hour. So to make this example simpler, I'm just going to index on an hour, and I'm gonna say, okay, we're only going to use that specific hour. So I'm just going to index on an hour, and I'm going to use an hour. So here, let's say. So this data frame is only going to be data frame where the hour, let's say it equals 12. Okay, so it's noon. All right. So now you'll see that all the equal to 12. And I'm actually going to now drop that column. Our access equals one. Alright, so we run this cell. Okay, so now we got rid of the hour in here. And we just have the by count, the temperature, humidity, wind, visibility, and yada, yada, yada. Alright, so what I want to do is I'm going to actually plot all of these. So for i in all the columns, so the range, length of whatever its data frame is, and all the columns, because I don't have by count as actually, it's my first thing. So what I'm going to do is say for a label in data frame, columns, everything after the first thing, so that would give me the temperature and onwards. So these are all my features, right? I'm going to just scatter. So I want to see how that label how that specific data, how that affects the by count. So I'm going to plot the bike count on the y axis. And I'm going to plot, you know, whatever the specific label is on the x axis. And I'm going to title this, whatever the label is. And, you know, make my y label, the bike count at noon. And the x label as just the label. Okay, now, I guess we don't even need the legend. We don't even need the legend. So just show that plot. All right. So it seems like functional is not really doesn't really give us any utility. So then snow rain seems like this radiation, you know, is fairly linear dew point temperature, visibility, wind doesn't really seem like it does much humidity, kind of maybe like an inverse relationship. But the temperature definitely looks like there's a relationship between that and the number of bikes, right. So what I'm actually going to do is I'm going to drop some of the ones that don't don't seem like they really matter. So maybe wind, you know, visibility. Yeah, so I'm going to get rid of when visibility and functional. So now data frame, and I'm going to drop wind, visibility, and functional. All right. And the axis again is the column. So that's one. So if I look at my data set, now, I have just the temperature, the humidity, the dew point temperature, radiation, rain, and snow. So again, what I want to do is I want to split this into my training, my validation and my test data set, just as we talked before. Here, we can use the exact same thing that we just did. And we can say numpy dot split, and sample, you know that the whole sample, and then create our splits of the data frame. And we're going to do that. But now set this to eight. Okay. So I don't really care about, you know, the the full grid, the full array. So I'm just going to use an underscore for that variable. But I will get my training x and y's. And actually, I don't have a function for getting the x and y's. So here, I'm going to write a function defined, get x y. And I'm going to pass in the data frame. And I'm actually going to pass in what the name of the y label is, and what the x what specific x labels I want to look at. So here, if that's none, then I'm just like, like, I'm only going to I'm going to get everything from the data set. That's not the wildlife. So here, I'm actually going to make first a deep copy of my data frame. And that basically means I'm just copying everything over. If, if like x labels is none, so if not x labels, then all I'm going to do is say, all right, x is going to be whatever this data frame is. And I'm just going to take all the columns. So C for C, and data frame, dot columns, if C does not equal the y label, right, and I'm going to get the values from that. But if there is the x labels, well, okay, so in order to index only one thing, so like, let's say I pass in only one thing in here, then my data frame is, so let me make a case for that. So if the length of x labels is equal to one, then what I'm going to do is just say that this is going to be x labels, and add that just that label values, and I actually need to reshape to make this 2d. So I'm going to pass in negative one comma one there. Now, otherwise, if I have like a list of specific x labels that I want to use, then I'm actually just going to say x is equal to data frame of those x labels, dot values. And that should suffice. Alright, so now that's just me extracting x. And in order to get my y, I'm going to do y equals data frame, and then passing the y label. And at the very end, I'm going to say data equals NP dot h stack. So I'm stacking them horizontally one next to each other. And I'll take x and y, and return that. Oh, but this needs to be values. And I'm actually going to reshape this to make it 2d as well so that we can do this h stack. And I will return data x, y. So now I should be able to say, okay, get x, y, and take that data frame. And the y label, so my y label is byte count. And actually, so for the x label, I'm actually going to let's just do like one dimension right now. And earlier, I got rid of the plots, but we had seen that maybe, you know, the temperature dimension does really well. And we might be able to use that to predict why. So I'm going to label this also that, you know, it's just using the temperature. And I am also going to do this again for, oh, this should be train. And this should be validation. And this should be a test. Because oh, that's Val. Right. But here, it should be Val. And this should be test. Alright, so we run this and now we have our training validation and test data sets for just the temperature. So if I look at x train temp, it's literally just the temperature. Okay, and I'm doing this first to show you simple linear regression. Alright, so right now I can create a regressor. So I can say the temp regressor here. And then I'm going to, you know, make a linear regression model. And just like before, I can simply fix fit my x train temp, y train temp in order to train train this linear regression model. Alright, and then I can also, I can print this regressor is coefficients and the intercept. So if I do that, okay, this is the coefficient for whatever the temperature is, and then the the x intercept, okay, or the y intercept, sorry. All right. And I can, you know, score, so I can get the the r squared score. So I can score x test and y test. All right, so it's an r squared of around point three eight, which is better than zero, which would mean, hey, there's absolutely no association. But it's also not, you know, like, good, it depends on the context. But, you know, the higher that number, it means the higher that the two variables would be correlated, right? Which here, it's all right. It just means there's maybe some association between the two. But the reason why I want to do this one D was to show you, you know, if we plotted this, this is what it would look like. So if I create a scatterplot, and let's take the training. So this is our data. And then let's make it blue. And then if I also plotted, so something that I can do is say, you know, the x range, I'm going to plot it, is when space, and this goes from negative 20 to 40, this piece of data. So I'm going to just say, let's take 100 things from there. So I'm going to plot x, and I'm going to take this temper, this, like, regressor, and predict x with that. Okay, and this label, I'm going to label that the fit. And this color, let's make this red. And let's actually set the line with, so I can, I can change how thick that value is. Okay. Now at the very end, let's create a legend. And let's, all right, let's also create, you know, title, all these things that matter, in some sense. So here, let's just say, this would be the bikes, versus the temperature, right? And the y label would be number of bikes. And the x label would be the temperature. So I actually think that this might cause an error. Yeah. So it's expecting a 2d array. So we actually have to reshape this. Okay, there we go. So I just had to make this an array and then reshape it. So it was 2d. Now, we see that, all right, this increases. But again, remember those assumptions that we had about linear regression, like this, I don't really know if this fits those assumptions, right? I just wanted to show you guys though, that like, all right, this is what a line of s fit through this data would look like. Okay. Now, we can do multiple linear regression, right. So I'm going to go ahead and do that as well. Now, if I take my data set, and instead of the labels, it's actually what's my current data set right now. Alright, so let's just use all of these except for the byte count, right. So I'm going to just say for the x labels, let's just take the data frames columns and just remove the byte count. So does that work? So if this part should be of x labels is none. And then this should work now. Oops, sorry. Okay, so I have Oh, but this here, because it's not just the temperature anymore, we should actually do this, let's say all, right. So I'm just going to quickly rerun this piece here so that we have our temperature only data set. And now we have our all data set. Okay. And this regressor, I can do the same thing. So I can do the all regressor. And I'm going to make this the linear regression. And I'm going to fit this to x train all and y train all. Okay. Alright, so let's go ahead and also score this regressor. And let's see how the R squared performs now. So if I test this on the test data set, what happens? Alright, so our R square seems to improve it went from point four to point five, two, which is a good sign. Okay. And I can't necessarily plot, you know, every single dimension. But this just this is just to say, okay, this is this is improved, right? Alright, so one cool thing that you can do with tensorflow is you can actually do regression, but with the neural net. So here, I'm going to we already have our our training data for just the temperature and just, you know, for all the different columns. So I'm not going to bother with splitting up the data again, I'm just going to go ahead and start building the model. So in this linear regression model, typically, you know, it does help if we normalize it. So that's very easy to do with tensorflow, I can just create some normalizer layer. So I'm going to do tensorflow Keras layers, and get the normalization layer. And the input shape for that will just be one because let's just do it again on just the temperature and the access I will make none. Now for this temp normalizer, and I should have had an equal sign there. I'm going to adapt this to X train temp, and reshape this to just a single vector. So that should work great. Now with this model, so temp neural net model, what I can do is I can do, you know, dot keras, sequential. And I'm going to pass in this normalizer layer. And then I'm going to say, hey, just give me one single dense layer with one single unit. And what that's doing is saying, all right, well, one single node just means that it's linear. And if you don't add any sort of activation function to it, the output is also linear. So here, I'm going to have tensorflow Keras layers dot dense. And I'm just going to have one unit. And that's going to be my model. Okay. So with this model, let's compile. And for our optimizer, let's use, let's use the atom again, dot atom, and we have to pass in the learning rate. So learning rate, and our learning rate, let's do 0.01. And now, the loss, we actually let's get this one 0.1. And the loss, I'm going to do mean squared error. Okay, so we run that we've compiled it, okay, great. And just like before, we can call history. And I'm going to fit this model. So here, if I call fit, I can just fit it, and I'm going to take the x train with the temperature, but reshape it. Y train for the temperature. And I'm going to set verbose equal to zero so that it doesn't, you know, display stuff. I'm actually going to set epochs equal to, let's do 1000. And the validation data should be let's pass in the validation data set here as a tuple. And I know I spelled that wrong. So let's just run this. And up here, I've copied and pasted the plot loss from our previous but changed the y label to MSC. Because now we're talking we're dealing with mean squared error. And I'm going to plot the loss of this history after it's done. So let's just wait for this to finish training and then to plot. Okay, so this actually looks pretty good. We see that the value is still the same. So this actually looks pretty good. We see that the values are converging. So now what I can do is I'm going to go back up and take this plot. And we are going to just run that plot again. So here, instead of this temperature regressor, I'm going to use the neural net regressor. This neural net model. And if I run that, I can see that, you know, this also gives me a linear regressor, you'll notice that this this fit is not entirely the same as the one up here. And that's due to the training process of, you know, of this neural net. So just two different ways to try and try to find the best linear regressor. Okay, but here we're using back propagation to train a neural net node, whereas in the other one, they probably are not doing that. Okay, they're probably just trying to actually compute the line of s fit. So, okay, given this, well, we can repeat the exact same exercise with our with our multiple linear regressions. Okay, but I'm actually going to skip that part. I will leave that as an exercise to the viewer. Okay, so now what would happen if we use a neural net, a real neural net instead of just, you know, one single node in order to predict this. So let's start on that code, we already have our normalizer. So I'm actually going to take the same setup here. But instead of, you know, this one dense layer, I'm going to set this equal to 32 units. And for my activation, I'm going to use Relu. And now let's duplicate that. And for the final output, I just want one answer. So I just want one cell. And this activation is also going to be Relu, because I can't ever have less than zero bytes. So I'm just going to set that as Relu. I'm just going to name this the neural net model. Okay. And at the bottom, I'm going to have this neural net model. I'm going to have this neural net model, I'm going to compile. And I will actually use the same compiler here. But instead of instead of a learning rate of 0.01, I'll use 0.001. Okay. And I'm going to train this here. So the history is this neural net model. And I'm going to fit that against x train temp, y train temp, and valid validation data, I'm going to set this again equal to x val temp, and y val temp. Now, for the verbose, I'm going to say equal to zero epochs, let's do 100. And here for the batch size, actually, let's just not do a batch size right now. Let's just try it. Let's see what happens here. And again, we can plot the loss of this history after it's done training. So let's just run this. And that's not what we're supposed to get. So what is going on? Here is sequential, we have our temperature normalizer, which I'm wondering now if we have to redo that. Do that. Okay, so we do see this decline, it's an interesting curve, but we do we do see it eventually. So this is our loss, which all right, if decreasing, that's a good sign. And actually, what's interesting is let's just let's plot this model again. So here instead of that. And you'll see that we actually have this like, curve that looks something like this. So actually, what if I got rid of this activation? Let's train this again. And see what happens. Alright, so even even when I got rid of that really at the end, it kind of knows, hey, you know, if it's not the best model, if we had maybe one more layer in here, these are just things that you have to play around with. When you're, you know, working with machine learning, it's like, you don't really know what the best model is going to be. For example, this also is not brilliant. But I guess it's okay. So my point is, though, that with a neural net, I mean, this is not brilliant, but also there's like no data down here, right? So it's kind of hard for our model to predict. In fact, we probably should have started the prediction somewhere around here. My point, though, is that with this neural net model, you can see that this is no longer a linear predictor, but yet we still get an estimate of the value, right? And we can repeat this exact same exercise, right? So let's do that. Right. And we can repeat this exact same exercise with the multiple inputs. So here, if I now pass in all of the data, so this is my all normalizer, and I should just be able to pass in that. So let's move this to the next cell. Here, I'm going to pass in my all normalizer. And let's compile it. Yeah, those parameters look good. Great. So here with the history, when we're trying to fit this model, instead of temp, we're going to use our larger data set with all the features. And let's just train that. And of course, we want to plot the loss. Okay, so that's what our loss looks like. So an interesting curve, but it's decreasing. So before we saw that our R squared score was around point five, two. Well, we don't really have that with a neural net anymore. But one thing that we can measure is hey, what is the mean squared error, right? So if I come down here, and I compare the two mean squared errors, so so I can predict x test all right. So these are my predictions using that linear regressor, will linear multiple multiple linear regressor. So these are my live predictions, linear regression. Okay. I'm actually going to do that at the bottom. So let me just copy and paste that cell and bring it down here. So now I'm going to calculate the mean squared error for both the linear regressor and the neural net. Okay, so this is my linear and this is my neural net. So if I do my neural net model, and I predict x test all, I get my two, you know, different y predictions. And I can calculate the mean squared error, right? So if I want to get the mean squared error, and I have y prediction and y real, I can do numpy dot square, and then I would need the y prediction minus, you know, the real. So this this is basically squaring everything. And this should be a vector. So if I just take this entire thing and take the mean of that, that should give me the MSC. So let's just try that out. And the y real is y test all, right? So that's my mean squared error for the linear regressor. And this is my mean squared error for the neural net. So that's interesting. I will debug this live, I guess. So my guess is that it's probably coming from this normalization layer. Because this input shape is probably just six. And okay, so that works now. And the reason why is because, like, my inputs are only for every vector, it's only a one dimensional vector of length six. So I should have I should have just had six, comma, which is a tuple of size six from the start, or it's a it's a tuple containing one element, which is a six. Okay, so it's actually interesting that my neural net results seem like they they have a larger mean squared error than my linear regressor. One thing that we can look at is, we can actually plot the real versus, you know, the the actual results versus what the predictions are. So if I say, some access, and I use plt dot axes, and make axes and make these equal, then I can scatter the the y, you know, the test. So what the actual values are on the x axis, and then what the prediction are on the x axis. Okay. And I can label this as the linear regression predictions. Okay, so then let me just label my axes. So the x axis, I'm going to say is the true values. The y axis is going to be my linear regression predictions. Or actually, let's plot. Let's just make this predictions. And then at the end, I'm going to plot. Oh, let's set some limits. Because I think that's like approximately the max number of bikes. So I'm going to set my x limit to this and my y limit to this. So here, I'm going to pass that in here too. And all right, this is what we actually get for our linear regressor. You see that actually, they align quite well, I mean, to some extent. So 2000 is probably too much 2500. I mean, looks like maybe like 1800 would be enough here for our limits. And I'm actually going to label something else, the neural net predictions. Let's add a legend. So you can see that our neural net for the larger values, it seems like it's a little bit more spread out. And it seems like we tend to underestimate a little bit down here in this area. Okay. And for some reason, these are way off as well. But yeah, so we've basically used a linear regressor and a neural net. Honestly, there are sometimes where a neural net is more appropriate and a linear regressor is more appropriate. I think that it just comes with time and trying to figure out, you know, and just literally seeing like, hey, what works better, like here, a linear, a multiple linear regressor might actually work better than a neural net. But for example, with the one dimensional case, a linear regressor would never be able to see this curve. Okay. I mean, I'm not saying this is a great model either, but I'm just saying like, hey, you know, sometimes it might be more appropriate to use something that's not linear. So yeah, I will leave regression at that. Okay, so we just talked about supervised learning. And in supervised learning, we have data, we have some a bunch of features and for a bunch of different samples. But each of those samples has some sort of label on it, whether that's a number, a category, a class, etc. Right, we were able to use that label in order to try to predict right, we were able to use that label in order to try to predict new labels of other points that we haven't seen yet. Well, now let's move on to unsupervised learning. So with unsupervised learning, we have a bunch of unlabeled data. And what can we do with that? You know, can we learn anything from this data? So the first algorithm that we're going to discuss is known as k means clustering. What k means clustering is trying to do is it's trying to compute k clusters from the data. So in this example below, I have a bunch of scattered points. And you'll see that this is x zero and x one on the two axes, which means I'm actually plotting two different features, right of each point, but we don't know what the y label is for those points. And now, just looking at these scattered points, we can kind of see how there are different clusters in the data set, right. So depending on what we pick for k, we might have different clusters. Let's say k equals two, right, then we might pick, okay, this seems like it could be one cluster, but this here is also another cluster. So those might be our two different clusters. If we have k equals three, for example, then okay, this seems like it could be a cluster. This seems like it could be a cluster. And maybe this could be a cluster, right. So we could have three different clusters in the data set. Now, this k here is predefined, if I can spell that correctly, by the person who's running the model. So that would be you. All right. And let's discuss how you know, the computer actually goes through and computes the k clusters. So I'm going to write those steps down here. Now, the first step that happens is we actually choose well, the computer chooses three random points on this plot to be the centroids. And by centuries, I just mean the center of the clusters. Okay. So three random points, let's say we're doing k equals three, so we're choosing three random points to be the centroids of the three clusters. If it were two, we'd be choosing two random points. Okay. So maybe the three random points I'm choosing might be here. Here, here, and here. All right. So we have three different points. And the second thing that we do is we actually calculate the distance for each point to those centroids. So between all the points and the centroid. So basically, I'm saying, all right, this is this distance, this distance, this distance, all of these distances, I'm computing between oops, not those two, between the points, not the centroids themselves. So I'm computing the distances for all of these plots to each of the centroids. Okay. And that comes with also assigning those points to the closest centroid. What do I mean by that? So let's take this point here, for example, so I'm computing this distance, this distance, and this distance. And I'm saying, okay, it seems like the red one is the closest. So I'm actually going to put this into the red centroid. So if I do that for all of these points, it seems slightly closer to red, and this one seems slightly closer to red, right? Now for the blue, I actually wouldn't put any blue ones in here, but we would probably actually, that first one is closer to red. And now it seems like the rest of them are probably closer to green. So let's just put all of these into green here, like that. And cool. So now we have, you know, our two, three, technically centroid. So there's this group here, there's this group here. And then blue is kind of just this group here, it hasn't really touched any of the points yet. So the next step, three that we do is we actually go and we recalculate the centroid. So we compute new centroids based on the points that we have in all the centroids. And by that, I just mean, okay, well, let's take the average of all these points. And where is that new centroid? That's probably going to be somewhere around here, right? The blue one, we don't have any points in there. So we won't touch and then the screen one, we can put that probably somewhere over here, oops, somewhere over here. Right. So now if I erase all of the previously computed centroids, I can go and I can actually redo step two over here, this calculation. Alright, so I'm going to go back and I'm going to iterate through everything again, and I'm going to recompute my three centroids. So let's see, we're going to take this red point, these are definitely all red, right? This one still looks a bit red. Now, this part, we actually start getting closer to the blues. So this one still seems closer to a blue than a green, this one as well. And I think the rest would belong to green. Okay, so now our three centroids are three, sorry, our three clusters would be this, this, and then this, right? Those are our three centroids. And so now we go back and we compute the new sorry, those would be the three clusters. So now we go back and we compute the three centroids. So I'm going to get rid of this, this and this. And now where would this red be centered, probably closer, you know, to this point here, this blue might be closer to up here. And then this green would probably be somewhere. It's pretty similar to what we had before. But it seems like it'd be pulled down a bit. So probably somewhere around there for green. All right. And now, again, we go back and we compute the distance between all the points and the centroids. And then we assign them to the closest centroid. Okay. So the reds are all here, it's very clear. Actually, let me just circle that. And this it actually seems like this point is it actually seemed like this point is closer to this blue now. So the blues seem like they would be maybe this point looks like it'd be blue. So all these look like they would be blue now. And the greens would probably be this cluster right here. So we go back, we compute the centroids, bam. This one probably like almost here, bam. And then the green looks like it would be probably here ish. Okay. And now we go back and we compute the we compute the clusters again. So red, still this blue, I would argue is now this cluster here. And green is this cluster here. Okay, so we go and we recompute the centroids, bam, bam. And, you know, bam. And now if I were to go and assign all the points to clusters again, I would get the exact same thing. Right. And so that's when we know that we can stop iterating between steps two and three is when we've converged on some solution when we've reached some stable point. And so now because none of these points are really changing out of their clusters anymore, we can go back to the user and say, Hey, these are our three clusters. Okay. And this process, something known as expectation maximization. This part where we're assigning the points to the closest centroid, this is something this is our expectation step. And this part where we're computing the new centroids, this is our maximization step. Okay, so that's expectation maximization. And we use this in order to compute the centroids, assign all the points to clusters, according to those centroids. And then we're recomputing all that over again, until we reach some stable point where nothing is changing anymore. Alright, so that's our first example of unsupervised learning. And basically, what this is doing is trying to find some structure, some pattern in the data. So if I came up with another point, you know, might be somewhere here, I can say, Oh, it looks like that's closer to if this is a, b, c, it looks like that's closest to cluster B. And so I would probably put it in cluster B. Okay, so we can find some structure in the data based on just how, how the points are scattered relative to one another. Now, the second unsupervised learning technique that I'm going to discuss with you guys, something noted, principal component analysis. And the point of principal component analysis is very often it's used as a dimensionality reduction technique. So let me write that down. It's used for dimensionality reduction. And what do I mean by dimensionality reduction is if I have a bunch of features like x1 x2 x3 x4, etc. Can I just reduce that down to one dimension that gives me the most information about how all these points are spread relative to one another. And that's what PCA is for. So PCA principal component analysis. Let's say I have some points in the x zero and x one feature space. Okay, so these points might be spread, you know, something like this. Okay. So for example, if this were something to do with housing prices, right, this here might be x zero might be hey, years since built, right, since the house was built, and x one might be square footage of the house. Alright, so like years since built, I mean, like right now it's been, you know, 22 years since a house in 2000 was built. Now principal component analysis is just saying, alright, let's say we want to build a model, or let's say we want to, you know, display something about our data, but we don't we don't have two axes to show it on. How do we display, you know, how do we how do we demonstrate that this point is a further away from this point than this point. And we can do that using principal component analysis. So take what you know about linear regression and just forget about it for a second. Otherwise, you might get confused. PCA is a way of trying to find direction in the space with the largest variance. So this principal component, what that means is basically the component. So some direction in this space with the largest variance, okay, it tells us the most about our data set without the two different dimensions. Like, let's say we have these two different mentions, and somebody's telling us, hey, you only get one dimension in order to show your data set. What dimension do you want to show us? Okay, so let's say we want to show our data set, what dimension like what do we do, we want to project our data onto a single dimension. Alright, so that in this case might be a dimension that looks something like this. And you might say, okay, we're not going to talk about linear regression, okay. We don't have a y value. So linear regression, this would be why this is not why, okay, we don't have a label for that. Instead, what we're doing is we're taking the right angle projection. So all of these take that's not very visible. But take this right angle projection onto this line. And what PCA is doing is saying, okay, map all of these points onto this one dimensional space. So the transformed data set would be here. This one's on the data sets are on the line. So we just put that there. But now this would be our new one dimensional data set. Okay, it's not our prediction or anything. This is our new data set. If somebody came to us said you only get one dimension, you only get one number to represent each of these 2d points. What number would you give us? What number would you give us? So this would be our new one dimensional data set. Okay, it's not our prediction or anything. What number would you give me? This would be the number that we gave. Okay, this in this direction, this is where our points are the most spread out. Right? If I took this plot, and let me actually duplicate this so I don't have to rewrite anything. Or so I don't have to erase and then redraw anything. Let me get rid of some of this stuff. And I just got rid of a point there too. So let me draw that back. Alright, so if this were my original data point, what if I had taken, you know, this to be the PCA dimension? Okay, well, I then would have points that let me actually do that in different color. So if I were to draw a right angle to this for every point, my points would look something like this. And so just intuitively looking at these two different plots, this top one and this one, we can see that the points are squished a little bit closer together. Right? Which means that the variance that's not the space with the largest variance. The thing about the largest variance is that this will give us the most discrimination between all of these points. The larger the variance, the further spread out these points will likely be. Now, and so that's the that's the dimension that we should project it on a different way to actually look at that, like what is the dimension with the largest variance. It's actually it also happens to be the dimension that decreases to be the dimension that decreases that minimizes the residuals. So if we take all the points, and we take the residual from that the XY residual, so in linear regression, in linear regression, we were looking only at this residual, the differences between the predictions right between y and y hat, it's not that here in principal component analysis, we're taking the difference from our current point in two dimensional space, and then it's projected point. Okay, so we're taking that dimension. And we're saying, alright, how much, you know, how much distance is there between that projection residual, and we're trying to minimize that for all of these points. So that actually equates to this largest variance dimension, this dimension here, the PCA dimension, you can either look at it as minimizing, minimize, let me get rid of this, the projection residuals. So that's the stuff in orange. Or to maximizing the variance between the points. Okay. And we're not really going to talk about, you know, the method that we need in order to calculate out the principal components, or like what that projection would be, because you will need to understand linear algebra for that, especially eigenvectors and eigenvalues, which I'm not going to cover in this class. But that's how you would find the principal components. Okay, now, with this two dimensional data set here, sorry, this one dimensional data set, we started from a 2d data set, and we now boil it down to one dimension. Well, we can go and take that dimension, and we can do other things with it. Right, we can, like if there were a y label, then we can now show x versus y, rather than x zero and x one in different plots with that y. Now we can just say, oh, this is a principal component. And we're going to plot that with the y. Or for example, if there were 100 different dimensions, and you only wanted to take five of them, well, you could go and you could find the top five PCA dimensions. And that might be a lot more useful to you than 100 different feature vector values. Right. So that's principal component analysis. Again, we're taking, you know, certain data that's unlabeled, and we're trying to make some sort of estimation, like some guess about its structure from that original data set, if we wanted to take, you know, a 3d thing, so like a sphere, but we only have a 2d surface to draw it on. Well, what's the best approximation that we can make? Oh, it's a circle. Right PCA is kind of the same thing. It's saying if we have something with all these different dimensions, but we can't show all of them, how do we boil it down to just one dimension? How do we extract the most information from that multiple dimensions? And that is exactly either you minimize the projection residuals, or you maximize the variance. And that is PCA. So we'll go through an example of that. Now, finally, let's move on to implementing the unsupervised learning part of this class. Here, again, I'm on the UCI machine learning repository. And I have a seeds data set where, you know, I have a bunch of kernels that belong to three different types of wheat. So there's comma, Rosa and Canadian. And the different features that we have access to are, you know, geometric parameters of those wheat kernels. So the area perimeter, compactness, length, width, width, asymmetry, and the length of the kernel groove. Okay, so all of these are real values, which is easy to work with. And what we're going to do is we're going to try to predict, or I guess we're going to try to cluster the different varieties of the wheat. So let's get started. I have a colab notebook open again. Oh, you're gonna have to, you know, go to the data folder, download this. And so I'm going to go to the data folder, download this, and let's get started. So the first thing to do is to import our seeds data set into our colab notebook. So I've done that here. Okay, and then we're going to import all the classics again, so pandas. And then I'm also going to import seedborn because I'm going to want that for this specific class. Okay. Great. So now our columns that we have in our seed data set are the area, the perimeter, the compactness, the length, with asymmetry, groove, length, I mean, I'm just going to call it groove. And then the class, right, the wheat kernels class. So now we have to import this, I'm going to do that using pandas read CSV. And it's called seeds data.csv. So I'm going to turn that into a data frame. And the names are equal to the columns over here. So what happens if I just do that? Oops, what did I call this seeds data set text? Alright, so if we actually look at our data frame right now, you'll notice something funky. Okay. And here, you know, we have all the stuff under area. And these are all our numbers with some dash t. So the reason is because we haven't actually told pandas what the separator is, which we can do like this. And this t that's just a tab. So in order to ensure that like all whitespace gets recognized as a separator, we can actually this is for like a space. So any spaces are going to get recognized as data separators. So if I run that, now our this, you know, this is a lot better. Okay. Okay. So now let's actually go and like visualize this data. So what I'm actually going to do is plot each of these against one another. So in this case, pretend that we don't have access to the class, right? Pretend that so this class here, I'm just going to show you in this example, that like, hey, we can predict our classes using unsupervised learning. But for this example, in unsupervised learning, we don't actually have access to the class. So I'm going to just try to plot these against one another and see what happens. So for some I in range, you know, the columns minus one because the classes in the columns. And I'm just going to say for j in range, so take everything from I onwards, you know, so I like the next thing after I until the end of this. So this will give us basically a grid of all the different like combinations. And our x label is going to be columns I our y label is going to be the columns j. So those are our labels up here. And I'm going to use seaborne this time. And I'm going to say scatter my data. So our x is going to be our x label. Or y is going to be our y label. And our data is going to be the data frame that we're passing in. So what's interesting here is that we can say hue. And what this will do is say, like if I give this class, it's going to separate the three different classes into three different hues. So now what we're doing is we're basically comparing the area and the perimeter or the area and the compactness. But we're going to visualize, you know, what classes they're in. So let's go ahead and I might have to show. So great. So basically, we can see perimeter and area we give we get these three groups. The area compactness, we get these three groups, and so on. So these all kind of look honestly like somewhat similar. Right, so Wow, look at this one. So this one, we have the compactness and the asymmetry. And it looks like there's not really I mean, it just looks like they're blobs, right? Sure, maybe class three is over here more, but one and two kind of look like they're on top of each other. Okay. I mean, there are some that might look slightly better in terms of clustering. But let's go through some of the some of the clustering examples that we talked about, and try to implement those. The first thing that we're going to do is just straight up clustering. So what we learned about was k means clustering. So from SK learn, I'm going to import k means. Okay. And just for the sake of being able to run, you know, any x and any y, I'm just going to say, hey, let's use some x. What's a good one, maybe. I mean, perimeter asymmetry could be a good one. So x could be perimeter, y could be asymmetry. Okay. And for this, the x values, I'm going to just extract those specific values. Alright, well, let's make a k means algorithm, or let's, you know, define this. So k means, and in this specific case, we know that the number of clusters is three. So let's just use that. And I'm going to fit this against this x that I've just defined right here. Right. So, you know, if I create this clusters, so one thing, one cool thing is I can actually go to this clusters, and I can say k mean dot labels. And it'll give give me if I can type correctly, it'll give me what its predictions for all the clusters are. And our actual, oops, not that. If we go to the data frame, and we get the class, and the values from those, we can actually compare these two and say, hey, like, you know, everything in general, most of the zeros that it's predicted, are the ones, right. And in general, the twos are the twos here. And then this third class one, okay, that corresponds to three. Now remember, these are separate classes. So the labels, what we actually call them don't really matter. We can say a map zero to one map two to two and map one to three. Okay, and our, you know, our mapping would do fairly well. But we can actually visualize this. And in order to do that, I'm going to create this cluster cluster data frame. So I'm going to create a data frame. And I'm going to pass in a horizontally stacked array with x, so my values for x and y. And then the clusters that I have here, but I'm going to reshape them. So it's 2d. Okay. And the columns, the labels for that are going to be x, y, and plus. Okay. So I'm going to go ahead and do that same seaborne scatter plot. Again, where x is x, y is y. And now, the hue is again the class. And the data is now this cluster data frame. Alright, so this here, this here is my k means like, I guess classes. So k means kind of looks like this. If I come down here and I plot, you know, my original data frame, this is my original classes with respect to this specific x and y. And you'll see that, honestly, like it doesn't do too poorly. Yeah, there's I mean, the colors are different, but that's fine. For the most part, it gets information of the clusters, right. And now we can do that with higher dimensions. So with the higher dimensions, if we make x equal to, you know, all the columns, except for the last one, which is our class, we can do the exact same thing. We can do the exact same thing. So here, and we can predict this. But now, our columns are equal to our data frame columns all the way to the last one. And then with this class, actually, so we can literally just say data frame columns. And we can fit all of this. And now, if I want to plot the k means classes. Alright, so this was my that's my clustered and my original. So actually, let me see if I can get these on the same page. So yeah, I mean, pretty similar to what we just saw. But what's actually really cool is even something like, you know, if we change. So what's one of them where they were like on top of each other? Okay, so compactness and asymmetry, this one's messy. Right. So if I come down here, and I say compactness and asymmetry, and I'm trying to do this in 2d, this is what my scatterplot. So this is what you know, my k means is telling me for these two dimensions for compactness and asymmetry, if we just look at those two, these are our three classes, right? And we know that the original looks something like this. And are these two remotely alike? No. Okay, so now if I come back down here, and I rerun this higher dimensions one, but actually, this clusters, I need to get the labels of the k means again. Okay, so if I rerun this with higher dimensions, well, if we zoom out, and we take a look at these two, sure, the colors are mixed up. But in general, there are the three groups are there, right? This does a much better job at assessing, okay, what group is what. So, for example, we could relabel the one in the original class to two. And then we could make sorry, okay, this is kind of confusing. But for example, if this light pink were projected onto this darker pink here, and then this dark one was actually the light pink, and this light one was this dark one, then you kind of see like these correspond to one another, right? Like even these two up here are the same class as all the other ones over here, which are the same in the same color. So you don't want to compare the two colors between the plots, you want to compare which points are in what colors in each of the plots. So that's one cool application. So this is how k means functions, it's basically taking all the data sets and saying, All right, where are my clusters given these pieces of data? And then the next thing that we talked about is PCA. So PCA, we're reducing the dimension, but we're mapping all these like, you know, seven dimensions. I don't know if there are seven, I made that number up, but we're mapping multiple dimensions into a lower dimension number. Right. And so let's see how that works. So from SK learn decomposition, I can import PCA and that will be my PCA model. So if I do PCA component, so this is how many dimensions you want to map it into. And you know, for this exercise, let's do two. Okay, so now I'm taking the top two dimensions. And my transformed x is going to be PCA dot fit transform, and the same x that I had up here. And the same x that I had up here. Okay, so all the other all the values basically, area, perimeter, compactness, length, width, asymmetry, groove. Okay. So let's run that. And we've transformed it. So let's look at what the shape of x used to be. So they're okay. So seven was right, I had 210 samples, each seven, seven features long, basically. And now my transformed x is 210 samples, but only of length two, which means that I only have two dimensions now that I'm plotting. And we can actually even take a look at, you know, the first five things. Okay, so now we see each each one is a two dimensional point, each sample is now a two dimensional point in our new in our new dimensions. So what's cool is I can actually scatter these zero and transformed x. So I actually have to take the columns here. And if I show that, basically, we've just taken this like seven dimensional thing, and we've made it into a single or I guess to a two dimensional representation. So that's a point of PCA. And actually, let's go ahead and do the same clustering exercise as we did up here. If I take the k means this PCA data frame, I can let's construct data frame out of that. And the data frame is going to be H stack. I'm going to take this transformed x and the clusters that reshape. So actually, instead of clusters, I'm going to use k means dot labels. And I need to reshape this. So it's 2d. So we can do the H stack. And for the columns, I'm going to set this to PCA one PCA two, and the class. All right. So now if I take this, I can also do the same for the truth. But instead of the k means labels, I want from the data frame the original classes. And I'm just going to take the values from that. And so now I have a data frame for the k means with PCA and then a data frame for the truth with also the PCA. And I can now plot these similarly to how I plotted these up here. So let me actually take these two. Instead of the cluster data frame, I want the this is the k means PCA data frame. This is still going to be class, but now x and y are going to be the two PCA dimensions. Okay. So these are my two PCA dimensions. And you can see that the data frame is going to be the same as the cluster data frame. So these are my two PCA dimensions. And you can see that, you know, they're, they're pretty spread out. And then here, I'm going to go to my truth classes. Again, it's PCA one PCA two, but instead of k means this should be truth PCA data frame. So you can see that like in the truth data frame along these two dimensions, we actually are doing fairly well in terms of separation, right? It does seem like this is slightly more separable than the other like dimensions that we had been looking at up here. So that's a good sign. And up here, you can see that hey, some of these correspond to one another. I mean, for the most part, our algorithm or unsupervised clustering algorithm is able to to give us is able to spit out, you know, what the proper labels are. I mean, if you map these specific labels to the different types of kernels. But for example, this one might all be the comma kernel kernels and same here. And then these might all be the Canadian kernels. And these might all be the Canadian kernels. So it does struggle a little bit with, you know, where they overlap. But for the most part, our algorithm is able to find the three different categories, and do a fairly good job at predicting them without without any information from us, we haven't given our algorithm any labels. So that's a gist of unsupervised learning. I hope you guys enjoyed this course. I hope you know, a lot of these examples made sense. If there are certain things that I have done, and you know, you're somebody with more experience than me, please let me know in the comments and we can all as a community learn from this together. So thank you all for watching."
    },
    {
        "id": "1f45ffd9-24f7-4cfd-a133-27fe543d5799",
        "type": "video",
        "domaine": "technology",
        "titre": "PyTorch for Deep Learning & Machine Learning – Full Course",
        "url": "https://www.youtube.com/watch?v=V_xro1bcAuA",
        "description": "Learn PyTorch for deep learning in this comprehensive course for beginners. PyTorch is a ",
        "chaine": "freeCodeCamp.org",
        "durée": "25:37:26",
        "keywords": [
            "data set",
            "Google Colab",
            "data",
            "model",
            "test data set",
            "data sets",
            "data dot data",
            "test data",
            "torch dot",
            "training data set"
        ],
        "transcription": "This comprehensive course will teach you the foundations of machine learning and deep learning using PyTorch. PyTorch is a machine learning framework written in Python. You'll learn machine learning by writing PyTorch code. So when in doubt, run the provided code and experiment. Your teacher for this course is Daniel Bourke. Daniel is a machine learning engineer and popular course creator. So enjoy the course and don't watch the whole thing in one sitting. Hello, welcome to the video. It's quite a big one. But if you've come here to learn machine learning and deep learning and PyTorch code, well, you're in the right place. Now, this video and tutorial is focused for beginners who have got about three to six months of Python coding experience. So we're going to cover a whole bunch of important machine learning concepts by writing PyTorch code. Now, if you get stuck, you can leave a comment below or post on the course GitHub discussions page. And on GitHub is where you'll be able to find all the materials that we cover, as well as on learn pytorch.io. There's an online readable book version of this course there. But if you finish this video and you find that, hey, I would still like to learn more PyTorch. I mean, you can't really cover all the PyTorch in a day that video titles just apply on words of the length of video. That's an aside. There is five more chapters available at learn pytorch.io, covering everything from transfer learning to model deployment to experiment tracking. And all the videos to go with those are available at zero to mastery.io. But that's enough for me. Having machine learning and I'll see you inside. Hello, my name is Daniel and welcome to the deep learning with PyTorch course. Now, that was too good not to watch twice. Welcome to the deep learning with cools at fire PyTorch course. So this is very exciting. Are you going to see that animation quite a bit because, I mean, it's fun and PyTorch's symbol is a flame because of torch. But let's get into it. So naturally, if you've come to this course, you might have already researched what is deep learning, but we're going to cover it quite briefly. And just in the sense of how much you need to know for this course, because we're going to be more focused on, rather than just definitions, we're going to be focused on getting practical and seeing things happen. So if we define what machine learning is, because as we'll see in a second, deep learning is a subset of machine learning. Machine learning is turning things data, which can be almost anything, images, text, tables of numbers, video, audio files, almost anything can be classified as data into numbers. So computers love numbers, and then finding patterns in those numbers. Now, how do we find those patterns? Well, the computer does this part specifically a machine learning algorithm or a deep learning algorithm of things that we're going to be building in this course. How? Code and math. Now, this course is code focused. I want to stress that before you get into it. We're focused on writing code. Now, behind the scenes, that code is going to trigger some math to find patterns in those numbers. If you would like to deep dive into the math behind the code, I'm going to be linking extra resources for that. However, we're going to be getting hands on and writing lots of code to do lots of this. And so if we keep going to break things down a little bit more, machine learning versus deep learning, if we have this giant bubble here of artificial intelligence, you might have seen something similar like this on the internet. I've just copied that and put it into pretty colors for this course. So you've got this overarching big bubble of the topic of artificial intelligence, which you could define as, again, almost anything you want. Then typically, there's a subset within artificial intelligence, which is known as machine learning, which is quite a broad topic. And then within machine learning, you have another topic called deep learning. And so that's what we're going to be focused on working with PyTorch, writing deep learning code. But again, you could use PyTorch for a lot of different machine learning things. And truth be told, I kind of use these two terms interchangeably. Yes, ML is the broader topic and deep learning is a bit more nuanced. But again, if you want to form your own definitions of these, I'd highly encourage you to do so. This course is more focused on, rather than defining what things are, is seeing how they work. So this is what we're focused on doing. Just to break things down, if you're familiar with the fundamentals of machine learning, you probably understand this paradigm, but we're going to just rehash on it anyway. So if we consider traditional programming, let's say you'd like to write a computer program that's enabled to, or has the ability to reproduce your grandmother's favorite or famous roast chicken dish. And so we might have some inputs here, which are some beautiful vegetables, a chicken that you've raised on the farm. You might write down some rules. This could be your program, cut the vegetables, season the chicken, preheat the oven, cook the chicken for 30 minutes and add vegetables. Now, it might not be this simple, or it might actually be because your Sicilian grandmother is a great cook. So she's put things into an art now and can just do it step by step. And then those inputs combined with those rules makes this beautiful roast chicken dish. So that's traditional programming. Now, a machine learning algorithm typically takes some inputs and some desired outputs and then figures out the rules. So the patterns between the inputs and the outputs. So where in traditional program, we had to hand write all of these rules, the ideal machine learning algorithm will figure out this bridge between our inputs and our idealized output. Now, in the machine learning sense, this is typically described as supervised learning, because you will have some kind of input with some kind of output, also known as features, and also known as labels. And the machine learning algorithm's job is to figure out the relationships between the inputs or the features and the outputs or the label. So if we wanted to write a machine learning algorithm to figure out our Sicilian grandmother's famous roast chicken dish, we would probably gather a bunch of inputs of ingredients such as these delicious vegetables and chicken, and then have a whole bunch of outputs of the finished product and see if our algorithm can figure out what we should do to go from these inputs to output. So that's almost enough to cover of the difference between traditional programming and machine learning as far as definitions go. We're going to get hands on encoding these sort of algorithms throughout the course. For now, let's go to the next video and ask the question, why use machine learning or deep learning? And actually, before we get there, I'd like you to think about that. So going back to what we just saw, the paradigm between traditional programming and machine learning, why would you want to use machine learning algorithms rather than traditional programming? So if you had to write all these rules, could that get cumbersome? So have a think about it and we'll cover it in the next video. Welcome back. So in the last video, we covered briefly the difference between traditional programming and machine learning. And again, I don't want to spend too much time on definitions. I'd rather you see this in practice. And I left you with the question, why would you want to use machine learning or deep learning? Well, let's think of a good reason. Why not? I mean, if we had to write all those handwritten rules to reproduce Alsace and grandmother's roast chicken dish all the time, that would be quite cumbersome, right? Well, let's draw a line on that. Why not? What's a better reason? And kind of what we just said, right? For a complex problem, can you think of all the rules? So let's imagine we're trying to build a self-driving car. Now, if you've learned to drive, you've probably done so in maybe 20 hours, 100 hours. But now, I'll give you a task of writing down every single rule about driving. How do you back out of your driveway? How do you turn left and go down the street? How do you park a reverse park? How do you stop at an intersection? How do you know how fast to go somewhere? So we just listed half a dozen rules. But you could probably go a fair few more. You might get into the thousands. And so for a complex problem, such as driving, can you think of all the rules? Well, probably not. So that's where machine learning and deep learning come in to help. And so this is a beautiful comment I like to share with you on one of my YouTube videos is my 2020 machine learning roadmap. And this is from Yashawing. I'm probably going to mispronounce this if I even try to. But Yashawing says, I think you can use ML. So ML is machine learning. I'm going to use that a lot throughout the course, by the way. ML is machine learning, just so you know. For literally anything, as long as you can convert it into numbers, ah, that's what we said before, machine learning is turning something into computer readable numbers. And then programming it to find patterns, except with a machine learning algorithm, typically we write the algorithm and it finds the patterns, not us. And so literally it could be anything, any input or output from the universe. That's pretty darn cool about machine learning, right? But should you always use it just because it could be used for anything? Well, I'd like to also introduce you to Google's number one rule of machine learning. Now, if you can build a simple rule based system such as the step of five rules that we had to map the ingredients to our Sicilian grandmothers roast chicken dish, if you can write just five steps to do that, that's going to work every time, well, you should probably do that. So if you can build a simple rule based system that doesn't require machine learning, do that. And of course, maybe it's not so very simple, but maybe you can just write some rules to solve the problem that you're working on. And this is from a wise software engineer, which is, I kind of hinted at it before, rule one of Google's machine learning handbook. Now, I'm going to highly recommend you read through that, but we're not going to go through that in this video. So check that out. You can Google that otherwise the links will be where you get links. So just keep that in mind, although machine learning is very powerful and very fun and very excited, it doesn't mean that you should always use it. I know this is quite the thing to be saying at the start of a deep learning machine learning course, but I just want you to keep in mind, simple rule based systems are still good. Machine learning isn't a solve all for everything. Now, let's have a look at what deep learning is good for, but I'm going to leave you on a clip hammock because we're going to check this out in the next video. See you soon. In the last video, we familiarized ourselves with Google's number one rule of machine learning, which is basically if you don't need it, don't use it. And with that in mind, what should we actually be looking to use machine learning or deep learning for? Well, problems with long lists of rules. So when the traditional approach fails to remember the traditional approach is you have some sort of data input, you write a list of rules for that data to be manipulated in some way, shape, or form, and then you have the outputs that you know. But if you have a long, long list of rules, like the rules of driving a car, which could be hundreds, could be thousands, could be millions, who knows, that's where machine learning and deep learning may help. And it kind of is at the moment in the world of self-driving cars, machine learning and deep learning are the state of the art approach. Continually changing environments. So whatever the benefits of deep learning is that it can keep learning if it needs to. And so it can adapt and learn to new scenarios. So if you update the data that your model was trained on, it can adjust to new different kinds of data in the future. So similarly to if you are driving a car, you might know your own neighborhood very well. But then when you go to somewhere you haven't been before, sure you can draw on the foundations of what you know, but you're going to have to adapt. How fast should you go? Where should you stop? Where should you park? These kinds of things. So with problems with long lists of rules, or continually changing environments, or if you had a large, large data set. And so this is where deep learning is flourishing in the world of technology. So let's give an example. One of my favorites is the food 101 data set, which you can search for online, which is images of 101 different kinds of foods. Now we briefly looked at what a rule list might look like for cooking your grandmother's famous Sicilian roast chicken dish. But can you imagine if you wanted to build an app that could take photos of different food, how long your list of rules would be to differentiate 101 different foods? It'd be so long. You need rule sets for every single one. Let's just take one food, for example. How do you write a program to tell what a banana looks like? I mean you'd have to code what a banana looks like, but not only a banana, what everything that isn't a banana looks like. So keep this in mind. What deep learning is good for? Problems with long lists of rules, continually changing environments, or discovering insights within large collections of data. Now, what deep learning is not good for? And I'm going to write typically here because, again, this is problem specific. Deep learning is quite powerful these days and things might change in the future. So keep an open mind, if there's anything about this course, it's not for me to tell you exactly what's what. It's for me to spark a curiosity into you to figure out what's what, or even better yet, what's not what. So when you need explainability, as we'll see, the patterns learned by a deep learning model, which is lots of numbers, called weights and biases, we'll have a look at that later on, are typically uninterpretable by a human. So some of the times deep learning models can have a million, 10 million, 100 million, a billion, some models are getting into the trillions of parameters. When I say parameters, I mean numbers or patterns in data. Remember, machine learning is turning things into numbers and then writing a machine learning model to find patterns in those numbers. So sometimes those patterns themselves can be lists of numbers that are in the millions. And so can you imagine looking at a list of numbers that has a million different things going on? That's going to be quite hard. I find it hard to understand three or four numbers, let alone a million. And when the traditional approach is a better option, again, this is Google's rule number one of machine learning. If you can do what you need to do with a simple rule based system, well, maybe you don't need to use machine learning or deep learning. Again, I'm going to use the deep learning machine learning terms interchangeably. I'm not too concerned with definitions. You can form your own definitions, but just so you know, from my perspective, ML and deep learning are quite similar. When arrows are unacceptable. So since the outputs of a deep learning model aren't always predictable, we'll see that deep learning models are probabilistic. That means they're when they predict something, they're making a probabilistic bet on it. Whereas in a rule based system, you kind of know what the outputs are going to be every single time. So if you can't have errors based on probabilistic errors, well, then you probably shouldn't use deep learning and you'd like to go back to a simple rule based system. And then finally, when you don't have much data, so deep learning models usually require a fairly large amount of data to produce great results. However, there's a caveat here, you know, at the start, I said typically, we're going to see some techniques of how to get great results without huge amounts of data. And again, I wrote typically here because there are techniques, you can just research deep learning explainability. You're going to find a whole bunch of stuff. You can look up examples of when machine learning versus deep learning. And then when arrows are unacceptable, again, there are ways to make your model reproducible. So it predicts you know what's going to come out. So we do a lot of testing to verify this as well. And so what's next? Ah, we've got machine learning versus deep learning, and we're going to have a look at some different problem spaces in a second, and mainly breaking down in terms of what kind of data you have. Not going to do this now prevent this video from getting too long. We'll cover all these colorful beautiful pictures in the next video. Welcome back. So in the last video, we covered a few things of what deep learning is good for and what deep learning is typically not good for. So let's dive in to a little more of a comparison of machine learning versus deep learning. Again, I'm going to be using these terms quite interchangeably. But there are some specific things that typically you want traditional style of machine learning techniques versus deep learning. However, this is constantly changing. So again, I'm not talking in absolutes here. I'm more just talking in general. And I'll leave it to you to use your own curiosity to research the specific differences between these two. But typically, for machine learning, like the traditional style of algorithms, although they are still machine learning algorithms, which is kind of a little bit confusing where deep learning and machine learning differ is you want to use traditional machine learning algorithms on structured data. So if you have tables of numbers, this is what I mean by structured rows and columns, structured data. And possibly one of the best algorithms for this type of data is a gradient boosted machine, such as xg boost. This is an algorithm that you'll see in a lot of data science competitions, and also used in production settings. When I say production settings, I mean, applications that you may interact with on the internet, or use on a day to day. So that's production. xg boost is typically the favorite algorithm for these kinds of situations. So again, if you have structured data, you might look into xg boost rather than building a deep learning algorithm. But again, the rules aren't set in stone. That's where deep learning and machine learning is kind of an art kind of a science is that sometimes xg boost is the best for structured data, but there might be exceptions to the rule. But for deep learning, it is typically better for unstructured data. And what I mean by that is data that's kind of all over the place. It's not in your nice, standardized rows and columns. So say you had natural language such as this tweet by this person, whose name is quite similar to mine, and has the same Twitter account as me. Oh, maybe I wrote that. How do I learn machine learning? What you need to hear? Learn Python, learn math, start probability, software engineering, build. What you need to do? Google it, go down the rabbit hole, resurfacing six to nine months, and ring assess. I like that. Or if you had a whole bunch of texts such as the definition for deep learning on Wikipedia, again, this is the reason why I'm not covering as many definitions in this course is because look how simple you can look these things up. Wikipedia is going to be able to define deep learning far better than what I can. I'm more focused on just getting involved in working hands on with this stuff than defining what it is. And then we have images. If we wanted to build a burger, take a photo app thing, you would work with image data, which doesn't really have much of a structure. Although we'll see that there are ways for deep learning that we can turn this kind of data to have some sort of structure through the beauty of a tensor. And then we might have audio files such as if you were talking to your voice assistant. I'm not going to say one because a whole bunch of my devices might go crazy if I say the name of my voice assistant, which rhymes with I'm not even going to say that out loud. And so typically, for unstructured data, you'll want to use a neural network of some kind. So structured data, gradient boosted machine, or a random forest, or a tree based algorithm, such as extra boost, and unstructured data, neural networks. So let's keep going. Let's have a look at some of the common algorithms that you might use for structured data, machine learning versus unstructured data, deep learning. So random forest is one of my favorites, gradient boosted models, native base nearest neighbor, support vector machine, SVM, and then many more. But since the advent of deep learning, these are often referred to as shallow algorithms. So deep learning, why is it called deep learning? Well, as we'll see is that it can have many different layers of algorithm, you might have an input layer, 100 layers in the middle, and then an output layer. But we'll get hands on with this later on. And so common algorithms for deep learning and neural networks, fully connected neural network, convolutional neural network, recurrent neural network, transformers have taken over over the past couple years, and of course, many more. And the beautiful thing about deep learning and neural networks is is almost as many problems that it can be applied to is as many different ways that you can construct them. So this is why I'm putting all these dot points on the page. And I can understand if you haven't had much experience of machine learning or deep learning, this can be a whole bunch of information overload. But good news is what we're going to be focused on building with PyTorch is neural networks, fully connected neural networks and convolutional neural networks, the foundation of deep learning. But the excellent thing is, the exciting thing is, is that if we learn these foundational building blocks, we can get into these other styles of things here. And again, part art, part science of machine learning and deep learning is depending on how you represent your problem, depending on what your problem is, many of the algorithms here and here can be used for both. So I know I've just kind of bedazzled you and saying that, Oh, well, you kind of use these ones for deep learning, you kind of use these ones for machine learning. But depending on what your problem is, you can also use both. So that's a little bit of confusion to machine learning. But that's a fun part about it too, is use your curiosity to figure out what's best for whatever you're working on. And with all this talk about neural networks, how about in the next video, we cover what are neural networks. Now, I'd like you to Google this before we watch the next video, because it's going to be hundreds of definitions of what they are. And I'd like you to start forming your own definition of what a neural network is. I'll see you in the next video. Welcome back. In the last video, I left you with the cliffhanger of a question. What are neural networks? And I gave you the challenge of Googling that, but you might have already done that by the time you've got here. Let's just do that together. If I type in what are neural networks, I've already done this. What are neural networks? Explain neural networks, neural network definition. There are hundreds of definitions of things like this online neural network in five minutes. Three blue one brown. I'd highly recommend that channel series on neural networks. That's going to be in the extracurricular stat quest is also amazing. So there's hundreds of different definitions on here, and you can read 10 of them, five of them, three of them, make your own definition. But for the sake of this course, here's how I'm going to find neural networks. So we have some data of whatever it is. We might have images of food. We might have tweets or natural language, and we might have speech. So these are some examples of inputs for unstructured data, because they're not rows and columns. So these are the input data that we have. And then how do we use them with a neural network? Well, before data can be used in a neural network, it needs to be turned into numbers, because humans, we like looking at images of Raman and spaghetti. We know that that's Raman. We know that that's spaghetti after we've seen it one or two times. And we like reading good tweets, and we like listening to amazing music or hearing our friend talk on the phone in audio file. However, before a computer understands what's going on in these inputs, it needs to turn them into numbers. So this is what I call a numerical encoding or a representation. And this numerical encoding, these square brackets indicate that it's part of a matrix or a tensor, which we're going to get very hands on with throughout this course. So we have our inputs, we've turned it into numbers, and then we pass it through a neural network. And now this is a graphic for a neural network. However, the graphics for neural networks, as we'll see, can get quite involved. But they all represent the same fundamentals. So if we go to this one, for example, we have an input layer, then we have multiple hidden layers. However, you define this, you can design these and how you want. Then we have an output layer. So our inputs will go in some kind of data. The hidden layers will perform mathematical operations on the input. So the numbers, and then we'll have an output. Oh, there's three blue one brown neural networks from the ground up. Great video. Highly recommend you check that out. But then if we come back to this, so we've got our inputs, we've turned it into numbers. And we've got our neural networks that we put the input in. This is typically the input layer, hidden layer. This can be as many different layers as you want, as many different, each of these little dots is called a node. There's a lot of information here, but we're going to get hands-on with seeing what this looks like. And then we have some kind of output. Now, which neural network should you use? Well, you can choose the appropriate neural network for your problem, which could involve you hand coding each one of these steps. Or you could find one that has worked on problems similar to your own, such as for images, you might use a CNN, which is a convolutional neural network. For natural language, you might use a transformer. For speech, you might also use a transformer. But fundamentally, they all follow the same principle of inputs, manipulation, outputs. And so the neural network will learn a representation on its own. We want to find what it learns. So it's going to manipulate these patterns in some way, shape, or form. And when I say learns representation, I'm going to also refer to it as learns patterns in the data. A lot of people refer to it as features. A feature may be the fact that the word do comes out to how, usually, in across a whole bunch of different languages. A feature can be almost anything you want. And again, we don't define this. The neural network learns these representations, patterns, features, also called weights on its own. And then where do we go from there? Well, we've got some sort of numbers, numerical encoding turned our data into numbers. Our neural network has learned a representation that it thinks best represents the patterns in our data. And then it outputs those representation outputs, which we can use. And often you'll hear this referred to as features or weight matrix or weight tensor. Learned representation is also another common one. There's a lot of different terms for these things. And then it will output. We can convert these outputs into human understandable outputs. So if we were to look at these, this could be, again, I said representations or patterns that are neural network learns can be millions of numbers. This is only nine. So imagine if these were millions of different numbers, I can barely understand the nine numbers that is going on here. So we need a way to convert these into human understandable terms. So for this example, we might have some input data, which are images of food. And then we want our neural network to learn the representations between an image of ramen and an image of spaghetti. And then eventually we'll take those patterns that it's learned and we'll convert them into whether it thinks that this is an image of ramen or spaghetti. Or in the case of this tweet, is this a tweet for a natural disaster or not a natural disaster? So our neural network has, well, we've written code to turn this into numbers. Pass it through our neural network. Our neural network has learned some kind of patterns. And then we ideally want it to represent this tweet as not a disaster. And then we can write code to do each of these steps here. And the same thing for these inputs going as speech, turning into something that you might say to your smart speaker, which I'm not going to say because a whole bunch of my devices might go off. And so let's cover the anatomy of neural networks. We've hinted at this a little bit already. But this is like neural network anatomy 101. Again, this is highly customizable what this thing actually is. We're going to see it in PyTorch code later on. But the data goes into the input layer. And in this case, the number of units slash neurons slash nodes is two hidden layers. You can have, I put a s here because you can have one hidden layer, or the deep in deep learning comes from having lots of layers. So this is only showing four layers. You might have, well, this is three layers as well. It might be very deep neural networks such as ResNet 152. This is 152 different layers. So again, you can, or this is 34, because this is only ResNet 34. But ResNet 152 has 152 different layers. So that's a common computer vision or a popular computer vision algorithm, by the way. Lots of terms we're throwing out here. But with time, you'll start to become familiar with them. So hidden layers can be almost as many as you want. We've only got pictured one here. And in this case, there's three hidden units slash neurons. And then we have an output layer. So the outputs learned representation or prediction probabilities from here, depending on how we set it up, which again, we will see what these are later on. And in this case, it has one hidden unit. So two input, three, one output, you can customize the number of these, you can customize how many layers there are, you can customize what goes into here, you can customize what goes out of there. So now, if we talk about the overall architecture, which is describing all of the layers combined. So that's, when you hear neural network architecture, it talks about the input, the hidden layers, which may be more than one, and the output layer. So that's a terminology for overall architecture. Now, I say patterns is an arbitrary term. You can hear embedding embedding might come from hidden layers, weights, feature representation, feature vectors, all referring to similar things. So, again, how do we turn our data into some numerical form, build a neural network to figure out patterns to output some desired output that we want. And now to get more technical, each layer is usually a combination of linear, so straight lines, and nonlinear, non-straight functions. So what I mean by that is a linear function is a straight line, a nonlinear function is a non-straight line. If I asked you to draw whatever you want with unlimited straight lines and not straight lines, so you can use straight lines or curved lines, what kind of patterns could you draw? At a fundamental level, that is basically what a neural network is doing. It's using a combination of linear, straight lines, and not straight lines to draw patterns in our data. We'll see what this looks like later on. Now, from the next video, let's dive in briefly to different kinds of learning. So we've looked at what a neural network is, the overall algorithm, but there are also different paradigms of how a neural network learns. I'll see you in the next video. Welcome back. We've discussed a brief overview of an anatomy of what a neural network is, but let's now discuss some learning paradigms. So the first one is supervised learning, and then we have unsupervised and self-supervised learning, and transfer learning. Now supervised learning is when you have data and labels, such as in the example we gave at the start, which was how you would build a neural network or a machine learning algorithm to figure out the rules to cook your Sicilian grandmother's famous roast chicken dish. So in the case of supervised learning, you'd have a lot of data, so inputs, such as raw ingredients as vegetables and chicken, and a lot of examples of what that inputs should ideally look like. Or in the case of discerning photos between a cat and a dog, you might have a thousand photos of a cat and a thousand photos of a dog that you know which photos are cat and which photos are dog, and you pass those photos to a machine learning algorithm to discern. So in that case, you have data, the photos, and the labels, aka cat and dog, for each of those photos. So that's supervised learning, data and labels. Unsupervised and self-supervised learning is you just have the data itself. You don't have any labels. So in the case of cat and dog photos, you only have the photos. You don't have the labels of cat and dog. So in the case of self-supervised learning, you could get a machine learning algorithm to learn an inherent representation of what, and when I say representation, I mean patterns and numbers, I mean weights, I mean features, a whole bunch of different names describing the same thing. You could get a self-supervised learning algorithm to figure out the fundamental patterns between a dog and a cat image, but it wouldn't necessarily know the difference between the two. That's where you could come in later and go show me the patterns you've learned, and it might show you the patterns and you could go, okay, the patterns that look like this, a dog and the patterns that look like that, a cat. So self-supervised and unsupervised learning learn solely on the data itself. And then finally, transfer learning is a very, very important paradigm in deep learning. It's taking the patterns that one model has learned of a data set and transferring it to another model, such in the case of if we were trying to build a supervised learning algorithm for discerning between cat and dog photos. We might start with a model that has already learned patterns and images and transfer those foundational patterns to our own model so that our model gets a head start. This is transfer learning is a very, very powerful technique, but as for this course, we're going to be writing code to focus on these two supervised learning and transfer learning, which are two of the most common paradigms or common types of learning in machine learning and deep learning. However, this style of code though can be adapted across different learning paradigms. Now, I just want to let you know there is one that I haven't mentioned here, which is kind of in its own bucket, and that is reinforcement learning. So I'll leave this as an extension if you wanted to look it up. But essentially, this is a good one. That's a good photo, actually. So shout out to Katie Nuggets. The whole idea of reinforcement learning is that you have some kind of environment and an agent that does actions in that environment, and you give rewards and observations back to that agent. So say, for example, you wanted to teach your dog to urinate outside. Well, you would reward its actions of urinating outside and possibly not reward its actions of urinating all over your couch. So reinforcement learning is again, it's kind of in its own paradigm. This picture has a good explanation between unsupervised learning, supervised learning to separate two different things, and then reinforcement learning is kind of like that. But again, I will let you research the different learning paradigms a little bit more in your own time. As I said, we're going to be focused on writing code to do supervised learning and transfer learning, specifically pytorch code. Now with that covered, let's get a few examples of what is deep learning actually used for. And before we get into the next video, I'm going to issue you a challenge to search this question yourself and come up with some of your own ideas for what deep learning is currently used for. So give that a shot and I'll see you in the next video. How'd you go? Did you do some research? Did you find out what deep learning is actually used for? I bet you found a treasure trail of things. And hey, I mean, if you're reading this course, chances are that you probably already know some use cases for deep learning. You're like, Daniel, hurry up and get to the code. Well, we're going to get there, don't you worry? But let's have a look at some things that deep learning can be used for. But before, I just want to remind you of this comment. This is from Yasha Sway on the 2020 machine learning roadmap video. I think you can use ML and remember, ML is machine learning. And remember, deep learning is a part of ML for literally anything as long as you can convert it into numbers and program it to find patterns. Literally, it could be anything, any input or output from the universe. So that's a beautiful thing about machine learning is that if you can encode it something into numbers, chances are you can build a machine learning algorithm to find patterns in those numbers. Will it work? Well, again, that's the reason machine learning and deep learning is part art, part science. A scientist would love to know that their experiments would work. But an artist is kind of excited about the fact that, I don't know, this might work, it might not. And so that's something to keep in mind. Along with the rule number one of machine learning is if you don't need it, you don't use it. But if you do use it, it can be used for almost anything. And let's get a little bit specific and find out some deep learning use cases. And I've put some up there for a reason because there are lots. These are just some that I interact with in my day to day life, such as recommendation, we've got a programming video, we've got a programming podcast, we got some jujitsu videos, we've got some RuneScape videos, a soundtrack from my favorite movie. Have you noticed, whenever you go to YouTube, you don't really search for things anymore. Well, sometimes you might, but the recommendation page is pretty darn good. That's all powered by deep learning. And in the last 10 years, have you noticed that translation has got pretty good too? Well, that's powered by deep learning as well. Now, I don't have much hands on experience with this. I did use it when I was in Japan. I speak a very little amount of Japanese and even smaller amount of Mandarin. But if I wanted to translate deep learning as epic to Spanish, it might come out as el aprendise, profando es ebiko. Now, all of the native Spanish speakers watching this video can laugh at me because that was a very Australian version of saying deep learning is epic in Spanish. But that's so cool. All the Google Translate is now powered by deep learning. And the beautiful thing, if I couldn't say it myself, I could click this speaker and it would say it for me. So that speech recognition that's powered by deep learning. So if you were to ask your voice assistant who's the biggest big dog of them all, of course, they're going to say you, which is what I've set up, my voice assistant to say. That's part of speech recognition. And in computer vision, oh, look at this. You see this? Where is this photo from? This photo is from this person driving this car. Did a hit and run on my car, at the front of my house, my apartment building, my car was parked on the street, this car, the trailer came off, ran into the back of my car, basically destroyed it, and then they drove off. However, my next door neighbors security camera picked up on this car. Now, I became a detective for a week, and I thought, hmm, if there was a computer vision algorithm built into that camera, it could have detected when the car hit. I mean, it took a lot of searching to find it, it turns out the car hit about 3.30am in the morning. So it's pitch black. And of course, we didn't get the license plate. So this person is out there somewhere in the world after doing a hit and run. So if you're watching this video, just remember computer vision might catch you one day. So this is called object detection, where you would place a box around the area where the pixels most represent the object that you're looking for. So for computer vision, we could train an object detector to capture cars that drive past a certain camera. And then if someone does a hit and run on you, you could capture it. And then fingers crossed, it's not too dark that you can read the license plate and go, hey, excuse me, please, this person has hit my car and wrecked it. So that's a very close to home story of where computer vision could be used. And then finally, natural language processing. Have you noticed as well, your spam detector on your email inbox is pretty darn good? Well, some are powered by deep learning, some not, it's hard to tell these days what is powered by deep learning, what isn't. But natural language processing is the process of looking at natural language text. So unstructured text. So whatever you'd write an email in a story in a Wikipedia document and deciding or getting your algorithm to find patterns in that. So for this example, you would find that this email is not spam. This deep learning course is incredible. I can't wait to use what I've learned. Thank you so much. And by the way, that is my real email. So if you want to email me, you can. And then this is spam. Hey, Daniel, congratulations, you win a lot of money. Wow, I really like that a lot of money. But somebody said, I don't think that this is real. So that would probably go to my spam inbox. Now, with that being said, if we wanted to put these problems in a little bit more of a classification, this is known as sequence to sequence because you put one sequence in and get one sequence out. Same as this, you have a sequence of audio waves and you get some text out. So sequence to sequence, sec to sec. This is classification slash regression. In this case, the regression is predicting a number. That's what a regression problem is. You would predict the coordinates of where these box corners should be. So say this should be at however many pixels in from the X angle and however many pixels down from the Y angle, that's that corner. And then you would draw in between the corners. And then the classification part would go, Hey, this is that car that did a hit and run on us. And in this case, this is classification. Classification is predicting whether something is one thing or another, or perhaps more than one thing or another in the class of multi class classification. So this email is not spam. That's a class and this email is spam. So that's also a class. So I think we've only got one direction to go now that we've sort of laid the foundation for the course. And that is Well, let's start talking about PyTorch. I'll see you in the next video. Well, let's now cover some of the foundations of PyTorch. But first, you might be asking, what is PyTorch? Well, of course, we could just go to our friend, the internet, and look up PyTorch.org. This is the homepage for PyTorch. This course is not a replacement for everything on this homepage. This should be your ground truth for everything PyTorch. So you can get started. You've got a big ecosystem. You've got a way to set up on your local computer. You've got resources. You've got docs. PyTorch. You've got the GitHub. You've got search. You've got blog, everything here. This website should be the place you're visiting most throughout this course as we're writing PyTorch code. You're coming here. You're reading about it. You're checking things out. You're looking at examples. But for the sake of this course, let's break PyTorch down. Oh, there's a little flame animation I just forgot about. What is PyTorch? I didn't sync up the animations. That's all right. So PyTorch is the most popular research deep learning framework. I'll get to that in a second. It allows you to write fast deep learning code in Python. If you know Python, it's a very user-friendly programming language. PyTorch allows us to write state-of-the-art deep learning code accelerated by GPUs with Python. It enables you access to many pre-built deep learning models from Torch Hub, which is a website that has lots of, if you remember, I said transfer learning is a way that we can use other deep learning models to power our own. Torch Hub is a resource for that. Same as Torch Vision.Models. We'll be looking at this throughout the course. It provides an ecosystem for the whole stack of machine learning. From pre-processing data, getting your data into tenses, what if you started with some images? How do you represent them as numbers? Then you can build models such as neural networks to model that data. Then you can even deploy your model in your application slash cloud, well, deploy your PyTorch model. Application slash cloud will be depending on what sort of application slash cloud that you're using, but generally it will run some kind of PyTorch model. And it was originally designed and used in-house by Facebook slash meta. I'm pretty sure Facebook have renamed themselves meta now, but it is now open source and used by companies such as Tesla, Microsoft and OpenAI. And when I say it is the most popular deep learning research framework, don't take my word for it. Let's have a look at papers with code dot com slash trends. If you're not sure what papers with code is, it is a website that tracks the latest and greatest machine learning papers and whether or not they have code. So we have some other languages here, other deep learning frameworks, PyTorch, TensorFlow, Jax is another one, MXNet, paddle paddle, the original torch. So PyTorch is an evolution of torch written in Python, CAF2, Mindspore. But if we look at this, when is this? Last date is December 2021. We have, oh, this is going to move every time I move it. No. So I'll highlight PyTorch at 58% there. So by far and large, the most popular research machine learning framework used to write the code for state of the art machine learning algorithms. So this is browse state of the art papers with code.com amazing website. We have semantic segmentation, image classification, object detection, image generation, computer vision, natural language processing, medical, I'll let you explore this. It's one of my favorite resources for staying up to date on the field. But as you see, out of the 65,000 papers with code that this website is tracked, 58% of them are implemented with PyTorch. How cool is that? And this is what we're learning. So let's jump into there. Why PyTorch? Well, other than the reasons that we just spoke about, it's a research favorite. This is highlighting. There we go. So there we go. I've highlighted it here. PyTorch, 58%, nearly 2,500 repos. If you're not sure what a repo is, a repo is a place where you store all of your code online. And generally, if a paper gets published in machine learning, if it's fantastic research, it will come with code, code that you can access and use for your own applications or your own research. Again, why PyTorch? Well, this is a tweet from Francois Chale, who's the author of Keras, which is another popular deep learning framework. But with tools like Colab, we're going to see what Colab is in a second, Keras and TensorFlow. I've added in here and PyTorch. Virtually anyone can solve in a day with no initial investment problems that would have required an engineering team working for a quarter and $20,000 in hardware in 2014. So this is just to highlight how good the space of deep learning and machine learning tooling has become. Colab, Keras and TensorFlow are all fantastic. And now PyTorch is added to this list. If you want to check that out, there's Francois Chale on Twitter. Very, very prominent voice in the machine learning field. Why PyTorch? If you want some more reasons, well, have a look at this. Look at all the places that are using PyTorch. It's just coming up everywhere. We've got Andre Kapathi here, who's the director of AI at Tesla. So if we go, we could search this, PyTorch at Tesla. We've got a YouTube talk there, Andre Kapathi, director of AI at Tesla. And so Tesla are using PyTorch for the computer vision models of autopilot. So if we go to videos or maybe images, does it come up there? Things like this, a car detecting what's going on in the scene. Of course, there'll be some other code for planning, but I'll let you research that. When we come back here, OpenAI, which is one of the biggest open artificial intelligence research firms, open in the sense that they publish a lot of their research methodologies, however, recently there's been some debate about that. But if you go to openai.com, let's just say that they're one of the biggest AI research entities in the world, and they've standardized on PyTorch. So they've got a great blog, they've got great research, and now they've got OpenAI API, which is, you can use their API to access some of the models that they've trained. Presumably with PyTorch, because this blog post from January 2020 says that OpenAI is now standardized across PyTorch. There's a repo called the incredible PyTorch, which collects a whole bunch of different projects that are built on top of PyTorch. That's the beauty of PyTorch is that you can build on top of it, you can build with it AI for AG, for agriculture. PyTorch has been used. Let's have a look. PyTorch in agriculture. There we go. Agricultural robots use PyTorch. This is a medium article. It's everywhere. So if we go down here, this is using object detection. Beautiful. Object detection to detect what kind of weeds should be sprayed with fertilizer. This is just one of many different things, so PyTorch on a big tractor like this. It can be used almost anywhere. If we come back, PyTorch builds the future of AI and machine learning at Facebook, so Facebook, which is also MetaAI, a little bit confusing, even though it says MetaAI, it's on AI.facebook.com. That may change by the time you watch this. They use PyTorch in-house for all of their machine learning applications. Microsoft is huge in the PyTorch game. It's absolutely everywhere. So if that's not enough reason to use PyTorch, well, then maybe you're in the wrong course. So you've seen enough reasons of why to use PyTorch. I'm going to give you one more. That is that it helps you run your code, your machine learning code accelerated on a GPU. We've covered this briefly, but what is a GPU slash a TPU, because this is more of a newer chip these days. A GPU is a graphics processing unit, which is essentially very fast at crunching numbers. Originally designed for video games, if you've ever designed or played a video game, you know that the graphics are quite intense, especially these days. And so to render those graphics, you need to do a lot of numerical calculations. And so the beautiful thing about PyTorch is that it enables you to leverage a GPU through an interface called CUDA, which is a lot of words I'm going to throw out you here, a lot of acronyms in the deep learning space, CUDA. Let's just search CUDA. CUDA toolkit. So CUDA is a parallel computing platform and application programming interface, which is an API that allows software to use certain types of graphics processing units for general purpose computing. That's what we want. So PyTorch leverages CUDA to enable you to run your machine learning code on NVIDIA GPUs. Now, there is also an ability to run your PyTorch code on TPUs, which is a tensor processing unit. However, GPUs are far more popular when running various types of PyTorch code. So we're going to focus on running our PyTorch code on the GPU. And to just give you a quick example, PyTorch on TPU, let's see that. Getting started with PyTorch on cloud TPUs, there's plenty of guys for that. But as I said, GPUs are going to be far more common in practice. So that's what we're going to focus on. And with that said, we've said tensor processing unit. Now, the reason why these are called tensor processing units is because machine learning and deep learning deals a lot with tensors. And so in the next video, let's answer the question, what is a tensor? But before I go through and answer that from my perspective, I'd like you to research this question. So open up Google or your favorite search engine and type in what is a tensor and see what you find. I'll see you in the next video. Welcome back. In the last video, I left you on the cliffhanger question of what is a tensor? And I also issued you the challenge to research what is a tensor. Because as I said, this course isn't all about telling you exactly what things are. It's more so sparking a curiosity in you so that you can stumble upon the answers to these things yourself. But let's have a look. What is a tensor? Now, if you remember this graphic, there's a lot going on here. But this is our neural network. We have some kind of input, some kind of numerical encoding. Now, we start with this data. In our case, it's unstructured data because we have some images here, some text here, and some audio file here. Now, these necessarily don't go in all at the same time. This image could just focus on a neural network specifically for images. This text could focus on a neural network specifically for text. And this sound bite or speech could focus on a neural network specifically for speech. However, the field is sort of also moving towards building neural networks that are capable of handling all three types of inputs. For now, we're going to start small and then build up the algorithms that we're going to focus on are neural networks that focus on one type of data. But the premise is still the same. You have some kind of input. You have to numerically encode it in some form, pass it to a neural network to learn representations or patterns within that numerical encoding, output some form of representation. And then we can convert that representation into things that humans understand. And you might have already seen these, and I might have already referenced the fact that these are tensors. So when the question comes up, what are tensors? A tensor could be almost anything. It could be almost any representation of numbers. We're going to get very hands on with tensors. And that's actually the fundamental building block of PyTorch aside from neural network components is the torch dot tensor. We're going to see that very shortly. But this is a very important takeaway is that you have some sort of input data. You're going to numerically encode that data, turn it into a tensor of some kind. Whatever that kind is will depend on the problem you're working with. Then you're going to pass it to a neural network, which will perform mathematical operations on that tensor. Now, a lot of those mathematical operations are taken care of by PyTorch behind the scenes. So we'll be writing code to execute some kind of mathematical operations on these tensors. And then the neural network that we create, or the one that's already been created, but we just use for our problem, we'll output another tensor, similar to the input, but has been manipulated in a certain way that we've sort of programmed it to. And then we can take this output tensor and change it into something that a human can understand. So to remove a lot of the text around it, make it a little bit more clearer. If we were focusing on building an image classification model, so we want to classify whether this was a photo of Raman or spaghetti, we would have images as input. We would turn those images into numbers, which are represented by a tensor. We would pass that tensor of numbers to a neural network, or there might be lots of tensors here. We might have 10,000 images. We might have a million images. Or in some cases, if you're Google or Facebook, you might be working with 300 million or a billion images at a time. The principle still stands that you encode your data in some form of numerical representation, which is a tensor, pass that tensor, or lots of tensors to a neural network. The neural network performs mathematical operations on those tensors, outputs a tensor, we convert that tensor into something that we can understand as humans. And so with that being said, we've covered a lot of the fundamentals. What is machine learning? What is deep learning? What is neural network? Well, we've touched the surface of these things. You can get as deep as you like. We've covered why use PyTorch. What is PyTorch? Now, the fundamental building block of deep learning is tensors. We've covered that. Let's get a bit more specific in the next video of what we're going to cover code-wise in this first module. I'm so excited we're going to start codes in. I'll see you in the next video. Now it's time to get specific about what we're going to cover code-wise in this fundamentals module. But I just want to reiterate the fact that going back to the last video where I challenge you to look up what is a tensor, here's exactly what I would do. I would come to Google. I would type in the question, what is a tensor? There we go. What is a tensor in PyTorch? It knows Google knows that using that deep learning data that we want to know what a tensor is in PyTorch. But a tensor is a very general thing. It's not associated with just PyTorch. Now we've got tensor on Wikipedia. We've got tensor. This is probably my favorite video on what is a tensor. By Dan Flesch. Flesch, I'm probably saying that wrong, but good first name. This is going to be your extra curriculum for this video and the previous video is to watch this on what is a tensor. Now you might be saying, well, what gives? I've come to this course to learn PyTorch and all this guy's doing, all you're doing, Daniel, is just Googling things when a question comes up. Why don't you just tell me what it is? Well, if I was to tell you everything about deep learning and machine learning and PyTorch and what it is and what it's not, that course would be far too long. I'm doing this on purpose. I'm searching questions like this on purpose because that's exactly what I do day to day as a machine learning engineer. I write code like we're about to do. And then if I don't know something, I literally go to whatever search engine I'm using, Google most of the time, and type in whatever error I'm getting or PyTorch, what is a tensor, something like that. So I want to not only tell you that it's okay to search questions like that, but it's encouraged. So just keep that in mind as we go through the whole course, you're going to see me do it a lot. Let's get into what we're going to cover. Here we go. Now, this tweet is from Elon Musk. And so I've decided, you know what, let's base the whole course on this tweet. We have learning MLDL from university, you have a little bit of a small brain. Online courses, well, like this one, that brain's starting to explode and you get some little fireworks from YouTube. Oh, you're watching this on YouTube. Look at that shiny brain from articles. My goodness. Lucky that this course comes in article format. If you go to learn pytorch.io, all of the course materials are in online book format. So we're going to get into this fundamental section very shortly. But if you want a reference, the course materials are built off this book. And by the time you watch this, there's going to be more chapters here. So we're covering all the bases here. And then finally, from memes, you would ascend to some godlike creature. I think that's hovering underwater. So that is the best way to learn machine learning. So this is what we're going to start with MLDL from university online courses, YouTube from articles from memes. No, no, no, no. But kind of here is what we're going to cover broadly. So now in this module, we are going to cover the pytorch basics and fundamentals, mainly dealing with tensors and tensor operations. Remember, a neural network is all about input tensors, performing operations on those tensors, creating output operations. Later, we're going to be focused on pre-processing data, getting it into tensors, so turning data from raw form, images, whatever, into a numerical encoding, which is a tensor. Then we're going to look at building and using pre-trained deep learning models, specifically neural networks. We're going to fit a model to the data. So we're going to show our model or write code for our model to learn patterns in the data that we've pre-processed. We're going to see how we can make predictions with our model, because that's what deep learning and machine learning is all about, right, using patterns from the past to predict the future. And then we're going to evaluate our model's predictions. We're going to learn how to save and load our models. For example, if you wanted to export your model from where we're working to an application or something like that. And then finally, we're going to see how we can use a trained model to make predictions on our own data on custom data, which is very fun. And how? Well, you can see that the scientist has faded out a little bit, but that's not really that true. We're going to do it like cooks, not chemists. So chemists are quite precise. Everything has to be exactly how it is. But cooks are more like, oh, you know what, a little bit of salt, a little bit of butter. Does it taste good? Okay, well, then we're on. But machine learning is a little bit of both. It's a little bit of science, a little bit of art. That's how we're going to do it. But I like the idea of this being a machine learning cooking show. So welcome to cooking with machine learning, cooking with PyTorch with Daniel. And finally, we've got a workflow here, which we have a PyTorch workflow, which is one of many. We're going to kind of use this throughout the entire course is step one, we're going to get our data ready. Step two, we're going to build a pick a pre trained model to suit whatever problem we're working on. Step two point one, pick a loss function and optimizer. Don't worry about what they are. We're going to cover them soon. Step two point two, build a training loop. Now this is kind of all part of the parcel of step two, hence why we've got two point one and two point two. You'll see what that means later on. Number three, we're going to fit the model to the data and make a prediction. So say we're working on image classification for Raman or spaghetti. How do we build a neural network or put our images through that neural network to get some sort of idea of what's in an image? We'll see how to do that. Well, the value weight our model to see if it's predicting BS or it's actually going all right. Number five, we're going to improve through experimentation. That's another big thing that you'll notice throughout machine learning throughout this course is that it's very experimental part art, part science. Number six, save and reload your trained model. Again, I put these with numerical order, but they can kind of be mixed and matched depending on where you are in the journey. But numerical order is just easy to understand for now. Now we've got one more video, maybe another one before we get into code. But in the next video, I'm going to cover some very, very important points on how you should approach this course. I'll see you there. Now you might be asking, how should I approach this course? You might not be asking, but we're going to answer it anyway. How to approach this course? This is how I would recommend approaching this course. So I'm a machine learning engineer day to day and learning machine learning to coding machine learning, a kind of two different things. I remember when I first learned it was kind of, you learned a lot of theory rather than writing code. So not to take away from the theory of being important, this course is going to be focusing on writing machine learning specifically PyTorch code. So the number one step to approaching this course is to code along. Now because this course is focused on purely writing code, I will be linking extracurricular resources for you to learn more about what's going on behind the scenes of the code. My idea of teaching is that if we can code together, write some code, see how it's working, that's going to spark your curiosity to figure out what's going on behind the scenes. So motto number one is if and out, run the code, write it, run the code, see what happens. Number two, I love that. Explore an experiment again. Approach this with the idea, the mind of a scientist and a chef or science and art. Experiment, experiment, experiment. Try things with rigor like a scientist would, and then just try things for the fun of it like a chef would. Number three, visualize what you don't understand. I can't emphasize this one enough. We have three models so far. If and out, run the code, you're going to hear me say this a lot. Experiment, experiment, experiment. And number three, visualize, visualize, visualize. Why is this? Well, because we've spoken about machine learning and deep learning deals with a lot of data, a lot of numbers. And so I find it that if I visualize some numbers in whatever form that isn't just numbers all over a page, I tend to understand it better. And there are some great extracurricular resources that I'm going to link that also turn what we're doing. So writing code into fantastic visualizations. Number four, ask questions, including the dumb questions. Really, there's no such thing as a dumb question. Everyone is just on a different part of their learning journey. And in fact, if you do have a quote unquote dumb question, it turns out that a lot of people probably have that one as well. So be sure to ask questions. I'm going to link a resource in a minute of where you can ask those questions, but please, please, please ask questions, not only to the community, but to Google to the internet to wherever you can, or just yourself. Ask questions of the code and write code to figure out the answer to those questions. Number five, do the exercises. There are some great exercises that I've created for each of the modules. If we go, have we got the book version of the course up here? We do. Within all of these chapters here, down the bottom is going to be exercises and extra curriculum. So we've got some exercises. I'm not going to jump into them, but I would highly recommend don't just follow along with the course and code after I code. Please, please, please give the exercises a go because that's going to stretch your knowledge. We're going to have a lot of practice writing code together, doing all of this stuff here. But then the exercises are going to give you a chance to practice what you've learned. And then of course, extra curriculum. Well, hey, if you want to learn more, there's plenty of opportunities to do so there. And then finally, number six, share your work. I can't emphasize enough how much writing about learning deep learning or sharing my work through GitHub or different code resources or with the community has helped with my learning. So if you learn something cool about PyTorch, I'd love to see it. Link it to me somehow in the Discord chat or on GitHub or whatever. There'll be links of where you can find me. I'd love to see it. Please do share your work. It's a great way to not only learn something because when you share it, when you write about it, it's like, how would someone else understand it? But it's also a great way to help others learn too. And so we said how to approach this course. Now, let's go how not to approach this course. I would love for you to avoid overthinking the process. And this is your brain, and this is your brain on fire. So avoid having your brain on fire. That's not a good place to be. We are working with PyTorch, so it's going to be quite hot. Just playing on words with the name torch. But avoid your brain catching on fire. And avoid saying, I can't learn, I've said this to myself lots of times, and then I've practiced it and it turns out I can actually learn those things. So let's just draw a red line on there. Oh, I think a red line. Yeah, there we go. Nice and thick red line. We'll get that out there. It doesn't really make sense now that this says avoid and crossed out. But don't say I can't learn and prevent your brain from catching on fire. Finally, we've got one more video that I'm going to cover before this one gets too long of the resources for the course before we get into coding. I'll see you there. Now, there are some fundamental resources that I would like you to be aware of before we go any further in this course. These are going to be paramount to what we're working with. So for this course, there are three things. There is the GitHub repo. So if we click this link, I've got a pinned on my browser. So you might want to do the same while you're going through the course. But this is Mr. D. Burks in my GitHub slash PyTorch deep learning. It is still a work in progress at the time of recording this video. But by the time you go through it, it won't look too much different, but there just be more materials. You'll have materials outline, section, what does it cover? As you can see, some more are coming soon at the time of recording this. So these will probably be done by the time you watch this exercise in extra curriculum. There'll be links here. Basically, everything you need for the course will be in the GitHub repo. And then if we come back, also on the GitHub repo, the same repo. So Mr. D. Burks slash PyTorch deep learning. If you click on discussions, this is going to be the Q and A. This is just the same link here, the Q and A for the course. So if you have a question here, you can click new discussion, you can go Q and A, and then type in video, and then the title PyTorch Fundamentals, and then go in here. Or you could type in your error as well. What is N-DIM for a tensor? And then in here, you can type in some stuff here. Hello. I'm having trouble on video X, Y, Z. Put in the name of the video. So that way I can, or someone else can help you out. And then code, you can go three back ticks, write Python, and then you can go import torch, torch dot rand n, which is going to create a tensor. We're going to see this in a second. Yeah, yeah, yeah. And then if you post that question, the formatting of the code is very helpful that we can understand what's going on, and what's going on here. So this is basically the outline of how I would ask a question video. This is going on. What is such and such for whatever's going on? Hello. This is what I'm having trouble with. Here's the code, and here's what's happening. You could even include the error message, and then you can just click start discussion, and then someone, either myself or someone else from the course will be able to help out there. And the beautiful thing about this is that it's all in one place. You can start to search it. There's nothing here yet because the course isn't out yet, but as you go through it, there will probably be more and more stuff here. Then if you have any issues with the code that you think needs fixed, you can also open a new issue there. I'll let you read more into what's going on. I've just got some issues here already about the fact that I need to record videos for the course. I need to create some stuff. But if you think there's something that could be improved, make an issue. If you have a question about the course, ask a discussion. And then if we come back to the keynote, we have one more resource. So that was the course materials all live in the GitHub. The course Q&A is on the course GitHub's discussions tab, and then the course online book. Now, this is a work of art. This is quite beautiful. It is some code to automatically turn all of the materials from the GitHub. So if we come into here code, if we click on notebook zero zero, this is going to sometimes if you've ever worked with Jupiter notebooks on GitHub, they can take a while to load. So all of the materials here automatically get converted into this book. So the beautiful thing about the book is that it's got different headings here. It's all readable. It's all online. It's going to have all the images there. And you can also search some stuff here, PyTorch training steps, creating a training loop in PyTorch. Beautiful. We're going to see this later on. So they're the three big materials that you need to be aware of, the three big resources for this specific course materials on GitHub course Q&A course online book, which is learn pytorch.io, simple URL to remember, all the materials will be there. And then specifically for PyTorch or things PyTorch, the PyTorch website and the PyTorch forums. So if you have a question that's not course related, but more PyTorch related, I'd highly recommend you go to the PyTorch forums, which is available at discuss.pytorch.org. We've got a link there. Then the PyTorch website, PyTorch.org, this is going to be your home ground for everything PyTorch of course. We have the documentation here. And as I said, this course is not a replacement for getting familiar with the PyTorch documentation. This, the course actually is built off all of the PyTorch documentation. It's just organized in a slightly different way. So there's plenty of amazing resources here on everything to do with PyTorch. This is your home ground. And you're going to see me referring to this a lot throughout the course. So just keep these in mind, course materials on GitHub, course discussions, learnpytorch.io. This is all for the course. And all things PyTorch specific, so not necessarily this course, but just PyTorch in general, the PyTorch website and the PyTorch forums. With that all being said, we've come so far. We've covered a lot already, but guess what time it is? Let's write some code. I'll see you in the next video. We've covered enough of the fundamentals so far. Well, from a theory point of view, let's get into coding. So I'm going to go over to Google Chrome. I'm going to introduce you to the tool. One of the main tools we're going to be using for the entire course. And that is Google Colab. So the way I would suggest following along with this course is remember, one of the major ones is to code along. So we're going to go to colab.research.google. I've got a typo here. Classic. You're going to see me do lots of typos throughout this course. Colab.research.google.com. This is going to load up Google Colab. Now, you can follow along with what I'm going to do, but if you'd like to find out how to use Google Colab from a top-down perspective, you can go through some of these. I'd probably recommend going through overview of Collaboratory Features. But essentially, what Google Colab is going to enable us to do is create a new notebook. And this is how we're going to practice writing PyTorch code. So if you refer to the reference document of learnpytorch.io, these are actually Colab notebooks just in book format, so online book format. So these are the basis materials for what the course is going to be. There's going to be more here, but every new module, we're going to start a new notebook. And I'm going to just zoom in here. So this one, the first module is going to be zero, zero, because Python code starts at zero, zero. And we're going to call this PyTorch Fundamentals. I'm going to call mine video, just so we know that this is the notebook that I wrote through the video. And what this is going to do is if we click Connect, it's going to give us a space to write Python code. So here we can go print. Hello, I'm excited to learn PyTorch. And then if we hit shift and enter, it comes out like that. But another beautiful benefit of Google Colab are PS. I'm using the pro version, which costs about $10 a month or so. That price may be different depending on where you're from. The reason I'm doing that is because I use Colab all the time. However, you do not have to use the paid version for this course. Google Colab comes with a free version, which you'll be able to use to complete this course. If you see it worthwhile, I find the pro version is worthwhile. Another benefit of Google Colab is if we go here, we can go to runtime. Let me just show you that again. Runtime, change runtime type, hardware accelerator. And we can choose to run our code on an accelerator here. Now we've got GPU and TPU. We're going to be focused on using GPU. If you'd like to look into TPU, I'll leave that to you. But we can click GPU, click save. And now our code, if we write it in such a way, will run on the GPU. Now we're going to see this later on code that runs on the GPU is a lot faster in terms of compute time, especially for deep learning. So if we write here in a video SMI, we now have access to a GPU. In my case, I have a Tesla P100. It's quite a good GPU. You tend to get the better GPUs. If you pay for Google Colab, if you don't pay for it, you get the free version, you get a free GPU. It just won't be as fast as the GPUs you typically get with the paid version. So just keep that in mind. A whole bunch of stuff that we can do here. I'm not going to go through it all because there's too much. But we've covered basically what we need to cover. So if we just come up here, I'm going to write a text cell. So oo dot pytorch fundamentals. And I'm going to link in here resource notebook. Now you can come to learn pytorch.io and all the notebooks are going to be in sync. So 00, we can put this in here. Resource notebook is there. That's what this notebook is going to be based off. This one here. And then if you have a question about what's going on in this notebook, you can come to the course GitHub. And then we go back, back. This is where you can see what's going on. This is pytorch deep learning projects as you can see what's happening. At the moment, I've got pytorch course creation because I'm in the middle of creating it. But if you have a question, you can come to Mr. D Burke slash pytorch deep learning slash discussions, which is this tab here, and then ask a question by clicking new discussion. So any discussions related to this notebook, you can ask it there. And I'm going to turn this right now. This is a code cell. CoLab is basically comprised of code and text cells. I'm going to turn this into a text cell by pressing command mm, shift and enter. Now we have a text cell. And then if we wanted another code cell, we could go like that text code text code, yada, yada, yada. But I'm going to delete this. And to finish off this video, we're going to import pytorch. So we're going to import torch. And then we're going to print torch dot dot version. So that's another beautiful thing about Google Colab is that it comes with pytorch pre installed and a lot of other common Python data science packages, such as we could also go import pandas as PD, import NumPy as MP import mapplot lib lib dot pyplot as PLT. This is Google Colab is by far the easiest way to get started with this course. You can run things locally. If you'd like to do that, I'd refer to you to pytorch deep learning is going to be set up dot MD, getting set up to code pytorch. We've just gone through number one setting up with Google Colab. There is also another option for getting started locally. Right now, this document's a work in progress, but it'll be finished by the time you watch this video. This is not a replacement, though, for the pytorch documentation for getting set up locally. So if you'd like to run locally on your machine, rather than going on Google Colab, please refer to this documentation or set up dot MD here. But if you'd like to get started as soon as possible, I'd highly recommend you using Google Colab. In fact, the entire course is going to be able to be run through Google Colab. So let's finish off this video, make sure we've got pytorch ready to go. And of course, some fundamental data science packages here. Wonderful. This means that we have pytorch 1.10.0. So if your version number is far greater than this, maybe you're watching this video a couple of years in the future, and pytorch is up to 2.11, maybe some of the code in this notebook won't work. But 1.10.0 should be more than enough for what we're going to do. And plus Q111, CU111, stands for CUDA version 11.1, I believe. And what that would mean is if we came in here, and we wanted to install it on Linux, which is what Colab runs on, there's Mac and Windows as well. We've got CUDA. Yeah. So right now, as of recording this video, the latest pytorch build is 1.10.2. So you'll need at least pytorch 1.10 to complete this course and CUDA 11.3. So that's CUDA toolkit. If you remember, CUDA toolkit is NVIDIA's programming. There we go. NVIDIA developer. CUDA is what enables us to run our pytorch code on NVIDIA GPUs, which we have access to in Google Colab. Beautiful. So we're set up ready to write code. Let's get started in the next video writing some pytorch code. This is so exciting. I'll see you there. So we've got set up. We've got access to pytorch. We've got a Google Colab instance running here. We've got a GPU because we've gone up to runtime, change runtime type, hardware accelerator. You won't necessarily need a GPU for this entire notebook, but I just wanted to show you how to get access to a GPU because we're going to be using them later on. So let's get rid of this. And one last thing, how I'd recommend going through this course is in a split window fashion. So for example, you might have the video where I'm talking right now and writing code on the left side, and then you might have another window over the other side with your own Colab window. And you can go new notebook, call it whatever you want, my notebook. You could call it very similar to what we're writing here. And then if I write code over on this side, on this video, you can't copy it, of course, but you'll write the same code here and then go on and go on and go on. And if you get stuck, of course, you have the reference notebook and you have an opportunity to ask a question here. So with that being said, let's get started. The first thing we're going to have a look at in PyTorch is an introduction to tenses. So tenses are the main building block of deep learning in general, or data. And so you may have watched the video, what is a tensor? For the sake of this course, tenses are a way to represent data, especially multi dimensional data, numeric data that is, but that numeric data represents something else. So let's go in here, creating tenses. So the first kind of tensor we're going to create is actually called a scalar. I know I'm going to throw a lot of different names of things at you, but it's important that you're aware of such nomenclature. Even though in PyTorch, almost everything is referred to as a tensor, there are different kinds of tenses. And just to exemplify the fact that we're using a reference notebook, if we go up here, we can see we have importing PyTorch. We've done that. Now we're up to introduction to tenses. We've got creating tenses, and we've got scalar, etc, etc, etc. So this is what we're going to be working through. Let's do it together. So scalar, the way to, oops, what have I done there? The way to create a tensor in PyTorch, we're going to call this scalar equals torch dot tensor. And we're going to fill it with the number seven. And then if we press or retype in scalar, what do we get back? Seven, wonderful. And it's got the tensor data type here. So how would we find out about what torch dot tensor actually is? Well, let me show you how I would. We go to torch dot tensor. There we go. We've got the documentation. So this is possibly the most common class in PyTorch other than one we're going to see later on that you'll use, which is torch dot nn. Basically, everything in PyTorch works off torch dot tensor. And if you'd like to learn more, you can read through here. In fact, I would encourage you to read through this documentation for at least 10 minutes after you finish some videos here. So with that being said, I'm going to link that in here. So PyTorch tensors are created using torch dot tensor. And then we've got that link there. Oops, typos got law Daniel. Come on. They're better than this. No, I'm kidding. There's going to be typos got law through the whole course. Okay. Now, what are some attributes of a scalar? So some details about scalars. Let's find out how many dimensions there are. Oh, and by the way, this warning, perfect timing. Google Colab will give you some warnings here, depending on whether you're using a GPU or not. Now, the reason being is because Google Colab provides GPUs to you and I for free. However, GPUs aren't free for Google to provide. So if we're not using a GPU, we can save some resources, allow someone else to use a GPU by going to none. And of course, we can always switch this back. So I'm going to turn my GPU off so that someone else out there, I'm not using the GPU at the moment, they can use it. So what you're also going to see is if your Google Colab instance ever restarts up here, we're going to have to rerun these cells. So if you stop coding for a while, go have a break and then come back and you start your notebook again, that's one downside of Google Colab is that it resets after a few hours. How many hours? I don't know exactly. The reset time is longer if you have the pro subscription, but because it's a free service and the way Google calculate usage and all that sort of stuff, I can't give a conclusive evidence or conclusive answer on how long until it resets. But just know, if you come back, you might have to rerun some of your cells and you can do that with shift and enter. So a scalar has no dimensions. All right, it's just a single number. But then we move on to the next thing. Or actually, if we wanted to get this number out of a tensor type, we can use scalar dot item, this is going to give it back as just a regular Python integer. Wonderful, there we go, the number seven back, get tensor back as Python int. Now, the next thing that we have is a vector. So let's write in here vector, which again is going to be created with torch dot tensor. But you will also hear the word vector used a lot too. Now, what is the deal? Oops, seven dot seven. Google Colab's auto complete is a bit funny. It doesn't always do the thing you want it to. So if we see a vector, we've got two numbers here. And then if we really wanted to find out what is a vector. So a vector usually has magnitude and direction. So what we're going to see later on is, there we go, magnitude, how far it's going and which way it's going. And then if we plotted it, we've got, yeah, a vector equals the magnitude would be the length here and the direction would be where it's pointing. And oh, here we go, scalar vector matrix tensor. This is what we're working on as well. So the thing about vectors, how they differ with scalars is how I just remember them is rather than magnitude and direction is a vector typically has more than one number. So if we go vector and dim, how many dimensions does it have? It has one dimension, which is kind of confusing. But when we see tensors with more than one dimension, it'll make sense. And another way that I remember how many dimensions something has is by the number of square brackets. So let's check out something else. Maybe we go vector dot shape shape is two. So the difference between dimension. So dimension is like number of square brackets. And when I say, even though there's two here, I mean number of pairs of closing square brackets. So there's one pair of closing square brackets here. But the shape of the vector is two. So we have two by one elements. So that means a total of two elements. Now if we wanted to step things up a notch, let's create a matrix. So this is another term you're going to hear. And you might be wondering why I'm capitalizing matrix. Well, I'll explain that in the second matrix equals torch dot tensor. And we're going to put two square brackets here. You might be thinking, what could the two square brackets mean? Or actually, that's a little bit of a challenge. If one pair of square brackets had an endem of one, what will the endem be number of dimensions of two square brackets? So let's create this matrix. Beautiful. So we've got another tensor here. Again, as I said, these things have different names, like the traditional name of scalar, vector matrix, but they're all still a torch dot tensor. That's a little bit confusing, but the thing you should remember in PyTorch is basically anytime you encode data into numbers, it's of a tensor data type. And so now how many n number of dimensions do you think a matrix has? It has two. So there we go. We have two square brackets. So if we wanted to get matrix, let's index on the zeroth axis. Let's see what happens there. Ah, so we get seven and eight. And then we get off the first dimension. Ah, nine and 10. So this is where the square brackets, the pairings come into play. We've got two square bracket pairings on the outside here. So we have an endem of two. Now, if we get the shape of the matrix, what do you think the shape will be? Ah, two by two. So we've got two numbers here by two. So we have a total of four elements in there. So we're covering a fair bit of ground here, nice and quick, but that's going to be the teaching style of this course is we're going to get quite hands on and writing a lot of code and just interacting with it rather than continually going back over and discussing what's going on here. The best way to find out what's happening within a matrix is to write more code that's similar to these matrices here. But let's not stop at matrix. Let's upgrade to a tensor now. So I might put this in capitals as well. And I haven't explained what the capitals mean yet, but we'll see that in a second. So let's go torch dot tensor. And what we're going to do is this time, we've done one square bracket pairing. We've done two square bracket pairings. Let's do three square bracket pairings and just get a little bit adventurous. All right. And so you might be thinking at the moment, this is quite tedious. I'm just going to write a bunch of random numbers here. One, two, three, three, six, nine, two, five, four. Now you might be thinking, Daniel, you've said tensors could have millions of numbers. If we had to write them all by hand, that would be quite tedious. And yes, you're completely right. The fact is, though, that most of the time, you won't be crafting tensors by hand. PyTorch will do a lot of that behind the scenes. However, it's important to know that these are the fundamental building blocks of the models and the deep learning neural networks that we're going to be building. So tensor capitals as well, we have three square brackets. So, or three square bracket pairings. I'm just going to refer to three square brackets at the very start because they're going to be paired down here. How many n dim or number of dimensions do you think our tensor will have? Three, wonderful. And what do you think the shape of our tensor is? We have three elements here. We have three elements here, three elements here. And we have one, two, three. So maybe our tensor has a shape of one by three by three. Hmm. What does that mean? Well, we've got three by one, two, three. That's the second square bracket there by one. Ah, so that's the first dimension there or the zeroth dimension because we remember PyTorch is zero indexed. We have, well, let's just instead of talking about it, let's just get on the zeroth axis and see what happens with the zeroth dimension. There we go. Okay. So there's, this is the far left one, zero, which is very confusing because we've got a one here, but so we've got, oops, don't mean that. What this is saying is we've got one three by three shape tensor. So very outer bracket matches up with this number one here. And then this three matches up with the next one here, which is one, two, three. And then this three matches up with this one, one, two, three. Now, if you'd like to see this with a pretty picture, we can see it here. So dim zero lines up. So the blue bracket, the very outer one, lines up with the one. Then dim equals one, this one here, the middle bracket, lines up with the middle dimension here. And then dim equals two, the very inner lines up with these three here. So again, this is going to take a lot of practice. It's taken me a lot of practice to understand the dimensions of tensors. But to practice, I would like you to write out your own tensor of, you can put however many square brackets you want. And then just interact with the end dim shape and indexing, just as I've done here, but you can put any combination of numbers inside this tensor. That's a little bit of practice before the next video. So give that a shot and then we'll move on to the next topic. I'll see you there. Welcome back. In the last video, we covered the basic building blocks of data representation in deep learning, which is the tensor, or in PyTorch, specifically torch.tensor. But within that, we had to look at what a scalar is. We had to look at what a vector is. We had to look at a matrix. We had to look at what a tensor is. And I issued you the challenge to get as creative as you like with creating your own tensor. So I hope you gave that a shot because as you'll see throughout the course and your deep learning journey, a tensor can represent or can be of almost any shape and size and have almost any combination of numbers within it. And so this is very important to be able to interact with different tensors to be able to understand what the different names of things are. So when you hear matrix, you go, oh, maybe that's a two dimensional tensor. When you hear a vector, maybe that's a one dimensional tensor. When you hear a tensor, that could be any amount of dimensions. And just for reference for that, if we come back to the course reference, we've got a scalar. What is it? A single number, number of dimensions, zero. We've got a vector, a number with direction, number of dimensions, one, a matrix, a tensor. And now here's another little tidbit of the nomenclature of things, the naming of things. Typically, you'll see a variable name for a scalar or a vector as a lowercase. So a vector, you might have a lowercase y storing that data. But for a matrix or a tensor, you'll often see an uppercase letter or variable in Python in our case, because we're writing code. And so I am not exactly sure why this is, but this is just what you're going to see in machine learning and deep learning code and research papers across the board. This is a typical nomenclature. Scalars and vectors, lowercase, matrix and tensors, uppercase, that's where that naming comes from. And that's why I've given the tensor uppercase here. Now, with that being said, let's jump in to another very important concept with tensors. And that is random tensors. Why random tensors? I'm just writing this in a code cell now. I could go here. This is a comment in Python, random tensors. But we'll get rid of that. We could just start another text cell here. And then three hashes is going to give us a heading, random tensors there. Or I could turn this again into a markdown cell with command mm when I'm using Google Colab. So random tensors. Let's write down here. Why random tensors? So we've done the tedious thing of creating our own tensors with some numbers that we've defined, whatever these are. Again, you could define these as almost anything. But random tensors is a big part in pytorch because let's write this down. Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data. So seriously, this is one of the big concepts of neural networks. I'm going to write in code here, which is this is what the tick is for. Start with random numbers. Look at data, update random numbers. Look at data, update random numbers. That is the crux of neural networks. So let's create a random tensor with pytorch. Remember how I said that pytorch is going to create tensors for you behind the scenes? Well, this is one of the ways that it does so. So we create a random tensor and we give it a size of random tensor of size or shape. Pytorch use these independently. So size, shape, they mean the different versions of the same thing. So random tensor equals torch dot rand. And we're going to type in here three, four. And the beautiful thing about Google Colab as well is that if we wait long enough, it's going to pop up with the doc string of what's going on. I personally find this a little hard to read in Google Colab, because you see you can keep going down there. You might be able to read that. But what can we do? Well, we can go to torch dot rand. Then we go to the documentation. Beautiful. Now there's a whole bunch of stuff here that you're more than welcome to read. We're not going to go through all that. We're just going to see what happens hands on. So we'll copy that in here. And write this in notes, torch random tensors. Done. Just going to make some code cells down here. So I've got some space. I can get this a bit up here. Let's see what our random tensor looks like. There we go. Beautiful of size three, four. So we've got three or four elements here. And then we've got three deep here. So again, there's the two pairs. So what do you think the number of dimensions will be for random tensor? And dim. Two beautiful. And so we have some random numbers here. Now the beautiful thing about pie torch again is that it's going to do a lot of this behind the scenes. So if we wanted to create a size of 10 10, in some cases, we won't want one dimension here. And then it's going to go 10 10. And then if we check the number of dimensions, how many do you think it will be now three? Why is that? Because we've got one 10 10. And then if we wanted to create 10 10 10. What's the number of dimensions going to be? It's not going to change. Why is that? We haven't run that cell yet, but we've got a lot of numbers here. We can find out what 10 times 10 times 10 is. And I know we can do that in our heads, but the beauty of collab is we've got a calculator right here. 10 times 10 times 10. We've got a thousand elements in there. But sometimes tenses can be hundreds of thousands of elements or millions of elements. But pie torch is going to take care of a lot of this behind the scenes. So let's clean up a bit of space here. This is a random tensor. Random numbers beautiful of now it's got two dimensions because we've got three by four. And if we put another one in the front there, we're going to have how many dimensions three dimensions there. But again, this number of dimensions could be any number. And what's inside here could be any number. Let's get rid of that. And let's get a bit specific because right now this is just a random tensor of whatever dimension. How about we create a random tensor with similar shape to an image tensor. So a lot of the time when we turn images, image size tensor, when we turn images into tenses, they're going to have, let me just write it in code for you first, size equals a height, a width, and a number of color channels. And so in this case, it's going to be height with color channels. And the color channels are red, green, blue. And so let's create a random image tensor. Let's view the size of it or the shape. And then random image size tensor will view the end dim. Beautiful. Okay, so we've got torch size, the same size two, two, four, two, four, three, height, width, color channels. And we've got three dimensions, one, four, height, width, color channels. Let's go and see an example of this. This is the PyTorch Fundamentals notebook. If we go up to here, so say we wanted to encode this image of my dad eating pizza with thumbs up of a square image of two, two, four by two, two, four. This is an input. And if we wanted to encode this into tensor format, well, one of the ways of representing an image tensor, very common ways is to split it into color channels because with red, green, and blue, you can create almost any color you want. And then we have a tensor representation. So sometimes you're going to see color channels come first. We can switch this around and our code quite easily by going color channels here. But you'll also see color channels come at the end. I know I'm saying a lot that we kind of haven't covered yet. The main takeaway from here is that almost any data can be represented as a tensor. And one of the common ways to represent images is in the format color channels, height, width, and how these values are will depend on what's in the image. But we've done this in a random way. So the takeaway from this video is that PyTorch enables you to create tensors quite easily with the random method. However, it is going to do a lot of this creating tensors for you behind the scenes and why a random tensor is so valuable because neural networks start with random numbers, look at data such as image tensors, and then adjust those random numbers to better represent that data. And they repeat those steps onwards and onwards and onwards. Let's finish this video here. I'm going to challenge for you just to create your own random tensor of whatever size and shape you want. So you could have 5, 10, 10 here and see what that looks like. And then we'll keep coding in the next video. I hope you took on the challenge of creating random tensor of your own size. And just a little tidbit here. You might have seen me in the previous video. I didn't use the size parameter. But in this case, I did here, you can go either way. So if we go torch dot rand size equals, we put in a tuple here of three three, we've got that tensor there three three. But then also if we don't put the size in there, it's the default. So it's going to create a very similar tensor. So whether you have this size or not, it's going to have quite a similar output depending on the shape that you put in there. But now let's get started to another kind of tensor that you might see zeros and ones. So say you wanted to create a tensor, but that wasn't just full of random numbers, you wanted to create a tensor of all zeros. This is helpful for if you're creating some form of mask. Now, we haven't covered what a mask is. But essentially, if we create a tensor of all zeros, what happens when you multiply a number by zero? All zeros. So if we wanted to multiply these two together, let's do zeros times random tensor. There we go, all zeros. So maybe if you're working with this random tensor and you wanted to mask out, say all of the numbers in this column for some reason, you could create a tensor of zeros in that column, multiply it by your target tensor, and you would zero all those numbers. That's telling your model, hey, ignore all of the numbers that are in here because I've zeroed them out. And then if you wanted to create a tensor of all ones, create a tensor of all ones, we can go ones equals torch dot ones, size equals three, four. And then if we have a look, there's another parameter I haven't showed you yet, but this is another important one is the D type. So the default data type, so that's what D type stands for, is torch dot float. We've actually been using torch dot float the whole time, because that's whenever you create a tensor with pytorch, we're using a pytorch method, unless you explicitly define what the data type is, we'll see that later on, defining what the data type is, it starts off as torch float 32. So these are float numbers. So that is how you create zeros and ones zeros is probably I've seen more common than ones in use, but just keep these in mind, you might come across them. There are lots of different methods to creating tensors. And truth be told, like random is probably one of the most common, but you might see zeros and ones out in the field. So now we've covered that. Let's move on into the next video, where we're going to create a range. So have a go at creating a tensor full of zeros and whatever size you want, and a tensor full of ones and whatever size you want. And I'll see you in the next video. Welcome back. I hope you took on the challenge of creating a torch tensor of zeros of your own size and ones of your own size. But now let's investigate how we might create a range of tensors and tensors like. So these are two other very common methods of creating tensors. So let's start by creating a range. So we'll first use torch dot range, because depending on when you're watching this video, torch dot range may be still in play or it may be deprecated. If we write in torch dot range right now with the pie torch version that I'm using, which is torch dot version, which is torch or pie torch 1.10 point zero torch range is deprecated and will be removed in a future release. So just keep that in mind. If you come across some code that's using torch dot range, maybe out of whack. So the way to get around that is to fix that is to use a range instead. And if we just write in torch dot a range, we've got tensors of zero to nine, because it of course starts at zero index. If we wanted one to 10, we could go like this. 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. And we can go zero, or we go 1, 2, 10, equals torch a range. Wonderful. And we can also define the step. So let's let's type in some start and where can we find the documentation on a range? Sometimes in Google Colab, you can press shift tab, but I find that it doesn't always work for me. Yeah, you could hover over it, but we can also just go torch a range and look for the documentation torch a range. So we've got start and step. Let's see what all of these three do. Maybe we start at zero, and maybe we want it to go to a thousand, and then we want a step of what should our step be? What's a fun number? 77. So it's not one to 10 anymore, but here we go. We've got start at zero, 77 plus 77 plus 77, all the way up to it finishes at a thousand. So if we wanted to take it back to one to 10, we can go up here. 110, and the default step is going to be one. Oops, we needed the end to be that it's going to finish at end minus one. There we go. Beautiful. Now we can also create tensors like. So creating tensors like. So tensors like is say you had a particular shape of a tensor you wanted to replicate somewhere else, but you didn't want to explicitly define what that shape should be. So what's the shape of one to 10? One to 10. Now if we wanted to create a tensor full of zeros that had the same shape as this, we can use tensor like or zeros like. So 10 zeros, zeros equals, I'm not even sure if I'm spelling zeros right then, zeros. Well, I might have a typo spelling zeros here, but you get what I'm saying is torch zeros. Oh, torch spell it like that. That's why I'm spelling it like that. Zeros like one to 10. And then the input is going to be one to 10. And we have a look at 10 zeros. My goodness, this is taking quite the while to run. This is troubleshooting on the fly. If something's happening like this, you can try to stop. If something was happening like that, you can click run and then stop. Well, it's running so fast that I can't click stop. If you do also run into trouble, you can go runtime, restart runtime. We might just do that now just to show you. Restart and run all is going to restart the compute engine behind the collab notebook. And run all the cells to where we are. So let's just see that we restart and run runtime. If you're getting errors, sometimes this helps. There is no set in stone way to troubleshoot errors. It's guess and check with this. So there we go. We've created 10 zeros, which is torch zeros like our one to 10 tensor. So we've got zeros in the same shape as one to 10. So if you'd like to create tensors, use torch arrange and get deprecated message. Use torch arrange instead for creating a range of tensors with a start and end in a step. And then if you wanted to create tensors or a tensor like something else, you want to look for the like method. And then you put an input, which is another tensor. And then it'll create a similar tensor with whatever this method here is like in that fashion or in the same shape as your input. So with that being said, give that a try, create a range of tensors, and then try to replicate that range shape that you've made with zeros. I'll see you in the next video. Welcome back. Let's now get into a very important topic of tensor data types. So we've briefly hinted on this before. And I said that let's create a tensor to begin with float 32 tensor. And we're going to go float 32 tensor equals torch dot tensor. And let's just put in the numbers three, six, nine. If you've ever played need for speed underground, you'll know where three, six, nine comes from. And then we're going to go D type equals, let's just put none and see what happens, hey, float 32 tensor. Oh, what is the data type? float 32, tensor dot D type. float 32, even though we put none, this is because the default data type in pytorch, even if it's specified as none is going to come out as float 32. What if we wanted to change that to something else? Well, let's type in here float 16. And now we've got float 32 tensor. This variable name is a lie now because it's a float 16 tensor. So we'll leave that as none. Let's go there. There's another parameter when creating tensors. It's very important, which is device. So we'll see what that is later on. And then there's a final one, which is also very important, which is requires grad equals false. Now this could be true, of course, we're going to set this as false. So these are three of the most important parameters when you're creating tensors. Now, again, you won't necessarily always have to enter these when you're creating tensors, because pytorch does a lot of tensor creation behind the scenes for you. So let's just write out what these are. Data type is what data type is the tensor, e.g. float 32, or float 16. Now, if you'd like to look at what data types are available for pytorch tensors, we can go torch tensor and write up the top unless the documentation changes. We have data types. It's so important that data types is the first thing that comes up when you're creating a tensor. So we have 32-bit floating point, 64-bit floating point, 16, 16, 32-bit complex. Now, the most common ones that you will likely interact with are 32-bit floating point and 16-bit floating point. Now, what does this mean? What do these numbers actually mean? Well, they have to do with precision in computing. So let's look up that. Precision in computing. Precision computer science. So in computer science, the precision of a numerical quantity, we're dealing with numbers, right? As a measure of the detail in which the quantity is expressed. This is usually measured in bits, but sometimes in decimal digits. It is related to precision in mathematics, which describes the number of digits that are used to express a value. So, for us, precision is the numerical quantity, is a measure of the detail, how much detail in which the quantity is expressed. So, I'm not going to dive into the background of computer science and how computers represent numbers. The important takeaway for you from this will be that single precision floating point is usually called float 32, which means, yeah, a number contains 32 bits in computer memory. So if you imagine, if we have a tensor that is using 32 bit floating point, the computer memory stores the number as 32 bits. Or if it has 16 bit floating point, it stores it as 16 bits or 16 numbers representing or 16. I'm not sure if a bit equates to a single number in computer memory. But what this means is that a 32 bit tensor is single precision. This is half precision. Now, this means that it's the default of 32, float 32, torch dot float 32, as we've seen in code, which means it's going to take up a certain amount of space in computer memory. Now, you might be thinking, why would I do anything other than the default? Well, if you'd like to sacrifice some detail in how your number is represented. So instead of 32 bits, it's represented by 16 bits, you can calculate faster on numbers that take up less memory. So that is the main differentiator between 32 bit and 16 bit. But if you need more precision, you might go up to 64 bit. So just keep that in mind as you go forward. Single precision is 32. Half precision is 16. What do these numbers represent? They represent how much detail a single number is stored in memory. That was a lot to take in. But we're talking about 10 to data types. I'm spending a lot of time here, because I'm going to put a note here, note, tensor data types is one of the three big issues with pytorch and deep learning or not not issues, they're going to be errors that you run into and deep learning. Three big errors, you'll run into with pytorch and deep learning. So one is tensors, not right data type. Two tensors, not right shape. We've seen a few shapes of four and three tensors, not on the right device. And so in this case, if we had a tensor that was float 16 and we were trying to do computations with a tensor that was float 32, we might run into some errors. And so that's the tensors not being in the right data type. So it's important to know about the D type parameter here. And then tensors not being the right shape. Well, that's once we get onto matrix multiplication, we'll see that if one tensor is a certain shape and another tensor is another shape and those shapes don't line up, we're going to run into shape errors. And this is a perfect segue to the device. Device equals none. By default, this is going to be CPU. This is why we are using Google Colab because it enables us to have access to, oh, we don't want to restart, enables us to have access to a GPU. As I've said before, a GPU enables us. So we could change this to CUDA. That would be, we'll see how to write device agnostic code later on. But this device, if you try to do operations between two tensors that are not on the same device. So for example, you have one tensor that lives on a GPU for fast computing, and you have another tensor that lives on a CPU and you try to do something with them, while pytorch is going to throw you an error. And then finally, this last requirement is grad is if you want pytorch to track the gradients, we haven't covered what that is of a tensor when it goes through certain numerical calculations. This is a bit of a bombardment, but I thought I'd throw these in as important parameters to be aware of since we're discussing data type. And really, it would be reminiscent of me to discuss data type without discussing not the right shape or not the right device. So with that being said, let's write down here what device is your tensor on, and whether or not to track gradients with this tensor's operations. So we have a float 32 tensor. Now, how might we change the tensor data type of this? Let's create float 16 tensor. And we saw that we could explicitly write in float 16 tensor. Or we can just type in here, float 16 tensor equals float 32 tensor dot type. And we're going to type in torch dot float 16, why float 16, because well, that's how we define float 16, or we could use half. So the same thing, these things are the same, let's just do half, or float 16 is more explicit for me. And then let's check out float 16 tensor. Beautiful, we've converted our float 32 tensor into float 16. So that is one of the ways that you'll be able to tackle the tensors not in the right data type issue that you run into. And just a little note on the precision and computing, if you'd like to read more on that, I'm going to link this in here. And this is all about how computers store numbers. So precision in computing. There we go. I'll just get rid of that. Wonderful. So give that a try, create some tensors, research, or go to the documentation of torch dot tensor and see if you can find out a little bit more about D type device and requires grad, and create some tensors of different data types. Play around with whatever the ones you want here, and see if you can run into some errors, maybe try to multiply two tensors together. So if you go float 16 tensor times float 32 tensor, give that a try and see what happens. I'll see you in the next video. Welcome back. In the last video, we covered a little bit about tensor data types, as well as some of the most common parameters you'll see past to the torch dot tensor method. And so I should do the challenge at the end of the last video to create some of your own tensors of different data types, and then to see what happens when you multiply a float 16 tensor by a float 32 tensor. Oh, it works. And but you've like Daniel, you said that you're going to have tensors not the right data type. Well, this is another kind of gotcha or caveat of pie torch and deep learning in general, is that sometimes you'll find that even if you think something may error because these two tensors are different data types, it actually results in no error. But then sometimes you'll have other operations that you do, especially training large neural networks, where you'll get data type issues. The important thing is to just be aware of the fact that some operations will run an error when your tensors are not in the right data type. So let's try another type. Maybe we try a 32 bit integer. So torch dot in 32. And we try to multiply that by a float. Wonder what will happen then? So let's go into 32 in 32 tensor equals torch dot tensor. And we'll just make it three. Notice that there's no floats there or no dot points to make it a float. Three, six, nine and D type can be torch in 32. And then in 32 tensor, what does this look like? Typo, of course, one of many in 32 tensor. So now let's go float 32 tensor and see what happens. Can we get pie torch to throw an error in 32 tensor? Huh, it worked as well. Or maybe we go into 64. What happens here? Still works. Now, see, this is again one of the confusing parts of doing tensor operations. What if we do a long tensor? Torch to long. Is this going to still work? Ah, torch has no attribute called long. That's not a data type issue. I think it's long tensor. Long tensor. Does this work? D type must be torch D type. Torch long tensor. I could have sworn that this was torch dot tensor. Oh, there we go. Torch dot long tensor. That's another word for 64 bit. So what is this saying? CPU tensor. Okay, let's see. This is some troubleshooting on the fly here. Then we multiply it. This is a float 32 times a long. It works. Okay, so it's actually a bit more robust than what I thought it was. But just keep this in mind when we're training models, we're probably going to run into some errors at some point of our tensor's not being the right data type. And if pie torch throws us an error saying your tensors are in the wrong data type, well, at least we know now how to change that data type or how to set the data type if we need to. And so with that being said, let's just formalize what we've been doing a fair bit already. And that's getting information from tensors. So the three big things that we'll want to get from our tensors in line with the three big errors that we're going to face in neural networks and deep lining is let's copy these down. Just going to get this, copy this down below. So if we want to get some information from tensors, how do we check the shape? How do we check the data type? How do we check the device? Let's write that down. So to get information from this, to get D type or let's write data type from a tensor can use tensor dot D type. And let's go here to get shape from a tensor can use tensor dot shape. And to get device from a tensor, which devices it on CPU or GPU can use tensor dot device. Let's see these three in action. So if we run into one of the three big problems in deep learning and neural networks in general, especially with PyTorch, tensor's not the right data type, tensor's not the right shape or tensor's not on the right device. Let's create a tensor and try these three out. We've got some tensor equals torch dot rand and we'll create it a three four. Let's have a look at what it looks like. There we go. Random numbers of shape three and four. Now let's find out some details about it. Find out details about some tensor. So print or print some tensor. And oops, didn't want that print. And let's format it or make an F string of shape of tensor. Oh, let's do data type first. We'll follow that order. Data type of tensor. And we're going to go, how do we do this? Some tensor dot what? Dot d type. Beautiful. And then we're going to print tensors not in the right shape. So let's go shape of tensor equals some tensor dot shape. Oh, I went a bit too fast, but we could also use size. Let's just confirm that actually. We'll code that out together. From my experience, some tensor dot size, and some tensor dot shape result in the same thing. Is that true? Oh, function. Oh, that's what it is. Some tensor dot size is a function, not an attribute. There we go. Which one should you use? For me, I'm probably more used to using shape. You may come across dot size as well, but just realize that they do quite the same thing except one's a function and one's an attribute. An attribute is written dot shape without the curly brackets. A function or a method is with the brackets at the end. So that's the difference between these are attributes here. D type size. We're going to change this to shape. Tensor attributes. This is what we're getting. I should probably write that down. This is tensor attributes. That's the formal name for these things. And then finally, what else do we want? Tensors, what device are we looking for? Let's get rid of this, get rid of this. And then print f device tensor is on. By default, our tensor is on the CPU. So some tensor dot device. There we go. So now we've got our tensor here, some tensor. The data type is a torch float 32 because we didn't change it to anything else. And torch float 32 is the default. The shape is three four, which makes a lot of sense because we passed in three four here. And the device tensor is on is the CPU, which is, of course, the default, unless we explicitly say to put it on another device, all of the tensors that we create will default to being on the CPU, rather than the GPU. And we'll see later on how to put tensors and other things in torch onto a GPU. But with that being said, give it a shot, create your own tensor, get some information from that tensor, and see if you can change these around. So see if you could create a random tensor, but instead of float 32, it's a float 16. And then probably another extracurricular, we haven't covered this yet. But see how to change the device a pytorch tensor is on. Give that a crack. And I'll see you in the next video. Welcome back. So in the last video, we had a look at a few tensor attributes, namely the data type of a tensor, the shape of a tensor, and the device that a tensor lives on. And I alluded to the fact that these will help resolve three of the most common issues in building neural networks, deep learning models, specifically with pytorch. So tensor has not been the right data type, tensor has not been the right shape, and tensor has not been on the right device. So now let's get into manipulating tensors. And what I mean by that, so let's just write here the title, manipulating tensors. And this is going to be tensor operations. So when we're building neural networks, neural networks are comprised of lots of mathematical functions that pytorch code is going to run behind the scenes for us. So let's go here, tensor operations include addition, subtraction, and these are the regular addition, subtraction, multiplication. There's two types of multiplication in that you'll typically see referenced in deep learning and neural networks, division, and matrix multiplication. And these, the ones here, so addition, subtraction, multiplication, division, your typical operations that you're probably familiar with matrix multiplication. The only different one here is matrix multiplication. We're going to have a look at that in a minute. But to find patterns in numbers of a data set, a neural network will combine these functions in some way, shape or form. So it takes a tensor full of random numbers, performs some kind of combination of addition, subtraction, multiplication, division, matrix multiplication. It doesn't have to be all of these. It could be any combination of these to manipulate these numbers in some way to represent a data set. So that's how a neural network learns is it will just comprise these functions, look at some data to adjust the numbers of a random tensor, and then go from there. But with that being said, let's look at a few of these. So we'll begin with addition. First thing we need to do is create a tensor. And to add something to a tensor, we'll just go torch tensor. Let's go one, two, three, add something to a tensor is tensor plus, we can use plus as the addition operator, just like in Python, tensor plus 10 is going to be tensor 11, 12, 13, tensor plus 100 is going to be as you'd expect plus 100. Let's leave that as plus 10 and add 10 to it. And so you might be able to guess how we would multiply it by 10. So let's go multiply tensor by 10. We can go tensor, star, which are my keyboard shift eight, 10. We get 10, 10, 10. And because we didn't reassign it, our tensor is still 123. So if we go, if we reassign it here, tensor equals tensor by 10, and then check out tensor, we've now got 10 2030. And the same thing here, we'll have 10 2030. But then if we go back from the top, if we delete this reassignment, oh, what do we get there, tensor by 10. Oh, what's happened here? Oh, because we've got, yeah, okay, I see, tensor by 10, tensor, still 123. What should we try now? How about subtract subtract 10 equals tensor minus 10. And you can also use, well, there we go, one minus 10, eight minus 10, three minus 10. You can also use like torch has inbuilt functions or pytorch. So try out pytorch inbuilt functions. So torch dot mall is short for multiply. We can pass in our tensor here, and we can add in 10. That's going to multiply each element of tensor by 10. So just taking the original tensor that we created, which is 123. And performing the same thing as this, I would recommend where you can use the operators from Python. If for some reason, you see torch dot mall, maybe there's a reason for that. But generally, these are more understandable if you just use the operators, if you need to do a straight up multiplication, straight up addition, or straight up subtraction, because torch also has torch dot add, torch dot add, is it torch dot add? It might be torch dot add. I'm not sure. Oh, there we go. Yeah, torch dot add. So as I alluded to before, there's two different types of multiplication that you'll hear about element wise and matrix multiplication. We're going to cover matrix multiplication in the next video. As a challenge, though, I would like you to search what is matrix multiplication. And I think the first website that comes up, matrix multiplication, Wikipedia, yeah, math is fun. It has a great guide. So before we get into matrix multiplication, jump into math is fun to have a look at matrix multiplying, and have a think about how we might be able to replicate that in pie torch. Even if you're not sure, just have a think about it. I'll see you in the next video. Welcome back. In the last video, we discussed some basic tensor operations, such as addition, subtraction, multiplication, element wise, division, and matrix multiplication. But we didn't actually go through what matrix multiplication is. So now let's start on that more particularly discussing the difference between element wise and matrix multiplication. So we'll come down here, let's write another heading, matrix multiplication. So there's two ways, or two main ways. Yeah, let's write that two main ways of performing multiplication in neural networks and deep learning. So one is the simple version, which is what we've seen, which is element wise multiplication. And number two is matrix multiplication. So matrix multiplication is actually possibly the most common tensor operation you will find inside neural networks. And in the last video, I issued the extra curriculum of having a look at the math is fun dot com page for how to multiply matrices. So the first example they go through is element wise multiplication, which just means multiplying each element by a specific number. In this case, we have two times four equals eight, two times zero equals zero, two times one equals two, two times negative nine equals negative 18. But then if we move on to matrix multiplication, which is multiplying a matrix by another matrix, we need to do the dot product. So that's something that you'll also hear matrix multiplication referred to as the dot product. So these two are used interchangeably matrix multiplication or dot product. And if we just look up the symbol for dot product, you'll find that it's just a dot. There we go, a heavy dot, images. There we go, a dot B. So this is vector a dot product B. A few different options there, but let's look at what it looks like in pytorch code. But first, there's a little bit of a difference here. So how did we get from multiplying this matrix here of one, two, three, four, five, six, times seven, eight, nine, 10, 11, 12? How did we get 58 there? Well, we start by going, this is the difference between element wise and dot product, by the way, one times seven. We'll record that down there. So that's seven. And then two times nine. So this is first row, first column, two times nine is 18. And then three times 11 is 33. And if we add those up, seven plus 18, plus 33, we get 58. And then if we were to do that for each other element that's throughout these two matrices, we end up with something like this. So that's what I'd encourage you to go through step by step and reproduce this a good challenge would be to reproduce this by hand with pytorch code. But now let's go back and write some pytorch code to do both of these. So I just want to link here as well, more information on multiplying matrices. So I'm going to turn this into markdown. Let's first see element wise, element wise multiplication. We're going to start with just a rudimentary example. So if we have our tensor, what is it at the moment? It's 123. And then if we multiply that by itself, we get 149. But let's print something out so it looks a bit prettier than that. So print, I'm going to turn this into a string. And then we do that. So if we print tensor times tensor, element wise multiplication is going to give us print equals. And then let's do in here tensor times tensor. We go like that. Wonderful. So we get one times one equals one, two times two equals four, three times three equals nine. Now for matrix multiplication, pytorch stores matrix multiplication, similar to torch dot mall in the torch dot mat mall space, which stands for matrix multiplication. So let's just test it out. Let's just true the exact same thing that we did here, instead of element wise, we'll do matrix multiplication on our 123 tensor. What happens here? Oh my goodness, 14. Now why did we get 14 instead of 149? Can you guess how we got to 14 or think about how we got to 14 from these numbers? So if we recall back, we saw that for we're only multiplying two smaller tensors, by the way, 123. This example is with a larger one, but the same principle applies across different sizes of tensors or matrices. And when I say matrix multiplication, you can also do matrix multiplication between tensors. And in our case, we're using vectors just to add to the confusion. But what is the difference here between element wise and dot product? Well, we've got one main addition. And that is addition. So if we were to code this out by hand, matrix multiplication by hand, we'd have recall that the elements of our tensor are 123. So if we wanted to matrix multiply that by itself, we'd have one times one, which is the equivalent of doing one times seven in this visual example. And then we'd have plus, it's going to be two times two, two times two. What does that give us? Plus three times three. What does it give us? Three times three. That gives us 14. So that's how we got to that number there. Now we could do this with a for loop. So let's have a gaze at when I say gaze, it means have a look. That's a Australian colloquialism for having a look. But I want to show you the time difference in it might not actually be that big a difference if we do it by hand versus using something like matmore. And that's another thing to note is that if PyTorch has a method already implemented, chances are it's a fast calculating version of that method. So I know for basic operators, I said it's usually best to just use this straight up basic operator. But for something like matrix multiplication or other advanced operators instead of the basic operators, you probably want to use the torch version rather than writing a for loop, which is what we're about to do. So let's go value equals zero. This is matrix multiplication by hand. So for I in range, len tensor, so for each element in the length of our tensor, which is 123, we want to update our value to be plus equal, which is doing this plus reassignment here. The ith element in each tensor times the ith element. So times itself. And then how long is this going to take? Let's now return the value. We should get 14, print 14. There we go. So 1.9 milliseconds on whatever CPU that Google collab is using behind the scenes. But now if we time it and use the torch method torch dot matmore, it was tensor dot sensor. And again, we're using a very small tensor. So okay, there we go. It actually showed how much quicker it is, even with such a small tensor. So this is 1.9 milliseconds. This is 252 microseconds. So this is 10 times slower using a for loop, then pie torches vectorized version. I'll let you look into that if you want to find out what vectorization means. It's just a type of programming that rather than writing for loops, because as you could imagine, if this tensor was, let's say, had a million elements instead of just three, if you have to loop through each of those elements one by one, that's going to be quite cumbersome. So a lot of pie torches functions behind the scenes implement optimized functions to perform mathematical operations, such as matrix multiplication, like the one we did by hand, in a far faster manner, as we can see here. And that's only with a tensor of three elements. So you can imagine the speedups on something like a tensor with a million elements. But with that being said, that is the crux of matrix multiplication. For a little bit more, I encourage you to read through this documentation here by mathisfun.com. Otherwise, let's look at a couple of rules that we have to satisfy for larger versions of matrix multiplication. Because right now, we've done it with a simple tensor, only 123. Let's step things up a notch in the next video. Welcome back. In the last video, we were introduced to matrix multiplication, which although we haven't seen it yet, is one of the most common operations in neural networks. And we saw that you should always try to use torches implementation of certain operations, except if they're basic operations, like plus multiplication and whatnot, because chances are it's a lot faster version than if you would do things by hand. And also, it's a lot less code. Like compared to this, this is pretty verbose code compared to just a matrix multiply these two tensors. But there's something that we didn't allude to in the last video. There's a couple of rules that need to be satisfied when performing matrix multiplication. It worked for us because we have a rather simple tensor. But once you start to build larger tensors, you might run into one of the most common errors in deep learning. I'm going to write this down actually here. This is one to be very familiar with. One of the most common errors in deep learning, we've already alluded to this as well, is shape errors. So let's jump back to this in a minute. I just want to write up here. So there are two rules that performing or two main rules that performing matrix multiplication needs to satisfy. Otherwise, we're going to get an error. So number one is the inner dimensions must match. Let's see what this means. So if we want to have two tensors of shape, three by two, and then we're going to use the at symbol. Now, we might be asking why the at symbol. Well, the at symbol is another, is a like an operator symbol for matrix multiplication. So I just want to give you an example. If we go tensor at at stands for matrix multiplication, we get tensor 14, which is exactly the same as what we got there. Should you use at or should you use mat mall? I would personally recommend to use mat mall. It's a little bit clearer at sometimes can get confusing because it's not as common as seeing something like mat mall. So we'll get rid of that, but I'm just using it up here for brevity. And then we're going to go three, two. Now, this won't work. We'll see why in a second. But if we go two, three, at, and then we have three, two, this will work. Or, and then if we go the reverse, say threes on the outside, twos here. And then we have twos on the inside and threes on the outside, this will work. Now, why is this? Well, this is the rule number one. The inner dimensions must match. So the inner dimensions are what I mean by this is let's create torch round or create of size 32. And then we'll get its shape. So we have, so if we created a tensor like this, three, two, and then if we created another tensor, well, let me just show you straight up torch dot mat mall torch dot ran to watch this won't work. We'll get an error. There we go. So this is one of the most common errors that you're going to face in deep learning is that matrix one and matrix two shapes cannot be multiplied because it doesn't satisfy rule number one. The inner dimensions must match. And so what I mean by inner dimensions is this dimension multiplied by this dimension. So say we were trying to multiply three, two by three, two, these are the inner dimensions. Now this will work because why the inner dimensions match. Two, three by three, two, two, three by three, two. Now notice how the inner dimensions, inner, inner match. Let's see what comes out here. Look at that. And now this is where rule two comes into play. Two. The resulting matrix has the shape of the outer dimensions. So we've just seen this one two, three at three, two, which is at remember is matrix multiply. So we have a matrix of shape, two, three, matrix multiply a matrix of three, two, the inner dimensions match. So it works. The resulting shape is what? Two, two. Just as we've seen here, we've got a shape of two, two. Now what if we did the reverse? What if we did this one that also will work? Three on the outside. What do you think is going to happen here? In fact, I encourage you to pause the video and give it a go. So this is going to result in a three three matrix. But don't take my word for it. Let's have a look. Three, put two on the inside and we'll put two on the inside here and then three on the outside. What does it give us? Oh, look at that. A three three. One, two, three. One, two, three. Now what if we were to change this? Two and two. This can be almost any number you want. Let's change them both to 10. What's going to happen? Will this work? What's the resulting shape going to be? So the inner dimensions match? What's rule number two? The resulting matrix has the shape of the outer dimension. So what do you think is going to be the shape of this resulting matrix multiplication? Well, let's have a look. It's still three three. Wow. Now what if we go 10? 10 on the outside and 10 and 10 on the inside? What do we get? Well, we get, I'm not going to count all of those, but if we just go shape, we get 10 by 10. Because these are the two main rules of matrix multiplication is if you're running into an error that the matrix multiplication can't work. So let's say this was 10 and this was seven. Watch what's going to happen? We can't multiply them because the inner dimensions do not match. We don't have 10 and 10. We have 10 and seven. But then when we change this so that they match, we get 10 and 10. Beautiful. So now let's create a little bit more of a specific example. We'll create two tenses. We'll come down. Actually, to prevent this video from being too long, I've got an error in the word error. That's funny. We'll go on with one of those common errors in deep learning shape errors. We've just seen it, but I'm going to get a little bit more specific with that shape error in the next video. Before we do that, have a look at matrix multiplication. There's a website, my other favorite website. I told you I've got two. This is my other one. Matrix multiplication dot XYZ. This is your challenge before the next video. Put in some random numbers here, whatever you want, two, 10, five, six, seven, eight, whatever you want. Change these around a bit, three, four. Well, that's a five, not a four. And then multiply and just watch what happens. That's all I'd like you to do. Just watch what happens and we're going to replicate something like this in PyTorch code in the next video. I'll see you there. Welcome back. In the last video, we discussed a little bit more about matrix multiplication, but we're not done there. We looked at two of the main rules of matrix multiplication, and we saw a few errors of what happens if those rules aren't satisfied, particularly if the inner dimensions don't match. So this is what I've been alluding to as one of the most common errors in deep learning, and that is shape errors. Because neural networks are comprised of lots of matrix multiplication operations, if you have some sort of tensor shape error somewhere in your neural network, chances are you're going to get a shape error. So now let's investigate how we can deal with those. So let's create some tenses, shapes for matrix multiplication. And I also showed you the website, sorry, matrix multiplication dot xyz. I hope you had a go at typing in some numbers here and visualizing what happens, because we're going to reproduce something very similar to what happens here, but with PyTorch code. Shapes for matrix multiplication, we have tensor a, let's create this as torch dot tensor. We're going to create a tensor with just the elements one, two, all the way up to, let's just go to six, hey, that'll be enough. Six, wonderful. And then tensor b can be equal to a torch tensor of where we're going to go for this one. Let's go seven, 10, this will be a little bit confusing this one, but then we'll go eight, 11, and this will go up to 12, nine, 12. So it's the same sort of sequence as what's going on here, but they've been swapped around. So we've got the vertical axis here, instead of one, two, three, four, this is just seven, eight, nine, 10, 11, 12. But let's now try and perform a matrix multiplication. How do we do that? Torch dot mat mall for matrix multiplication. PS torch also has torch dot mm, which stands for matrix multiplication, which is a short version. So I'll just write down here so that you know tensor a, tensor b. I'm going to write torch dot mm is the same as torch dot mat mall. It's an alias for writing less code. This is literally how common matrix multiplications are in PyTorch is that they've made torch dot mm as an alias for mat mall. So you have to type four less characters using torch dot mm instead of mat mall. But I like to write mat mall because it's a little bit like it explains what it does a little bit more than mm. So what do you think's going to happen here? It's okay if you're not sure. But what you could probably do to find out is check the shapes of these. Does this operation matrix multiplication satisfy the rules that we just discussed? Especially this one. This is the main one. The inner dimensions must match. Well, let's have a look, hey? Oh, no, mat one and mat two shapes cannot be multiplied. Three by two and three by two. This is very similar to what we went through in the last video. But now we've got some actual numbers there. Let's check the shape. Oh, torch size three two. Torch size three two now. In the last video we created a random tensor and we could adjust the shape on the fly. But these tensors already exist. How might we adjust the shape of these? Well, now I'm going to introduce you to another very common operation or tensor manipulation that you'll see. And that is the transpose. To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a transpose. And so, all right here, we're going to see this anyway, but I'm going to define it in words. A transpose switches the axes or dimensions of a given tensor. So let's see this in action. If we go, and the way to do it, is you can go tensor b dot t. Let's see what happens. Let's look at the original tensor b as well. So dot t stands for transpose. And that's a little bit hard to read, so we might do these on different lines, tensor b. We'll get rid of that. So you see what's happened here. Instead of tensor b, this is the original one. We might put the original on top. Instead of the original one having seven, eight, nine, 10, 11, 12 down the vertical, the transpose has transposed it to seven, eight, nine across the horizontal and 10, 11, 12 down here. Now, if we get the shape of this, tensor b dot shape, let's have a look at that. Let's have a look at the original shape, tensor b dot shape. What's happened? Oh, no, we've still got three, two. Oh, that's what I've missed out here. I've got a typo. Excuse me. I thought I was, you think code that you've written is working, but then you realize you've got something as small as just a dot t missing, and it throws off your whole train of thought. So you're seeing these arrows on the fly here. Now, tensor b is this, but its shape is torch dot size three, two. And if we try to matrix multiply three, two, and three, two, tensor a and tensor b, we get an error. Why? Because the inner dimensions do not match. But if we perform a transpose on tensor b, we switch the dimensions around. So now, we perform a transpose with tensor b dot t, t's for transpose. We have, this is the important point as well. We still have the same elements. It's just that they've been rearranged. They've been transposed. So now, tensor b still has the same information encoded, but rearranged. So now we have torch size two, three. And so when we try to matrix multiply these, we satisfy the first criteria. And now look at the output of the matrix multiplication of tensor a and tensor b dot t transposed is three, three. And that is because of the second rule of matrix multiplication. The resulting matrix has the shape of the outer dimensions. So we've got three, two matrix multiply two, three results in a shape of three, three. So let's predify some of this, and we'll print out what's going on here. Just so we know, we can step through it, because right now we've just got codal over the place a bit. Let's see here, the matrix multiplication operation works when tensor b is transposed. And in a second, I'm going to show you what this looks like visually. But right now we've done it with pytorch code, which might be a little confusing. And that's perfectly fine. Matrix multiplication takes a little while and a little practice. So original shapes is going to be tensor a dot shape. Let's see what this is. And tensor b equals tensor b dot shape. But the reason why we're spending so much time on this is because as you'll see, as you get more and more into neural networks and deep learning, the matrix multiplication operation is one of the most or if not the most common. Same shape as above, because we haven't changed tensor a shape, we've only changed tensor b shape, or we've transposed it. And then in tensor b dot transpose equals, we want tensor b dot t dot shape. Wonderful. And then if we print, let's just print out, oops, print, I spelled the wrong word there, print. We want, what are we multiplying here? This is one of the ways, remember our motto of visualize, visualize, visualize, well, this is how I visualize, visualize, visualize things, shape, let's do the at symbol for brevity, tensor, and let's get b dot t dot shape. We'll put down our little rule here, inner dimensions must match. And then print, let's get the output output, I'll put that on a new line. The output is going to equal torch dot, or our outputs already here, but we're going to rewrite it for a little bit of practice, tensor a, tensor b dot t. And then we can go print output. And then finally, print, let's get it on a new line as well, the output shape, a fair bit going on here. But we're going to step through it, and it's going to help us understand a little bit about what's going on. That's the data visualizes motto. There we go. Okay, so the original shapes are what torch size three two, and torch size three two, the new shapes tensor a stays the same, we haven't changed tensor a, and then we have tensor b dot t is torch size two three, then we multiply a three by two by a two by three. So the inner dimensions must match, which is correct, they do match two and two. Then we have an output of tensor at 27, 30, 33, 61, 68, 75, etc. And the output shape is what the output shape is the outer dimensions three three. Now, of course, you could rearrange this maybe transpose tensor a instead of tensor b, have a play around with it. See if you can create some more errors trying to multiply these two, and see what happens if you transpose tensor a instead of tensor b, that's my challenge. But before we finish this video, how about we just recreate what we've done here with this cool website matrix multiplication. So what did we have? We had tensor a, which is one to six, let's recreate this, remove that, this is going to be one, two, three, four, five, six, and then we want to increase this, and this is going to be seven, eight, nine, 10, 11, 12. Is that the right way of doing things? So this is already transposed, just to let you know. So this is the equivalent of tensor b on the right here, tensor b dot t. So let me just show you, if we go tensor b dot transpose, which original version was that, but we're just passing in the transpose version to our matrix multiplication website. And then if we click multiply, this is what's happening behind the scenes with our pytorch code of matmore. We have one times seven plus two times 10. Did you see that little flippy thing that it did? That's where the 27 comes from. And then if we come down here, what's our first element? 27 when we matrix multiply them. Then if we do the same thing, the next step, we get 30 and 61, from a combination of these numbers, do it again, 33, 68, 95, from a combination of these numbers, again, and again, and finally we end up with exactly what we have here. So that's a little bit of practice for you to go through is to create some of your own tensors can be almost whatever you want. And then try to matrix multiply them with different shapes. See what happens when you transpose and what different values you get. And if you'd like to visualize it, you could write out something like this. That really helps me understand matrix multiplication. And then if you really want to visualize it, you can go through this website and recreate your target tensors in something like this. I'm not sure how long you can go. But yeah, that should be enough to get started. So give that a try and I'll see you in the next video. Welcome back. In the last few videos, we've covered one of the most fundamental operations in neural networks. And that is matrix multiplication. But now it's time to move on. And let's cover tensor aggregation. And what I mean by that is finding the min, max, mean, sum, et cetera, tensor aggregation of certain tensor values. So for whatever reason, you may want to find the minimum value of a tensor, the maximum value, the mean, the sum, what's going on there. So let's have a look at some few PyTorch methods that are in built to do all of these. And again, if you're finding one of these values, it's called tensor aggregation because you're going from what's typically a large amount of numbers to a small amount of numbers. So the min of this tensor would be 27. So you're turning it from nine elements to one element, hence aggregation. So let's create a tensor, create a tensor, x equals torch dot, let's use a range. We'll create maybe a zero to 100 with a step of 10. Sounds good to me. And we can find the min by going, can we do torch dot min? Maybe we can. Or we could also go x dot min. And then we can do the same, find the max torch dot max and x dot max. Now how do you think we might get the average? So let's try it out. Or find the mean, find the mean torch dot mean x. Oops, we don't have an x. Is this going to work? What's happened? Mean input data type should be either floating point or complex D types got long instead. Ha ha. Finally, I knew the error would show its face eventually. Remember how I said it right up here that we've covered a fair bit already. But right up here, some of the most common errors that you're going to run into is tensor is not the right data type, not the right shape. We've seen that with matrix multiplication, not the right device. We haven't seen that yet. But not the right data type. This is one of those times. So it turns out that the tensor that we created, x is of the data type, x dot D type. In 64, which is long. So if we go to, let's look up torch tensor. This is where they're getting long from. We've seen long before is N64. Where's that or long? Yeah. So long tenter. That's what it's saying. And it turns out that the torch mean function can't work on tensors with data type long. So what can we do here? Well, we can change the data type of x. So let's go torch mean x type and change it to float 32. Or before we do that, if we go to torch dot mean, is this going to tell us that it needs a D type? Oh, D type. One option on the desired data type. Does it have float 32? It doesn't tell us. Ah, so this is another one of those little hidden things that you're going to come across. And you only really come across this by writing code is that sometimes the documentation doesn't really tell you explicitly what D type the input should be, the input tensor. However, we find out that with this error message that it should either be a floating point or a complex D type, not along. So we can convert it to torch float 32. So all we've done is gone x type as type float 32. Let's see what happens here. 45 beautiful. And then the same thing, if we went, can we do x dot mean? Is that going to work as well? Oh, same thing. So if we go x dot type torch dot float 32, get the mean of that. There we go. So that is, I knew it would come up eventually. A beautiful example of finding the right data type. Let me just put a note here. Note the torch dot mean function requires a tensor of float 32. So so far, we've seen two of the major errors in PyTorch is data type and shape issues. What's another one that we said? Oh, some. So find the sum. Find the sum we want x dot sum or maybe we just do torch dot sum first. Keep it in line with what's going on above and x dot sum. Which one of these should you use like torch dot something x or x dot sum? Personally, I prefer torch dot max, but you'll also probably see me at points right this. It really depends on what's going on. I would say pick whichever style you prefer. And because behind the scenes, they're calling the same methodology. Picture whichever style you prefer and stick with that throughout your code. For now, let's leave it at that tensor aggregation. There's some finding min max mean sum. In the next video, we're going to look at finding the positional min and max, which is also known as arg max and arg min or vice versa. So actually, that's a little bit of a challenge for the next video is see how you can find out what the positional min and max is of this. And what I mean by that is which index does the max value occur at and which index of this tensor does the min occur at? You'll probably want to look into the methods arg min torch dot arg min for that one and torch dot arg max for that. But we'll cover that in the next video. I'll see you there. Welcome back. In the last video, we learned all about tensor aggregation. And we found the min the max the mean and the sum. And we also ran into one of the most common issues in pie torch and deep learning and neural networks in general. And that was wrong data types. And so we solved that issue by converting because some functions such as torch dot mean require a specific type of data type as input. And we created our tensor here, which was of by default torch in 64. However, torch dot mean requires torch dot float 32. We saw that in an error. We fix that by changing the type of the inputs. I also issued you the challenge of finding finding the positional min and max. And you might have found that you can use the arg min for the minimum. Let's remind ourselves of what x is x. So this means at tensor index of tensor x. If we find the argument, that is the minimum value, which is zero. So at index zero, we get the value zero. So that's at zero there. Zero there. This is an index value. So this is what arg min stands for find the position in tensor that has the minimum value with arg min. And then returns index position of target tensor where the minimum value occurs. Now, let's just change x to start from one, just so there we go. So the arg min is still position zero, position zero. So this is an index value. And then if we index on x at the zeroth index, we get one. So the minimum value in x is one. And then the maximum, you might guess, is find the position in tensor that has the maximum value with arg max. And it's going to be the same thing, except it'll be the maximum, which is, which position index nine. So if we go zero, one, two, three, four, five, six, seven, eight, nine. And then if we index on x for the ninth element, we get 91 beautiful. Now these two are useful for if yes, you want to define the minimum of a tensor, you can just use min. But if you sometimes you don't want the actual minimum value, you just want to know where it appears, particularly with the arg max value. This is helpful for when we use the soft max activation function later on. Now we haven't covered that yet. So I'm not going to allude too much to it. But just remember to find the positional min and max, you can use arg min and arg max. So that's all we need to cover with that. Let's keep going in the next video. I'll see you then. Welcome back. So we've covered a fair bit of ground. And just to let you know, I took a little break after going through all of these. And I'd just like to show you how I get back to where I'm at, because if we tried to just write x here and press shift and enter, because our collab was disconnected, it's now connecting because as soon as you press any button in collab, it's going to reconnect. It's going to try to connect, initialize, and then x is probably not going to be stored in memory anymore. So there we go. Name x is not defined. That's because the collab state gets reset if you take a break for a couple of hours. This is to ensure Google can keep providing resources for free. And it deletes everything to ensure that there's no compute resources that are being wasted. So to get back to here, I'm just going to go restart and run all. You don't necessarily have to restart the notebook. You could also go, do we have run all? Yeah, we could do run before. That'll run every cell before this. We could run after we could run the selection, which is this cell here. I'm going to click run all, which is just going to go through every single cell that we've coded above and run them all. However, it will also stop at the errors where I've left in on purpose. So remember when we ran into a shape error? Well, because this error, we didn't fix it. I left it there on purpose so that we could keep seeing a shape error. It's going to stop at this cell. So we're going to have to run every cell after the error cell. So see how it's going to run these now. They run fine. And then we get right back to where we were, which was X. So that's just a little tidbit of how I get back into coding. Let's now cover reshaping, stacking, squeezing, and unsqueezing. You might be thinking, squeezing and unsqueezing. What are you talking about, Daniel? Well, it's all to do with tenses. And you're like, are we going to squeeze our tenses? Give them a hug. Are we going to let them go by unsqueezing them? Well, let's quickly define what these are. So reshaping is we saw before one of the most common errors in machine learning and deep learning is shape mismatches with matrices because they have to satisfy certain rules. So reshape reshapes an input tensor to a defined shape. Now, we're just defining these things in words right now, but we're going to see it in code in just a minute. There's also view, which is return a view of an input tensor of certain shape, but keep the same memory as the original tensor. So we'll see what view is in a second. Reshaping and view are quite similar, but a view always shares the same memory as the original tensor. It just shows you the same tensor, but from a different perspective, a different shape. And then we have stacking, which is combine multiple tensors on top of each other. This is a V stack for vertical stack or side by side. H stack. Let's see what different types of torch stacks there are. Again, this is how I research different things. If I wanted to learn something new, I would search torch something stack concatenate a sequence of tensors along a new dimension. Okay. So maybe we not H stack or V stack, we can just define what dimension we'd like to combine them on. I wonder if there is a torch V stack. Torch V stack. Oh, there it is. And is there a torch H stack for horizontal stack? There is a H stack. Beautiful. So we'll focus on just the plain stack. If you want to have a look at V stack, it'll be quite similar to what we're going to do with stack and same with H stack. Again, this is just words for now. We're going to see the code in a minute. So there's also squeeze, which removes all one dimensions. I'm going to put one in code, dimensions from a tensor. We'll see what that looks like. And then there's unsqueeze, which adds a one dimension to our target tensor. And then finally, there's permute, which is return a view of the input with dimensions permuted. So swapped in a certain way. So a fair few methods here. But essentially the crust of all of these, the main point of all of these is to manipulate our tensors in some way to change their shape or change their dimension. Because again, one of the number one issues in machine learning and deep learning is tensor shape issues. So let's start off by creating a tensor and have a look at each of these. Let's create a tensor. And then we're going to just import torch. We don't have to, but this will just enable us to run the notebook directly from this cell if we wanted to, instead of having to run everything above here. So let's create another X torch dot a range because range is deprecated. I'm just going to add a few code cells here so that I can scroll and that's in the middle of the screen there. Beautiful. So let's just make it between one and 10 nice and simple. And then let's have a look at X and X dot shape. What does this give us? Okay, beautiful. So we've got the numbers from one to nine. Our tensor is of shape torch size nine. Let's start with reshape. So how about we add an extra dimension. So then we have X reshaped equals X dot reshape. Now a key thing to keep in mind about the reshape is that the dimensions have to be compatible with the original dimensions. So we're going to change the shape of our original tensor with a reshape. And we try to change it into the shape one seven. Does that work with the number nine? Well, let's find out, hey, let's check out X reshaped. And then we'll look at X reshaped dot shape. What's this going to do? Oh, why do we get an error there? Well, it's telling us here, this is what pie torch is actually really good at is giving us errors for what's going wrong. We have one seven is invalid for input size of nine. Well, why is that? Well, we're trying to squeeze nine elements into a tensor of one times seven into seven elements. But if we change this to nine, what do we get? Ah, so do you notice what just happened here? We just added a single dimension. See the single square bracket with the extra shape here. What if we wanted to add two? Can we do that? No, we can't. Why is that? Well, because two nine is invalid for input size nine, because two times nine is what? 18. So we're trying to double the amount of elements without having double the amount of elements. So if we change this back to one, what happens if we change these around nine one? What does this do? Oh, a little bit different there. So now instead of adding one on the first dimension or the zeroth dimension, because Python is zero indexed, we added it on the first dimension, which is giving us a square bracket here if we go back. So we add it to the outside here, because we've put the one there. And then if we wanted to add it on the inside, we put the one on the outside there. So then we've got the torch size nine one. Now, let's try change the view, change the view. So just to reiterate, the reshape has to be compatible with the original size. So how about we change this to one to 10? So we have a size of 10, and then we can go five, two, what happens there? Oh, it's compatible because five times two equals 10. And then what's another way we could do this? How about we make it up to 12? So we've got 12 elements, and then we can go three, four, a code cells taking a little while run here. Then we'll go back to nine, just so we've got the original there. Whoops, they're going to be incompatible. Oh, so this is another thing. This is good. We're getting some errors on the fly here. Sometimes you'll get saved failed with Google CoLab, and automatic saving failed. What you can do to fix this is just either keep coding, keep running some cells, and CoLab will fix itself in the background, or restart the notebook, close it, and open again. So we've got size nine, or size eight, sorry, incompatible. But this is good. You're seeing the errors that come up on the fly, rather than me sort of just telling you what the errors are, you're seeing them as they come up for me. I'm trying to live code this, and this is what's going to happen when you start to use Google CoLab, and subsequently other forms of Jupyter Notebooks. But now let's get into the view, so we can go z equals, let's change the view of x. View will change it to one nine, and then we'll go z, and then z dot shape. Ah, we get the same thing here. So view is quite similar to reshape. Remember, though, that a view shares the memory with the original tensor. So z is just a different view of x. So z shares the same memory as what x does. So let's exemplify this. So changing z changes x, because a view of a tensor shares the same memory as the original input. So let's just change z, change the first element by using indexing here. So we're targeting one, we'll set this to equal five, and then we'll see what z and x equal. Yeah, so see, we've got z, the first one here, we change the first element, the zero element to five. And the same thing happens with x, we change the first element of z. So because z is a view of x, the first element of x changes as well. But let's keep going. How about we stack some tenses on top of each other? And we'll see what the stack function does in torch. So stack tenses on top of each other. And I'll just see if I press command S to save, maybe we'll get this fixed. Or maybe it just will fix itself. Oh, notebook is saved. Unless you've made some extensive changes that you're worried about losing, you could just download this notebook, so file download, and upload it to collab. But usually if you click yes, it sort of resolves itself. Yeah, there we go. All changes saved. So that's beautiful troubleshooting on the fly. I like that. So x stack, let's stack some tenses together, equals torch stack. Let's go x x x, because if we look at what the doc string of stack is, will we get this in collab? Or we just go to the documentations? Yeah. So list, it takes a list of tenses and concatenates a sequence of tenses along a new dimension. And we define the dimension, the dimension by default is zero. That's a little bit hard to read for me. So tenses, dim equals zero. If we come into here, the default dimension is zero. Let's see what happens when we play around with the dimension here. So we've got four x's. And the first one, we'll just do it by default, x stack. Okay, wonderful. So they're stacked vertically. Let's see what happens if we change this to one. Oh, they rearranged a little and stack like that. What happens if we change it to two? Does it have a dimension to? Oh, we can't do that. Well, that's because the original shape of x is incompatible with using dimension two. So the only real way to get used to what happens here by stacking them on top of each other is to play around with the different values for the dimension. So dim zero, dim one, they look a little bit different there. Now they're on top of each other. And so the first zero index is now the zeroth tensor. And then same with two being there, three and so on. But we'll leave it at the default. And there's also v stack and h stack. I'll leave that to you to to practice those. But I think from memory v stack is using dimension equals zero. Or h stack is like using dimension equals one. I may have those back the front. You can correct me if I'm wrong there. Now let's move on. We're going to now have a look at squeeze and unsqueeze. So actually, I'm going to get you to practice this. So see if you can look up torch squeeze and torch unsqueeze. And see if you can try them out. We've created a tensor here. We've used reshape and view and we've used stack. The usage of squeeze and unsqueeze is quite similar. So give that a go. And to prevent this video from getting too long, we'll do them together in the next video. Welcome back. In the last video, I issued the challenge of trying out torch dot squeeze, which removes all single dimensions from a target tensor. And how would you try that out? Well, here's what I would have done. I'd go to torch dot squeeze and see what happens. Open up the documentation. Squeeze input dimension returns a tensor with all the dimensions of input size one removed. And does it have some demonstrations? Yes, it does. Wow. Okay. So you could copy this in straight into a notebook, copy it here. But what I'd actually encourage you to do quite often is if you're looking up a new torch method you haven't used, code all of the example by hand. And then just practice what the inputs and outputs look like. So x is the input here. Check the size of x, squeeze x, well, set the squeeze of x to y, check the size of y. So let's replicate something similar to this. We'll go into here, we'll look at x reshaped and we'll remind ourselves of x reshaped dot shape. And then how about we see what x reshaped dot squeeze looks like. Okay. What happened here? Well, we started with two square brackets. And we started with a shape of one nine and removes all single dimensions from a target tensor. And now if we call the squeeze method on x reshaped, we only have one square bracket here. So what do you think the shape of x reshaped dot squeeze is going to be? We'll check the shape here. It's just nine. So that's the squeeze method, removes all single dimensions. If we had one one nine, it would remove all of the ones. So it would just end up being nine as well. Now, let's write some print statements so we can have a little pretty output. So previous tensor, this is what I like to do. This is a form of visualize, visualize, visualize. If I'm trying to get my head around something, I print out each successive change to see what's happening. That way, I can go, Oh, okay. So that's what it was there. And then I called that line of code there. Yes, it's a bit tedious. But you do this half a dozen times, a fair few times. I mean, I still do it a lot of the time, even though I've written thousands of lines of machine learning code. But it starts to become instinct after a while, you start to go, Oh, okay, I've got a dimension mismatch on my tensors. So I need to squeeze them before I put them into a certain function. For a little while, but with practice, just like riding a bike, right? But that try saying is like when you first start, you're all wobbly all over the place having to look up the documentation, not that there's much documentation for riding a bike, you just kind of keep trying. But that's the style of coding. I'd like you to adopt is to just try it first. Then if you're stuck, go to the documentation, look something up, print it out like this, what we're doing, quite cumbersome. But this is going to give us a good explanation for what's happening. Here's our previous tensor x reshaped. And then if we look at the shape of x reshaped, it's one nine. And then if we call the squeeze method, which removes all single dimensions from a target tensor, we have the new tensor, which is has one square bracket removed. And the new shape is all single dimensions removed. So it's still the original values, but just a different dimension. Now, let's do the same as what we've done here with unsqueeze. So we've given our tensors a hug and squeezed out all the single dimensions of them. Now we're going to unsqueeze them. We're going to take a step back and let them grow a bit. So torch unsqueeze adds a single dimension to a target tensor at a specific dim dimension. Now that's another thing to note in PyTorch whenever it says dim, that's dimension as in this is a zeroth dimension, first dimension. And if there was more here, we'd go two, three, four, five, six, et cetera. Because why tensors can have unlimited dimensions. So let's go previous target can be excused. So we'll get this squeezed version of our tensor, which is x squeezed up here. And then we'll go print. The previous shape is going to be x squeezed dot shape. And then we're going to add an extra dimension with unsqueeze. There we go, x unsqueezed equals x squeezed. So our tensor before that we remove the single dimension. And we're going to put in unsqueeze, dim, we'll do it on the zeroth dimension. And I want you to have a think about what this is going to output even before we run the code. Just think about, because we've added an extra dimension on the zeroth dimension, what's the new shape of the unsqueeze tensor going to be? So we're going to go x unsqueezed. And then we're going to go print, we'll get our new tensor shape, which is going to be x unsqueezed dot shape. All right, let's have a look. There we go. So there's our previous tensor, which is the squeezed version, just as a single dimension here. And then we have our new tensor, which with the unsqueeze method on dimension zero, we've added a square bracket on the zeroth dimension, which is this one here. Now what do you think's going to happen if I change this to one? Where's the single dimension going to be added? Let's have a look. Ah, so instead of adding the single dimension on the zeroth dimension, we've added it on the first dimension here. It's quite confusing because Python is zero index. So I kind of want to my brain's telling me to say first, but it's really the zeroth index here or the zeroth dimension. Now let's change this back to zero. But that's just another way of exploring things. Every time there's like a parameter that we have here, dim equals something like that could be shape, could be size, whatever, try changing the values. That's what I'd encourage you to do. And even write some print code like we've done here. Now there's one more we want to try out. And that's permute. So torch dot permute rearranges the dimensions of a target tensor in a specified order. So if we wanted to check out, let's get rid of some of these extra tabs. Torch dot permute. Let's have a look. This one took me a little bit of practice to get used to. Because again, working with zeroth dimensions, even though it seems like the first one. So returns a view. Okay. So we know that a view shares the memory of the original input tensor with its dimensions permuted. So permuted for me, I didn't really know what that word meant. I just have mapped in my own memory that permute means rearrange dimensions. So the example here is we start with a random tensor, we check the size, and then we'd have torch permute. We're going to swap the order of the dimensions. So the second dimension is first, the zeroth dimension is in the middle, and the first dimension is here. So these are dimension values. So if we have torch random two, three, five, two, zero, one has changed this one to be over here. And then zero, one is two, three, and now two, three there. So let's try something similar to this. So one of the common places you'll be using permute, or you might see permute being used is with images. So there's a data specific data format. We've kind of seen a little bit before, not too much. Original equals torch dot rand size equals. So an image tensor, we go height width color channels on the end. So I'll just write this down. So this is height width color channels. Remember, much of, and I'm going to spell color Australian style, much of deep learning is turning your data into numerical representations. And this is quite common numerical representation of image data. You have a tensor dimension for the height, a tensor dimension for the width, and a tensor dimension for the color channels, which is red, green, and blue, because a certain number of red, green, and blue creates almost any color. Now, if we want to permute this, so permute the original tensor to rearrange the axis or dimension, axis or dimension, are kind of used in the same light for tensors or dim order. So let's switch the color channels to be the first or the zeroth dimension. So instead of height width color channels, it'll be color channels height width. How would we do that with permute? Let's give it a shot. X permuted equals X original dot permute. And we're going to take the second dimension, because this takes a series of dims here. So the second dimension is color channels. Remember, zero, one, two. So two, we want two first, then we want the height, which is a zero. And then we want the width, which is one. And now let's do this shifts, axis, zero to one, one to two, and two to zero. So this is the order as well. This two maps to zero. This zero maps to the first index. This one maps to this index. But that's enough talk about it. Let's see what it looks like. So print, previous shape, X original dot shape. And then we go here, print new shape. This will be the permuted version. We want X permuted dot shape. Let's see what this looks like. Wonderful. That's exactly what we wanted. So you see, let's just write a little note here. Now this is color channels, height, width. So the same data is going to be in both of these tenses. So X original X permuted, it's just viewed from a different point of view. Because remember, a permute is a view. And what did we discuss? A view shares the same memory as the original tensor. So X permuted will share the same place in memory as X original, even though it's from a different shape. So a little challenge before we move on to the next video for you, or before you move on to the next video, try change one of the values in X original. Have a look at X original. And see if that same value, it could be, let's get one of this zero, zero, get all of the dimensions here, zero. See what that is? Or can we get a single value maybe? Oops. Oh, no, we'll need a zero here, getting some practice on indexing here. Oh, zero, zero, zero. There we go. Okay, so maybe we set that to some value, whatever you choose, and see if that changes in X permuted. So give that a shot, and I'll see you in the next video. Welcome back. In the last video, we covered squeezing, unsqueezing, and permuting, which I'm not going to lie, these concepts are quite a lot to take in, but just so you're aware of them. Remember, what are they working towards? They're helping us fix shape and dimension issues with our tensors, which is one of the most common issues in deep learning and neural networks. And I usually do the little challenge of changing a value of X original to highlight the fact that permute returns a different view of the original tensor. And a view in PyTorch shares memory with that original tensor. So if we change the value at zero, zero, zero of X original to, in my case, 728218, it happens the same value gets copied across to X permuted. So with that being said, we looked at selecting data from tensors here, and this is using a technique called indexing. So let's just rehash that, because this is another thing that can be a little bit of a hurdle when first working with multi dimensional tensors. So let's see how we can select data from tensors with indexing. So if you've ever done indexing, indexing, with PyTorch is similar to indexing with NumPy. If you've ever worked with NumPy, and you've done indexing, selecting data from arrays, NumPy uses an array as its main data type, PyTorch uses tensors. It's very similar. So let's again start by creating a tensor. And again, I'm just going to add a few code cells here, so I can make my screen right in the middle. Now we're going to import torch. Again, we don't need to import torch all the time, just so you can run the notebook from here later on. X equals torch dot. Let's create a range again, just nice and simple. This is how I like to work out the fundamentals too, is just create the small range, reshape it, and the reshape has to be compatible with the original dimension. So we go one, three, three, and why is this because torch a range is going to return us nine values, because it's from the start here to the end minus one, and then one times three times three is what is nine. So let's have a look x x dot shape. Beautiful. So we have one, two, three, four, five, six, seven, eight, nine of size one. So we have this is the outer bracket here, which is going to contain all of this. And then we have three, which is this one here, one, two, three. And then we have three, which is one, two, three. Now let's work with this. Let's index on our new tensor. So let's see what happens when we get x zero, this is going to index on the first bracket. So we get this one here. So we've indexed on the first dimension here, the zero dimension on this one here, which is why we get what's inside here. And then let's try again, let's index on the middle bracket. So dimension one. So we got to go x, and then zero, and then zero. Let's see what happens there. Now is this the same as going x zero, zero? It is, there we go. So it depends on what you want to use. Sometimes I prefer to go like this. So I know that I'm getting the first bracket, and then the zeroth version of that first bracket. So then we have these three values here. Now what do you think what's going to happen if we index on third dimension or the second dimension here? Well, let's find out. So let's index on the most in our bracket, which is last dimension. So we have x zero, zero, zero. What numbers is going to give us back of x zero, on the zero dimension gives us back this middle tensor. And then if x zero, zero gives us back the zeroth index of the middle tensor. If we go x zero, zero, zero is going to give us the zeroth tensor, the zeroth index, and the zeroth element. A lot to take in there. But what we've done is we've just broken it down step by step. We've got this first zero targets this outer bracket and returns us all of this. And then zero, zero targets this first because of this first zero, and then the zero here targets this. And then if we go zero, zero, zero, we target this, then we target this, and then we get this back because we are getting the zeroth index here. So if we change this to one, what do we get back? Two. And if we change these all to one, what will we get? This is a bit of trivia here, or a challenge. So we're going one, one, one. Let's see what happens. Oh, no, did you catch that before I ran the code? I did that one quite quickly. We have index one is out of bounds. Why is that? Well, because this dimension is only one here. So we can only index on the zero. That's where it gets a little bit confusing because this says one, but because it's only got zero dimension, we can only index on the zero if to mention. But what if we do 011? What does that give us? Five. Beautiful. So I'd like to issue you the challenge of how about getting number nine? How would you get number nine? So rearrange this code to get number nine. That's your challenge. Now, I just want to show you as well, is you can use, you can also use, you might see this, the semicolon to select all of a target dimension. So let's say we wanted to get all of the zeroth dimension, but the zero element from that. We can get 123. And then let's say we want to say get all values of the zeroth and first dimensions, but only index one of the second dimension. Oh, that was a mouthful. But get all values of zeroth and first dimensions, but only index one of second dimension. So let's break this down step by step. We want all values of zeroth and first dimensions, but only index one of the second dimension. We press enter, shift enter, 258. So what did we get there? 258. Okay. So we've got all elements of the zeroth and first dimension, but then so which will return us this thing here. But then we only want 258, which is the first element here of the second dimension, which is this three there. So quite confusing. But with some practice, you can figure out how to select almost any numbers you want from any kind of tensor that you have. So now let's try again, get all values of the zero dimension, but only the one index value of the first and second dimension. So what might this look like? Let's break it down again. So we come down here x, and we're going to go all values of the zero dimension because zero comes first. And then we want only the one index value of the first and only the one index value of the second. What is this going to give us five? Oh, we selected the middle tensor. So really, this line of code is exactly the same as this line of code here, except we've got the square brackets on the outside here, because we've got this semicolon there. So if we change this to a zero, we remove that. But because we've got the semicolon there, we've selected all the dimensions. So we get back the square bracket there, something to keep in mind. Finally, let's just go one more. So get index zero of zero and first dimension, and all values of second dimension. So x zero, zero. So zero, the index of zero and first dimension, zero, zero, and all values of the second dimension. What have we just done here? We've got tensor one, two, three, lovely. This code again is equivalent to what we've done up here. This has a semicolon on the end. But what this line explicitly says without the semicolon is, hey, give us all the values on the remaining dimension there. So my challenge for you is to take this tensor that we have got here and index on it to return nine. So I'll write down here, index on x to return nine. So if you have a look at x, as well as index on x to return three, six, nine. So these values here. So give those both a go and I'll see you in the next video. Welcome back. How'd you go? Did you give the challenge ago? I finished the last video with issuing the challenge to index on x to return nine and index on x to return three, six, nine. Now here's what I came up with. Again, there's a few different ways that you could approach both of these. But this is just what I've found. So because x is one, three, three of size, well, that's his dimensions. If we want to select nine, we need zero, which is this first outer bracket to get all of these elements. And then we need two to select this bottom one here. And then we need this final two to select the second dimension of this bottom one here. And then for three, six, nine, we need all of the elements in the first dimension, all of the in the zeroth dimension, all of the elements in the first dimension. And then we get two, which is this three, six, nine set up here. So that's how I would practice indexing, start with whatever shape tensor you like, create it something like this, and then see how you can write different indexing to select whatever number you pick. So now let's move on to the next part, which is PyTorch tensors and NumPy. So NumPy is a popular scientific, very popular. PyTorch actually requires NumPy when you install PyTorch. Popular scientific Python numerical computing library, that's a bit of a mouthful. And because of this, PyTorch has functionality to interact with it. So quite often, you might start off with, let's change this into Markdown, you might start off with your data, because it's numerical format, you might start off with data in NumPy, NumPy array, want in PyTorch tensor. Because your data might be represented by NumPy because it started in NumPy, but say you want to do some deep learning on it and you want to leverage PyTorch's deep learning capabilities, well, you might want to change your data from NumPy to a PyTorch tensor. And PyTorch has a method to do this, which is torch from NumPy, which will take in an ND array, which is NumPy's main data type, and change it into a torch tensor. We'll see this in a second. And then if you want to go from PyTorch tensor to NumPy because you want to use some sort of NumPy method, well, the method to do this is torch dot tensor, and you can call dot NumPy on it. But this is all just talking about in words, let's see it in action. So NumPy array to tensor. Let's try this out first. So we'll import torch so we can run this cell on its own, and then import NumPy as np, the common naming convention for NumPy, we're going to create an array in NumPy. And we're going to just put one to eight, a range. And then we're going to go tensor equals torch from NumPy because we want to go from NumPy array to a torch tensor. So we use from NumPy, and then we pass in array, and then we have array and tensor. Wonderful. So there's our NumPy array, and our torch tensor with the same data. But what you might notice here is that the D type for the tensor is torch dot float 64. Now why is this? It's because NumPy's default data type. Oh, D type is float 64. Whereas tensor, what have we discussed before? What's pytorch's default data type? float 64. Well, that's not pytorch's default data type. If we were to create torch, a range, 1.0 to 8.0, by default, pytorch is going to create it in float 32. So just be aware of that. If you are going from NumPy to pytorch, the default NumPy data type is float 64. And pytorch reflects that data type when you use the from NumPy method. I wonder if there's a D type. Can we go D type equals torch dot float 32? Takes no keyword. Okay. But how could we change the data type here? Well, we could go type torch float 32. Yeah, that will give us a tensor D type of float 32 instead of float 64. Beautiful. I'll just keep that there so you know, warning when converting from NumPy pytorch, pytorch reflects NumPy's default data type of float 64, unless specified. Otherwise, because what have we discussed, when you're trying to perform certain calculations, you might run into a data type issue. So you might need to convert the type from float 64 to float 32. Now, let's see what happens. What do you think will happen if we change the array? We change the value of an array. Well, let's find out. So change the value of array. The question is, what will this do to tensor? Because we've used the from NumPy method, do you think if we change the array, the tensor will change? So let's try this array equals array plus one. So we're just adding one to every value in the array. Now, what is the array and the tensor going to look like? Uh huh. So array, we only change the first value there. Oh, sorry, we change every value because we have one to seven. Now it's two, three, four, five, six, seven, eight. We change the value from the array. It doesn't change the value of the tensor. So that's just something to keep in mind. If you use from NumPy, we get a new tensor in memory here. So the original, the new tensor doesn't change if you change the original array. So now let's go from tensor to NumPy. If you wanted to go back to NumPy, tensor to NumPy array. So we'll start with a tensor. We could use the one we have right now, but we're going to create another one, but we'll create one of ones just for fun. One rhymes with fun. NumPy tensor equals. How do we go to NumPy? Well, we have torch dot tensor dot NumPy. So we just simply call NumPy on here. And then we have tensor and NumPy tensor. What data type do you think the NumPy tensor is going to have? Because we've returned it to NumPy. Pi torches, default data type is Flight 32. So if we change that to NumPy, what's going to be the D type of the NumPy tensor? NumPy tensor dot D type. It reflects the original D type of what you set the tensor as. So just keep that in mind. If you're going between PyTorch and NumPy, default data type of NumPy is float 64, whereas the default data type of PyTorch is float 32. So that may cause some errors if you're doing different kinds of calculations. Now, what do you think is going to happen if we went from our tensor to an array, if we change the tensor, change the tensor, what happens to NumPy tensor? So we get tensor equals tensor plus one. And then we go NumPy tensor. Oh, we'll get tensor as well. So our tensor is now all twos because we added one to the ones. But our NumPy tensor remains the same. Remains unchanged. So this means they don't share memory. So that's how we go in between PyTorch and NumPy. If you'd like to look up more, I'd encourage you to go PyTorch and NumPy. So warm up NumPy, beginner. There's a fair few tutorials here on PyTorch because NumPy is so prevalent, they work pretty well together. So have a look at that. There's a lot going on there. There's a few more links, I'd encourage you to check out, but we've covered some of the main ones that you'll see in practice. With that being said, let's now jump into the next video where we're going to have a look at the concept of reproducibility. If you'd like to look that up, I'd encourage you to search PyTorch's reproducibility and see what you can find. Otherwise, I'll see you in the next video. Welcome back. It's now time for us to cover the topic of reproducibility. If I could even spell it, that would be fantastic. Reproducibility. Trying to take the random out of random. So we've touched upon the concept of neural networks harnessing the power of randomness. And what I mean by that is we haven't actually built our own neural network yet, but we will be doing that. And we've created tenses full of random values. And so in short, how our neural network learns is start with random numbers, perform tensor operations, update random numbers to try and make them better representations of the data. Again, again, again, again, again. However, if you're trying to do reproducible experiments, sometimes you don't want so much randomness. And what I mean by this is if we were creating random tensors, from what we've seen so far is that every time we create a random tensor, let's create one here, torch dot rand, and we'll create it of three three. Every time we run this cell, it gives us new numbers. So 7 7 5 2. There we go. Rand again. Right. So we get a whole bunch of random numbers here. Every single time. But what if you were trying to share this notebook with a friend, so say you went up share and you clicked the share link and you sent that to someone and you're like, hey, try out this machine learning experiment I did. And you wanted a little less randomness because neural networks start with random numbers. How might you do that? Well, let's this write down to reduce the randomness in neural networks. And pytorch comes the concept of a random seed. So we're going to see this in action. But essentially, let's write this down, essentially what the random seed does is flavor the randomness. So because of how computers work, they're actually not true randomness. And actually, there's arguments against this, and it's quite a big debate in the computer science topic, whatnot, but I am not a computer scientist, I am a machine learning engineer. So computers are fundamentally deterministic. It means they run the same steps over and over again. So what the randomness we're doing here is referred to as pseudo randomness or generated randomness. And the random seed, which is what you see a lot in machine learning experiments, flavors that randomness. So let's see it in practice. And at the end of this video, I'll give you two resources that I'd recommend to learn a little bit more about the concept of pseudo randomness and reproducibility in pytorch. Let's start by importing torch so you could start this notebook right from here. Create two random tensors. We'll just call this random tensor a equals torch dot rand and we'll go three four and we'll go random tensor b equals torch dot rand same size three four. And then if we have a look at let's go print random tensor a print random tensor b. And then let's print to see if they're equal anywhere random tensor a equals equals equals random tensor b. Now what do you think this is going to do? If we have a look at one equals one, what does it return? True. So this is comparison operator to compare two different tensors. We're creating two random tensors here. We're going to have a look at them. We'd expect them to be full of random values. Do you think any of the values in each of these random tensors is going to be equal to each other? Well, there is a chance that they are, but it's highly unlikely. I'll be quite surprised if they are. Oh, again, my connection might be a little bit. Oh, there we go. Beautiful. So we have tensor a tensor of three four with random numbers. And we have tensor b of three four with random numbers. So if we were, if I was to share this notebook with my friend or my colleague or even you, if you ran this cell, you are going to get random numbers as well. And you have every chance of replicating one of these numbers. But again, it's highly unlikely. So again, I'm getting that automatic save failed. You might get that if your internet connection is dropping out, maybe that's something going on with my internet connection. But again, as we've seen, usually this resolves itself. If you try a few times, I'll just keep coding. If it really doesn't resolve itself, you can go file is a download notebook or save a copy and drive download. You can download the notebook, save it to your local machine, re upload it to upload notebook and start again in another Google Colab instance. But there we go. It fixed itself. Wonderful troubleshooting on the fly. So the way we make these reproducible is through the concept of a random seed. So let's have a look at that. Let's make some random, but reproducible tenses. So import torch. And we're going to set the random seed by going torch dot manual seed random. Oh, we don't have random set yet. I'm going to set my random seed. You set the random seed to some numerical value. 42 is a common one. You might see zero. You might see one, two, three, four. Essentially, you can set it to whatever you want. And each of these, you can think of 77, 100, as different flavors of randomness. So I like to use 42, because it's the answer to the universe. And then we go random seed. And now let's create some random tenses. Random tensor C with the flavor of our random seed. Three, four. And then we're going to go torch tensor D equals torch dot rand three, four. Now, let's see what happens. We'll print out random tensor C. And we'll print out random tensor D. And then we'll print out to see if they're equal anywhere. Random tensor C equals random tensor D. So let's find out what happens. Huh, what gives? Well, we've got randomness. We set the random seed. We're telling pytorch a flavor our randomness with 42 torch manual seed. Hmm, let's try set the manual seed each time we call a random method. We go there. Ah, much better. So now we've got some flavored randomness. So a thing to keep in mind is that if you want to use the torch manual seed, generally it only works for one block of code if you're using a notebook. So that's just something to keep in mind. If you're creating random tensors, one after the other, we're using assignment like this, you should use torch dot manual seed every time you want to call the rand method or some sort of randomness. However, if we're using other torch processes, usually what you might see is torch manual seed is set right at the start of a cell. And then a whole bunch of code is done down here. But because we're calling subsequent methods here, we have to reset the random seed. Otherwise, if we don't do this, we comment this line, it's going to flavor the randomness of torch random tensor C with torch manual seed. But then random tensor D is just going to have no flavor. It's not going to use a random seed. So we reset it there. Wonderful. So I wonder, does this have a seed method? Let's go torch dot rand. Does this have seed? Sometimes they have a seed method. Seed, no, it doesn't. Okay, that's all right. The more you learn, but there's documentation for torch dot rand. And I said that I was going to link at the end of this video. So the manual seed is a way to, or the random seed, but in torch, it's called a manual seed is a way to flavor the randomness. So these numbers, as you see, are still quite random. But the random seed just makes them reproducible. So if I was to share this with you, if you had to run this block of code, ideally, you're going to get the same numerical output here. So with that being said, I'd like to refer to you to the pie torch reproducibility document, because we've only quite scratched the surface of this of reproducibility. We've covered one of the main ones. But this is a great document on how to go through reproducibility in pie torch. So this is your extra curriculum for this, even if you don't understand what's going on in a lot of the code here, just be aware of reproducibility, because it's an important topic in machine learning and deep learning. So I'll put this here, extra resources for reproducibility. As we go pie torch randomness, we'll change this into markdown. And then finally, the concept of a random seed is Wikipedia random seed. So random seeds quite a universal concept, not just for pie torch, there's a random seed and NumPy as well. So if you'd like to see what this means, yeah, initialize a pseudo random number generator. So that's a big word, pseudo random number generator. But if you'd like to learn about more random number generation computing, and what a random seed does is I'd refer to you to check out this documentation here. Whoo, far out, we have covered a lot. But there's a couple more topics you should really be aware of to finish off the pie torch fundamentals. You got this. I'll see you in the next video. Welcome back. Now, let's talk about the important concept of running tenses or pie torch objects. So running tenses and pie torch objects on GPUs and making faster computations. So we've discussed that GPUs, let me just scroll down a little bit here, GPUs equal faster computation on numbers. Thanks to CUDA plus NVIDIA hardware plus pie torch working behind the scenes to make everything hunky dory. Good. That's what hunky dory means, by the way, if you never heard that before. So let's have a look at how we do this. Now, we first need to talk about, let's go here one getting a GPU. There's a few different ways we've seen one before. Number one easiest is to use what we're using right now. Use Google Colab for a free GPU. But there's also Google Colab Pro. And I think there might even be, let's look up Google Colab Pro. Choose the best that's right for you. I use Google Colab Pro because I use it almost every day. So yeah, I pay for Colab Pro. You can use Colab for free, which is might be what you're using. There's also Colab Pro Plus, which has a lot more advantages as well. But Colab Pro is giving me faster GPUs, so access to faster GPUs, which means you spend less time waiting while your code is running. More memory, longer run time, so it'll last a bit longer if you leave it running idle. And then Colab Pro again is a step up from that. I personally haven't had a need yet to use Google Colab Pro Plus. You can complete this whole course on the free tier as well. But as you start to code more, as you start to run bigger models, as you start to want to compute more, you might want to look into something like Google Colab Pro. Or let's go here. Options to upgrade as well. And then another way is use your own GPU. Now this takes a little bit of setup and requires the investment of purchasing a GPU. There's lots of options. So one of my favorite posts for getting a GPU is, yeah, the best GPUs for deep learning in 2020, or something like this. What do we got? Deep learning? Tim Detmos. This is, yeah, which GPUs to get for deep learning? Now, I believe at the time of this video, I think it's been updated since this date. So don't take my word for it. But this is a fantastic blog post for figuring out what GPUs see this post for what option to get. And then number three is use cloud computing. So such as GCP, which is Google Cloud Platform AWS, which is Amazon Web Services or Azure. These services, which is Azure is by Microsoft, allow you to rent computers on the cloud and access them. So the first option using Google Colab, which is what we're using is by far the easiest and free. So there's big advantages there. However, the downside is that you have to use a website here, Google Colab, you can't run it locally. You don't get the benefit of using cloud computing, but my personal workflow is I run basically all of my small scale experiments and things like learning new stuff in Google Colab. And then if I want to upgrade things, run video experiments, I have my own dedicated deep learning PC, which I have built with a big powerful GPU. And then also I use cloud computing if necessary. So that's my workflow. Start with Google Colab. And then these two, if I need to do some larger experiments. But because this is the beginning of course, we can just stick with Google Colab for the time being. But I thought I'd make you aware of these other two options. And if you'd like to set up a GPU, so four, two, three, PyTorch plus GPU drivers, which is CUDA takes a little bit of setting up to do this, refer to PyTorch setup documentation. So if we go to pytorch.org, they have some great setup guides here, get started. And we have start locally. This is if you want to run on your local machine, such as a Linux setup. This is what I have Linux CUDA 11.3. It's going to give you a conda install command to use conda. And then if you want to use cloud partners, which is Alibaba Cloud, Amazon Web Services, Google Cloud Platform, this is where you'll want to go. So I'll just link this in here. But for this course, we're going to be focusing on using Google Colab. So now, let's see how we might get a GPU in Google Colab. And we've already covered this, but I'm going to recover it just so you know. We're going to change the runtime type. You can go in any notebook and do this, runtime type, hardware accelerator, we can select GPU, click save. Now this is going to restart our runtime and connect us to our runtime, aka a Google compute instance with a GPU. And so now if we run NVIDIA SMI, I have a Tesla P100 GPU. So let's look at this Tesla P100 GPU. Do we have an image? Yeah, so this is the GPU that I've got running, not the Tesla car, the GPU. So this is quite a powerful GPU. That is because I have upgraded to Colab Pro. Now, if you're not using Colab Pro, you might get something like a Tesla K80, which is a slightly less powerful GPU than a Tesla P100, but still a GPU nonetheless and will still work faster than just running PyTorch code on the pure CPU, which is the default in Google Colab and the default in PyTorch. And so now we can also check to see if we have GPU access with PyTorch. So let's go here. This is number two now. Check for GPU access with PyTorch. So this is a little command that's going to allow us or tell us if PyTorch, just having the GPU here, this is by the way, another thing that Colab has a good setup with, is that all the connections between PyTorch and the NVIDIA GPU are set up for us. Whereas when you set it up on your own GPU or using cloud computing, there are a few steps you have to go through, which we're not going to cover in this course. I'd highly recommend you go through the getting started locally set up if you want to do that, to connect PyTorch to your own GPU. So let's check for the GPU access with PyTorch. This is another advantage of using Google Colab. Almost zero set up to get started. So import torch and then we're going to go torch dot cuda dot is available. And remember, cuda is NVIDIA's programming interface that allows us to use GPUs for numerical computing. There we go, beautiful. So big advantage of Google Colab is we get access to a free GPU. In my case, I'm paying for the faster GPU, but in your case, you're more than welcome to use the free version. All that means it'll be slightly slower than a faster GPU here. And we now have access to GPUs with PyTorch. So there is one more thing known as device agnostic code. So set up device agnostic code. Now, this is an important concept in PyTorch because wherever you run PyTorch, you might not always have access to a GPU. But if there was access to a GPU, you'd like it to use it if it's available. So one of the ways that this is done in PyTorch is to set the device variable. Now, really, you could set this to any variable you want, but you're going to see it used as device quite often. So cuda if torch dot cuda is available. Else CPU. So all this is going to say, and we'll see where we use the device variable later on is set the device to use cuda if it's available. So it is so true. If it's not available, if we don't have access to a GPU that PyTorch can use, just default to the CPU. So with that being said, there's one more thing. You can also count the number of GPUs. So this won't really apply to us for now because we're just going to stick with using one GPU. But as you upgrade your PyTorch experiments and machine learning experiments, you might have access to more than one GPU. So you can also count the devices here. We have access to one GPU, which is this here. So the reason why you might want to count the number of devices is because if you're running huge models on large data sets, you might want to run one model on a certain GPU, another model on another GPU, and so on and so on. But final thing before we finish this video is if we go PyTorch device agnostic code, cuda semantics, there's a little section in here called best practices. This is basically what we just covered there is setting the device argument. Now this is using the arg pass, but so yeah, there we go. args.device, torch.device, cuda, args.device, torch.device, CPU. So this is one way to set it from the Python arguments when you're running scripts, but we're using the version of running it through a notebook. So check this out. I'll just link this here, device agnostic code. It's okay if you're not sure of what's going on here. We're going to cover it a little bit more later on throughout the course, but right here for PyTorch, since it's capable of running compute on the GPU or CPU, it's best practice to set up device agnostic code, e.g. run on GPU if available, else default to CPU. So check out the best practices for using cuda, which is namely setting up device agnostic code. And let's in the next video, see what I mean about setting our PyTorch tensors and objects to the target device. Welcome back. In the last video, we checked out a few different options for getting a GPU, and then getting PyTorch to run on the GPU. And for now we're using Google Colab, which is the easiest way to get set up because it gives us free access to a GPU, faster ones if you set up with Colab Pro, and it comes with PyTorch automatically set up to use the GPU if it's available. So now let's see how we can actually use the GPU. So to do so, we'll look at putting tensors and models on the GPU. So the reason we want our tensors slash models on the GPU is because using GPU results in faster computations. And if we're getting our machine learning models to find patterns and numbers, GPUs are great at doing numerical calculations. And the numerical calculations we're going to be doing are tensor operations like we saw above. So the tensor operations, well, we've covered a lot. Somewhere here, tensor operations, there we go, manipulating tensor operations. So if we can run these computations faster, we can discover patterns in our data faster, we can do more experiments, and we can work towards finding the best possible model for whatever problem that we're working on. So let's see, we'll create a tensor, as usual, create a tensor. Now the default is on the CPU. So tensor equals torch dot tensor. And we'll just make it a nice simple one, one, two, three. And let's write here, tensor not on GPU will print out tensor. And this is where we can use, we saw this parameter before device. Can we pass it in here? Device equals CPU. Let's see what this comes out with. There we go. So if we print it out, tensor 123 is on the CPU. But even if we got rid of that device parameter, by default, it's going to be on the CPU. Wonderful. So now PyTorch makes it quite easy to move things to, and I'm saying to for a reason, to the GPU, or to, even better, the target device. So if the GPU is available, we use CUDA. If it's not, it uses CPU. This is why we set up the device variable. So let's see, move tensor to GPU. If available, tensor on GPU equals tensor dot two device. Now let's have a look at this, tensor on GPU. So this is going to shift the tensor that we created up here to the target device. Wonderful. Look at that. So now our tensor 123 is on device CUDA zero. Now this is the index of the GPU that we're using, because we only have one, it's going to be at index zero. So later on, when you start to do bigger experiments and work with multiple GPUs, you might have different tensors that are stored on different GPUs. But for now, we're just sticking with one GPU, keeping it nice and simple. And so you might have a case where you want to move, oh, actually, the reason why we set up device agnostic code is again, this code would work if we run this, regardless if we had, so it won't error out. But regardless if we had a GPU or not, this code will work. So whatever device we have access to, whether it's only a CPU or whether it's a GPU, this tensor will move to whatever target device. But since we have a GPU available, it goes there. You'll see this a lot. This two method moves tensors and it can be also used for models. We're going to see that later on. So just keep two device in mind. And then you might want to, for some computations, such as using NumPy, NumPy only works with the CPU. So you might want to move tensors back to the CPU, moving tensors back to the CPU. So can you guess how we might do that? It's okay if you don't know. We haven't covered a lot of things, but I'm going to challenge you anyway, because that's the fun part of thinking about something. So let's see how we can do it. Let's write down if tensor is on GPU, can't transform it to NumPy. So let's see what happens if we take our tensor on the GPU and try to go NumPy. What happens? Well, we get an error. So this is another huge error. Remember the top three errors in deep learning or pytorch? There's lots of them, but number one, shape errors, number two, data type issues. And with pytorch, number three is device issues. So can't convert CUDA zero device type tensor to NumPy. So NumPy doesn't work with the GPU. Use tensor dot CPU to copy the tensor to host memory first. So if we call tensor dot CPU, it's going to bring our target tensor back to the CPU. And then we should be able to use it with NumPy. So to fix the GPU tensor with NumPy issue, we can first set it to the CPU. So tensor back on CPU equals tensor on GPU dot CPU. We're just taking what this said here. That's a beautiful thing about pytorch is very helpful error messages. And then we're going to go NumPy. And then if we go tensor back on CPU, is this going to work? Let's have a look. Oh, of course, it's not because I typed it wrong. And I've typed it again twice. Third time, third time's a charm. There we go. Okay, so that works because we've put it back to the CPU first before calling NumPy. And then if we refer back to our tensor on the GPU, because we've reassociated this, again, we've got typos galore classic, because we've reassigned tensor back on CPU, our tensor on GPU remains unchanged. So that's the four main things about working with pytorch on the GPU. There are a few more tidbits such as multiple GPUs, but now you've got the fundamentals. We're going to stick with using one GPU. And if you'd like to later on once you've learned a bit more research into multiple GPUs, well, as you might have guessed, pytorch has functionality for that too. So have a go at getting access to a GPU using colab, check to see if it's available, set up device agnostic code, create a few dummy tensors and just set them to different devices, see what happens if you change the device parameter, run a few errors by trying to do some NumPy calculations with tensors on the GPU, and then bring those tensors on the GPU back to NumPy and see what happens there. So I think we've covered, I think we've reached the end of the fundamentals. We've covered a fair bit. Introduction to tensors, the minmax, a whole bunch of stuff inside the introduction to tensors, finding the positional minmax, reshaping, indexing, working with tensors and NumPy, reproducibility, using a GPU and moving stuff back to the GPU far out. Now you're probably wondering, Daniel, we've covered a whole bunch. What should I do to practice all this? Well, I'm glad you asked. Let's cover that in the next video. Welcome back. And you should be very proud of your self right now. We've been through a lot, but we've covered a whole bunch of PyTorch fundamentals. These are going to be the building blocks that we use throughout the rest of the course. But before moving on to the next section, I'd encourage you to try out what you've learned through the exercises and extra curriculum. Now, I've set up a few exercises here based off everything that we've covered. If you go into learn pytorch.io, go to the section that we're currently on. This is going to be the case for every section, by the way. So just keep this in mind, is we're working on PyTorch fundamentals. Now, if you go to the PyTorch fundamentals notebook, this is going to refresh, but that if you scroll down to the table of contents at the bottom of each one is going to be some exercises and extra curriculum. So these exercises here, such as documentation reading, because a lot you've seen me refer to the PyTorch documentation for almost everything we've covered a lot, but it's important to become familiar with that. So exercise number one is read some of the documentation. Exercise number two is create a random tensor with shape, seven, seven. Three, perform a matrix multiplication on the tensor from two with another random tensor. So these exercises are all based off what we've covered here. So I'd encourage you to reference what we've covered in whichever notebook you choose, could be this learn pytorch.io, could be going back through the one we've just coded together in the video. So I'm going to link this here, exercises, see exercises for this notebook here. So then how should you approach these exercises? So one way would be to just read them here, and then in collab we'll go file new notebook, wait for the notebook to load. Then you could call this zero zero pytorch exercises or something like that, and then you could start off by importing torch, and then away you go. For me, I'd probably set this up on one side of the screen, this one up on the other side of the screen, and then I just have the exercises here. So number one, I'm not going to really write much code for that, but you could have documentation reading here. And then so this encourages you to read through torch.tensor and go through there for 10 minutes or so. And then for the other ones, we've got create a random tensor with shape seven seven. So we just comment that out. So torch, round seven seven, and there we go. Some are as easy as that. Some are a little bit more complex. As we go throughout the course, these exercises are going to get a little bit more in depth as we've learned more. But if you'd like an exercise template, you can come back to the GitHub. This is the home for all of the course materials. You can go into extras and then exercises. I've created templates for each of the exercises. So pytorch fundamentals exercises. If you open this up, this is a template for all of the exercises. So you see there, create a random tensor with shape seven seven. These are all just headings. And if you'd like to open this in CoLab and work on it, how can you do that? Well, you can copy this link here. Come to Google CoLab. We'll go file, open notebook, GitHub. You can type in the link there. Click search. What's this going to do? Boom. Pytorch fundamentals exercises. So now you can go through all of the exercises. This will be the same for every module on the course and test your knowledge. Now it is open book. You can use the notebook here, the ones that we've coded together. But I would encourage you to try to do these things on your own first. If you get stuck, you can always reference back. And then if you'd like to see an example solutions, you can go back to the extras. There's a solutions folder as well. And that's where the solutions live. So the fundamental exercise solutions. But again, I would encourage you to try these out, at least give them a go before having a look at the solutions. So just keep that in mind at the end of every module, there's exercises and extra curriculum. The exercises will be code based. The extra curriculum is usually like reading based. So spend one hour going through the Pytorch basics tutorial. I recommend the quick start in tensor sections. And then finally to learn more on how a tensor can represent data, watch the video what's a tensor which we referred to throughout this. But massive effort on finishing the Pytorch fundamentals section. I'll see you in the next section. Friends, welcome back to the Pytorch workflow module. Now let's have a look at what we're going to get into. So this is a Pytorch workflow. And I say a because it's one of many. When you get into deep learning machine learning, you'll find that there's a fair few ways to do things. But here's the rough outline of what we're going to do. We're going to get our data ready and turn it into tensors because remember a tensor can represent almost any kind of data. We're going to pick or build or pick a pre-trained model. We'll pick a loss function and optimize it. Don't worry if you don't know what they are. We're going to cover this. We're going to build a training loop, fit the model to make a prediction. So fit the model to the data that we have. We'll learn how to evaluate our models. We'll see how we can improve through experimentation and we'll save and reload our trained model. So if you wanted to export your model from a notebook and use it somewhere else, this is what you want to be doing. And so where can you get help? Probably the most important thing is to follow along with the code. We'll be coding all of this together. Remember model number one. If and out, run the code. Try it for yourself. That's how I learn best. Is I write code? I try it. I get it wrong. I try again and keep going until I get it right. Read the doc string because that's going to show you some documentation about the functions that we're using. So on a Mac, you can use shift command and space in Google Colab or if you're on a Windows PC, it might be control here. If you're still stuck, try searching for it. You'll probably come across resources such as stack overflow or the PyTorch documentation. We've already seen this a whole bunch and we're probably going to see it a lot more throughout this entire course actually because that's going to be the ground truth of everything PyTorch. Try again. And finally, if you're still stuck, ask a question. So the best place to ask a question will be at the PyTorch deep learning slash discussions tab. And then if we go to GitHub, that's just under here. So Mr. Deeburg PyTorch deep learning. This is all the course materials. We see here, this is your ground truth for the entire course. And then if you have a question, go to the discussions tab, new discussion, you can ask a question there. And don't forget to please put the video and the code that you're trying to run. That way we can reference what's going on and help you out there. And also, don't forget, there is the book version of the course. So learn pytorch.io. By the time you watch this video, it'll probably have all the chapters here. But here's what we're working through. This is what the videos are based on. All of this, we're going to go through all of this. How fun is that? But this is just reference material. So you can read this at your own time. We're going to focus on coding together. And speaking of coding. Let's code. I'll see you over at Google Colab. Oh, right. Well, let's get hands on with some code. I'm going to come over to colab.research.google.com. You may already have that bookmark. And I'm going to start a new notebook. So we're going to do everything from scratch here. We'll let this load up. I'm just going to zoom in a little bit. Beautiful. And now I'm going to title this 01 pytorch workflow. And I'm going to put the video ending on here so that you know that this notebook's from the video. Why is that? Because in the course resources, we have the original notebook here, which is what this video notebook is going to be based off. You can refer to this notebook as reference for what we're going to go through. It's got a lot of pictures and beautiful text annotations. We're going to be focused on the code in the videos. And then of course, you've got the book version of the notebook as well, which is just a different formatted version of this exact same notebook. So I'm going to link both of these up here. So let's write in here, pytorch workflow. And let's explore an example, pytorch end to end workflow. And then I'm going to put the resources. So ground truth notebook. We go here. And I'm also going to put the book version. Book version of notebook. And finally, ask a question, which will be where at the discussions page. Then we'll go there. Beautiful. Let's turn this into markdown. So let's get started. Let's just jump right in and start what we're covering. So this is the trend I want to start getting towards is rather than spending a whole bunch of time going through keynotes and slides, I'd rather we just code together. And then we explain different things as they need to be explained because that's what you're going to be doing if you end up writing a lot of pytorch is you're going to be writing code and then looking things up as you go. So I'll get out of these extra tabs. I don't think we need them. Just these two will be the most important. So what we're covering, let's create a little dictionary so we can check this if we wanted to later on. So referring to our pytorch workflows, at least the example one that we're going to go through, which is just here. So we're going to go through all six of these steps, maybe a little bit of each one, but just to see it going from this to this, that's what we're really focused on. And then we're going to go through through rest the course like really dig deep into all of these. So what we're covering number one is data preparing and loading. Number two is we're going to see how we can build a machine learning model in pytorch or a deep learning model. And then we're going to see how we're going to fit our model to the data. So this is called training. So fit is another word. As I said in machine learning, there's a lot of different names for similar things, kind of confusing, but you'll pick it up with time. So we're going to once we've trained a model, we're going to see how we can make predictions and evaluate those predictions, evaluating a model. If you make predictions, it's often referred to as inference. I typically say making predictions, but inference is another very common term. And then we're going to look at how we can save and load a model. And then we're going to put it all together. So a little bit different from the visual version we have of the pytorch workflow. So if we go back to here, I might zoom in a little. There we go. So we're going to focus on this one later on, improve through experimentation. We're just going to focus on the getting data ready, building a model, fitting the model, evaluating model, save and reload. So we'll see this one more, like in depth later on, but I'll hint at different things that you can do for this while we're working through this workflow. And so let's put that in here. And then if we wanted to refer to this later, we can just go what we're covering. Oh, this is going to connect, of course. Beautiful. So we can refer to this later on, if we wanted to. And we're going to start by import torch. We're going to get pytorch ready to go import nn. So I'll write a note here. And then we haven't seen this one before, but we're going to see a few things that we haven't seen, but that's okay. We'll explain it as we go. So nn contains all of pytorch's building blocks for neural networks. And how would we learn more about torch nn? Well, if we just go torch.nn, here's how I'd learn about it, pytorch documentation. Beautiful. Look at all these. These are the basic building blocks for graphs. Now, when you see the word graph, it's referring to a computational graph, which is in the case of neural networks, let's look up a photo of a neural network. Images, this is a graph. So if you start from here, you're going to go towards the right. There's going to be many different pictures. So yeah, this is a good one. Input layer. You have a hidden layer, hidden layer to output layer. So torch and n comprises of a whole bunch of different layers. So you can see layers, layers, layers. And each one of these, you can see input layer, hidden layer one, hidden layer two. So it's our job as data scientists and machine learning engineers to combine these torch dot nn building blocks to build things such as these. Now, it might not be exactly like this, but that's the beauty of pytorch is that you can combine these in almost any different way to build any kind of neural network you can imagine. And so let's keep going. That's torch nn. We're going to get hands on with it, rather than just talk about it. And we're going to need map plot lib because what's our other motto? Our data explorers motto is visualize, visualize, visualize. And let's check our pytorch version. Pytorch version torch dot version. So this is just to show you you'll need at least this version. So 1.10 plus CUDA 111. That means that we've got CU stands for CUDA. That means we've got access to CUDA. We don't have a GPU on this runtime yet, because we haven't gone to GPU. We might do that later. So if you have a version that's lower than this, say 1.8, 0.0, you'll want pytorch 1.10 at least. If you have a version higher than this, your code should still work. But that's about enough for this video. We've got our workflow ready to set up our notebook, our video notebook. We've got the resources. We've got what we're covering. We've got our dependencies. Let's in the next one get started on one data, preparing and loading. I'll see you in the next video. Let's now get on to the first step of our pytorch workflow. And that is data, preparing and loading. Now, I want to stress data can be almost anything in machine learning. I mean, you could have an Excel spreadsheet, which is rows and columns, nice and formatted data. You could have images of any kind. You could have videos. I mean, YouTube has lots of data. You could have audio like songs or podcasts. You could have even DNA these days. Patents and DNA are starting to get discovered by machine learning. And then, of course, you could have text like what we're writing here. And so what we're going to be focusing on throughout this entire course is the fact that machine learning is a game of two parts. So one, get data into a numerical representation to build a model to learn patterns in that numerical representation. Of course, there's more around it. Yes, yes, yes. I understand you can get as complex as you like, but these are the main two concepts. And machine learning, when I say machine learning, saying goes for deep learning, you need some kind of, oh, number a call. Number a call. I like that word, number a call representation. Then you want to build a model to learn patterns in that numerical representation. And if you want, I've got a nice pretty picture that describes that machine learning a game of two parts. Let's refer to our data. Remember, data can be almost anything. These are our inputs. So the first step that we want to do is create some form of numerical encoding in the form of tenses to represent these inputs, how this looks will be dependent on the data, depending on the numerical encoding you choose to use. Then we're going to build some sort of neural network to learn a representation, which is also referred to as patterns features or weights within that numerical encoding. It's going to output that representation. And then we want to do something without representation, such as in the case of this, we're doing image recognition, image classification, is it a photo of Raman or spaghetti? Is this tweet spam or not spam? Is this audio file saying what it says here? I'm not going to say this because my audio assistant that's also named to this word here is close by and I don't want it to go off. So this is our game of two parts. One here is convert our data into a numerical representation. And two here is build a model or use a pre trained model to find patterns in that numerical representation. And so we've got a little stationary picture here, turn data into numbers, part two, build a model to learn patterns in numbers. So with that being said, now let's create some data to showcase this. So to showcase this, let's create some known data using the linear regression formula. Now, if you're not sure what linear regression is, or the formula is, let's have a look linear regression formula. This is how I'd find it. Okay, we have some fancy Greek letters here. But essentially, we have y equals a function of x and b plus epsilon. Okay. Well, there we go. A linear regression line has the equation in the form of y equals a plus bx. Oh, I like this one better. This is nice and simple. We're going to start from as simple as possible and work up from there. So y equals a plus bx, where x is the explanatory variable, and y is the dependent variable. The slope of the line is b. And the slope is also known as the gradient. And a is the intercept. Okay, the value of when y when x equals zero. Now, this is just text on a page. This is formula on a page. You know how I like to learn things? Let's code it out. So let's write it here. We'll use a linear regression formula to make a straight line with known parameters. I'm going to write this down because parameter is a common word that you're going to hear in machine learning as well. So a parameter is something that a model learns. So for our data set, if machine learning is a game of two parts, we're going to start with this. Number one is going to be done for us, because we're going to start with a known representation, a known data set. And then we want our model to learn that representation. This is all just talk, Daniel, let's get into coding. Yes, you're right. You're right. Let's do it. So create known parameters. So I'm going to use a little bit different names to what that Google definition did. So weight is going to be 0.7 and bias is going to be 0.3. Now weight and bias are another common two terms that you're going to hear in neural networks. So just keep that in mind. But for us, this is going to be the equivalent of our weight will be B and our bias will be A. But forget about this for the time being. Let's just focus on the code. So we know these numbers. But we want to build a model that is able to estimate these numbers. How? By looking at different examples. So let's create some data here. We're going to create a range of numbers. Start equals zero and equals one. We're going to create some numbers between zero and one. And they're going to have a gap. So the step the gap is going to be 0.02. Now we're going to create an X variable. Why is X a capital here? Well, it's because typically X in machine learning you'll find is a matrix or a tensor. And if we remember back to the fundamentals, a capital represents a matrix or a tensor and a lowercase represents a vector. But now case it's going to be a little confusing because X is a vector. But later on, X will start to be a tensor and a matrix. So for now, we'll just keep the capital, not capital notation. We're going to create the formula here, which is remember how I said our weight is in this case, the B and our bias is the A. So we've got the same formula here. Y equals weight times X plus bias. Now let's have a look at these different numbers. So we'll view the first 10 of X and we'll view the first 10 of Y. We'll have a look at the length of X and we'll have a look at the length of Y. Wonderful. So we've got some values here. We've got 50 numbers of each. This is a little confusing. Let's just view the first 10 of X and Y first. And then we can have a look at the length here. So what we're going to be doing is building a model to learn some values, to look at the X values here and learn what the associated Y value is and the relationship between those. Of course, we know what the relationship is between X and Y because we've coded this formula here. But you won't always know that in the wild. That is the whole premise of machine learning. This is our ideal output and this is our input. The whole premise of machine learning is to learn a representation of the input and how it maps to the output. So here are our input numbers and these are our output numbers. And we know that the parameters of the weight and bias are 0.7 and 0.3. We could have set these to whatever we want, by the way. I just like the number 7 and 3. You could set these to 0.9, whatever, whatever. The premise would be the same. So, oh, and what I've just done here, I kind of just coded this without talking. But I just did torch a range and it starts at 0 and it ends at 1 and the step is 0.02. So there we go, 000 by 0.02, 04. And I've unsqueezed it. So what does unsqueezed do? Removes the extra dimensions. Oh, sorry, ads are extra dimension. You're getting confused here. So if we remove that, we get no extra square bracket. But if we add unsqueeze, you'll see that we need this later on for when we're doing models. Wonderful. So let's just leave it at that. That's enough for this video, we've got some data to work with. Don't worry if this is a little bit confusing for now, we're going to keep coding on and see what we can do to build a model to infer patterns in this data. But right now, I want you to have a think, this is tensor data, but it's just numbers on a page. What might be a better way to hint, this is a hint by the way, visualize it. What's our data explorer's motto? Let's have a look at that in the next video. Welcome back. In the last video, we created some numbers on a page using the linear regression formula with some known parameters. Now, there's a lot going on here, but that's all right. We're going to keep building upon what we've done and learn by doing. So in this video, we're going to cover one of the most important concepts in machine learning in general. So splitting data into training and test sets. One of the most important concepts in machine learning in general. Now, I know I've said this already a few times. One of the most important concepts, but truly, this is possibly, in terms of data, this is probably the number one thing that you need to be aware of. And if you've come from a little bit of a machine learning background, you probably well and truly know all about this. But we're going to recover it anyway. So let's jump in to some pretty pictures. Oh, look at that one speaking of pretty pictures. But that's not what we're focused on now. We're looking at the three data sets. And I've written down here possibly the most important concept in machine learning, because it definitely is from a data perspective. So the course materials, imagine you're at university. So this is going to be the training set. And then you have the practice exam, which is the validation set. Then you have the final exam, which is the test set. And the goal of all of this is for generalization. So let's step back. So say you're trying to learn something at university or through this course, you might have all of the materials, which is your training set. So this is where our model learns patterns from. And then to practice what you've done, you might have a practice exam. So the mid semester exam or something like that. Now, let's just see if you're learning the course materials well. So in the case of our model, we might tune our model on this plastic exam. So we might find that on the validation set, our model doesn't do too well. And we adjusted a bit, and then we retrain it, and then it does better. Before finally, at the end of semester, the most important exam is your final exam. And this is to see if you've gone through the entire course materials, and you've learned some things. Now you can adapt to unseen material. And that's a big point here. We're going to see this in practice is that when the model learns something on the course materials, it never sees the validation set or the test set. So say we started with 100 data points, you might use 70 of those data points for the training material. You might use 15% of those data points, so 15 for the practice. And you might use 15 for the final exam. So this final exam is just like if you're at university learning something is to see if, hey, have you learned any skills from this material at all? Are you ready to go into the wild into the quote unquote real world? And so this final exam is to test your model's generalization, because it's never seen this data is, let's define generalization is the ability for a machine learning model or a deep learning model to perform well on data it hasn't seen before, because that's our whole goal, right? We want to build a machine learning model on some training data that we can deploy in our application or production setting. And then more data comes in that it hasn't seen before. And it can make decisions based on that new data because of the patterns it's learned in the training set. So just keep this in mind, three data sets training validation test. And if we jump in to the learn pytorch book, we've got split data. So we're going to create three sets. Or in our case, we're only going to create two or training in a test. Why is that? Because you don't always need a validation set. There is often a use case for a validation set. But the main two that are always used is the training set and the testing set. And how much should you split? Well, usually for the training set, you'll have 60 to 80% of your data. If you do create a validation set, you'll have somewhere between 10 and 20. And if you do create a testing set, it's a similar split to the validation set, you'll have between 10 and 20%. So training, always testing always validation often, but not always. So with that being said, I'll let you refer to those materials if you want. But now let's create a training and test set with our data. So we saw before that we have 50 points, we have X and Y, we have one to one ratio. So one value of X relates to one value of Y. And we know that the split now for the training set is 60 to 80%. And the test set is 10 to 20%. So let's go with the upper bounds of each of these, 80% and 20%, which is a very common split, actually 80, 20. So let's go create a train test split. And we're going to go train split. We'll create a number here so we can see how much. So we want an integer of 0.8, which is 80% of the length of X. What does that give us? Train split should be about 40 samples. Wonderful. So we're going to create 40 samples of X and 40 samples of Y. Our model will train on those 40 samples to predict what? The other 10 samples. So let's see this in practice. So X train, Y train equals X. And we're going to use indexing to get all of the samples up until the train split. That's what this colon does here. So hey, X up until the train split, Y up until the train split, and then for the testing. Oh, thanks for that. Auto correct cola, but didn't actually need that one. X test. Y test equals X. And then we're going to get everything from the train split onwards. So the index onwards, that's what this notation means here. And Y from the train split onwards as well. Now, there are many different ways to create a train and test split. Ours is quite simple here, but that's because we're working with quite a simple data set. One of the most popular methods that I like is scikit learns train test split. We're going to see this one later on. It adds a little bit of randomness into splitting your data. But that's for another video, just to make you aware of it. So let's go length X train. We should have 40 training samples to how many testing samples length X test and length Y test. Wonderful 40 40 10 10 because we have training features, training labels, testing features, testing labels. So essentially what we've created here is now a training set. We've split our data. Training set could also be referred to as training split yet another example of where machine learning has different names for different things. So set split same thing training split test split. This is what we've created. Remember, the validation set is used often, but not always because our data set is quite simple. We're just sticking with the necessities training and test. But keep this in mind. One of your biggest, biggest, biggest hurdles in machine learning will be creating proper training and test sets. So it's a very important concept. With that being said, I did issue the challenge in the last video to visualize these numbers on a page. We haven't done that in this video. So let's move towards that next. I'd like you to think of how could you make these more visual? Right. These are just numbers on a page right now. Maybe that plot lib can help. Let's find out. Hey, hey, hey, welcome back. In the last video, we split our data into training and test sets. And now later on, we're going to be building a model to learn patterns in the training data to relate to the testing data. But as I said, right now, our data is just numbers on a page. It's kind of hard to understand. You might be able to understand this, but I prefer to get visual. So let's write this down. How might we better visualize our data? And I'm put a capital here. So we're grammatically correct. And this is where the data Explorers motto comes in. Visualize, visualize, visualize. Ha ha. Right. So if ever you don't understand a concept, one of the best ways to start understanding it more for me is to visualize it. So let's write a function to do just that. We're going to call this plot predictions. We'll see why we call it this later on. That's the benefit of making these videos is that I've got a plan for the future. Although it might seem like I'm winging it, there is a little bit of behind the scenes happening here. So we'll have the train data, which is our X train. And then we'll have the train labels, which is our Y train. And we'll also have the test data. Yeah, that's a good idea. X test. And we'll also have the test labels, equals Y test. Excuse me. I was looking at too many X's there. And then the predictions. And we'll set this to none, because we don't have any predictions yet. But as you might have guessed, we might have some later on. So we'll put a little doc string here, so that we're being nice and Pythonic. So plots training data, test data, and compares predictions. Nice and simple. Nothing too outlandish. And then we're going to create a figure. This is where map plot lib comes in. Plot figure. And we'll go fig size equals 10, seven, which is my favorite hand in poker. And we'll plot the training data in blue also happens to be a good dimension for a map plot. Plot dot scatter. Train data. Creating a scatter plot here. We'll see what it does in a second. Color. We're going to give this a color of B for blue. That's what C stands for in map plot lib scatter. We'll go size equals four and label equals training data. Now, where could you find information about this scatter function here? We've got command shift space. Is that going to give us a little bit of a doc string? Or sometimes if command not space is not working, you can also hover over this bracket. I think you can even hover over this. There we go. But this is a little hard for me to read. Like it's there, but it's got a lot going on. X, Y, S, C, C map. I just like to go map plot lib scatter. There we go. We've got a whole bunch of information there. A little bit easier to read for me here. And then you can see some examples. Beautiful. So now let's jump back into here. So in our function plot predictions, we've taken some training data, test data. We've got the training data plotting in blue. What color should we use for the testing data? How about green? I like that idea. Plot.scatter. Test data. Green's my favorite color. What's your favorite color? C equals G. You might be able to just plot it in your favorite color here. Just remember though, it'll be a little bit different from the videos. And then we're going to call this testing data. So just the exact same line is above, but with a different set of data. Now, let's check if there are predictions. So are there predictions? So if predictions is not none, let's plot the predictions, plot the predictions, if they exist. So plot scatter test data. And why are we plotting the test data? Remember, what is our scatter function? Let's go back up to here. It takes in x and y. So our predictions are going to be compared to the testing data labels. So that's the whole game that we're playing here. We're going to train our model on the training data. And then to evaluate it, we're going to get our model to predict the y values as with the input of x test. And then to evaluate our model, we compare how good our models predictions are. In other words, predictions versus the actual values of the test data set. But we're going to see this in practice. Rather than just talk about it. So let's do our predictions in red. And label equals predictions. Wonderful. So let's also show the legend, because, I mean, we're legends. So we could just put in a mirror here. Now I'm kidding. Legend is going to show our labels on the map plot. So prop equals size and prop stands for properties. Well, it may or may not. I just like to think it does. That's how I remember it. So we have a beautiful function here to plot our data. Should we try it out? Remember, we've got hard coded inputs here, so we don't actually need to input anything to our function. We've got our train and test data ready to go. If in doubt, run the code, let's check it out. Did we make a mistake in our plot predictions function? You might have caught it. Hey, there we go. Beautiful. So because we don't have any predictions, we get no red dots. But this is what we're trying to do. We've got a simple straight line. You can't get a much more simple data set than that. So we've got our training data in blue, and we've got our testing data in green. So the whole idea of what we're going to be doing with our machine learning model is we don't actually really need to build a machine learning model for this. We could do other things, but machine learning is fun. So we're going to take in the blue dots. There's quite a pattern here, right? This is the relationship we have an x value here, and we have a y value. So we're going to build a model to try and learn the pattern of these blue dots, so that if we fed our model, our model, the x values of the green dots, could it predict the appropriate y values for that? Because remember, these are the test data set. So pass our model x test to predict y test. So blue dots as input, green dots as the ideal output. This is the ideal output, a perfect model would have red dots over the top of the green dots. So that's what we will try to work towards. Now, we know the relationship between x and y. How do we know that? Well, we set that up above here. This is our weight and bias. We created that line y equals weight times x plus bias, which is the simple version of the linear regression formula. So mx plus c, you might have heard that in high school algebra, so gradient plus intercept. That's what we've got. With that being said, let's move on to the next video and build a model. Well, this is exciting. I'll see you there. Welcome back. In the last video, we saw how to get visual with our data. We followed the data explorer's motto of visualize, visualize, visualize. And we've got an idea of the training data that we're working with and the testing data that we're trying to build a model to learn the patterns in the training data, essentially this upwards trend here, to be able to predict the testing data. So I just want to give you another heads up. I took a little break after the recording last video. And so now my colab notebook has disconnected. So I'm going to click reconnect. And my variables here may not work. So this is what might happen on your end. If you take a break from using Google Colab and come back, if I try to run this function, they might have been saved, it looks like they have. But if not, you can go restart and run all. This is typically one of the most helpful troubleshooting steps of using Google Colab. If a cell, say down here isn't working, you can always rerun the cells above. And that may help with a lower cell here, such as if this function wasn't instantiated because this cell wasn't run, and we couldn't run this cell here, which calls this function here, we just have to rerun this cell above so that we can run this one. But now let's get into building our first PyTorch model. We're going to jump straight into the code. So our first PyTorch model. Now this is very exciting. Let's do it. So we'll turn this into Markdown. Now we're going to create a linear regression model. So look at linear regression formula again, we're going to create a model that's essentially going to run this computation. So we need to create a model that has a parameter for A, a parameter for B, and in our case it's going to be weight and bias, and a way to do this forward computation. What I mean by that, we're going to see with code. So let's do it. We'll do it with pure PyTorch. So create a linear regression model class. Now if you're not experienced with using Python classes, I'm going to be using them throughout the course, and I'm going to call this one linear regression model. If you haven't dealt with Python classes before, that's okay. I'm going to be explaining what we're doing as we're doing it. But if you'd like a deeper dive, I'd recommend you to real Python classes. OOP in Python three. That's a good rhyming. So I'm just going to link this here. Because we're going to be building classes throughout the course, I'd recommend getting familiar with OOP, which is object oriented programming, a little bit of a mouthful, hence the OOP in Python. To do so, you can use the following resource from real Python. But when I'm going to go through that now, I'd rather just code it out and talk it out while we do it. So we've got a class here. Now the first thing you might notice is that the class inherits from nn.module. And you might be wondering, well, what's nn.module? Well, let's write down here, almost everything in PyTorch inherits from nn.module. So you can imagine nn.module as the Lego building bricks of PyTorch model. And so nn.module has a lot of helpful inbuilt things that's going to help us build our PyTorch models. And of course, how could you learn more about it? Well, you could go nn.module, PyTorch. Module. Here we go. Base class for all neural network modules. Wonderful. Your models should also subclass this class. So that's what we're building. We're building our own PyTorch model. And so the documentation here says that your models should also subclass this class. And another thing with PyTorch, this is what makes it, it might seem very confusing when you first begin. But modules can contain other modules. So what I mean by being a Lego brick is that you can stack these modules on top of each other and make progressively more complex neural networks as you go. But we'll leave that for later on. For now, we're going to start with something nice and simple. And let's clean up our web browser. So we're going to create a constructor here, which is with the init function. It's going to take self as a parameter. If you're not sure of what's going on here, just follow along with the code for now. And I'd encourage you to read this documentation here after the video. So then we have super dot init. I know when I first started learning this, I was like, why do we have to write a knit twice? And then what's super and all that jazz. But just for now, just take this as being some required Python syntax. And then we have self dot weights. So that means we're going to create a weights parameter. We'll see why we do this in a second. And to create that parameter, we're going to use nn dot parameter. And just a quick reminder that we imported nn from torch before. And if you remember, nn is the building block layer for neural networks. And within nn, so nn stands for neural network is module. So we've got nn dot parameter. Now, we're going to start with random parameters. So torch dot rand n. One, we're going to talk through each of these in a second. So I'm also going to put requires, requires grad equals true. We haven't touched any of these, but that's okay. D type equals torch dot float. So let's see what nn parameter tells us. What do we have here? A kind of tensor that is to be considered a module parameter. So we've just created a module using nn module. Parameters are torch tensor subclasses. So this is a tensor in itself that have a very special property when used with modules. When they're assigned as a module attribute, they are automatically added to the list of its parameters. And we'll appear e g in module dot parameters iterator. Oh, we're going to see that later on. Assigning a tensor doesn't have such effect. So we're creating a parameter here. Now requires grad. What does that mean? Well, let's just rather than just try to read the doc string collab, let's look it up. nn dot parameter. What does it say requires grad optional. If the parameter requires gradient. Hmm. What does requires gradient mean? Well, let's come back to that in a second. And then for now, I just want you to think about it. D type equals torch dot float. Now, the data type here torch dot float is, as we've discussed before, is the default for pytorch to watch dot float. This could also be torch dot float 32. So we're just going to leave it as torch float 32, because pytorch likes to work with flight 32. Now, do we have this by default? We do. So we don't necessarily have to set requires grad equals true. So just keep that in mind. So now we've created a parameter for the weights. We also have to create a parameter for the bias. Let's finish creating this. And then we'll write the code, then we'll talk about it. So rand n. Now requires grad equals true. And d type equals torch dot float. There we go. And now we're going to write a forward method. So forward method to define the computation in the model. So let's go def forward, which self takes in a parameter x, which is data, which X is expected to be of type torch tensor. And it returns a torch dot tensor. And then we go here. And so we say X, we don't necessarily need this comment. I'm just going to write it anyway. X is the input data. So in our case, it might be the training data. And then from here, we want it to return self dot weights times X plus self dot bias. Now, where have we seen this before? Well, this is the linear regression formula. Now, let's take a step back into how we created our data. And then we'll go back through and talk a little bit more about what's going on here. So if we go back up to our data, where did we create that? We created it here. So you see how we've created known parameters, weight and bias. And then we created our y variable, our target, using the linear regression formula, wait times X plus bias, and X were a range of numbers. So what we've done with our linear regression model that we've created from scratch, if we go down here, we've created a parameter, weights. This could just be weight, if we wanted to. We've created a parameter here. So when we created our data, we knew what the parameters weight and bias were. The whole goal of our model is to start with random numbers. So these are going to be random parameters. And to look at the data, which in our case will be the training samples, and update those random numbers to represent the pattern here. So ideally, our model, if it's learning correctly, will take our weight, which is going to be a random value, and our bias, which is going to be a random value. And it will run it through this forward calculation, which is the same formula that we use to create our data. And it will adjust the weight and bias to represent as close as possible, if not perfect, the known parameters. So that's the premise of machine learning. And how does it do this? Through an algorithm called gradient descent. So I'm just going to write this down because we've talked a lot about this, but I'd like to just tie it together here. So what our model does, so start with random values, weight and bias, look at training data, and adjust the random values to better represent the, or get closer to the ideal values. So the weight and bias values we use to create the data. So that's what it's going to do. It's going to start with random values, and then continually look at our training data to see if it can adjust those random values to be what would represent this straight line here. Now, how does it do so? How does it do so? Through two main algorithms. So one is gradient descent, and two is back propagation. So I'm going to leave it here for the time being, but we're going to continue talking about this gradient descent is why we have requires grad equals true. And so what this is going to do is when we run computations using this model here, pytorch is going to keep track of the gradients of our weights parameter and our bias parameter. And then it's going to update them through a combination of gradient descent and back propagation. Now, I'm going to leave this as extracurricular for you to look through and gradient descent and back propagation. I'm going to add some resources here. There will also be plenty of resources in the pytorch workflow fundamentals book chapter on how these algorithms work behind the scenes. We're going to be focused on the code, the pytorch code, to trigger these algorithms behind the scenes. So pytorch, lucky for us, has implemented gradient descent and back propagation for us. So we're writing the higher level code here to trigger these two algorithms. So in the next video, we're going to step through this a little bit more, and then further discuss some of the most useful and required modules of pytorch, particularly an N and a couple of others. So let's leave it there, and I'll see you in the next video. Welcome back. In the last video, we covered a whole bunch in creating our first pytorch model that inherits from nn.module. We talked about object oriented programming and how a lot of pytorch uses object oriented programming. I can't say that. I might just say OOP for now. What I've done since last video, though, is I've added two resources here for gradient descent and back propagation. These are two of my favorite videos on YouTube by the channel three blue one brown. So this is on gradient descent. I would highly recommend watching this entire series, by the way. So that's your extra curriculum for this video, in particular, and for this course overall is to go through these two videos. Even if you're not sure entirely what's happening, you will gain an intuition for the code that we're going to be writing with pytorch. So just keep that in mind as we go forward, a lot of what pytorch is doing behind the scenes for us is taking care of these two algorithms for us. And we also created two parameters here in our model where we've instantiated them as random values. So one parameter for each of the ones that we use, the weight and bias for our data set. And now I want you to keep in mind that we're working with a simple data set here. So we've created our known parameters. But in a data set that you haven't created by yourself, you've maybe gathered that from the internet, such as images, you won't be necessarily defining these parameters. Instead, another module from nn will define the parameters for you. And we'll work out what those parameters should end up being. But since we're working with a simple data set, we can define our two parameters that we're trying to estimate. This is a key point here is that our model is going to start with random values. That's the annotation I've added here. Start with a random weight value using torch random. And then we've told it that it can update via gradient descent. So pytorch is going to track the gradients of this parameter for us. And then we've told it that the D type we want is float 32. We don't necessarily need these two set explicitly, because a lot of the time the default in pytorch is to set these two requires grad equals true and d type equals torch dot float. Does that for us behind the scenes? But just to keep things as fundamental and as straightforward as possible, we've set all of this explicitly. So let's jump into the keynote. I'd just like to explain what's going on one more time in a visual sense. So here's the exact code that we've just written. I've just copied it from here. And I've just made it a little bit more colorful. But here's what's going on. So when you build a model in pytorch, it subclasses the nn.modgable class. This contains all the building blocks for neural networks. So our class of model, subclasses nn.modgable. Now, inside the constructor, we initialize the model parameters. Now, as we'll see, later on with bigger models, we won't necessarily always explicitly create the weights and biases. We might initialize whole layers. Now, this is a concept we haven't touched on yet, but we might initialize a list of layers or whatever we need. So basically, what happens in here is that we create whatever variables that we need for our model to use. And so these could be different layers from torch.nn, single parameters, which is what we've done in our case, hard coded values, or even functions. Now, we've explicitly set requires grad equals true for our model parameters. So this, in turn, means that pytorch behind the scenes will track all of the gradients for these parameters here for use with torch.auto grad. So torch.auto grad module of pytorch is what implements gradient descent. Now, a lot of this will happen behind the scenes for when we write our pytorch training code. So if you'd like to know what's happening behind the scenes, I'd highly recommend you checking out these two videos, hence is why I've linked them here. Oh, and for many pytorch.nn modules requires grad is true is set by default. Finally, we've got a forward method. Now, any subclass of nn.modgable, which is what we've done, requires a forward method. Now, we can see this in the documentation. If we go torch dot nn.modgable. Click on module. Do we have forward? Yeah, there we go. So forward, we've got a lot of things built into an nn.modgable. So you see here, this is a subclass of an nn.modgable. And then we have forward. So forward is what defines the computation performed at every call. So if we were to call linear regression model and put some data through it, the forward method is the operation that this module does that this model does. And in our case, our forward method is the linear regression function. So keep this in mind, any subclass of nn.modgable needs to override the forward method. So you need to define a forward method if you're going to subclass nn.modgable. We'll see this very hands on. But for now, I believe that's enough coverage of what we've done. If you have any questions, remember, you can ask it in the discussions. We've got a fair bit going on here. But I think we've broken it down a fair bit. The next step is for us to, I know I mentioned this in a previous video is to cover some PyTorch model building essentials. But we're going to cover a few more of them. We've seen some already. But the next way to really start to understand what's going on is to check the contents of our model, train one, and make some predictions with it. So let's get hands on with that in the next few videos. I'll see you there. Welcome back. In the last couple of videos, we stepped through creating our first PyTorch model. And it looks like there's a fair bit going on here. But some of the main takeaways is that almost every model in PyTorch inherits from nn.modgable. And if you are going to inherit from nn.modgable, you should override the forward method to define what computation is happening in your model. And for later on, when our model is learning things, in other words, updating its weights and bias values from random values to values that better fit the data, it's going to do so via gradient descent and back propagation. And so these two videos are some extra curriculum for what's happening behind the scenes. But we haven't actually written any code yet to trigger these two. So I'll refer back to these when we actually do write code to do that. For now, we've just got a model that defines some forward computation. But speaking of models, let's have a look at a couple of PyTorch model building essentials. So we're not going to write too much code for this video, and it's going to be relatively short. But I just want to introduce you to some of the main classes that you're going to be interacting with in PyTorch. And we've seen some of these already. So one of the first is torch.nn. So contains all of the building blocks for computational graphs. Computational graphs is another word for neural networks. Well, actually computational graphs is quite general. I'll just write here, a neural network can be considered a computational graph. So then we have torch.nn.parameter. We've seen this. So what parameters should our model try and learn? And then we can write here often a PyTorch layer from torch.nn will set these for us. And then we've got torch.nn.module, which is what we've seen here. And so torch.nn.module is the base class for all neural network modules. If you subclass it, you should overwrite forward, which is what we've done here. We've created our own forward method. So what else should we cover here? We're going to see these later on, but I'm going to put it here, torch.optim. This is where the optimizers in PyTorch live. They will help with gradient descent. So optimizer, an optimizer is, as we've said before, that our model starts with random values. And it looks at training data and adjusts the random values to better represent the ideal values. The optimizer contains algorithm that's going to optimize these values, instead of being random, to being values that better represent our data. So those algorithms live in torch.optim. And then one more for now, I'll link to extra resources. And we're going to cover them as we go. That's how I like to do things, cover them as we need them. So all nn.module. So this is the forward method. I'm just going to explicitly say here that all nn.module subclasses require you to overwrite forward. This method defines what happens in the forward computation. So in our case, if we were to pass some data to our linear regression model, the forward method would take that data and perform this computation here. And as your models get bigger and bigger, ours is quite straightforward here. This forward computation can be as simple or as complex as you like, depending on what you'd like your model to do. And so I've got a nice and fancy slide here, which basically reiterates what we've just discussed. PyTorch is central neural network building modules. So the module torch.nn, torch.nn.module, torch.optim, torch.utils.dataset. We haven't actually talked about this yet. And I believe there's one more data loader. We're going to see these two later on. But these are very helpful when you've got a bit more of a complicated data set. In our case, we've got just 50 integers for our data set. We've got a simple straight line. But when we need to create more complex data sets, we're going to use these. So this will help us build models. This will help us optimize our models parameters. And this will help us load data. And if you'd like more, one of my favorite resources is the PyTorch cheat sheet. Again, we're referring back to the documentation. See, all of this documentation, right? As I said, this course is not a replacement for the documentation. It's just my interpretation of how one should best become familiar with PyTorch. So we've got imports, the general import torch from torch.utils.dataset data loader. Oh, did you look at that? We've got that mentioned here, data, data set data loader. And torch, script and jit, neural network API. I want an X. I'll let you go through here. We're covering some of the most fundamental ones here. But there's, of course, PyTorch is quite a big library. So some extra curricula for this video would be to go through this for five to 10 minutes and just read. You don't have to understand them all. We're going to start to get more familiar with all of these. We're not all of them because, I mean, that would require making videos for the whole documentation. But a lot of these through writing them via code. So that's enough for this video. I'll link this PyTorch cheat sheet in the video here. And in the next video, how about we, we haven't actually checked out what happens if we do create an instance of our linear regression model. I think we should do that. I'll see you there. Welcome back. In the last video, we covered some of the PyTorch model building essentials. And look, I linked a cheat sheet here. There's a lot going on. There's a lot of text going on in the page. Of course, the reference material for here is in the Learn PyTorch book. PyTorch model building essentials under 0.1, which is the notebook we're working on here. But I couldn't help myself. I wanted to add some color to this. So before we inspect our model, let's just add a little bit of color to our text on the page. We go to whoa. Here's our workflow. This is what we're covering in this video, right? Or in this module, 0.1. But to get data ready, here are some of the most important PyTorch modules. Torchvision.transforms. We'll see that when we cover computer vision later on. Torch.utils.data.data set. So that's if we want to create a data set that's a little bit more complicated than because our data set is so simple, we haven't used either of these data set creator or data loader. And if we go build a picker model, well, we can use torch.nn. We've seen that one. We've seen torch.nn.module. So in our case, we're building a model. But if we wanted a pre-trained model, well, there's some computer vision models that have already been built for us in torchvision.models. Now torchvision stands for PyTorch's computer vision module. So we haven't covered that either. But this is just a spoiler for what's coming on later on. Then if the optimizer, if we wanted to optimize our model's parameters to better represent a data set, we can go to torch.optim. Then if we wanted to evaluate the model, well, we've got torch metrics for that. We haven't seen that, but we're going to be hands-on with all of these later on. Then if we wanted to improve through experimentation, we've got torch.utils.tensorboard. Hmm. What's this? But again, if you want more, there's some at the PyTorch cheat sheet. But now this is just adding a little bit of color and a little bit of code to our PyTorch workflow. And with that being said, let's get a little bit deeper into what we've built, which is our first PyTorch model. So checking the contents of our PyTorch model. So now we've created a model. Let's see what's inside. You might already be able to guess this by the fact of what we've created in the constructor here in the init function. So what do you think we have inside our model? And how do you think we'd look in that? Now, of course, these are questions you might not have the answer to because you've just, you're like, Daniel, I'm just starting to learn PyTorch. I don't know these, but I'm asking you just to start thinking about these different things, you know? So we can check out our model parameters or what's inside our model using, wait for it, dot parameters. Oh, don't you love it when things are nice and simple? Well, let's check it out. Hey, well, first things we're going to do is let's create a random seed. Now, why are we creating a random seed? Well, because recall, we're creating these parameters with random values. And if we were to create them with outer random seed, we would get different values every time. So for the sake of the educational sense, for the sake of this video, we're going to create a manual seed here, torch dot manual seed. I'm going to use 42 or maybe 43, I could use 43 now 42 because I love 42. It's the answer to the universe. And we're going to create an instance of the model that we created. So this is a subclass of an end up module. So let's do it. Model zero, because it's going to be the zeroth model, the first model that we've ever created in this whole course, how amazing linear regression model, which is what our class is called. So we can just call it like that. That's all I'm doing, just calling this class. And so let's just see what happens there. And then if we go model zero, what does it give us? Oh, linear regression. Okay, it doesn't give us much. But we want to find out what's going on in here. So check out the parameters. So model zero dot parameters. What do we get from this? Oh, a generator. Well, let's turn this into a list that'll be better to look at. There we go. Oh, how exciting is that? So parameter containing. Look at the values tensor requires grad equals true parameter containing wonderful. So these are our model parameters. So why are they the values that they are? Well, it's because we've used torch rand n. Let's see what happens if we go, let's just create torch dot rand n one, what happens? We get a value like that. And now if we run this again, we get the same values. But if we run this again, so keep this in one two, three, four, five, actually, that's, wow, that's pretty cool that we got a random value that was all in order, four in a row. Can we do it twice in a row? Probably not. Oh, we get it the same one. Now, why is that? Oh, we get a different one. Did we just get the same one twice? Oh, my gosh, we got the same value twice in a row. You saw that. You saw that. That's incredible. Now, the reason why we get this is because this one is different every time because there's no random seed. Watch if we put the random seed here, torch dot manual seed, 42, 3, 3, 6, 7, what happens? 3, 3, 6, 7, what happens? 3, 3, 6, 7. Okay. And what if we commented out the random seed here, initialized our model, different values, two, three, five, two, three, four, five, it must like that value. Oh, my goodness. Let me know if you get that value, right? So if we keep going, we get different values every single time. Why is this? Why are we getting different values every single time? You might be, Daniel, you sound like a broken record, but I'm trying to really drive home the fact that we initialize our models with random parameters. So this is the essence of what our machine learning models and deep learning models are going to do. Start with random values, weights and bias. Maybe we've only got two parameters here, but the future models that we build might have thousands. And so of course, we're not going to do them all by hand. We'll see how we do that later on. But for now, we start with random values. And our ideal model will look at the training data and adjust these random values. But just so that we can get reproducible results, I'll get rid of this cell. I've set the random seed here. So you should be getting similar values to this. If you're not, because there's maybe some sort of pytorch update and how the random seeds calculated, you might get slightly different values. But for now, we'll use torch.manualc.42. And I want you to just be aware of this can be a little bit confusing. If you just do the list of parameters, for me, I understand it better if I list the name parameters. So the way we do that is with model zero, and we call state dict on it. This is going to give us our dictionary of the parameters of our model. So as you can see here, we've got weights, and we've got bias, and they are random values. So where did weights and bias come from? Well, of course, they came from here, weights, bias. But of course, as well up here, we've got known parameters. So now our whole goal is what? Our whole goal is to build code, or write code, that is going to allow our model to look at these blue dots here, and adjust this weight and bias value to be weights as close as possible to weight and bias. Now, how do we go from here and here to here and here? Well, we're going to see that in future videos, but the closer we get these values to these two, the better we're going to be able to predict and model our data. Now, this principle, I cannot stress enough, is the fundamental entire foundation, the fundamental foundation. Well, good description, Daniel. The entire foundation of deep learning, we start with some random values, and we use gradient descent and back propagation, plus whatever data that we're working with to move these random values as close as possible to the ideal values. And in most cases, you won't know what the ideal values are. But in our simple case, we already know what the ideal values are. So just keep that in mind going forward. The premise of deep learning is to start with random values and make them more representative closer to the ideal values. With that being said, let's try and make some predictions with our model as it is. I mean, it's got random values. How do you think the predictions will go? So I think in the next video, we'll make some predictions on this test data and see what they look like. I'll see you there. Welcome back. In the last video, we checked out the internals of our first PyTorch model. And we found out that because we're creating our model with torch dot or the parameters of our model, with torch dot rand, they begin as random variables. And we also discussed the entire premise of deep learning is to start with random numbers and slowly progress those towards more ideal numbers, slightly less random numbers based on the data. So let's see, before we start to improve these numbers, let's see what their predictive power is like right now. Now you might be able to guess how well these random numbers will be able to predict on our data. You're not sure what that predicting means? Let's have a look. So making predictions using torch dot inference mode, something we haven't seen. But as always, we're going to discuss it while we use it. So to check our models predictive power, let's see how well it predicts Y test based on X test. Because remember again, another premise of a machine learning model is to take some features as input and make some predictions close to some sort of labels. So when we pass data through our model, it's going to run it through the forward method. So here's where it's a little bit confusing. We defined a forward method and it takes X as input. Now I've done a little X, but we're going to pass it in a large X as its input. But the reason why I've done a little X is because oftentimes in pytorch code, you're going to find all over the internet is that X is quite common, commonly used in the forward method here, like this as the input data. So I've just left it there because that's what you're going to find quite often. So let's test it out. We haven't discussed what inference mode does yet, but we will make predictions with model. So with torch dot inference mode, let's use it. And then we will discuss what's going on. Y threads equals a model zero X test. So that's all we're doing. We're passing the X test data through our model. Now, when we pass this X test in here, let's remind ourselves of what X test is. X test 10 variables here. And we're trying to our ideal model will predict the exact values of Y test. So this is what our model will do if it's a perfect model. It will take these X test values as input, and it will return these Y test values as output. That's an ideal model. So the predictions are the exact same as the test data set. How do you think our model will go considering it's starting with random values as its parameters? Well, let's find out, hey. So what can that Y threads? Oh, what's happened here? Not implemented error. Ah, this is an error I get quite often in Google Colab when I'm creating a high-torch model. Now, it usually happens. I'm glad we've stumbled upon this. And I think I know the fix. But if not, we might see a little bit of troubleshooting in this video is that when we create this, if you see this not implemented error, right, it's saying that the Ford method. Here we go. Ford implemented. There we go. It's a little bit of a rabbit hole this not implemented area. I've come across it a fair few times and it took me a while to figure out that for some reason the spacing. So in Python, you know how you have space space and that defines a function space space. There's another thing there and another line there. For some reason, if you look at this line in my notebook, and by the way, if you don't have these lines or if you don't have these numbers, you can go into tools, settings, editor, and then you can define them here. So show line numbers, show notation guides, all that sort of jazz there. You can customize what's going on. But I just have these two on because I've run into this error a fair few times. And so it's because that this Ford method is not in line with this bracket here. So we need to highlight this and click shift tab, move it over. So now you see that it's in line here. And then if we run this, won't change any output there. See, that's the hidden gotcha. Is that when we ran this before, it found no error. But then when we run it down here, it works. So just keep that in mind. I'm really glad we stumbled upon that because indentation errors, not implemented errors, one of the most common errors you'll find in PyTorch, or in, well, when you're writing PyTorch code in Google CoLab, I'm not sure why, but it just happens. So these are our models predictions so far by running the test data through our models Ford method that we defined. And so if we look at Y test, are these close? Oh my gosh, they are shocking. So why don't we visualize them? Plot predictions. And we're going to put in predictions equals Y threads. Let's have a look. Oh my goodness. All the way over here. Remember how we discussed before that an ideal model will have, what, red dots on top of the green dots because our ideal model will be perfectly predicting the test data. So right now, because our model is initialized with random parameters, it's basically making random predictions. So they're extremely far from where our ideal predictions are, is that we'll have some training data. And our model predictions, when we first create our model will be quite bad. But we want to write some code that will hopefully move these red dots closer to these green dots. I'm going to see how we can do that in later videos. But we did one thing up here, which we haven't discussed, which is with torch dot inference mode. Now this is a context manager, which is what happens when we're making predictions. So making predictions, another word for predictions is inference torch uses inference. So I'll try to use that a bit more, but I like to use predictions as well. We could also just go Y preds equals model zero dot X test. And we're going to get quite a similar output. Right. But I've put on inference mode because I want to start making that a habit for later on, when we make predictions, put on inference mode. Now why do this? You might notice something different. What's the difference here between the outputs? Y preds equals model. There's no inference mode here, no context manager. Do you notice that there's a grad function here? And we don't need to go into discussing what exactly this is doing here. But do you notice that this one is lacking that grad function? So do you remember how behind the scenes I said that pie torch does a few things with requires grad equals true, it keeps track of the gradients of different parameters so that they can be used in gradient descent and back propagation. Now what inference mode does is it turns off that gradient tracking. So it essentially removes all of the, because when we're doing inference, we're not doing training. So we don't need to keep track of the gradient. So we don't need to do to keep track of how we should update our models. So inference mode disables all of the useful things that are available during training. What's the benefit of this? Well, it means that pie torch behind the scenes is keeping track of less data. So in turn, it will, with our small data set, it probably won't be too dramatic. But with a larger data set, it means that your predictions will potentially be a lot faster because a whole bunch of numbers aren't being kept track of or a whole bunch of things that you don't need during prediction mode or inference mode. That's why it's called inference mode. I'm not being saved to memory. If you'd like to learn more about this, you go pie torch inference mode Twitter. I just remember to search for Twitter because they did a big tweet storm about it. Here we go. So oh, this is another thing that we can cover. I'm going to copy this in here. But there's also a blog post about what's going on behind the scenes. Long story short, it makes your code faster. Want to make your inference code and pie torch run faster? Here's a quick thread on doing exactly that. And that's what we're doing. So I'm going to write down here. See more on inference mode here. And I just want to highlight something as well is that they referenced torch no grad with the torch inference mode context manager. Inference mode is fairly new in pie torch. So you might see a lot of code existing pie torch code with torch dot no grad. You can use this as well. Why? Preds equals model zero. And this will do much of the same as what inference mode is doing. But inference mode has a few things that are advantages over no grad, which are discussed in this thread here. But if we do this, we get very similar output to what we got before. Grad function. But as you'll read in here and in the pie torch documentation, inference mode is the favored way of doing inference for now. I just wanted to highlight this. So you can also do something similar with torch dot no grad. However, inference mode is preferred. Alrighty. So I'm just going to comment this out. So we just have one thing going on there. The main takeaway from this video is that when we're making predictions, we use the context manager torch dot inference mode. And right now, because our models variables or internal parameters are randomly initialized, our models predictions are as good as random. So they're actually not too far off where our values are. At least the red dots aren't like scattered all over here. But in the upcoming videos, we're going to be writing some pie torch training code to move these values closer to the green dots by looking at the training data here. So with that being said, I'll see you in the next video. Friends, welcome back. In the last video, we saw that our model performs pretty poorly. Like, ideally, these red dots should be in line with these green dots. And we know that because why? Well, it's because our model is initialized with random parameters. And I just want to put a little note here. You don't necessarily have to initialize your model with random parameters. You could initialize it with this could be zero. Yeah, these two values, weights can bias could be zero and you could go from there. Or you could also use the parameters from another model. But we're going to see that later on. That's something called transfer learning. That's just a little spoiler for what's to come. And so we've also discussed that an ideal model will replicate these known parameters. So in other words, start with random unknown parameters, these two values here. And then we want to write some code for our model to move towards estimating the ideal parameters here. Now, I just want to be explicit here and write down some intuition before we jump into the training code. But this is very exciting. We're about to get into training our very first machine learning model. So what's right here, the whole idea of training is for a model to move from some unknown parameters, these may be random to some known parameters. Or in other words, from a poor representation, representation of the data to a better representation of the data. And so in our case, would you say that our models representation of the green dots here with this red dots, is that a good representation? Or is that a poor representation? I mean, I don't know about you, but I would say that to me, this is a fairly poor representation. And one way to measure the representation between your models outputs, in our case, the red dots, the predictions, and the testing data, is to use a loss function. So I'm going to write this down here. This is what we're moving towards. We're moving towards training, but we need a way to measure how poorly our models predictions are doing. So one way to measure how poor or how wrong your models predictions are, is to use a loss function. And so if we go pytorch loss functions, we're going to see that pytorch has a fair few loss functions built in. But the essence of all of them is quite similar. So just wait for this to load my internet's going a little bit slow today, but that's okay. We're not in a rush here. We're learning something fun. If I search here for loss, loss functions, here we go. So yeah, this is torch in N. These are the basic building blocks for graphs, whole bunch of good stuff in here, including loss functions. Beautiful. And this is another thing to note as well, another one of those scenarios where there's more words for the same thing. You might also see a loss function referred to as a criterion. There's another word called cost function. So I might just write this down so you're aware of it. Yeah, cost function versus loss function. And maybe some formal definitions about what all of these are. Maybe they're used in different fields. But in the case of we're focused on machine learning, right? So I'm just going to go note, loss function may also be called cost function or criterion in different areas. For our case, we're going to refer to it as a loss function. And let's just formally define a loss function here, because we're going to go through a fair few steps in the upcoming videos. So this is a warning, nothing we can't handle. But I want to put some formal definitions on things. We're going to see them in practice. That's what I prefer to do, rather than just sit here defining stuff. This lecture has already had enough text on the page. So hurry up and get into coding Daniel. A loss function is a function to measure how wrong your models predictions are to the ideal outputs. So lower is better. So ideally, think of a measurement, how could we measure the difference between the red dots and the green dots? One of the simplest ways to do so would be just measure the distance here, right? So if we go, let's just estimate this is 035 to 0.8. They're abouts. So what's the difference there? About 0.45. Then we could do the same again for all of these other dots, and then maybe take the average of that. Now, if you've worked with loss functions before, you might have realized that I've just reproduced mean absolute error. But we're going to get to that in a minute. So we need a loss function. I'm going to write down another little dot point here. This is just setting up intuition. Things we need to train. We need a loss function. This is PyTorch. And this is machine learning in general, actually. But we're focused on PyTorch. We need an optimizer. What does the optimizer do? Takes into account the loss of a model and adjusts the model's parameters. So the parameters recall our weight and bias values. Weight and biases. We can check those or bias. We can check those by going model dot parameter or parameters. But I also like, oh, that's going to give us a generator, isn't it? Why do we not define the model yet? What do we call our model? Oh, model zero. Excuse me. I forgot where. I'm going to build a lot of models in this course. So we're giving them numbers. Modeled up parameters. Yeah, we've got a generator. So we'll turn that into a list. But model zero, if we want to get them labeled, we want state dict here. There we go. So our weight is this value. That's a random value we've set. And there's the bias. And now we've only got two parameters for our model. So it's quite simple. However, the principles that we're learning here are going to be the same principles, taking a loss function, trying to minimize it, so getting it to lower. So the ideal model will predict exactly what our test data is. And an optimizer will take into account the loss and will adjust a model's parameter. And our case weights and bias to be, let's finish this definition takes into account the loss of a model and adjust the model's parameters, e.g. weight and bias, in our case, to improve the loss function. And specifically, for PyTorch, we need a training loop and a testing loop. Now, this is what we're going to work towards building throughout the next couple of videos. We're going to focus on these two first, the loss function and optimizer. There's the formal definition of those. You're going to find many different definitions. That's how I'm going to find them. Loss function measures how wrong your model's predictions are, lower is better, optimizer takes into account the loss of your model. So how wrong it is, and starts to move these two values into a way that improves where these red dots end up. But these, again, these principles of a loss function and an optimizer can be for models with two parameters or models with millions of parameters, can be for computer vision models, or could be for simple models like ours that predict the dots on a straight line. So with that being said, let's jump into the next video. We'll start to look a little deeper into loss function, row problem, and an optimizer. I'll see you there. Welcome back. We're in the exciting streak of videos coming up here. I mean, the whole course is fun. Trust me. But this is really exciting because training your first machine learning model seems a little bit like magic, but it's even more fun when you're writing the code yourself what's going on behind the scenes. So we discussed that the whole concept of training is from going unknown parameters, random parameters, such as what we've got so far to parameters that better represent the data. And we spoke of the concept of a loss function. We want to minimize the loss function. That is the whole idea of a training loop in PyTorch, or an optimization loop in PyTorch. And an optimizer is one of those ways that can nudge the parameters of our model. In our case, weights or bias towards values rather than just being random values like they are now towards values that lower the loss function. And if we lower the loss function, what does a loss function do? It measures how wrong our models predictions are compared to the ideal outputs. So if we lower that, well, hopefully we move these red dots towards the green dots. And so as you might have guessed, PyTorch has some built in functionality for implementing loss functions and optimizers. And by the way, what we're covering so far is in the train model section of the PyTorch workflow fundamentals, I've got a little nice table here, which describes a loss function. What does it do? Where does it live in PyTorch? Common values, we're going to see some of these hands on. If you'd like to read about it, of course, you have the book version of the course here. So loss functions in PyTorch, I'm just in docstorch.nn. Look at this. Look at all these loss functions. There's far too many for us to go through all in one hit. So we're just going to focus on some of the most common ones. Look at that. We've got about what's our 15 loss functions, something like that? Well, truth be told is that which one should use? You're not really going to know unless you start to work hands on with different problems. And so in our case, we're going to be looking at L1 loss. And this is an again, once more another instance where different machine learning libraries have different names for the same thing, this is mean absolute error, which we kind of discussed in the last video, which is if we took the distance from this red dot to this green dot and say at 0.4, they're about 0.4, 0.4, and then took the mean, well, we've got the mean absolute error. But in PyTorch, they call it L1 loss, which is a little bit confusing because then we go to MSE loss, which is mean squared error, which is L2. So naming conventions just takes a little bit of getting used to this is a warning for you. So let's have a look at the L1 loss function. Again, I'm just making you aware of where the other loss functions are. We'll do with some binary cross entropy loss later in the course. And maybe even is that categorical cross entropy? We'll see that later on. But all the others will be problem specific. For now, a couple of loss functions like this, L1 loss, MSE loss, we use for regression problems. So that's predicting a number. Cross entropy loss is a loss that you use with classification problems. But we'll see those hands on later on. Let's have a look at L1 loss. So L1 loss creates a criterion. As I said, you might hear the word criterion used in PyTorch for a loss function. I typically call them loss functions. The literature typically calls it loss functions. That measures the mean absolute error. There we go. L1 loss is the mean absolute error between each element in the input X and target Y. Now, your extracurricular measure might have guessed is to read through the documentation for the different loss functions, especially L1 loss. But for the sake of this video, let's just implement it for ourselves. Oh, and if you want a little bit of a graphic, I've got one here. This is where we're up to, by the way, picking a loss function optimizer for step two. This is a fun part, right? We're getting into training a model. So we've got mean absolute error. Here's that graph we've seen before. Oh, look at this. Okay. So we've got the difference here. I've actually measured this before in the past. So I kind of knew what it was. Mean absolute error is if we repeat for all samples in our set that we're working with. And if we take the absolute difference between these two dots, well, then we take the mean, we've got mean absolute error. So MAE loss equals torch mean we could write it out. That's the beauty of pine torch, right? We could write this out. Or we could use the torch and N version, which is recommended. So let's jump in. There's a colorful slide describing what we're about to do. So let's go set up a loss function. And then we're also going to put in here, set up an optimizer. So let's call it loss FN equals NN dot L1 loss. Simple as that. And then if we have a look at what's our loss function, what does this say? Oh my goodness. My internet is going quite slow today. It's raining outside. So there might be some delays somewhere. But that's right. Gives us a chance to sit here and be mindful about what we're doing. Look at that. Okay. Loss function. L1 loss. Beautiful. So we've got a loss function. Our objective for training a machine learning model will be two. Let's go back. Look at the colorful graphic will be to minimize these distances here. And in turn, minimize the overall value of MAE. That is our goal. If our red dots line up with our green dots, we will have a loss value of zero, the ideal point for a model to be. And so let's go here. We now need an optimizer. As we discussed before, the optimizer takes into account the loss of a model. So these two work in tandem. That's why I've put them as similar steps if we go back a few slides. So this is why I put these as 2.1. Often picking a loss function and optimizer and pytorch come as part of the same package because they work together. The optimizer's objective is to give the model values. So parameters like a weight and a bias that minimize the loss function. They work in tandem. And so let's see what an optimizer optimizes. Where might that be? What if we search here? I typically don't use this search because I prefer just using Google search. But does this give us optimizer? Hey, there we go. So again, pytorch has torch.optim which is where the optimizers are. Torch.optim. Let me put this link in here. This is another bit of your extracurricular. If you want to read more about different optimizers in pytorch, as you might have guessed, they have a few. Torch.optim is a package implementing various optimization algorithms. Most commonly used methods are already supported and the interface is general enough so that more sophisticated ones can also be easily integrated into the future. So if we have a look at what algorithms exist here, again, we're going to throw a lot of names at you. But in the literature, a lot of them that have made it into here are already good working algorithms. So it's a matter of picking whichever one's best for your problem. How do you find that out? Well, SGD, stochastic gradient descent, is possibly the most popular. However, there are some iterations on SGD, such as Adam, which is another one that's really popular. So again, this is one of those other machine learning is part art, part science is trial and error of figuring out what works best for your problem for us. We're going to start with SGD because it's the most popular. And if you were paying attention to a previous video, you might have seen that I said, look up gradient descent, wherever we got this gradient descent. There we go. So this is one of the main algorithms that improves our models. So gradient descent and back propagation. So if we have a look at this stochastic gradient descent, bit of a tongue twister, is random gradient descent. So that's what stochastic means. So basically, our model improves by taking random numbers, let's go down here, here, and randomly adjusting them so that they minimize the loss. And once how optimizer, that's right here, once how optimizer torch dot opt in, let's implement SGD, SGD stochastic gradient descent. We're going to write this here, stochastic gradient descent. It starts by randomly adjusting these values. And once it's found some random values or random steps that have minimized the loss value, we're going to see this in action later on, it's going to continue adjusting them in that direction. So say it says, oh, weights, if I increase the weights, it reduces the loss. So it's going to keep increasing the weights until the weights no longer reduce the loss. Maybe it gets to a point at say 0.65. If you increase the weights anymore, the loss is going to go up. So the optimizer is like, well, I'm going to stop there. And then for the bias, the same thing happens. If it decreases the bias and finds that the loss increases, well, it's going to go, well, I'm going to try increasing the bias instead. So again, one last summary of what's going on here, a loss function measures how wrong our model is. And the optimizer adjust our model parameters, no matter whether there's two parameters or millions of them to reduce the loss. There are a couple of things that an optimizer needs to take in. It needs to take in as an argument, params. So this is if we go to SGD, I'm just going to link this as well. SGD, there's the formula of what SGD does. I look at this and I go, hmm, there's a lot going on here. And take me a while to understand that. So I like to see it in code. So we need params. This is short for what parameters should I optimize as an optimizer. And then we also need an LR, which stands for, I'm going to write this in a comment, LR equals learning rate, possibly the most, oh, I didn't even type rate, did I possibly the most important hyper parameter you can set? So let me just remind you, I'm throwing lots of words out here, but I'm kind of like trying to write notes about what we're doing. Again, we're going to see these in action in a second. So check out our models and parameters. So a parameter is a value that the model sets itself. So learning rate equals possibly the most important learning hyper parameter. I don't need learning there, do I? Hyper parameter. And a hyper parameter is a value that us as a data scientist or a machine learning engineer set ourselves, you can set. So the learning rate is, in our case, let's go 0.01. You're like, Daniel, where did I get this value from? Well, again, these type of values come with experience. I think it actually says it in here, LR, LR 0.1. Yeah, okay, so the default is 0.1. But then if we go back to Optim, I think I saw it somewhere. Did I see it somewhere? 0.0? Yeah, there we go. Yeah, so a lot of the default settings are pretty good in torch optimizers. However, the learning rate, what does it actually do? We could go 0.01. These are all common values here. Triple zero one. I'm not sure exactly why. Oh, model, it's model zero. The learning rate says to our optimizer, yes, it's going to optimize our parameters here. But the higher the learning rate, the more it adjusts each of these parameters in one hit. So let's say it's 0.01. And it's going to optimize this value here. So it's going to take that big of a step. If we changed it to here, it's going to take a big step on this three. And if we changed it to all the way to the end 0.01, it's only going to change this value. So the smaller the learning rate, the smaller the change in the parameter, the larger the learning rate, the larger the change in the parameter. So we've set up a loss function. We've set up an optimizer. Let's now move on to the next step in our training workflow. And that's by building a training loop. Far out. This is exciting. I'll see you in the next video. Welcome back. In the last video, we set up a loss function. And we set up an optimizer. And we discussed the roles of each. So loss function measures how wrong our model is. The optimizer talks to the loss function and goes, well, if I change these parameters a certain way, does that reduce the loss function at all? And if it does, yes, let's keep adjusting them in that direction. If it doesn't, let's adjust them in the opposite direction. And I just want to show you I added a little bit of text here just to concretely put down what we were discussing. Inside the optimizer, you'll often have to set two parameters, params and lr, where params is the model parameters you'd like to optimize for an example, in our case, params equals our model zero parameters, which were, of course, a weight and a bias. And the learning rate, which is lr in optimizer, lr stands for learning rate. And the learning rate is a hyper parameter. Remember, a hyper parameter is a value that we the data scientist or machine learning engineer sets, whereas a parameter is what the model sets itself defines how big or smaller optimizer changes the model parameters. So a small learning rate, so the smaller this value results in small changes, a large learning rate results in large changes. So another question might be, well, very valid question. Hey, I put this here already, is which loss function and which optimizer should I use? So this is another tough one, because it's problem specific. But with experience and machine learning, I'm showing you one example here, you'll get an idea of what works for your particular problem for a regression problem, like ours, a loss function of l1 loss, which is mai and pytorch. And an optimizer like torch dot opt in slash s gd like sarcastic gradient descent will suffice. But for a classification problem, we're going to see this later on. Not this one specifically, whether a photo is a cat of a dog, that's just an example of a binary classification problem, you might want to use a binary classification loss. But with that being said, we now are moving on to, well, here's our whole goal is to reduce the MAE of our model. Let's get the workflow. We've done these two steps. Now we want to build a training loop. So let's get back into here. There's going to be a fair few steps going on. We've already covered a few, but hey, nothing we can't handle together. So building a training loop in pytorch. So I thought about just talking about what's going on in the training loop, but we can talk about the steps after we've coded them. How about we do that? So we want to build a training loop and a testing loop. How about we do that? So a couple of things we need in a training loop. So there's going to be a fair few steps here if you've never written a training loop before, but that is completely fine because you'll find that the first couple of times that you write this, you'll be like, oh my gosh, there's too much going on here. But then when you have practice, you'll go, okay, I see what's going on here. And then eventually you'll write them with your eyes closed. I've got a fun song for you to help you out remembering things. It's called the unofficial pytorch optimization loop song. We'll see that later on, or actually, I'll probably leave that as an extension, but you'll see that you can also functionize these things, which we will do later in the course so that you can just write them once and then forget about them. But we're going to write it all from scratch to begin with so we know what's happening. So we want to, or actually step zero, is loop through the data. So we want to look at the data multiple times because our model is going to, at first, start with random predictions on the data, make some predictions. We're trying to improve those. We're trying to minimize the loss to make those predictions. We do a forward pass. So forward pass. Why is it called a forward pass? So this involves data moving through our model's forward functions. Now that I say functions because there might be plural, there might be more than one. And the forward method recall, we wrote in our model up here. Ford. A forward pass is our data going through this function here. And if you want to look at it visually, let's look up a neural network graphic. Images, a forward pass is just data moving from the inputs to the output layer. So starting here input layer moving through the model. So that's a forward pass, also called forward propagation. Another time we'll have more than one name is used for the same thing. So we'll go back down here, forward pass. And I'll just write here also called forward propagation, propagation. Wonderful. And then we need to calculate the loss. So forward pass. Let me write this. To calculate or to make predictions, make predictions on data. So calculate the loss, compare forward pass predictions. Oh, there's an undergoing in the background here of my place. We might be in for a storm. Perfect time to write code, compare forward pass predictions to ground truth labels. We're going to see all this in code in a second, calculate the loss. And then we're going to go optimise a zero grad. We haven't spoken about what this is, but that's okay. We're going to see that in a second. I'm not going to put too much there. Loss backward. We haven't discussed this one either. There's probably three steps that we haven't really discussed. We've discussed the idea behind them, but not too much in depth. Optimise our step. So this one is loss backwards is move backwards. If the forward pass is forwards, like through the network, the forward pass is data goes into out. The backward pass data goes, our calculations happen backwards. So we'll see what that is in a second. Where were we over here? We've got too much going on. I'm getting rid of these moves backwards through the network to calculate the gradients. Oh, oh, the gradients of each of the parameters of our model with respect to the loss. Oh my gosh, that is an absolute mouthful, but that'll do for now. Optimise a step. This is going to use the optimiser to adjust our model's parameters to try and improve the loss. So remember how I said in a previous video that I'd love you to watch the two videos I linked above. One on gradient descent and one on back propagation. If you did, you might have seen like there's a fair bit of math going on in there. Well, that's essentially how our model goes from random parameters to better parameters, using math. Many people, one of the main things I get asked from machine learning is how do I learn machine learning if I didn't do math? Well, the beautiful thing about PyTorch is that it implements a lot of the math of back propagation. So this is back propagation. I'm going to write this down here. This is an algorithm called back, back propagation, hence the loss backward. We're going to see this in code in a second, don't you worry? And this is gradient descent. So these two algorithms drive the majority of our learning. So back propagation, calculate the gradients of the parameters of our model with respect to the loss function and optimise our step, we'll trigger code to run gradient descent, which is to minimise the gradients because what is a gradient? Let's look this up. What is a gradient? I know we haven't written a code yet, but we're going to do that. Images. Gradient, there we go. Changing y, changing x. Gradient is from high school math. Gradient is a slope. So if you were on a hill, let's find a picture of a hill. Picture of a hill. There we go. This is a great big hill. So if you were on the top of this hill, and you wanted to get to the bottom, how would you get to the bottom? Well, of course, you just walked down the hill. But if you're a machine learning model, what are you trying to do? Let's imagine your loss is the height of this hill. You start off with your losses really high, and you want to take your loss down to zero, which is the bottom, right? Well, if you measure the gradient of the hill, the bottom of the hill is in the opposite direction to where the gradient is steep. Does that make sense? So the gradient here is an incline. We want our model to move towards the gradient being nothing, which is down here. And you could argue, yeah, the gradient's probably nothing up the top here, but let's just for argument's sake say that we want to get to the bottom of the hill. So we're measuring the gradient, and one of the ways an optimisation algorithm works is it moves our model parameters so that the gradient equals zero, and then if the gradient of the loss equals zero, while the loss equals zero two. So now let's write some code. So we're going to set up a parameter called or a variable called epochs. And we're going to start with one, even though this could be any value, let me define these as we go. So we're going to write code to do all of this. So epochs, an epoch is one loop through the data dot dot dot. So epochs, we're going to start with one. So one time through all of the data, we don't have much data. And so for epoch, let's go this, this is step zero, zero, loop through the data. By the way, when I say loop through the data, I want you to do all of these steps within the loop. And do dot dot dot loop through the data. So for epoch in range epochs, even though it's only going to be one, we can adjust this later. And because epochs, we've set this ourselves, it is a, this is a hyper parameter, because we've set it ourselves. And I know you could argue that, hey, our machine learning parameters of model zero, or our model parameters, model zero aren't actually parameters, because we've set them. But in the models that you build in the future, they will likely be set automatically rather than you setting them explicitly like we've done when we created model zero. And oh my gosh, this is taking quite a while to run. That's all right. We don't need it to run fast. We just, we need to write some more code, then you'll come on. There's a step here I haven't discussed either. Set the model to training mode. So pytorch models have a couple of different modes. The default is training mode. So we can set it to training mode by going like this. Train. So what does train mode do in a pytorch model? My goodness. Is there a reason my engineer is going this slide? That's all right. I'm just going to discuss this with talking again list. Train mode. Train mode in pytorch sets. Oh, there we go. Requires grad equals true. Now I wonder if we do with torch dot no grad member no grad is similar to inference mode. Will this adjust? See, I just wanted to take note of requires grad equals true. Actually, what I might do is we do this in a different cell. Watch this. This is just going to be rather than me just spit words at you. I reckon we might be able to get it work in doing this. Oh, that didn't list the model parameters. Why did that not come out? Model zero dot eval. So there's two modes of our mode and train mode model dot eval parameters. Hey, we're experimenting together on the fly here. And actually, this is what I want you to do is I want you to experiment with different things. It's not going to say requires grad equals false. Hmm. With torch dot no grad. Model zero dot parameters. I don't know if this will work, but it definitely works behind the scenes. And what I mean by works behind the scenes are not here. It works behind the scenes when calculations have been made, but not if we're trying to explicitly print things out. Well, that's an experiment that I thought was going to work and it didn't work. So train mode in pytorch sets all parameters that require gradients to require gradients. So do you remember with the picture of the hill? I spoke about how we're trying to minimize the gradient. So the gradient is the steepness of the hill. If the height of the hill is a loss function and we want to take that down to zero, we want to take the gradient down to zero. So same thing with the gradients of our model parameters, which are here with respect to the loss function, we want to try and minimize that gradient. So that's gradient descent is take that gradient down to zero. So model dot train. And then there's also model zero dot a vowel. So turns off gradient tracking. So we're going to see that later on. But for now, I feel like this video is getting far too long. Let's finish the training loop in the next video. I'll see you there. Friends, welcome back. In the last video, I promised a lot of code, but we didn't get there. We discussed some important steps. I forgot how much behind the scenes there is to apply towards training loop. And I think it's important to spend the time that we did discussing what's going on, because there's a fair few steps. But once you know what's going on, I mean, later on, we don't have to write all the code that we're going to write in this video, you can functionize it. We're going to see that later on in the course, and it's going to run behind the scenes for us. But we're spending a fair bit of time here, because this is literally the crux of how our model learns. So let's get into it. So now we're going to implement the forward pass, which involves our model's forward function, which we defined up here. When we built our model, the forward pass runs through this code here. So let's just write that. So in our case, because we're training, I'm just going to write here. This is training. We're going to see dot of our later on. We'll talk about that when it comes. Let's do the forward pass. So the forward pass, we want to pass data through our model's forward method. We can do this quite simply by going y pred. So y predictions, because remember, we're trying to use our ideal model is using x test to predict y test on our test data set. We make predictions on our test data set. We learn on our training data set. So we're passing, which is going to get rid of that because we don't need that. So we're passing our model x train and model zero is going to be our current model. There we go. So we learn patterns on the training data to evaluate our model on the test data. Number two, where we are. So we have to calculate the loss. Now, in a previous video, we set up a loss function. So this is going to help us calculate the what what kind of loss are we using? We want to calculate the MAE. So the difference or the distance between our red dot and a green dot. And the formula would be the same if we had 10,000 red dots and 10,000 green dots, we're calculating how far they are apart. And then we're taking the mean of that value. So let's go back here. So calculate the loss. And in our case, we're going to set loss equal to our loss function, which is L one loss in PyTorch, but it is MAE. Y-pred and Y-train. So we're calculating the difference between our models predictions on the training data set and the ideal training values. And if you want to go into torch dot NN loss functions, that's going to show you the order because sometimes this confuses me to what order the values go in here, but it goes prediction first, then labels and I may be wrong there because I get confused here. My dyslexia kicks in, but I'm pretty sure it's predictions first, then actual labels. Do we have an example of where it's used? Yeah, import first, target next. So there we go. And truth be told, because it's mean absolute error, it shouldn't actually matter too much. But in the case of staying true to the documentation, let's do inputs first and then targets next for the rest of the course. Then we're going to go optimizer zero grad. Hmm, haven't discussed this one, but that's okay. I'm going to write the code and then I'm going to discuss what it does. So what does this do? Actually, before we discuss this, I'm going to write these two steps because they kind of all work together. And it's a lot easier to discuss what optimizer zero grad does in the context of having everything else perform back propagation on the loss with respect to the parameters of the model. Back propagation is going to take the loss value. So lost backward, I always say backwards, but it's just backward. That's the code there. And then number five is step the optimizer. So perform gradient descent. So optimizer dot step. Oh, look at us. We just wrote the five major steps of a training loop. Now let's discuss how all of these work together. So it's kind of strange, like the ordering of these, you might think, Oh, what should I do the order? Typically the forward pass and the loss come straight up. Then there's a little bit of ambiguity around what order these have to come in. But the optimizer step should come after the back propagation. So I just like to keep this order how it is because this works. Let's just keep it that way. But what happens here? Well, it also is a little bit confusing in the first iteration of the loop because we've got zero grad. But what happens here is that the optimizer makes some calculations in how it should adjust model parameters with regards to the back propagation of the loss. And so by default, these will by default, how the optimizer changes will accumulate through the loop. So we have to zero them above in step three for the next iteration of the loop. So a big long comment there. But what this is saying is, let's say we go through the loop and the optimizer chooses a value of one, change it by one. And then it goes through a loop again, if we didn't zero it, if we didn't take it to zero, because that's what it is doing, it's going one to zero, it would go, okay, next one, two, three, four, five, six, seven, eight, all through the loop, right? Because we're looping here. If this was 10, it would accumulate the value that it's supposed to change 10 times. But we want it to start again, start fresh each iteration of the loop. And now the reason why it accumulates, that's pretty deep in the pytorch documentation. From my understanding, there's something to do with like efficiency of computing. If you find out what the exact reason is, I'd love to know. So we have to zero it, then we perform back propagation. If you recall, back propagation is discussed in here. And then with optimizer step, we form gradient descent. So the beauty of pytorch, this is the beauty of pytorch, is that it will perform back propagation, we're going to have a look at this in second, and gradient descent for us. So to prevent this video from getting too long, I know we've just written code, but I would like you to practice writing a training loop yourself, just write this code, and then run it and see what happens. Actually, you can comment this out, we're going to write the testing loop in a second. So your extra curriculum for this video is to, one, rewrite this training loop, is to, two, sing the pytorch optimization loop song, let's go into here. If you want to remember the steps, well, I've got a song for you. This is the training loop song, we haven't discussed the test step, but maybe you could try this yourself. So this is an old version of the song, actually, I've got a new one for you. But let's sing this together. It's training time. So we do the forward pass, calculate the loss, optimise a zero grad, loss backwards, optimise a step, step, step. Now you only have to call optimise a step once, this is just for jingle purposes. But for test time, let's test with torch no grad, do the forward pass, calculate the loss, watch it go down, down, down. That's from my Twitter, but this is a way that I help myself remember the steps that are going on in the code here. And if you want the video version of it, well, you're just going to have to search unofficial pytorch optimisation loop song. Oh, look at that, who's that guy? Well, he looks pretty cool. So I'll let you check that out in your own time. But for now, go back through the training loop steps. I've got a colorful graphic coming up in the next video, we're going to write the testing steps. And then we're going to go back one more time and talk about what's happening in each of them. And again, if you'd like some even more extra curriculum, don't forget the videos I've shown you on back propagation and gradient descent. But for now, let's leave this video here. I'll see you in the next one. Friends, welcome back. In the last few videos, we've been discussing the steps in a training loop in pytorch. And there's a fair bit going on. So in this video, we're going to step back through what we've done just to recap. And then we're going to get into testing. And it's nice and early where I am right now. The sun's about to come up. It's a very, very beautiful morning to be writing code. So let's jump in. We've got a little song here for what we're doing in the training steps. For an epoch in a range, comodel.train, do the forward pass, calculate the loss of the measure zero grad, last backward of the measure step step step. That's the little jingle I use to remember the steps in here, because the first time you write it, there's a fair bit going on. But subsequent steps and subsequent times that you do write it, you'll start to memorize this. And even better later on, we're going to put it into a function so that we can just call it over and over and over and over again. With that being said, let's jump in to a colorful slide, because that's a lot of code on the page. Let's add some color to it, understand what's happening. That way you can refer to this and go, Hmm, I see what's going on now. So for the loop, this is why it's called a training loop. We step through a number of epochs. One epoch is a single forward pass through the data. So pass the data through the model for a number of epochs. Epox is a hyper parameter, which means you could set it to 100, you could set it to 1000, you could set it to one as we're going to see later on in this video. We skip this step with the colors, but we put the model in we call model.train. This is the default mode that the model is in. Essentially, it sets up a whole bunch of settings behind the scenes in our model parameters so that they can track the gradients and do a whole bunch of learning behind the scenes with these functions down here. PyTorch does a lot of this for us. So the next step is the forward pass. We perform a forward pass on the training data in the training loop. This is an important note. In the training loop is where the model learns patterns on the training data. Whereas in the testing loop, we haven't got to that yet is where we evaluate the patterns that our model has learned or the parameters that our model has learned on unseen data. So we pass the data through the model, this will perform the forward method located within the model object. So because we created a model object, you can actually call your models whatever you want, but it's good practice to you'll often see it just called model. And if you remember, we'll go back to the code. We created a forward method in our model up here, which is this, because our linear regression model, class, subclasses, nn.module, we need to create our own custom forward method. So that's why it's called a forward pass is because not only does it, well, the technical term is forward propagation. So if we have a look at a neural network picture, forward propagation just means going through the network from the input to the output, there's a thing called back propagation, which we're going to discuss in a second, which happens when we call loss.backward, which is going backward through the model. But let's return to our colorful slide. We've done the forward pass, call a forward method, which performs some calculation on the data we pass it. Next is we calculate the loss value, how wrong the model's predictions are. And this will depend on what loss function you use, what kind of predictions your model is outputting, and what kind of true values you have. But that's what we're doing here. We're comparing our model's predictions on the training data to what they should ideally be. And these will be the training labels. The next step, we zero the optimizer gradients. So why do we do this? Well, it's a little confusing for the first epoch in the loop. But as we get down to optimizer dot step here, the gradients that the optimizer calculates accumulate over time so that for each epoch for each loop step, we want them to go back to zero. And now the exact reason behind why the optimizer accumulates gradients is buried somewhere within the pie torch documentation. I'm not sure of the exact reason from memory. It's because of compute optimization. It just adds them up in case you wanted to know what they were. But if you find out exactly, I'd love to know. Next step is to perform back propagation on the loss function. That's what we're calling loss. backward. Now back propagation is we compute the gradient of every parameter with requires grad equals true. And if you recall, we go back to our code. We've set requires grad equals true for our parameters. Now the reason we've set requires grad equals true is not only so back propagation can be performed on it. But let me show you what the gradients look like. So let's go loss function curve. That's a good idea. So we're looking for so we're looking for some sort of convex curve here. There we go. L two loss. We're using L one loss at the moment. Is there a better one here? All we need is just a nice looking curve. Here we go. So this is why we keep track of the gradients behind the scenes. Pie torch is going to create some sort of curve for all of our parameters that looks like this. Now this is just a 2d plot. So the reason why we're just using an example from Google images is one, because you're going to spend a lot of your time Googling different things. And two, in practice, when you have your own custom neural networks, right now we only have two parameters. So it's quite easy to visualize a loss function curve like this. But when you have say 10 million parameters, you basically can't visualize what's going on. And so pie torch again will take care of these things behind the scenes. But what it's doing is when we say requires grad pie torch is going to track the gradients of each of our parameters. And so what we're trying to do here with back propagation and subsequently gradient descent is calculate where the lowest point is. Because this is a loss function, this is MSC loss, we could trade this out to be MAE loss in our case or L1 loss for our specific problem. But this is some sort of parameter. And we calculate the gradients because what is the gradient? Let's have a look. What is a gradient? A gradient is an inclined part of a road or railway. Now we want it in machine learning. What's it going to give us in machine learning, a gradient is a derivative of a function that has more than one input variable. Okay, let's dive in a little deeper. See, here's some beautiful loss landscapes. We're trying to get to the bottom of here. This is what gradient descent is all about. So oh, there we go. So this is a cost function, which is also a loss function. We start with a random initial variable. What have we done? We started with a random initial variable. Right? Okay. And then we take a learning step. Beautiful. This is W. So this could be our weight parameter. Okay, we're connecting the dots here. This is exciting. We've got a lot of tabs here, but that's all right. We'll bring this all together in a second. And what we're trying to do is come to the minimum. Now, why do we need to calculate the gradients? Well, the gradient is what? Oh, value of weight. Here we go. This is even better. I love Google images. So this is our loss. And this is a value of a weight. So we calculate the gradients. Why? Because the gradient is the slope of a line or the steepness. And so if we calculate the gradient here, and we find that it's really steep right up the top of this, this incline, we might head in the opposite direction to that gradient. That's what gradient descent is. And so if we go down here, now, what are these step points? There's a little thing that I wrote down in the last video at the end of the last video I haven't told you about yet, but I was waiting for a moment like this. And if you recall, I said kind of all of these three steps optimizes zero grad loss backward, optimizes step are all together. So we calculate the gradients because we want to head in the opposite direction of that gradient to get to a gradient value of zero. And if we get to a gradient value of zero with a loss function, well, then the loss is also zero. So that's why we keep track of a gradient with requires grad equals true. And again, PyTorch does a lot of this behind the scenes. And if you want to dig more into what's going on here, I'm going to show you some extra resources for back propagation, which is calculating this gradient curve here, and gradient descent, which is finding the bottom of it towards the end of this video. And again, if we started over this side, we would just go in the opposite direction of this. So maybe this is a positive gradient here, and we just go in the opposite direction here. We want to get to the bottom. That is the main point of gradient descent. And so if we come back, I said, just keep this step size in mind here. If we come back to where we created our loss function and optimizer, I put a little tidbit here for the optimizer. Because we've written a lot of code, and we haven't really discussed what's going on, but I like to do things on the fly as we need them. So inside our optimizer, we'll have main two parameters, which is params. So the model parameters you'd like to optimize, params equals model zero dot parameters in our case. And then PyTorch is going to create something similar to this curve, not visually, but just mathematically behind the scenes for every parameter. Now, this is a value of weight. So this would just be potentially the weight parameter of our network. But again, if you have 10 million parameters, there's no way you could just create all of these curves yourself. That's the beauty of PyTorch. It's doing this behind the scenes through a mechanism called torch autograd, which is auto gradient calculation. And there's beautiful documentation on this. If you'd like to read more on how it works, please go through that. But essentially behind the scenes, it's doing a lot of this for us for each parameter. That's the optimizer. Then within the optimizer, once we've told it what parameters to optimize, we have the learning rate. So the learning rate is another hyper parameter that defines how big or small the optimizer changes the parameters with each step. So a small learning rate results in small changes, whereas a large learning rate is in large changes. And so if we look at this curve here, we might at the beginning start with large steps, so we can get closer and closer to the bottom. But then as we get closer and closer to the bottom, to prevent stepping over to this side of the curve, we might do smaller and smaller steps. And the optimizer in PyTorch, there are optimizers that do that for us. But there is also another concept called learning rate scheduling, which is, again, something if you would like to look up and do more. But learning rate scheduling essentially says, hey, maybe start with some big steps. And then as we get closer and closer to the bottom, reduce how big the steps are that we take. Because if you've ever seen a coin, coin at the back of couch. This is my favorite analogy for this. If you've ever tried to reach a coin at the back of a couch, like this excited young chap, if you're reaching towards the back of a couch, you take quite big steps as you say your arm was over here, you would take quite big steps until you get to about here. And in the closer you get to the coin, the smaller and smaller your steps are. Otherwise, what's going to happen? The coin is going to be lost. Or if you took two small steps, you'd never get to the coin. It would take forever to get there. So that's the concept of learning rate. If you take two big steps, you're going to just end up over here. If you take two small steps, it's going to take you forever to get to the bottom here. And this bottom point is called convergence. That's another term you're going to come across. I know I'm throwing a lot of different terms at you, but that's the whole concept of the learning rate. How big is your step down here? In gradient descent. Gradient descent is this. Back propagation is calculating these derivative curves or the gradient curves for each of the parameters in our model. So let's get out of here. We'll go back to our training steps. Where were we? I think we're up to back propagation. Have we done backward? Yes. So the back propagation is where we do the backward steps. So the forward pass, forward propagation, go from input to output. Back propagation, we take the gradients of the loss function with respect to each parameter in our model by going backwards. That's what happens when we call loss.backward. PyTorch does that for us behind the scenes. And then finally, step number five is step the optimizer. We've kind of discussed that. As I said, if we take a step, let's get our loss curve back up. Loss function curve. Doesn't really matter what curve we use. The optimizer step is taking a step this way to try and optimize the parameters so that we can get down to the bottom here. And I also just noted here that you can turn all of this into a function so we don't necessarily have to remember to write these every single time. The ordering of this, you'll want to do the forward pass first. And then calculate the loss because you can't calculate the loss unless you do the forward pass. I like this ordering here of these three as well. But you also want to do the optimizer step after the loss backward. So this is my favorite ordering. It works. If you like this ordering, you can take that as well. With that being said, I think this video has gotten long enough. In the next video, I'd like to step through this training loop one epoch at a time so that we can see, I know I've just thrown a lot of words at you that this optimizer is going to try and optimize our parameters each step. But let's see that in action how our parameters of our model actually change every time we go through each one of these steps. So I'll see you in the next video. Let's step through our model. Welcome back. And we've spent a fair bit of time on the training loop and the testing loop. Well, we haven't even got to that yet, but there's a reason behind this, because this is possibly one of the most important things aside from getting your data ready, which we're going to see later on in PyTorch deep learning is writing the training loop, because this is literally like how your model learns patterns and data. So that's why we're spending a fair bit of time on here. And we'll get to the testing loop, because that's how you evaluate the patterns that your model has learned from data, which is just as important as learning the patterns themselves. And following on from the last couple of videos, I've just linked some YouTube videos that I would recommend for extra curriculum for back propagation, which is what happens when we call loss stop backward down here. And for the optimizer step, gradient descent is what's happening there. So I've linked some extra resources for what's going on behind the scenes there from a mathematical point of view. Remember, this course focuses on writing PyTorch code. But if you'd like to dive into what math PyTorch is triggering behind the scenes, I'd highly recommend these two videos. And I've also added a note here as to which loss function and optimizer should I use, which is a very valid question. And again, it's another one of those things that's going to be problem specific. But with experience over time, you work with machine learning problems, you write a lot of code, you get an idea of what works and what doesn't with your particular problem set. For example, like a regression problem, like ours, regression is again predicting a number. We use MAE loss, which PyTorch causes L1 loss. You could also use MSE loss and an optimizer like torch opt-in stochastic gradient descent will suffice. But for classification, you might want to look into a binary classification, a binary cross entropy loss, but we'll look at a classification problem later on in the course. For now, I'd like to demonstrate what's going on in the steps here. So let's go model zero. Let's look up the state dict and see what the parameters are for now. Now they aren't the original ones I don't think. Let's re-instantiate our model so we get re new parameters. Yeah, we recreated it here. I might just get rid of that. So we'll rerun our model code, rerun model state dict. And we will create an instance of our model and just make sure your parameters should be something similar to this. If it's not exactly like that, it doesn't matter. But yeah, I'm just going to showcase you'll see on my screen what's going on anyway. State dict 3367 for the weight and 012888 for the bias. And again, I can't stress enough. We've only got two parameters for our model and we've set them ourselves future models that you build and later ones in the course will have much, much more. And we won't actually explicitly set any of them ourselves. We'll check out some predictions. They're going to be terrible because we're using random parameters to begin with. But we'll set up a new loss function and an optimizer. Optimizer is going to optimize our model zero parameters, the weight and bias. The learning rate is 0.01, which is relatively large step. That would be a bit smaller. Remember, the larger the learning rate, the bigger the step, the more the optimizer will try to change these parameters every step. But let's stop talking about it. Let's see it in action. I've set a manual seed here too, by the way, because the optimizer steps are going to be quite random as well, depending on how the models predictions go. But this is just to try and make it as reproduces possible. So keep this in mind, if you get different values to what we're going to output here from my screen to your screen, don't worry too much. What's more important is the direction they're going. So ideally, we're moving these values here. This is from we did one epoch before. We're moving these values closer to the true values. And in practice, you won't necessarily know what the true values are. But that's where evaluation of your model comes in. We're going to cover that when we write a testing loop. So let's run one epoch. Now I'm going to keep that down there. Watch what happens. We've done one epoch, just a single epoch. We've done the forward pass. We've calculated the loss. We've done optimizer zero grad. We've performed back propagation. And we've stepped the optimizer. What is stepping the optimizer do? It updates our model parameters to try and get them further closer towards the weight and bias. If it does that, the loss will be closer to zero. That's what it's trying to do. How about we print out the loss at the same time. Print loss and the loss. Let's take another step. So the loss is 0301. Now we check the weights and the bias. We've changed again three, three, four, four, five, one, four, eight, eight. We go again. The loss is going down. Check it. Hey, look at that. The values are getting closer to where they should be if over so slightly. Loss went down again. Oh my goodness, this is so amazing. Look, we're training our, let's print this out in the same cell. Print our model. State dict. We're training our first machine learning model here, people. This is very exciting, even if it's only step by step and it's only a small model. This is very important. Loss is going down again. Values are getting closer to where they should be. Again, we won't really know where they should be in real problems, but for now we do. So let's just get excited. The real way to sort of measure your model's progress and practice is a lower loss value. Remember, lower is better. A loss value measures how wrong your model is. We're going down. We're going in the right direction. So that's what I meant by, as long as your values are going in the similar direction. So down, we're writing similar code here, but if your values are slightly different in terms of the exact numbers, don't worry too much because that's inherent to the randomness of machine learning, because the steps that the optimizer are taking are inherently random, but they're sort of pushed in a direction. So we're doing gradient descent here. This is beautiful. How low can we get the loss? How about we try to get to 0.1? Look at that. We're getting close to 0.1. And then, I mean, we don't have to do this hand by hand. The bias is getting close to where it exactly should be. We're below 0.1. Beautiful. So that was only about, say, 10 passes through the data, but now you're seeing it in practice. You're seeing it happen. You're seeing gradient descent. Let's go gradient descent work in action. We've got images. This is what's happening. We've got our cost function. J is another term for cost function, which is also our loss function. We start with an initial weight. What have we done? We started with an initial weight, this value here. And what are we doing? We've measured the gradient pytorch has done that behind the scenes for us. Thank you pytorch. And we're taking steps towards the minimum. That's what we're trying to do. If we minimize the gradient of our weight, we minimize the cost function, which is also a loss function. We could keep going here for hours and get as long as we want. But my challenge for you, or actually, how about we make some predictions with our model we've got right now? Let's make some predictions. So with torch dot inference mode, we'll make some predictions together. And then I'm going to set you a challenge. How about you run this code here for 100 epochs after this video, and then you make some predictions and see how that goes. So why preds? Remember how poor our predictions are? Why preds new equals, we just do the forward pass here. Model zero on the test data. Let's just remind ourselves quickly of how poor our previous predictions were. Plot predictions, predictions equals y. Do we still have this saved? Why preds? Hopefully, this is still saved. There we go. Shocking predictions, but we've just done 10 or so epochs. So 10 or so training steps have our predictions. Do they look any better? Let's run this. We'll copy this code. You know my rule. I don't really like to copy code, but in this case, I just want to exemplify a point. I like to write all the code myself. What do we got? Why preds new? Look at that. We are moving our predictions close at the red dots closer to the green dots. This is what's happening. We're reducing the loss. In other words, we're reducing the difference between our models predictions and our ideal outcomes through the power of back propagation and gradient descent. So this is super exciting. We're training our first machine learning model. My challenge to you is to run this code here. Change epochs to 100. See how low you can get this loss value and run some predictions, plot them. And I think it's time to start testing. So give that a go yourself, and then we'll write some testing code in the next video. I'll see you there. Welcome back. In the last video, we did something super excited. We saw our loss go down. So the loss is remember how different our models predictions are to what we'd ideally like them. And we saw our model update its parameters through the power of back propagation and gradient descent, all taken care of behind the scenes for us by PyTorch. So thank you, PyTorch. And again, if you'd like some extra resources on what's actually happening from a math perspective for back propagation and gradient descent, I would refer to you to these. Otherwise, this is also how I learn about things. Gradient descent. There we go. How does gradient descent work? And then we've got back propagation. And just to reiterate, I am doing this and just Googling these things because that's what you're going to do in practice. You're going to come across a lot of different things that aren't covered in this course. And this is seriously what I do day to day as a machine learning engineer if I don't know what's going on. Just go to Google, read, watch a video, write some code, and then I build my own intuition for it. But with that being said, I also issued you the challenge of trying to run this training code for 100 epochs. Did you give that a go? I hope you did. And how low did your loss value? Did the weights and bias get anywhere close to where they should have been? How do the predictions look? Now, I'm going to save that for later on, running this code for 100 epochs. For now, let's write some testing code. And just a note, you don't necessarily have to write the training and testing loop together. You can functionize them, which we will be doing later on. But for the sake of this intuition, building and code practicing and first time where we're writing this code together, I'm going to write them together. So testing code, we call model.ofour, what does this do? So this turns off different settings in the model not needed for evaluation slash testing. This can be a little confusing to remember when you're writing testing code. But we're going to do it a few times until it's habit. So just make it a habit. If you're training your model, call model dot train to make sure it's in training mode. If you're testing or evaluating your model. So that's what a vowel stands for evaluate, call model dot a vowel. So it turns off different settings in the model not needed for evaluation. So testing, this is things like drop out. We haven't seen what drop out is slash batch norm layers. But if we go into torch dot and end, I'm sure you'll come across these things in your future machine learning endeavors. So drop out drop out layers. There we go. And batch norm. Do we have batch batch norm? There we go. If you'd like to work out what they are, feel free to check out the documentation. Just take it from me for now that model of our turns off different settings not needed for evaluation and testing. Then we set up with torch dot inference mode, inference mode. So what does this do? Let's write down here. So this turns off gradient tracking. So as we discussed, if we have parameters in our model, and it turns off actually a few more things and a couple more things behind the scenes, these are things again, not needed for testing. So we discussed that if parameters in our model have requires grad equals true, which is the default for many different parameters in pytorch, pytorch will behind the scenes keep track of the gradients of our model and use them in lost up backward and optimizer step for back propagation and gradient descent. However, we only need those two back propagation and gradient descent during training because that is when our model is learning. When we are testing, we are just evaluating the parameters the patterns that our model has learned on the training data set. So we don't need to do any learning when we're testing. So we turn off the things that we don't need. And is this going to have the correct spacing for me? I'm not sure we'll find out. So we still do the forward pass in testing mode, do the forward pass. And if you want to look up torch inference mode, just go torch inference mode. There's a great tweet about it that pytorch did, which explains what's happening. I think we've covered this before, but yeah, want to make your inference code and pytorch run faster. Here's a quick thread on doing exactly that. So inference mode is torch no grad. Again, you might see torch no grad. I think I'll write that down just to let you know. But here's what's happening behind the scenes. A lot of optimization code, which is beautiful. This is why we're using pytorch so that our code runs nice and far. Let me go there. You may also see with torch dot no grad in older pytorch code. It does similar things, but inference mode is the faster way of doing things according to the thread. And according to there's a blog post attached to there as well, I believe. So you may also see torch dot no grad in older pytorch code, which would be valid. But again, inference mode is the better way of doing things. So do forward pass. So let's get our model. We want to create test predictions here. So we're going to go model zero. There's a lot of code going on here, but I'm going to just step by step it in a second. We'll go back through it all. And then number two is calculate the loss. Now we're doing the test predictions here, calculate the loss test predictions with model zero. So now we want to calculate the what we want to calculate the test loss. So this will be our loss function, the difference between the test pred and the test labels. That's important. So for testing, we're working with test data, for training, we're working with training data. Model learns patterns on the training data, and it evaluates those patterns that it's learned, the different parameters on the testing data. It has never seen before, just like in a university course, you'd study the course materials, which is the training data, and you'd evaluate your knowledge on materials you'd hopefully never seen before, unless you sort of were friends with your professor, and they gave you the exam before the actual exam that would be cheating right. So that's a very important point for the test data set. Don't let your model see the test data set before you evaluate it. Otherwise, you'll get poor results. And that's putting it out what's happening. Epoch, we're going to go Epoch, and then I will introduce you to my little jingle to remember all of these steps because there's a lot going on. Don't you worry. I know there's a lot going on, but again, with practice, we're going to know what's happening here. Like it's the back of our hand. All right. So do we need this? Oh, yeah, we could say that. Oh, no, we don't need test here. Loss. This is loss, not test. Print out what's happening. Okay. And we don't actually need to do this every epoch. We could just go say if epoch divided by 10 equals zero, print out what's happening. Let's do that rather than clutter everything up, print it out, and we'll print out this. So let's just step through what's happening. We've got 100 epochs. That's what we're about to run, 100 epochs. Our model is trained for about 10 so far. So it's got a good base. Maybe we'll just get rid of that base. Start a new instance of our model. So we'll come right back down. So our model is back to randomly initialized parameters, but of course, randomly initialized flavored with a random seed of 42. Lovely, lovely. And so we've got our training code here. We've discussed what's happening there. Now, we've got our testing code. We call model dot eval, which turns off different settings in the model, not needed for evaluation slash testing. We call with torch inference mode context manager, which turns off gradient tracking and a couple more things behind the scenes to make our code faster. We do the forward pass. We do the test predictions. We pass our model, the test data, the test features to calculate the test predictions. Then we calculate the loss using our loss function. We can use the same loss function that we used for the training data. And it's called the test loss, because it's on the test data set. And then we print out what's happening, because we want to know what's happening while our model's training, we don't necessarily have to do this. But the beauty of PyTorch is you can use basic Python printing statements to see what's happening with your model. And so, because we're doing 100 epochs, we don't want to clutter up everything here. So we'll just print out what's happening every 10th epoch. Again, you can customize this as much as you like what's printing out here. This is just one example. If you had other metrics here, such as calculating model accuracy, we might see that later on, hint hint. We might print out our model accuracy. So this is very exciting. Are you ready to run 100 epochs? How low do you think our loss can go? This loss was after about 10. So let's just save this here. Let's give it a go. Ready? Three, two, one. Let's run. Oh my goodness. Look at that. Waits. Here we go. Every 10 epochs were printing out what's happening. So the zero epoch, we started with losses 312. Look at it go down. Yes, that's what we want. And our weights and bias, are they moving towards our ideal weight and bias values of 0.7 and 0.3? Yes, they're moving in the right direction here. The loss is going down. Epoch 20, wonderful. Epoch 30, even better. 40, 50, going down, down, down. Yes, this is what we want. This is what we want. Now, we're predicting a straight line here. Look how low the loss gets. After 100 epochs, we've got about three times less than what we had before. And then we've got these values are quite close to where they should be, 0.5629, 0.3573. We'll make some predictions. What do they look like? Why preds new? This is the original predictions with random values. And if we make why preds new, look how close it is after 100 epochs. Now, what's our, do we print out the test loss? Oh no, we're printing out loss as well. Let's get rid of that. I think this is this. Yeah, that's this statement here. Our code would have been a much cleaner if we didn't have that, but that's all right. Life goes on. So our test loss, because this is the test predictions that we're making, is not as low as our training loss. I wonder how we could get that lower. What do you think we could do? We just trained it for longer. And what happened? How do you think you could get these red dots to line up with these green dots? Do you think you could? So that's my challenge to you for the next video. Think of something that you could do to get these red dots to match up with these green dots, maybe train for longer. How do you think you could do that? So give that a shot. And I'll see in the next video, we'll review what our testing code is doing. I'll see you there. Welcome back. In the last video, we did something super exciting. We trained our model for 100 epochs and look how good the predictions got. But I finished it off with challenging you to see if you could align the red dots with the green dots. And it's okay if you're not sure how the best way to do that. That's what we're here for. We're here to learn what are the best way to do these things together. But you might have had the idea of potentially training the model for a little bit longer. So how could we do that? Well, we could just rerun this code. So the model is going to remember the parameters that it has from what we've done here. And if we rerun it, well, it's going to start from where it finished off, which is already pretty good for our data set. And then it's going to try and improve them even more. This is, I can't stress enough, like what we are doing here is going to be very similar throughout the entire rest of the course for training more and more models. So this step that we've done here for training our model and evaluating it is seriously like the fundamental steps of deep learning with PyTorch is training and evaluating a model. And we've just done it. Although I'll be it to predict some red dots and green dots. That's all right. So let's try to line them up, hey, red dots onto green dots. I reckon if we train it for another 100 epochs, we should get pretty darn close. Ready? Three, two, one. I'm going to run this cell again. Runs really quick because our data's nice and simple. But look at this, lastly, we started 0244. Where do we get down to? 008. Oh my goodness. So we've improved it by another three X or so. And now this is where our model has got really good. On the test loss, we've gone from 00564. We've gone down to 005. So almost 10X improvement there. And so we make some more predictions. What are our model parameters? Remember the ideal ones here. We won't necessarily know them in practice, but because we're working with a simple data set, we know what the ideal parameters are. Model zero state dig weights. These are what they previously were. What are they going to change to? Oh, would you look at that? Oh, 06990. Now, again, if yours are very slightly different to mine, don't worry too much. That is the inherent randomness of machine learning and deep learning. Even though we set a manual seed, it may be slightly different. The direction is more important. So if your number here is not exactly what mine is, it should still be quite close to 0.7. And the same thing with this one. If it's not exactly what mine is, don't worry too much. The same with all of these loss values as well. The direction is more important. So we're pretty darn close. How do these predictions look? Remember, these are the original ones. We started with random. And now we've trained a model. So close. So close to being exactly that. So a little bit off. But that's all right. We could tweak a few things to improve this. But I think that's well and truly enough for this example purpose. You see what's happened. Of course, we could just create a model and set the parameters ourselves manually. But where would be the fun in that? We just wrote some machine learning code to do it for us with the power of back propagation and gradient descent. Now in the last video, we wrote the testing loop. We discussed a few other steps here. But now let's go over it with a colorful slide. Hey, because I mean, code on a page is nice, but colors are even nicer. Oh, we haven't done this. We might set up this in this video too. But let's just discuss what's going on. Create an empty list for storing useful value. So this is helpful for tracking model progress. How can we just do this right now? Hey, we'll go here and we'll go. So what did we have? Epoch count equals that. And then we'll go lost values. So why do we keep track of these? It's because if we want to monitor our models progress, this is called tracking experiments. So track different values. If we wanted to try and improve upon our current model with a future model. So our current results, such as this, if we wanted to try and improve upon it, we might build an entire other model. And we might train it in a different setup. We might use a different learning rate. We might use a whole bunch of different settings, but we track the values so that we can compare future experiments to past experiments, like the brilliant scientists that we are. And so where could we use these lists? Well, we're calculating the loss here. And we're calculating the test loss here. So maybe we each time append what's going on here as we do a status update. So epoch count dot append, and we're going to go a current epoch. And then we'll go loss values dot append, a current loss value. And then we'll do test loss values dot append, the current test loss values. Wonderful. And now let's re-instantiate our model so that it starts from fresh. So this is just create another instance. So we're just going to re-initialize our model parameters to start from zero. If we wanted to, we could functionize all of this so we don't have to go right back up to the top of the code. But just for demo purposes, we're doing it how we're doing it. And I'm going to run this for let's say 200 epochs, because that's what we ended up doing, right? We ran it for 200 epochs, because we did 100 epochs twice. And I want to show you something beautiful, one of the most beautiful sites in machine learning. So there we go, we run it for 200 epochs, we start with a fairly high training loss value and a fairly high test loss value. So remember, what is our loss value? It's ma e. So if we go back, yeah, this is what we're measuring for loss. So this means for the test loss on average, each of our dot points here, the red predictions are 0.481. That's the average distance between each dot point. And then ideally, what are we doing? We're trying to minimize this distance. That's the ma e. So the mean absolute error. And we get it right down to 0.05. And if we make predictions, what do we have here, we get very close to the ideal weight and bias, make our predictions, have a look at the new predictions. Yeah, very small distance here. Beautiful. That's a low loss value. Ideally, they'd line up, but we've got as close as we can for now. So this is one of the most beautiful sites in machine learning. So plot the loss curves. So let's make a plot, because what we're doing, we were tracking the value of epoch count, loss values and test loss values. Let's have a look at what these all look like. So epoch count goes up, loss values ideally go down. So we'll get rid of that. We're going to create a plot p l t dot plot. We're going to step back through the test loop in a second with some colorful slides, label equals train loss. And then we're going to go plot. You might be able to tell what's going on here. Test loss values. We're going to visualize it, because that's the data explorer's motto, right, is visualize, visualize, visualize. This is equals. See, collab does this auto correct. That doesn't really work very well. And I don't know when it does it and why it doesn't. And we got, I know, we didn't, we didn't say loss value. So that's a good auto correct. Thank you, collab. So training and loss and test loss curves. So this is another term you're going to come across often is a loss curve. Now you might be able to think about a loss curve. If we're doing a loss curve, and it's starting at the start of training, what do we want that curve to do? What do we want our loss value to do? We want it to go down. So what should an ideal loss curve look like? Well, we're about to see a couple. Let's have a look. Oh, what do we got wrong? Well, we need to, I'll turn it into NumPy. Is this what we're getting wrong? So why is this wrong? Loss values. Why are we getting an issue? Test loss values. Ah, it's because they're all tens of values. So I think we should, let's, I might change this to NumPy. Oh, can I just do that? If I just call this as a NumPy array, we're going to try and fix this on the fly. People, NumPy array, we'll just turn this into a NumPy array. Let's see if we get NumPy. I'm figuring these things out together. NumPy as NumPy, because mapplotlib works with NumPy. Yeah, there we go. So can we do loss values? Maybe I'm going to try one thing, torch dot tensor, loss values, and then call CPU dot NumPy. See what happens here. There we go. Okay, so let's just copy this. So what we're doing here is our loss values are still on PyTorch, and they can't be because mapplotlib works with NumPy. And so what we're doing here is we're converting our loss values of the training loss to NumPy. And if you call from the fundamental section, we call CPU and NumPy, I wonder if we can just do straight up NumPy, because we're not working on there. Yeah, okay, we don't need CPU because we're not working on the GPU yet, but we might need that later on. Well, this work. Beautiful. There we go. One of the most beautiful sides in machine learning is a declining loss curve. So this is how we keep track of our experiments, or one way, quite rudimentary. We'd like to automate this later on. But I'm just showing you one way to keep track of what's happening. So the training loss curve is going down here. The training loss starts at 0.3, and then it goes right down. The beautiful thing is they match up. If there was a two bigger distance behind the train loss and the test loss, or sorry, between, then we're running into some problems. But if they match up closely at some point, that means our model is converging and the loss is getting as close to zero as it possibly can. If we trained for longer, maybe the loss will go almost basically to zero. But that's an experiment I'll leave you to try to train that model for longer. Let's just step back through our testing loop to finish off this video. So we did that. We created empty lists for strong useful values, storing useful values, strong useful values. Told the model what we want to evaluate or that we want to evaluate. So we put it in an evaluation mode. It turns off functionality used for training, but not evaluations, such as drop out and batch normalization layers. If you want to learn more about them, you can look them up in the documentation. Turn on torch inference mode. So this is for faster performance. So we don't necessarily need this, but it's good practice. So I'm going to say that yes, turn on torch inference mode. So this disables functionality such as gradient tracking for inference. Gradient tracking is not needed for inference only for training. Now we pass the test data through the model. So this will call the models implemented forward method. The forward pass is the exact same as what we did in the training loop, except we're doing it on the test data. So big notion there, training loop, training data, testing loop, testing data. Then we calculate the test loss value, how wrong the models predictions are on the test data set. And of course, lower is better. And finally, we print out what's happening. So we can keep track of what's going on during training. We don't necessarily have to do this. You can customize this print value to print out almost whatever you want, because it's pie torches, basically very beautifully interactive with pure Python. And then we keep track of the values of what's going on on epochs and train loss and test loss. We could keep track of other values here. But for now, we're just going, okay, what's the loss value at a particular epoch for the training set? And for the test set. And of course, all of this could be put into a function. And that way we won't have to remember these steps off by heart. But the reason why we've spent so much time on this is because we're going to be using this training and test functionality for all of the models that we build throughout this course. So give yourself a pat in the back for getting through all of these videos. We've written a lot of code. We've discussed a lot of steps. But if you'd like a song to remember what's happening, let's finish this video off with my unofficial PyTorch optimization loop song. So for an epoch in a range, go model dot train, do the forward pass, calculate the loss, optimize a zero grad, loss backward, optimize a step, step, step. No, you only have to call this once. But now let's test, go model dot eval with torch inference mode, do the forward pass, calculate the loss. And then the real song goes for another epoch because you keep going back through. But we finish off with print out what's happening. And then of course, we evaluate what's going on. With that being said, it's time to move on to another thing. But if you'd like to review what's happening, please, please, please try to run this code for yourself again and check out the slides and also check out the extra curriculum. Oh, by the way, if you want to link to all of the extra curriculum, just go to the book version of the course. And it's all going to be in here. So that's there ready to go. Everything I link is extra curriculum will be in the extra curriculum of each chapter. I'll see you in the next video. Welcome back. In the last video, we saw how to train our model and evaluate it by not only looking at the loss metrics and the loss curves, but we also plotted our predictions and we compared them. Hey, have a go at these random predictions. Quite terrible. But then we trained a model using the power of back propagation and gradient descent. And now look at our predictions. They're almost exactly where we want them to be. And so you might be thinking, well, we've trained this model and it took us a while to write all this code to get some good predictions. How might we run that model again? So I've took in a little break after the last video, but now I've come back and you might notice that my Google Colab notebook has disconnected. So what does this mean if I was to run this? Is it going to work? I'm going to connect to a new Google Colab instance. But will we have all of the code that we've run above? You might have already experienced this if you took a break before and came back to the videos. Ah, so plot predictions is no longer defined. And do you know what that means? That means that our model is also no longer defined. So we would have lost our model. We would have lost all of that effort of training. Now, luckily, we didn't train the model for too long. So we can just go run time, run all. And it's going to rerun all of the previous cells and be quite quick. Because we're working with a small data set and using a small model. But we've been through all of this code. Oh, what have we got wrong here? Model zero state dict. Well, that's all right. This is good. We're finding errors. So if you want to as well, you can just go run after. It's going to run all of the cells after. Beautiful. And we come back down. There's our model training. We're getting very similar values to what we got before. There's the lost curves. Beautiful. Still going. Okay. Now our predictions are back because we've rerun all the cells and we've got our model here. So what we might cover in this video is saving a model in PyTorch. Because if we're training a model and you get to a certain point, especially when you have a larger model, you probably want to save it and then reuse it in this particular notebook itself. Or you might want to save it somewhere and send it to your friend so that your friend can try it out. Or you might want to use it in a week's time. And if Google Colab is disconnected, you might want to be able to load it back in somehow. So now let's see how we can save our models in PyTorch. So I'm going to write down here. There are three main methods you should know about for saving and loading models in PyTorch because of course with saving comes loading. So we're going to over the next two videos discuss saving and loading. So one is torch.save. And as you might guess, this allows you to save a PyTorch object in Python's pickle format. So you may or may not be aware of Python pickle. There we go. Python object serialization. There we go. So we've got the pickle module implements a binary protocols or implements binary protocols for serializing and deserializing a Python object. So serializing means I understand it is saving and deserializing means that it's loading. So this is what PyTorch uses behind the scenes, which is from pure Python. So if we go back here in Python's pickle format, number two is torch.load, which you might be able to guess what that does as well, allows you to load a saved PyTorch object. And number three is also very important is torch.nn.module.loadStatedict. Now what does this allow you to do? Well, this allows you to load a model's saved dictionary or save state dictionary. Yeah, that's what we'll call it. Save state dictionary. Beautiful. And what's the model state dict? Well, let's have a look, model zero dot state dict. The beauty of PyTorch is that it stores a lot of your model's important parameters in just a simple Python dictionary. Now it might not be that simple because our model, again, only has two parameters. In the future, you may be working with models with millions of parameters. So looking directly at the state deck may not be as simple as what we've got here. But the principle is still the same. It's still a dictionary that holds the state of your model. And so I've got these three methods I want to show you where from because this is going to be your extra curriculum, save and load models, your extra curriculum for this video. If we go into here, this is a very, very, very important piece of PyTorch documentation, or maybe even a tutorial. So your extra curriculum for this video is to go through it. Here we go. We've got torch, save, torch, load, torch, module, state deck. That's where, or load state deck, that's where I've got the three things that we've just written down. And there's a fair few different pieces of information. So what is a state deck? So in PyTorch, the learnable parameters, i.e. the weights and biases of a torch and end module, which is our model. Remember, our model subclasses and end module are contained in the model's parameters. Access with model.parameters, a state deck is simply a Python dictionary object that maps each layer to its parameter tensor. That's what we've seen. And so then if we define a model, we can initialize the model. And if we wanted to print the state decked, we can use that. The optimizer also has a state deck. So that's something to be aware of. You can go optimizer.state deck. And then you get an output here. And this is our saving and loading model for inference. So inference, again, is making a prediction. That's probably what we want to do in the future at some point. For now, we've made predictions right within our notebook. But if we wanted to use our model outside of our notebook, say in an application, or in another notebook that's not this one, you'll want to know how to save and load it. So the recommended way of saving and loading a PyTorch model is by saving its state deck. Now, there is another method down here, which is saving and loading the entire model. So your extracurricular for this lesson, we're going to go through the code to do this. But your extracurricular is to read all of the sections in here, and then figure out what the pros and cons are of saving and loading the entire model versus saving and loading just the state deck. So that's a challenge for you for this video. I'm going to link this in here. And now let's write some code to save our model. So PyTorch save and load code. Code tutorial plus extracurricular. So if we go saving our PyTorch model. So what might we want? What do you think the save parameter takes? If we have torch.save, what do you think it takes inside it? Well, let's find out together. Hey, so let's import part lib. We're going to see why in a second. This is Python's module for dealing with writing file paths. So if we wanted to save something to this is Google Colab's file section over here. But just remember, if we do save this from within Google Colab, the model will disappear if our Google Colab notebook instance disconnects. So I'll show you how to download it from Google Colab if you want. Google Colab also has a way save from Google Colab Google Colab to Google Drive to save it to your Google Drive if you wanted to. But I'll leave you to look at that on your own if you like. So we're first going to create a model directory. So create models directory. So this is going to help us create a folder over here called models. And of course, we could create this by hand by adding a new folder here somewhere. But I like to do it with code. So model path, we're going to set this to path, which is using the path library here to create us a path called models. Simple. We're just going to save all of our models to models to the models file. And then we're going to create model path, we're going to make that directory model path dot mkdir for make directory. We're going to set parents to equals true. And we're also going to set exist okay equals to true. That means if it already existed, it won't throw us an error. It will try to create it. But if it already exists, it'll just recreate the parents directory or it'll leave it there. It won't error out on us. We're also going to create a model save path. This way, we can give our model a name. Right now, it's just model zero. We want to save it under some name to the models directory. So let's create the model name. Model name equals 01. I'm going to call it 01 for the section. That way, if we have more models later on the course, we know which ones come from where you might create your own naming convention, model workflow, pytorch workflow, model zero dot pth. And now this is another important point. Pytorch objects usually have the extension dot pth for pytorch or dot pth. So if we go in here, and if we look up dot pth, yeah, a common convention is to save models using either a dot pth or dot pth file extension. I'll let you choose which one you like. I like dot pth. So if we go down here dot pth, they both result in the same thing. You just have to remember to make sure you write the right loading path and right saving path. So now we're going to create our model save path, which is going to be our model path. And because we're using the path lib, we can use this syntax that we've got here, model path slash model name. And then if we just print out model save path, what does this look like? There we go. So it creates a supposic path using the path lib library of models slash 01 pytorch workflow model zero dot pth. We haven't saved our model there yet. It's just got the path that we want to save our model ready. So if we refresh this, we've got models over here. Do we have anything in there? No, we don't yet. So now is our step to save the model. So three is save the model state dict. Why are we saving the state dict? Because that's the recommended way of doing things. If we come up here, saving and loading the model for inference, save and load the state dict, which is recommended. We could also save the entire model. But that's part of your extra curriculum to look into that. So let's use some syntax. It's quite like this torch dot save. And then we pass it an object. And we pass it a path of where to save it. We already have a path. And good thing is we already have a model. So we just have to call this. Let's try it out. So let's go print f saving model to and we'll put in the path here. Model save path. I like to print out some things here and there that way. We know what's going on. And I don't need that capital. Why do I? Getting a little bit trigger happy here with the typing. So torch dot save. And we're going to pass in the object parameter here. And if we looked up torch save, we can go. What does this code take? So torch save object f. What is f? A file like object. Okay. Or a string or OS path like object. Beautiful. That's what we've got. A path like object containing a file name. So let's jump back into here. The object is what? It's our model zero dot state dict. That's what we're saving. And then the file path is model save path. You ready? Let's run this and see what happens. Beautiful. Saving model to models. So it's our model path. And there's our model there. So if we refresh this, what do we have over here? Wonderful. We've saved our trained model. So that means we could potentially if we wanted to, you could download this file here. That's going to download it from Google CoLab to your local machine. That's one way to do it. But there's also a guide here to save from Google Collaboratory to Google Drive. That way you could use it later on. So there's many different ways. The beauty of pie torches is flexibility. So now we've got a saved model. But let's just check using our LS command. We're going to check models. Yeah, let's just check models. This is going to check here. So this is list. Wonderful. There's our 01 pie torch workflow model zero dot pth. Now, of course, we've saved a model. How about we try loading it back in and seeing how it works. So if you want to challenge, read ahead on the documentation and try to use torch dot load to bring our model back in. See what happens. I'll see in the next video. Welcome back. In the last video, we wrote some code here to save our pie torch model. I'm just going to exit out of this couple of things that we don't need just to clear up the screen. And now we've got our dot pth file, because remember dot pth or dot pth is a common convention for saving a pie torch model. We've got it saved there, and we didn't necessarily have to write all of this path style code. But this is just handy for later on if we wanted to functionize this and create it in say a save dot pie file over here, so that we could just call our save function and pass it in a file path where we wanted to save like a directory and a name, and then it'll save it exactly how we want it for later on. But now we've got a saved model. I issued a challenge of trying to load that model in. So do we have torch dot load in here? Did you try that out? We've got, oh, we've got a few options here. Wonderful. But we're using one of the first ones. So let's go back up here. If we wanted to check the documentation for torch dot load, we've got this option here, load. What happens? Loads and objects saved with torch dot save from a file. Torch dot load uses Python's unpickling facilities, but treat storages which underlie tenses specially. They are firstly serialized on the CPU, and then I moved the device they were saved from. Wonderful. So this is moved to the device. If later on when we're using a GPU, this is just something to keep in mind. We'll see that when we start to use a CPU and a GPU. But for now, let's practice using the torch dot load method and see how we can do it. So we'll come back here and we'll go loading a pytorch model. And since we, she's going to start writing here, since we saved our models state debt, so just the dictionary of parameters from a model, rather than the entire model, we'll create a new instance of our model class and load the state deck, load the saved state deck. That's better state deck into that. Now, this is just words on a page. Let's see this in action. So to load in a state deck, which is what we say, we didn't save the entire model itself, which is one option. That's extra curriculum, but we saved just the model state deck. So if we remind ourselves what model zero dot state deck looks like, we saved just this. So to load this in, we have to instantiate a new class or a new instance of our linear regression model class. So to load in a saved state deck, we have to instantiate a new instance of our model class. So let's call this loaded model zero. I like that. That way we can differentiate because it's still going to be the same parameters as model zero, but this way we know that this instance is the loaded version, not just the version we've been training before. So we'll create a new version of it here, linear regression model. This is just the code that we wrote above, linear regression model. And then we're going to load the saved state deck of model zero. And so this will update the new instance with updated parameters. So let's just check before we load it, we haven't written any code to actually load anything. What does loaded model zero? What does the state deck look like here? It won't have anything. It'll be initialized with what? Oh, loaded. That's what I called it loaded. See how it's initialized with random parameters. So essentially all we're doing when we load a state dictionary into our new instance of our model is that we're going, hey, take the saved state deck from this model and plug it into this. So let's see what happens when we do that. So loaded model zero. Remember how I said there's a method to also be aware of up here, which is torch nn module dot load state deck. And because our model is a what, it's a subclass of torch dot nn dot module. So we can call load state deck on our model directly or on our instance. So recall linear regression model is a subclass of nn dot module. So let's call in load state deck. And this is where we call the torch dot load method. And then we pass it the model save path. Is that what we call it? Because torch dot load, it takes in F. So what's F a file like object or a string or a OS path like object. So that's why we created this path like object up here. Model save path. So all we're doing here, we're creating a new instance, linear regression model, which is a subclass of nn dot module. And then on that instance, we're calling in load state deck of torch dot load model save path. Because what's saved at the model save path, our previous models state deck, which is here. So if we run this, let's see what happens. All keys match successfully. That is beautiful. And so see the values here, loaded state deck of model zero. Well, let's check the loaded version of that. We now have wonderful, we have the exact same values as above. But there's a little way that we can test this. So how about we go make some predictions. So make some predictions. Just to make sure with our loaded model. So let's put it in a valve mode. Because when you make predictions, you want it in evaluation mode. So it goes a little bit faster. And we want to also use inference mode. So with torch dot inference mode for making predictions. We want to write this loaded model preds, we're going to make some predictions on the test data as well. So loaded model zero, we're going to forward pass on the X test data. And then we can have a look at the loaded model preds. Wonderful. And then to see if the two models are the same, we can compare loaded model preds with original model preds. So why preds? These should be equivalent equals equals loaded model preds. Do we have the same thing? False, false, false, what's going on here? Why preds? How much different are they? Oh, where's that happened? Have we made some model preds with this yet? So how about we make some model preds? This is troubleshooting on the fly team. So let's go model zero dot eval. And then with torch dot inference mode, this is how we can check to see that our two models are actually equivalent. Why preds equals, I have a feeling why preds actually save somewhere else equals model zero. And then we pass it the X test data. And then we might move this above here. And then have a look at what why preds equals. Do we get the same output? Yes, we should. Wonderful. Okay, beautiful. So now we've covered saving and loading models or specifically saving the models state deck. So we saved it here with this code. And then we loaded it back in with load state deck plus torch load. And then we checked to see by testing equivalents of the predictions of each of our models. So the original one that we trained here, model zero, and the loaded version of it here. So that's saving and loading a model in pytorch. There are a few more things that we could cover. But I'm going to leave that for extra curriculum. We've covered the two main things or three main things. One, two, three. If you'd like to read more, I'd highly encourage you to go through and read this tutorial here. But with that being said, we've covered a fair bit of ground over the last few videos. How about we do a few videos where we put everything together just to reiterate what we've done. I think that'll be good practice. I'll see you in the next video. Welcome back. Over the past few videos, we've covered a whole bunch of ground in a pytorch workflow, starting with data, then building a model. Well, we split the data, then we built a model. We looked at the model building essentials. We checked the contents of our model. We made some predictions with a very poor model because it's based off random numbers. We spent a whole bunch of time figuring out how we could train a model. We figured out what the loss function is. We saw an optimizer. We wrote a training and test loop. We then learned how to save and load a model in pytorch. So now I'd like to spend the next few videos putting all this together. We're not going to spend as much time on each step, but we're just going to have some practice together so that we can reiterate all the things that we've done. So putting it all together, let's go back through the steps above and see it all in one place. Wonderful. So we're going to start off with 6.1 and we'll go have a look at our workflow. So 6.1 is data, but we're going to do one step before that. And I'm just going to get rid of this so we have a bit more space. So we've got our data ready. We've turned it into tenses way back at the start. Then we built a model and then we picked a loss function and an optimizer. We built a training loop. We trained our model. We made some predictions. We saw that they were better. We evaluated our model. We didn't use torch metrics, but we got visual. We saw our red dots starting to line up with the green dots. We haven't really improved through experimentation. We did a little bit of it though, as in we saw that if we trained our model for more epochs, we got better results. So you could argue that we have done a little bit of this, but there are other ways to experiment. We're going to cover those throughout the course. And then we saw how to save and reload a trained model. So we've been through this entire workflow, which is quite exciting, actually. So now let's go back through it, but we're going to do it a bit quicker than what we've done before, because I believe you've got the skills to do so now. So let's start by importing pytorch. So you could start the code from here if you wanted to. And that plot live. And actually, if you want, you can pause this video and try to recode all of the steps that we've done by putting some headers here, like data, and then build a model and then train the model, save and load a model, whatever, and try to code it out yourself. If not, feel free to follow along with me and we'll do it together. So import torch from torch import. Oh, would help if I could spell torch import and n because we've seen that we use an n quite a bit. And we're going to also import map plot live because we like to make some plots because we like to get visual. Visualize visualize visualize as PLT. And we're going to check out pytorch version. That way we know if you're on an older version, some of the code might not work here. But if you're on a newer version, it should work. If it doesn't, let me know. There we go. 1.10. I'm using 1.10 for this. By the time you watch this video, there may be a later version out. And we're also going to let's create some device agnostic code. So create device agnostic code, because I think we're up to this step now. This means if we've got access to a GPU, our code will use it for potentially faster computing. If no GPU is available, the code will default to using CPU. We don't necessarily need to use a GPU for our particular problem that we're working on right now because it's a small model and it's a small data set, but it's good practice to write device agnostic code. So that means our code will use a GPU if it's available, or a CPU by default, if a GPU is not available. So set up device agnostic code. We're going to be using a similar setup to this throughout the entire course from now on. So that's why we're bringing it back. CUDA is available. So remember CUDA is NVIDIA's programming framework for their GPUs, else use CPU. And we're going to print what device are we using? Device. So what we might do is if we ran this, it should be just a CPU for now, right? Yours might be different to this if you've enabled a GPU, but let's change this over to use CUDA. And we can do that if you're using Google Colab, we can change the runtime type by selecting GPU here. And then I'm going to save this, but what's going to happen is it's going to restart the runtime. So we're going to lose all of the code that we've written above. How can we get it all back? Well, we can go. Run all. This is going to run all of the cells above here. They should all work and it should be quite quick because our model and data aren't too big. And if it all worked, we should have CUDA as our device that we can use here. Wonderful. So the beauty of Google Colab is that they've given us access to on a video GPU. So thank you, Google Colab. Just once again, I'm paying for the paid version of Google Colab. You don't have to. The free version should give you access to a GPU, or be it it might not be as a later version as GPU as the pro versions give access to. But this will be more than enough for what we're about to recreate. So I feel like that's enough for this video. We've got some device agnostic code ready to go. And for the next few videos, we're going to be rebuilding this except using device agnostic code. So give it a shot yourself. There's nothing in here that we haven't covered before. So I'll see you in the next video. Let's create some data. Welcome back. In the last video, we set up some device agnostic code and we got ready to start putting everything we've learned together. So now let's continue with that. We're going to recreate some data. Now we could just copy this code, but we're going to write it out together so we can have some practice creating a dummy data set. And we want to get to about this stage in this video. So we want to have some data that we can plot so that we can build a model to once again, learn on the blue dots to predict the green dots. So we'll come down here data. I'm going to get out of this as well so that we have a bit more room. Let's now create some data using the linear regression formula of y equals weight times features plus bias. And you may have heard this as y equals mx plus c or mx plus b or something like that, or you can substitute these for different names. Images when I learned this in high school, it was y equals mx plus c. Yours might be slightly different. Yeah, bx plus a. That's what they use here. A whole bunch of different ways to name things, but they're all describing the same thing. So let's see this in code rather than formulaic examples. So we're going to create our weight, which is 0.7 and a bias, which is 0.3. These are the values we previously used for a challenge you could change these to 0.1 maybe and 0.2. These could be whatever values you'd like to set them as. So weight and bias, the principle is going to be the same thing. We're going to try and build a model to estimate these values. So we're going to start at 0 and we're going to end at 1. So we can just create a straight line and we're going to fill in those between 0 and 1 with a step of 0.02. And now we'll create the x and y features x and y, which is features and labels actually. So x is our features and y are our labels. x equals torch dot a range and x is a capital Y is that because typically x is a feature matrix. Even though ours is just a vector now, we're going to unsqueeze this so we don't run into dimensionality issues later on. You can check this for yourself without unsqueeze, errors will pop up and y equals weight times x plus bias. You see how we're going a little bit faster now? This is sort of the pace that we're going to start going for things that we've already covered. If we haven't covered something, we'll slow down, but if we have covered something, I'm going to step it through. We're going to start speeding things up a little. So if we get some values here, wonderful. We've got some x values and they correlate to some y values. We're going to try and use the training values of x to predict the training values of y and subsequently for the test values. Oh, and speaking of training and test values, how about we split the data? So let's split the data. Split data. So we'll create the train split equals int 0.8. We're going to use 80%, which is where 0.8 comes from, for the length of x. So we use 80% of our samples for the training, which is a typical training and test split, 80, 20. They're abouts. You could use like 70, 30. You could use 90, 10. It all depends on how much data you have. There's a lot of things in machine learning that are quite flexible. Train split, we're going to index on our data here so that we can create our splits. Google Colab auto corrected my code in a non-helpful way just then. And we're going to do the opposite split for the testing data. Now let's have a look at the lengths of these. If my calculations are correct, we should have about 40 training samples and 10 testing samples. And again, this may change in the future. When you work with larger data sets, you might have 100,000 training samples and 20,000 testing samples. The ratio will often be quite similar. And then let's plot what's going on here. So plot the data and note, if you don't have the plot predictions function loaded, this will error. So we can just run plot predictions here if we wanted to. And we'll pass it in X train, Y train, X test, Y test. And this should come up with our plot. Wonderful. So we've just recreated the data that we've been previously using. We've got blue dots to predict green dots. But if this function errors out because you've started the notebook from here, right from this cell, and you've gone down from there, just remember, you'll just have to go up here and copy this function. We don't have to do it because we've run all the cells, but if you haven't run that cell previously, you could put it here and then run it, run it, and we'll get the same outcome here. Wonderful. So what's next? Well, if we go back to our workflow, we've just created some data. And have we turned it into tenses yet? I think it's just still, oh, yeah, it is. It's tenses because we use PyTorch to create it. But now we're up to building or picking a model. So we've built a model previously. We did that back in build model. So you could refer to that code and try to build a model to fit the data that's going on here. So that's your challenge for the next video. So building a PyTorch linear model. And why do we call it linear? Because linear refers to a straight line. What's nonlinear? Non-straight. So I'll see you in the next video. Give it a shot before we get there. But we're going to build a PyTorch linear model. Welcome back. We're going through some steps to recreate everything that we've done. In the last video, we created some dummy data. And we've got a straight line here. So now by the workflow, we're up to building a model or picking a model. In our case, we're going to build one to suit our problem. So we've got some linear data. And I've put building a PyTorch linear model here. I issued you the challenge of giving it a go. You could do exactly the same steps that we've done in build model. But I'm going to be a little bit cheeky and introduce something new here. And that is the power of torch.nn. So let's see it. What we're going to do is we're going to create a linear model by subclassingnn.module because why a lot of PyTorch models, subclass, and then module. So class linear regression, what should we call this one? Linear regression model v2. How about that? And we'll subclassnn.module. So much similar code to what we've been writing so far. Or when we first created our linear regression model. And then we're going to put the standard constructor code here, def init underscore underscore. And it's going to take as an argument self. And then we're going to call super dot another underscore init underscore underscore brackets. But we're going to instead of if you recall above back in the build model section, we initialized these parameters ourselves. And I've been hinting at in the past in videos we've seen before that oftentimes you won't necessarily initialize the parameters yourself. You'll instead initialize layers that have the parameters in built in those layers. We still have to create a forward method. But what we're going to see is how we can use our torch linear layer to do these steps for us. So let's write the code and then we'll step through it. So we'll go usenn.linear because why we're building linear regression model and our data is linear. And in the past, our previous model has implemented linear regression formula. So for creating the model parameters. So we can go self dot linear layer equals. So this is constructing a variable that this class can use self linear layer equals nn dot linear. Remember, nn in PyTorch stands for neural network. And we have in features as one of the parameters and out features as another parameter. This means we want to take as input of size one and output of size one. Where does that come from? Well, if we have a look at x train and y train, we have one value of x. Maybe there's too many here. x five will be the first five five and five. So recall, we have one value of x equates to one value of y. So that means within this linear layer, we want to take as one feature x to output one feature y. And we're using just one layer here. So the input and the output shapes of your model in features, out features, what data goes in and what data comes out. These values will be highly dependent on the data that you're working with. And we're going to see different data or different examples of input features and output features all throughout this course. So but that is what's happening. We have one in feature to one out feature. Now what's happening inside nn.linear. Let's have a look torch and then linear. We go the documentation applies a linear transformation to the incoming data. Where have we seen this before? y equals x a t plus b. Now they're using different letters, but we've got the same formula as what's happening up here. Look at the same formula as our data. Wait times x plus bias. And then if we look up linear regression formula once again, linear regression formula. We've got this formula here. Now again, these letters can be replaced by whatever letters you like. But this linear layer is implementing the linear regression formula that we created in our model before. So it's essentially doing this part for us. And behind the scenes, the layer creates these parameters for us. So that's a big piece of the puzzle of pie torch is that as I've said, you won't always be initializing the parameters your model yourself. You'll generally initialize layers. And then you'll use those layers in some Ford computation. So let's see how we could do that. So we've got a linear layer which takes us in features one and out features one. What should we do now? Well, because we've subclassed nn.module we need to override the Ford method. So we need to tell our model what should it do as the Ford computation. And in here it's going to take itself as input, as well as x, which is conventional for the input data. And then we're just going to return here, self dot linear layer x. Right. And actually, we might use some typing here to say that this should be a torch tensor. And it's also going to return a torch dot tensor. That's using Python's type ins. So this is just saying, hey, X should be a torch tensor. And I'm going to return you a torch tensor, because I'm going to pass x through the linear layer, which is expecting one in feature and one out feature. And it's going to this linear transform. That's another word for it. Again, pytorch and machine learning in general has many different names of the same thing. I would call this linear layer. I'm going to write here, also called linear transform, probing layer, fully connected layer, dense layer, intensive flow. So a whole bunch of different names for the same thing, but they're all implementing a linear transform. They're all implementing a version of linear regression y equals x, a ranspose plus b, in features, out features, wonderful. So let's see this in action. So we're going to go set the manual seed so we can get reproducibility as well, torch dot manual seed. And we're going to set model one equals linear regression. This is model one, because we've already got model zero, linear regression V two, and we're going to check model one, and we're going to check its state dictionary, state dict. There we go. What do we have inside this ordered dict? Has that not created anything for us? Model one, dot state dinked, ordered dink. We haven't got anything here in the regression model V two. Ideally, this should be outputting a weight and a bias. Yeah, variables, weight, and bias. Let's dig through our code line by line and see what we've got wrong. Ah, did you notice this? The init function so the constructor had the wrong amount of underscores. So it was never actually constructing this linear layer troubleshooting on the fly team. There we go. Beautiful. So we have a linear layer, and we have it is created for us inside a weight and a bias. So effectively, we've replaced the code we wrote above for build model, initializing a weight and bias parameter with the linear layer. And you might be wondering why the values are slightly different, even though we've used the manual seed. This goes behind the scenes of how PyTorch creates its different layers. It's probably using a different form of randomness to create different types of variables. So just keep that in mind. And to see this in action, we have a conversion here. So this is what's going on. We've converted, this is our original model class, linear regression. We initialize our model parameters here. We've got a weight and a bias. But instead, we've swapped this in our linear regression model V2. This should be V2 to use linear layer. And then in the forward method, we had to write the formula manually here when we initialize the parameters manually. But because of the power of torch.nn, we have just passed it through the linear layer, which is going to perform some predefined forward computation in this layer. So this style of what's going on here is how you're going to see the majority of your PyTorch deep learning models created using pre-existing layers from the torch.nn module. So if we go back into torch.nn, torch.nn, we have a lot of different layers here. So we have convolutional layers, pooling layers, padding layers, normalization, recurrent, transformer, linear, we're using a linear layer, dropout, et cetera, et cetera. So for all of the common layers in deep learning, because that's what neural networks are, they're layers of different mathematical transformations, PyTorch has a lot of pre-built implementations. So that's a little bit of a sneaky trick that I've done to alter our model. But we've still got basically the exact same model as we had before. So what's next? Well, it's to train this model. So let's do that in the next video. Welcome back. So in the last video, we built a PyTorch linear model, nice and simple using a single nn.linear layer with one in feature, one out feature. And we over read the forward method of nn.module using the linear layer that we created up here. So what's going to happen is when we do the forward parser on our model, we're going to put some data in and it's going to go through this linear layer, which behind the scenes, as we saw with torch and n linear, behind the scenes, it's going to perform the linear regression formula here. So y equals x, a t plus b. But now case, we've got weight and bias. So let's go back. It's now time to write some training code. But before we do, let's set the model to use the target device. And so in our case, we've got a device of CUDA. But because we've written device agnostic code, if we didn't have access to a CUDA device, a GPU, our default device would be a CPU. So let's check the model device. We can do that first up here, check the model current device, because we're going to use the GPU here, or we're going to write device agnostic code. That's better to say device agnostic code. That's the proper terminology device. What device are we currently using? This is the CPU, right? So by default, the model will end up on the CPU. But if we set it to model one call dot two device, what do you think it's going to do now? If our current target device is CUDA, we've seen what two does in the fundamental section, two is going to send the model to the GPU memory. So now let's check whether parameters of our model live dot device. If we send them to the device previously, it was the CPU, it's going to take a little bit longer while the GPU gets fired up and goes, PyTorch goes, Hey, I'm about to send you this model. You ready for it? Boom, there we go. Wonderful. So now our model is on the device or the target device, which is CUDA. And if CUDA wasn't available, the target device would be CPU. So this would just come out just exactly how we've got it here. But with that being said, now let's get on to some training code. And this is the fun part. What do we have to do? We've already seen this for training. I'm just going to clear up our workspace a little bit here. For training, we need, this is part of the PyTorch workflow, we need a loss function. What does a loss function do? Measures how wrong our model is, we need an optimizer, we need a training loop and a testing loop. And the optimizer, what does that do? Well, it optimizes the parameters of our model. So in our case, model one dot state dig, what do we have? So we have some parameters here within the linear layer, we have a weight, and we have a bias. The optimizer is going to optimize these random parameters so that they hopefully reduce the loss function, which remember the loss function measures how wrong our model is. So in our case, because we're working with the regression problem, let's set up the loss function. And by the way, all of these steps are part of the workflow. We've got data ready, we've built or picked a model, we're using a linear model. Now we're up to here 2.1 pick a loss function and an optimizer, we're going to do build a training loop in the same session, because you know what, we're getting pretty darn good at this, loss function equals what? Well, we're going to use l one loss. So let's set that up and then dot l one loss, which is the same as ma and if we wanted to set up our optimizer, what optimizer could we use? Well, pytorch offers a lot of optimizers in torch dot opt in SGD. That's stochastic gradient descent, because remember gradient descent is the algorithm that optimizes our model parameters. Adam is another popular option. For now, we're going to stick with SGD. LR, which stands for learning rate. In other words, how big of a step will our optimizer change our parameters with every iteration, a smaller learning rate. So such as 0001 will be a small step. And then a large learning rate, such as 0.1 will be a larger step. Too big of a step. Our model learns too much. And it explodes too small of a step. Our model never learns anything. But oh, we actually have to pass params first. I forgot about that. I got ahead of myself with a learning rate. Params is the parameters we'd like our optimizer to optimize. So in our case, it's model one dot parameters, because model one is our current target model. Beautiful. So we've got a loss function and an optimizer. Now, let's write a training loop. So I'm going to set torch manual seeds so we can try and get as reproducible as results as possible. Remember, if you get different numbers to what I'm getting, don't worry too much if they're not exactly the same, the direction is more important. So that means if my loss function is getting smaller, yours should be getting smaller too. Don't worry too much if your fourth decimal place isn't the same as what my values are. So we have a training loop ready to be written here. Epox, how many should we do? Well, we did 200 last time and that worked pretty well. So let's do 200 again. Did you go through the extra curriculum yet? Did you watch the video for the unofficial PyTorch optimization loop song yet? This one here, listen to the unofficial PyTorch optimization loop song. If not, it's okay. Let's sing it together. So for an epoch in range, epochs, we're going to go through the song in a second. We're going to set the model to train. In our case, it's model one, model to train. Now, step number one is what? Do the forward pass. This is where we calculate the predictions. So we calculate the predictions by passing the training data through our model. And in our case, because the forward method in model one implements the linear layer, this data is going to go through the linear layer, which is torch.nn.linear and go through the linear regression formula. And then we calculate the loss, which is how wrong our models predictions are. So the loss value equals loss fn. And here we're going to pass in y-pred and y-train. Then what do we do? We zero the optimizer, optimizer zero grad, which because by default, the optimizer is going to accumulate gradients behind the scenes. So every epoch, we want to reduce those back to zero. So it starts from fresh. We're going to perform back propagation here, back propagation, by calling loss, stop backwards. If the forward pass goes forward through the network, the backward pass goes backwards through the network, calculating the gradients for the loss function with respect to each parameter in the model. So optimizer step, this next part, is going to look at those gradients and go, you know what? Which way should I optimize the parameters? So because the optimizer is optimizing the model parameters, it's going to look at the loss and go, you know what? I'm going to adjust the weight to be increased. And I'm going to lower the bias and see if that reduces the loss. And then we can do testing. We can do both of these in the same hit. Now we are moving quite fast through this because we spent a whole bunch of time discussing what's going on here. So for testing, what do we do? We set the model into evaluation mode. That's going to turn off things like dropout and batch normalization layers. We don't have any of that in our model for now, but just it's good practice to always call a vowel whenever you're doing testing. And same with inference mode. We don't need to track gradients and a whole bunch of other things PyTorch does behind the scenes when we're testing or making predictions. So we use the inference mode context manager. This is where we're going to create test pred, which is going to be our test predictions, because here we're going to pass the test data features, forward pass through our model. And then we can calculate the test loss, which is our loss function. And we're going to compare the test pred to Y test. Wonderful. And then we can print out what's happening. So what should we print out? How about if epoch divided by 10 equals zero. So every 10 epochs, let's print something out, print. We'll do an F string here, epoch is epoch. And then we'll go loss, which is the training loss, and just be equal to the loss. And then we'll go test loss is equal to test loss. So do you think this will work? It's okay if you're not sure. But let's find out together, hey, oh, we've got a, we need a bracket there. Oh my goodness, what's going on? Run time error. Expected all tenses to be on the same device. Oh, of course. Do you know what's happening here? But we found at least two devices, CUDA and CPU. Yes, of course, that's what's happened. So what have we done? Up here, we put our model on the GPU. But what's going on here? Our data? Has our data on the GPU? No, it's not. By default, it's on the CPU. So we haven't written device agnostic code for our data. So let's write it here, put data on the target device. Device agnostic code for data. So remember, one of the biggest issues with pytorch aside from shape errors is that you should have your data or all of the things that you're computing with on the same device. So that's why if we set up device agnostic code for our model, we have to do the same for our data. So now let's put X train to device. Y train equals Y train to device. This is going to create device agnostic code. In our case, it's going to use CUDA because we have access to a CUDA device. But if we don't, this code will still work. It will still default to CPU. So this is good. I like that we got that error because that's the sum of the things you're going to come across in practice, right? So now let's run this. What's happening here? Hey, look at that. Wonderful. So our loss starts up here nice and high. And then it starts to go right down here for the training data. And then the same for the testing data. Beautiful. Right up here. And then all the way down. Okay. So this looks pretty good on the test data set. So how can we check this? How can we evaluate our model? Well, one way is to check its state deck. So state decked. What do we got here? What are our weight and bias? Oh my gosh, so close. So we just set weight and bias before to be 0.7 and 0.3. So this is what our model has estimated our parameters to be based on the training data. 0.6968. That's pretty close to 0.7, nearly perfect. And the same thing with the bias 0.3025 versus the perfect value is 0.93. But remember, in practice, you won't necessarily know what the ideal parameters are. This is just to exemplify what our model is doing behind the scenes. It's moving towards some ideal representative parameters of whatever data we're working with. So in the next video, I'd like you to give it a go of before we get to the next video, make some predictions with our model and plot them on the original data. How close to the green dots match up with the red dots? And you can use this plot predictions formula or function that we've been using in the past. So give that a go and I'll see you in the next video. But congratulations. Look how quickly we just trained a model using the steps that we've covered in a bunch of videos so far and device agnostic code. So good. I'll see you soon. In the last video, we did something very, very exciting. We worked through training an entire neural network. Some of these steps took us an hour or so worth of videos to go back through before. But we coded that in one video. So you're ready listening the song just to remind ourselves of what's going on. For an epoch in a range, call model dot train, do the forward pass, calculate the loss, optimizer zero grad, loss backward, optimizer step, step, step, let's test, come on a dot eval with torch inference mode, do the forward pass, calculate the loss, print out what's happening. And then we do it again, again, again, for another epoch in a range. Now I'm kidding. We'll just leave it there. We'll just leave it there. But that's the unofficial pytorch optimization loop song. We created some device agnostic code so that we could make the calculations on the same device as what our model is because the models also using device agnostic code. And so now we've got to evaluate our models. We've looked at the loss and the test lost here. And we know that our models loss is going down. But what does this actually equate to when it makes predictions? That's what we're most interested in, right? And we've looked at the parameters. They're pretty close to the ideal parameters. So at the end of last video, I issued you the challenge to making and evaluating predictions to make some predictions and plot them. I hope you gave it a shot. Let's see what it looks like together. Hey, so turn the model into evaluation mode. Why? Because every time we're making predictions or inference, we want our model to be in a vowel mode. And every time we're training, we want our model to be in training mode. And then we're going to make predictions on the test data, because we train on the train data, and we evaluate our model on the test data data that our model has never actually seen, except for when it makes predictions. With torch inference mode, we turn on inference mode whenever we make inference or predictions. So we're going to set Y threads equal to model one, and the test data goes in here. Let's have a look at what the Y threads look like. Wonderful. So we've got a tensor here. It shows us that they're still on the device CUDA. Why is that? Well, that's because previously we set the model one to the device, the target device, the same with the test data. So subsequently, our predictions are also on the CUDA device. Now, let's bring in the plot predictions function here. So check out our model predictions visually. We're going to adhere to the data explorer's motto of visualize visualize visualize plot predictions. And predictions are going to be set to equals Y threads. And let's have a look. How good do these look? Oh, no. Oh, we've got another error type error. Can't convert CUDA device type tensor to NumPy. Oh, of course. Look what we've done. So our plot predictions function, if we go back up, where did we define that? What does our plot predictions function use? It uses matplotlib, of course, and matplotlib works with NumPy, not pytorch. And NumPy is CPU based. So of course, we're running into another error down here, because we just said that our predictions are on the CUDA device. They're not on the CPU. They're on a GPU. So it's giving us this helpful information here. Use tensor dot CPU to copy the tensor to host memory first. So this is our tensor. Let's call dot CPU and see what happens then. Is that going to go to CPU? Oh, my goodness. Look at that. Look at that. Go the linear layer. The red dots, the predictions are basically on top of the testing data. That is very exciting. Now again, you may not get the exact same numbers here, and that is perfectly fine. But the direction should be quite similar. So your red dots should be basically on top of the green dots, if not very slightly off. But that's okay. That's okay. We just want to focus on the direction here. So thanks to the power of back propagation here and gradient descent, our models random parameters have updated themselves to be as close as possible to the ideal parameters. And now the predictions are looking pretty darn good for what we're trying to predict. But we're not finished there. We've just finished training this model. What would happen if our notebook disconnected right now? Well, that wouldn't be ideal, would it? So in the next part, we're going to move on to 6.5, saving, and loading a trained model. So I'm going to give you a challenge here as well, is to go ahead and go back and refer to this code here, saving model in PyTorch, loading a PyTorch model, and see if you can save model one, the state dictionary of model one, and load it back in and get something similar to this. Give that a shot, and I'll see you in the next video. Welcome back. In the last video, we saw the power of the torch.nn.linear layer, and back propagation and gradient descent. And we've got some pretty darn good predictions out of our model. So that's very exciting. Congratulations. You've now trained two machine learning models. But it's not over yet. We've got to save and load our trained model. So I issued you the challenge in the last video to try and save and load the model yourself. I hope you gave that a go. But we're going to do that together in this video. So we're going to start by importing path because we would like a file path to save our model to. And the first step we're going to do is create models directory. We don't have to recreate this because I believe we already have one. But I'm going to put the code here just for completeness. And this is just so if you didn't have a models directory, this would create one. So model path is going to go to path models. And then we'd like to model path dot maker, we're going to call maker for make directory. We'll set parents equal to true. And if it exists, okay, that'll also be true. So we won't get an error. Oh my gosh, Google collab. I didn't want that. We won't get an error if it already exists. And two, we're going to create a model save path. So if you recall that pytorch objects in general have the extension of what? There's a little pop quiz before we get to the end of this sentence. So this is going to be pytorch workflow for this module that we're going through. This one here, chapter 01 pytorch workflow model one. And they usually have the extension dot PT for pytorch or PT H for pytorch as well. I like PT H. But just remember, sometimes you might come across slightly different versions of that PT or PT H. And we're going to create the model save name or the save path. It's probably a better way to do it is going to be model path. And then we can use because we're using the path lib module from Python, we can save it under model name. And so if we look at this, what do we get model save path? We should get Oh, path is not defined. Oh, too many capitals here, Daniel. The reason why I'm doing these in capitals is because oftentimes hyper parameters such as epochs in machine learning are set as hyper parameters LR could be learning rate. And then you could have as well model name equals Yeah, yeah, yeah. But that's just a little bit of nomenclature trivia for later on. And model save path, we've done that. Now we're going to save the model state dictionary rather than the whole model, save the model state deck, which you will find the pros and cons of in where in the pytorch documentation for saving and loading model, which was a little bit of extra curriculum for a previous video. But let's have a look at our model save path will print it out. And we'll go torch save, we'll set the object that we're trying to save to equal model one dot state deck, which is going to contain our trained model parameters. We can inspect what's going on in here, state deck. They'll show us our model parameters. Remember, because we're only using a single linear layer, we only have two parameters. But in practice, when you use a model with maybe hundreds of layers or tens of millions of parameters, viewing the state deck explicitly, like we are now, might not be too viable of an option. But the principle still remains a state deck contains all of the models trained or associated parameters, and what state they're in. And the file path we're going to use is, of course, the model save path, which we've seen here is a POSIX path. Let's save our model. Wonderful saving model to this file path here. And if we have a look at our folder, we should have two saved models now, beautiful to save models. This one for us from the workflow we did before up here, saving a model in PyTorch, loading a PyTorch model. And now the one we've got, of course, model one is the one that we've just saved. Beautiful. So now let's load a model. We're going to do both of these in one video. Load a PyTorch model. You know what, because we've had a little bit of practice so far, and we're going to pick up the pace. So let's go loaded, let's call it, we'll create a new instance of loaded model one, which is, of course, our linear regression model V2, which is the version two of our linear regression model class, which subclasses, what? Subclasses and n.module. So if we go back here up here to where we created it. So linear regression model V2 uses a linear layer rather than the previous iteration of linear regression model, which we created right up here. If we go up to here, which explicitly defined the parameters, and then implemented a linear regression formula in the forward method, the difference between what we've got now is we use PyTorch's pre-built linear layer, and then we call that linear layer in the forward method, which is probably the far more popular way of building PyTorch models, is stacking together pre-built NN layers, and then calling them in some way in the forward method. So let's load it in. So we'll create a new instance of linear regression model V2, and now what do we do? We've created a new instance, I'm just going to get out of this, make some space for us. We want to load the model state deck, the saved model one state deck, which is the state deck that we just saved beforehand. So we can do this by going loaded model one, calling the load state decked method, and then passing it torch dot load, and then the file path of where we saved that PyTorch object before. But the reason why we use the path lib is so that we can just call model save path in here. Wonderful. And then let's check out what's going on. Or actually, we need to put the target model or the loaded model to the device. The reason being is because we're doing all our computing with device agnostic code. So let's send it to the device. And I think that'll be about it. Let's see if this works. Oh, there we go. Linear regression model V2 in features one, out features one, bias equals true. Wonderful. Let's check those parameters. Hey, next loaded model one dot parameters. Are they on the right device? Let's have a look. Beautiful. And let's just check the loaded state dictionary of loaded model one. Do we have the same values as we had previously? Yes, we do. Okay. So to conclusively make sure what's going on, let's evaluate the loaded model. Evaluate loaded model, loaded model one. What do we do for making predictions? Or what do we do to evaluate? We call dot a vowel. And then if we're going to make some predictions, we use torch inference mode with torch inference mode. And then let's create loaded model one, threads equals loaded model one. And we'll pass it the test data. And now let's check for a quality between Y threads, which is our previous model one preds that we made up here, Y threads. And we're going to compare them to the fresh loaded model one preds. And should they be the same? Yes, they are beautiful. And we can see that they're both on the device CUDA. How amazing is that? So I want to give you a big congratulations, because you've come such a long way. We've gone through the entire PyTorch workflow from making data, preparing and loading it to building a model. All of the steps that come in building a model, there's a whole bunch there, making predictions, training a model, we spent a lot of time going through the training steps. But trust me, it's worth it, because we're going to be using these exact steps all throughout the course. And in fact, you're going to be using these exact steps when you build PyTorch models after this course. And then we looked at how to save a model so we don't lose all our work, we looked at loading a model, and then we put it all together using the exact same problem, but in far less time. And as you'll see later on, we can actually make this even quicker by functionalizing some of the code we've already written. But I'm going to save that for later. I'll see you in the next video, where I'm just going to show you where you can find some exercises and all of the extra curriculum I've been talking about throughout this section 01 PyTorch workflow. I'll see you there. Welcome back. In the last video, we finished up putting things together by saving and loading our trained model, which is super exciting, because let's come to the end of the PyTorch workflow section. So now, this section is going to be exercises and extra curriculum, or better yet, where you can find them. So I'm going to turn this into markdown. And I'm going to write here for exercises and extra curriculum. Refer to. So within the book version of the course materials, which is at learnpytorch.io, we're in the 01 section PyTorch workflow fundamentals. There'll be more here by the time you watch this video likely. And then if we go down here, at the end of each of these sections, we've got the table of contents over here. We've got exercises and extra curriculum. I listed a bunch of things throughout this series of 01 videos, like what's gradient descent and what's back propagation. So I've got plenty of resources to learn more on that. There's the loading and saving PyTorch documentation. There's the PyTorch cheat sheet. There's a great article by Jeremy Howard for a deeper understanding of what's going on in torch.nn. And there's, of course, the unofficial PyTorch optimization loop song by yours truly, which is a bit of fun. And here's some exercises. So the exercises here are all based on the code that we wrote throughout section 01. So there's nothing in the exercises that we haven't exactly covered. And if so, I'll be sure to put a note in the exercise itself. But we've got create a straight line data set using the linear regression formula. And then build a model by subclassing and end up module. So for these exercises, there's an exercise notebook template, which is, of course, linked here. And in the PyTorch deep learning GitHub, if we go into here, and then if we go into extras, and if we go into exercises, you'll find all of these templates here. They're numbered by the same section that we're in. This is PyTorch workflow exercises. So if you wanted to complete these exercises, you could click this notebook here, open in Google CoLab. I'll just wait for this to load. There we go. And you can start to write some code here. You could save a copy of this in your own Google Drive and go through this. It's got some notes here on what you should be doing. You can, of course, refer to the text-based version of them. They're all here. And then if you want an example of what some solutions look like, now, please, I can't stress enough that I would highly, highly recommend trying the exercises yourself. You can use the book that we've got here. This is just all the code from the videos. You can use this. You can use, I've got so many notebooks here now, you can use all of the code that we've written here to try and complete the exercises. But please give them a go yourself. And then if you go back into the extras folder, you'll also find solutions. And this is just one example solutions for section 01. But I'm going to get out of that so you can't cheat and look at the solutions first. But there's a whole bunch of extra resources all contained within the PyTorch deep loaning repo, extras, exercises, solutions, and they're also in the book version of the course. So I'm just going to link this in here. I'm going to put this right at the bottom here. Wonderful. But that is it. That is the end of the section 01 PyTorch workflow. So exciting. We went through basically all of the steps in a PyTorch workflow, getting data ready, turning into tenses, build or pick a model, picking a loss function on an optimizer. We built a training loop. We fit the model to the data. We made a prediction. We evaluated our model. We improved through experimentation by training for more epochs. We'll do more of this later on. And we saved and reload our trained model. But that's going to finish 01. I will see you in the next section. Friends, welcome back. We've got another very exciting module. You ready? Neural network classification with PyTorch. Now combining this module once we get to the end with the last one, which was regression. So remember classification is predicting a thing, but we're going to see this in a second. And regression is predicting a number. Once we've covered this, we've covered two of the the biggest problems in machine learning, predicting a number or predicting a thing. So let's start off with before we get into any ideas or code, where can you get help? First things first is follow along with the code. If you can, if in doubt, run the code. Try it for yourself. Write the code. I can't stress how important this is. If you're still stuck, press shift, command, and space to read the doc string of any of the functions that we're running. If you are on Windows, it might be control. I'm on a Mac, so I put command here. If you're still stuck, search for your problem. If an error comes up, just copy and paste that into Google. That's what I do. You might come across resources like Stack Overflow or, of course, the PyTorch documentation. We'll be referring to this a lot again throughout this section. And then finally, oh wait, if you're still stuck, try again. If in doubt, run the code. And then finally, if you're still stuck, don't forget, you can ask a question. The best place to do so will be on the course GitHub, which will be at the discussions page, which is linked here. If we load this up, there's nothing here yet, because as I record these videos, the course hasn't launched yet, but press new discussion. Talk about what you've got. Problem with XYZ. Let's go ahead. Leave a video number here and a timestamp, and that way, we'll be able to help you out as best as possible. So video number, timestamp, and then your question here, and you can select Q&A. Finally, don't forget that this notebook that we're about to go through is based on chapter two of the Zero to Mastery Learn PyTorch for deep learning, which is neural network classification with PyTorch. All of the text-based code that we're about to write is here. That was a little spoiler. And don't forget, this is the home page. So my GitHub repo slash PyTorch deep learning for all of the course materials, everything you need will be here. So that's very important. How can you get help? But this is the number one. Follow along with the code and try to write it yourself. Well, with that being said, when we're talking about classification, what is a classification problem? Now, as I said, classification is one of the main problems of machine learning. So you probably already deal with classification problems or machine learning powered classification problems every day. So let's have a look at some examples. Is this email spam or not spam? Did you check your emails this morning or last night or whenever? So chances are that there was some sort of machine learning model behind the scenes. It may have been a neural network. It may have not that decided that some of your emails won't spam. So to Daniel, at mrdberg.com, hey, Daniel, this steep learning course is incredible. I can't wait to use what I've learned. Oh, that's such a nice message. If you want to send that email directly to me, you can. That's my actual email address. But if you want to send me this email, well, hopefully my email, which is hosted by some email service detects this as spam because although that is a lot of money and it would be very nice, I think if someone can't spell too well, are they really going to pay me this much money? So thank you email provider for classifying this as spam. And now because this is one thing or another, not spam or spam, this is binary classification. So in this case, it might be one here and this is a zero or zero or one. So one thing or another, that's binary classification. If you can split it into one thing or another, binary classification. And then we have an example of say we had the question, we asked our photos app on our smartphone or whatever device you're using. Is this photo of sushi steak or pizza? We wanted to search our photos for every time we've eaten sushi or every time we've eaten steak or every time we've eaten pizza far out and this looks delicious. But this is multi class classification. Now, why is this? Because we've got more than two things. We've got 123. And now this could be 10 different foods. It could be 100 different foods. It could be 1000 different categories. So the image net data set, which is a popular data set for computer vision, image net, we go to here, does it say 1000 anywhere, 1k or 1000? No, it doesn't. But if we go image net 1k, download image net data, maybe it's here. It won't say it, but you just, oh, there we go, 1000 object classes. So this is multi class classification because it has 1000 classes, that's a lot, right? So that's multi class classification, more than one thing or another. And finally, we might have multi label classification, which is what tags should this article have when I first got into machine learning, I got these two mixed up a whole bunch of times. Multi class classification has multiple classes such as sushi steak pizza, but assigns one label to each. So this photo would be sushi in an ideal world. This is steak and this is pizza. So one label to each. Whereas multi label classification means you could have multiple different classes. But each of your target samples such as this Wikipedia article, what tags should this article have? It may have more than one label. It might have three labels, it might have 10 labels. In fact, what if we went to the Wikipedia page for deep learning Wikipedia and does it have any labels? Oh, there we go. Where was that? I mean, you can try this yourself. This is just the Wikipedia page for deep learning. There is a lot, there we go categories deep learning, artificial neural networks, artificial intelligence and emerging technologies. So that is an example. If we wanted to build a machine learning model to say, read all of the text in here and then go tell me what are the most relevant categories to this article? It might come up with something like these. In this case, because it has one, two, three, four, it has multiple labels rather than just one label of deep learning, it could be multi label classification. So we'll go back. But there's a few more. These will get you quite far in the world of classification. So let's dig a little deeper on binary versus multi class classification. You may have already experienced this. So in my case, if I search on my phone in the photos app for photos of a dog, it might come here. If I search for photos of a cat, it might come up with this. But if I wanted to train an algorithm to detect the difference between photos of these are my two dogs. Aren't they cute? They're nice and tired and they're sleeping like a person. This is seven. Number seven, that's her name. And this is Bella. This is a cat that me and my partner rescued. And so I'm not sure what this cat's name is actually. So I'd love to give it a name, but I can't. So binary classification, if we wanted to build an algorithm, we wanted to feed it, say, 10,000 photos of dogs and 10,000 photos of cats. And then we wanted to find a random image on the internet and pass it through to our model and say, hey, is this a dog or is this a cat? It would be binary classification because the options are one thing or another dog or cat. But then for multi-class classification, let's say we've been working on a farm and we've been taking some photos of chickens because they groovy, right? Well, we updated our model and added some chicken photos in there. We would now be working with a multi-class classification problem because we've got more than one thing or another. So let's jump in to what we're going to cover. This is broadly, by the way, because this is just text on a page. You know, I like to just write code of what we're actually doing. So we're going to look at the architecture of a neural network classification model. We're going to check what the input shapes and output shapes of a classification model are features and labels. In other words, because remember, machine learning models, neural networks love to have numerical inputs. And those numerical inputs often come in tenses. Tenses have different shapes, depending on what data you're working with. We're going to see all of this in code, creating custom data to view, fit and predict on. We're going to go back through our steps in modeling. We covered this a fair bit in the previous section, but creating a model for neural network classification. It's a little bit different to what we've done, but not too out landishly different. We're going to see how we can set up a loss function and an optimizer for a classification model. We'll recreate a training loop and a evaluating loop or a testing loop. We'll see how we can save and load our models. We'll harness the power of nonlinearity. Well, what does that even mean? Well, if you think of what a linear line is, what is that? It's a straight line. So you might be able to guess what a nonlinear line looks like. And then we'll look at different classification evaluation methods. So ways that we can evaluate our classification models. And how are we going to do all of this? Well, of course, we're going to be part cook, part chemist, part artist, part science. But for me, I personally prefer the cook side of things because we're going to be cooking up lots of code. So in the next video, before we get into coding, let's do a little bit more on what are some classification inputs and outputs. I'll see you there. Welcome back. In the last video, we had a little bit of a brief overview of what a classification problem is. But now, let's start to get more hands on by discussing what the actual inputs to a classification problem look like and the outputs look like. And so let's say we had our beautiful food photos from before, and we were trying to build this app here called maybe food vision to understand what foods are in the photos that we take. And so what might this look like? Well, let's break it down to inputs, some kind of machine learning algorithm, and then outputs. In this case, the inputs we want to numerically represent these images in some way, shape or form. Then we want to build a machine learning algorithm. Hey, one might actually exist. We're going to see this later on in the transfer learning section for our problem. And then we want some sort of outputs. And in the case of food vision, we want to know, okay, this is a photo of sushi. And this is a photo of steak. And this is a photo of pizza. You could get more hands on and technical and complicated, but we're just going to stick with single label multi class classification. So it could be a sushi photo, it could be a steak photo, or it could be a pizza photo. So how might we numerically represent these photos? Well, let's just say we had a function in our app that every photo that gets taken automatically gets resized into a square into 224 width and 224 height. This is actually quite a common dimensionality for computer vision problems. And so we've got the width dimension, we've got the height, and then we've got this C here, which isn't immediately recognizable. But in the case of pictures, they often get represented by width, height color channels. And the color channels is red, green and blue, which is each pixel in this image has some value of red, green or blue, that makes whatever color is displayed here. And this is one way that we can numerically represent an image by taking its width, its height and color channels, and whatever number makes up this particular image. We're going to see this later on when we work with computer vision problems. So we create a numerical encoding, which is the pixel values here. Then we import the pixel values of each of these images into a machine learning algorithm, which is often already exists. And if it doesn't exist for our particular problem, hey, well, we're learning the skills to build them now, we could use pytorch to build a machine learning algorithm for this. And then outputs, what might these look like? Well, in this case, these are prediction probabilities, which the outputs of machine learning models are never actually discrete, which means it is definitely pizza. It will give some sort of probability value between zero and one for say the closer to one, the more confident our model is that it's going to be pizza. And the closer to zero is means that, hey, this photo of pizza, let's say this one, and we're trying to predict sushi. Well, it doesn't think that it's sushi. So it's giving it quite a low value here. And then the same for steak, but it's really high, the value here for pizza. We're going to see this hands on. And then it's the opposite here. So it might have got this one wrong. But with more training and more data, we could probably improve this prediction. That's the whole idea of machine learning, is that if you adjust the algorithm, if you adjust the data, you can improve your predictions. And so the ideal outputs that we have here, this is what our models going to output. But for our case of building out food vision, we want to bring them back to. So we could just put all of these numbers on the screen here, but that's not really going to help people. We want to put out labels of what's going on here. So we can write code to transfer these prediction probabilities into these labels too. And so how did these labels come about? How do these predictions come about? Well, it comes from looking at lots of different samples. So this loop, we could keep going, improve these, find the ones where it's wrong, add more images here, train the model again, and then make our app better. And so if we want to look at this from a shape perspective, we want to create some tenses for an image classification example. So we're building food vision. We've got an image again, this is just reiterating on some of the things that we've discussed. We've got a width of 224 and a height of 224. This could be different. This could be 300, 300. This could be whatever values that you decide to use. Then we numerically encoded in some way, shape or form. We use this as the inputs to our machine learning algorithm, because of what? Computers and machine learning algorithms, they love numbers. They can find patterns in here that we couldn't necessarily find. Or maybe we could, if you had a long enough time, but I'd rather write an algorithm to do it for me. Then it has some outputs, which comes in the formal prediction probabilities, the closer to one, the more confident model is and saying, hey, I'm pretty damn confident that this is a photo of sushi. I don't think it's a photo of steak. So I'm giving that zero. It might be a photo of pizza, but I don't really think so. So I'm giving it quite a low prediction probability. And so if we have a look at what the shapes are for our tenses here, if this doesn't make sense, don't worry. We're going to see the code to do all of this later on. But for now, we're just focusing on a classification input and output. The big takeaway from here is numerical encoding, outputs and numerical encoding. But we want to change these numerical codings from the outputs to something that we understand, say the word sushi. But this tensor may be batch size. We haven't seen what batch size is. That's all right. We're going to cover it. Color channels with height. So this is represented as a tensor of dimensions. It could be none here. None is a typical value for a batch size, which means it's blank. So when we use our model and we train it, all the code that we write with pytorch will fill in this behind the scenes. And then we have three here, which is color channels. And we have 224, which is the width. And we have 224 as well, which is the height. Now there is some debate in the field on the ordering. We're using an image as our particular example here on the ordering of these shapes. So say, for example, you might have height width color channels, typically width and height come together in this order. Or they're just side by side in the tensor in terms of their whether dimension appears. But color channels sometimes comes first. That means after the batch size or at the end here. But pytorch, the default for now is color channels with height, though you can write code to change this order because tenses are quite flexible. And so or the shape could be 32 for the batch size, three, two, two, four, two, two, four, because 32 is a very common batch size. And you don't believe me? Well, let's go here. Yarn LeCoon 32 batch size. Now what is a batch size? Great tweet. Just keep this in mind for later on. Training with large mini batches is bad for your health. More importantly, it's bad for your test error. Friends don't let friends use mini batches larger than 32. So this is quite an old tweet. However, it still stands quite true. Because like today, it's 2022 when I'm recording these videos, there are batch sizes a lot larger than 32. But 32 works pretty darn well for a lot of problems. And so this means that if we go back to our slide, that if we use a batch size of 32, our machine learning algorithm looks at 32 images at a time. Now why does it do this? Well, because sadly, our computers don't have infinite compute power. In an ideal world, we look at thousands of images at a time, but it turns out that using a multiple of eight here is actually quite efficient. And so if we have a look at the output shape here, why is it three? Well, because we're working with three different classes, one, two, three. So we've got shape equals three. Now, of course, as you could imagine, these might change depending on the problem you're working with. So say if we just wanted to predict if a photo was a cat or a dog, we still might have this same representation here because this is the image representation. However, the shape here may be two, or will be two because it's cat or dog, rather than three classes here, but a little bit confusing as well with binary classification, you could have the shape just being one here. But we're going to see this all hands on. Just remember, the shapes vary with whatever problem you're working on. The principle of encoding your data as a numerical representation stays the same for the inputs. And the outputs will often be some form of prediction probability based on whatever class you're working with. So in the next video, right before we get into coding, let's just discuss the high level architecture of a classification model. And remember, architecture is just like the schematic of what a neural network is. I'll see you there. Welcome back. In the last video, we saw some example classification inputs and outputs. The main takeaway that the inputs to a classification model, particularly a neural network, want to be some form of numerical representation. And the outputs are often some form of prediction probability. So let's discuss the typical architecture of a classification model. And hey, this is just going to be text on a page, but we're going to be building a fair few of these. So we've got some hyper parameters over here. We've got binary classification. And we've got multi class classification. Now, there are some similarities between the two in terms of what problem we're working with. But there also are some differences here. And by the way, this has all come from, if we go to the book version of the course, we've got what is a classification problem. And we've got architecture of a classification neural network. So all of this text is available at learnpytorch.io and in section two. So we come back. So the input layer shape, which is typically decided by the parameter in features, as you can see here, is the same of number of features. So if we were working on a problem, such as we brought it to predict whether someone had heart disease or not, we might have five input features, such as one for age, a number for age, it might be in my case, 28, sex could be male, height, 180 centimeters. If I've been growing overnight, it's really close to 177. Wait, well, it depends on how much I've eaten, but it's around about 75 kilos and smoking status, which is zero. So it could be zero or one, because remember, we want numerical representation. So for sex, it could be zero for males, one for female, height could be its number, weight could be its number as well. All of these numbers could be more, could be less as well. So this is really flexible. And it's a hyper parameter. Why? Because we decide the values for each of these. So in the case of our image prediction problem, we could have in features equals three for number of color channels. And then we go hidden layers. So there's the blue circle here. I forgot that this was all timed and colorful. But let's just discuss hidden layers. Each of these is a layer and n dot linear and n dot linear and n dot relu and n dot linear. So that's the kind of the syntax you'll see in PyTorch for a layer is nn dot something. Now, there are many different types of layers in this in PyTorch. If we go torch and n, basically everything in here is a layer in a neural network. And then if we look up what a neural network looks like, neural network, recall that all of these are different layers of some kind of mathematical operation. Input layer, hidden layer, you could have as many hidden layers as you want. Do we have ResNet architecture? The ResNet architecture, some of them have 50 layers. Look at this. Each one of these is a layer. And this is only the 34 layer version. I mean, there's ResNet 152, which is 152 layers. We're not at that yet. But we're working up the tools to get to that stage. Let's come back to here. The neurons per hidden layer. So we've got these, out features, the green circle, the green square. Now, this is, if we go back to our neural network picture, this is these. Each one of these little things is a neuron, some sort of parameter. So if we had 100, what would that look like? Well, we'd have a fairly big graphic. So this is why I like to teach with code because you could customize this as flexible as you want. So behind the scenes, PyTorch is going to create 100 of these little circles for us. And within each circle is what? Some sort of mathematical operation. So if we come back, what do we got next? Output layer shape. So this is how many output features we have. So in the case of binary classification is one, one class or the other. We're going to see this later on. Multi-class classification is you might have three output features, one per class, e.g., one for food, person or dog, if you're building a food, person or dog, image classification model. Hidden layer activation, which is, we haven't seen these yet. Relu, which is a rectified linear unit, but can be many others because PyTorch, of course, has what? Has a lot of non-linear activations. We're going to see this later on. Remember, I'm kind of planting the seed here. We've seen what a linear line is, but I want you to imagine what a non-linear line is. It's going to be a bit of a superpower for our classification problem. What else do we have? Output activation. We haven't got that here, but we'll also see this later on, which could be sigmoid for, which is generally sigmoid for binary classification, but softmax for multi-class classification. A lot of these things are just names on a page. We haven't seen them yet. I like to teach them as we see them, but this is just a general overview of what we're going to cover. Loss function. What loss function or what does a loss function do? It measures how wrong our model's predictions are compared to what the ideal predictions are. So for binary classification, we might use binary cross entropy loss in PyTorch, and for multi-class classification, we might just use cross entropy rather than binary cross entropy. Get it? Binary classification? Binary cross entropy? And then optimizer. SGD is stochastic gradient descent. We've seen that one before. Another common option is the atom optimizer, and of course, the torch.optim package has plenty more options. So this is an example multi-class classification problem. This network here. Why is that? And we haven't actually seen an end up sequential, but as you could imagine, sequential stands for it just goes through each of these steps. So multi-class classification, because it has three output features, more than one thing or another. So three for food, person or dog, but going back to our food vision problem, we could have the input as sushi, steak, or pizza. So we've got three output features, which would be one prediction probability per class of image. We have three classes, sushi, steak, or pizza. Now, I think we've done enough talking here, and enough just pointing to text on slides. How about in the next video? Let's code. I'll see you in Google CoLab. Welcome back. Now, we've done enough theory of what a classification problem is, what the inputs and outputs are and the typical architecture. Let's get in and write some code. So I'm going to get out of this, and going to go to colab.research.google.com, so we can start writing some PyTorch code. I'm going to click new notebook. We're going to start exactly from scratch. I'm going to name this section two, and let's call it neural network classification with PyTorch. I'm going to put underscore video, because I'll just show you, you'll see this in the GitHub repo. But for all the video notebooks, the ones that I write code during these videos that you're watching, the exact code is going to be saved on the GitHub repo under video notebooks. So there's 00, which is the fundamentals, and there's the workflow underscore video. But the reference notebook with all the pretty pictures and stuff is in the main folder here. So PyTorch classification that I pi and b are actually, maybe we'll just rename it that PyTorch classification. But we know it's with neural networks. PyTorch classification. Okay, and let's go here. We'll add a nice title. So O2, neural network classification with PyTorch. And so we'll remind ourselves, classification is a problem of predicting whether something is one thing or another. And there can be multiple things as the options, such as email, spam or not spam, photos of dogs or cats or pizza or sushi or steak. Lots of talk about food. And then I'm just going to link in here, this resource, because this is the book version of the course. These are what the videos are based off. So book version of this notebook. And then all the resources are in here. All other resources in the GitHub, and then stuck. Ask a question here, which is under the discussions tab. We'll copy that in here. That way we've got everything linked and ready to go. But as always, what's our first step in our workflow? This is a little test. See if you remember. Well, it's data, of course, because all machine learning problems start with some form of data. We can't write a machine learning algorithm to learn patterns and data that doesn't exist. So let's do this video. We're going to make some data. Of course, you might start with some of your own that exists. But for now, we're going to focus on just the concepts around the workflow. So we're going to make our own custom data set. And to do so, I'll write the code first, and then I'll show you where I get it from. We're going to import the scikit loan library. One of the beautiful things about Google Colab is that it has scikit loan available. You're not sure what scikit loan is. It's a very popular machine learning library. PyTorch is mainly focused on deep learning, but scikit loan is focused on a lot of things around machine learning. So Google Colab, thank you for having scikit loan already installed for us. But we're going to import the make circles data set. And rather than talk about what it does, let's see what it does. So make 1000 samples. We're going to go N samples equals 1000. And we're going to create circles. You might be wondering why circles. Well, we're going to see exactly why circles later on. So X and Y, we're going to use this variable. How would you say nomenclature as capital X and Y. Why is that? Because X is typically a matrix features and labels. So let's go here. Mate circles. And we're going to make N samples. So 1000 different samples. We're going to add some noise in there. Just put a little bit of randomness. Why not? You can increase this as you want. I found that 0.03 is fairly good for what we're doing. And then we're going to also pass in the random state variable, which is equivalent to sitting a random or setting a random seed. So we're flavoring the randomness here. Wonderful. So now let's have a look at the length of X, which should be what? And length of Y. Oh, we don't have Y underscore getting a bit trigger happy with this keyboard here. 1000. So we have 1000 samples of X caught with 1000 or paired with 1000 samples of Y features labels. So let's have a look at the first five of X. So print first five samples of X. And then we'll put in here X. And we can index on this five because we're adhering to the data, explorer's motto of visualize visualize visualize first five samples of Y. And then we're going to go why same thing here. Wonderful. Let's have a look. Maybe we'll get a new line in here. Just so looks a bit better. Wonderful. So numerical. Our samples are already numerical. This is one of the reasons why we're creating our own data set. We'll see later on how we get non numerical data into numbers. But for now, our data is numerical, which means we can learn it with our model or we can build a model to learn patterns in here. So this sample has the label of one. And this sample has the label of one as well. Now, how many features do we have per sample? If I highlight this line, how many features is this? It would make it a bit easier if there was a comma here, but we have two features of X, which relates to one label of Y. And so far, we've only seen, let's have a look at all of Y. We've got zero on one. So we've got two classes. What does this mean? Zero or one? One thing or another? Well, it looks like binary classification to me, because we've got only zero or only one. If there was zero, one, two, it would be multi class classification, because we have more than two things. So let's X out of this. Let's keep going and do a little bit more data exploration. So how about we make a data frame? With pandas of circle data. There is truly no real definite way of how to explore data. For me, I like to visualize it multiple different ways, or even look at random samples. In the case of large data sets, such as images or text or whatnot. If you have 10 million samples, perhaps visualizing them one by one is not the best way to do so. So random can help you out there. So we're going to create a data frame, and we can insert a dictionary here. So I'm going to call the features in this part of X, X1, and these are going to be X2. So let's say I'll write some code to index on this. So everything in the zero index will be X1. And everything in the first index, there we go, will be X2. Let me clean up this code. This should be on different lines, enter. And then we've got, let's put in the label as Y. So this is just a dictionary here. So X1 key to X0. X2, a little bit confusing because of zero indexing, but X feature one, X feature two, and the label is Y. Let's see what this looks like. We'll look at the first 10 samples. Okay, beautiful. So we've got X1, some numerical value, X2, another numerical value, correlates to or matches up with label zero. But then this one, 0442208, and negative that number matches up with label zero. So I can't tell what the patterns are just looking at these numbers. You might be able to, but I definitely can't. We've got some ones. All these numbers look the same to me. So what can we do next? Well, how about we visualize, visualize, visualize, and instead of just numbers in a table, let's get graphical this time, visualize, visualize, visualize. So we're going to bring in our friendly mapplotlib, import mapplotlib, which is a very powerful plotting library. I'm just going to add some cells here. So we've got some space, mapplotlib.pyplot as PLT. That's right. We've got this plot.scatter. We're going to do a scatterplot equals X. And we want the first index. And then Y is going to be X as well. So that's going to appear on the Y axis. And then we want to color it with labels. We're going to see what this looks like in a second. And then the color map, C map stands for color map is going to be plot dot color map PLT. And then red, yellow, blue, one of my favorite color outputs. So let's see what this looks like. You ready? Ah, there we go. There's our circles. That's a lot better for me. So what do you think we're going to try and do here? If this is our data and we're working on classification, we're trying to predict if something is one thing or another. So our problem is we want to try and separate these two circles. So say given a number here or given two numbers and X one and an X two, which are coordinates here, we want to predict the label. Is it going to be a blue dot or is it going to be a red dot? So we're working with binary classification. So we have one thing or another. Do we have a blue dot or a red dot? So this is going to be our toy data here. And a toy problem is, let me just write this down. This is a common thing that you'll also hear in machine learning. Note, the data we're working with is often referred to as a toy data set, a data set that is small enough to experiment on, but still sizable enough to practice the fundamentals. And that's what we're really after in this notebook is to practice the fundamentals of neural network classification. So we've got a perfect data set to do this. And by the way, we've got this from scikit-learn. So this little function here made all of these samples for us. And how could you find out more about this function here? Well, you could go scikit-learn classification data sets. There are actually a few more in here that we could have done. I just like the circle one. Toy data sets, we saw that. So this is like a toy box of different data sets. So if you'd like to learn more about some data sets that you can have a look in here and potentially practice on with neural networks or other forms of machine learning models from scikit-learn, check out this scikit-learn. I can't speak highly enough. I know this is a pie-torch course. We're not focused on this, but they kind of all come together in terms of the machine learning and deep learning world. You might use something from scikit-learn, like we've done here, to practice something. And then you might use pie-torch for something else, like what we're doing here. Now, with that being said, what are the input and output shapes of our problem? Have a think about that. And also have a think about how we'd split this into training and test. So give those a go. We covered those concepts in some previous videos, but we'll do them together in the next video. I'll see you there. Welcome back. In the last video, we made some classification data so that we can practice building a neural network in pie-torch to separate the blue dots from the red dots. So let's keep pushing forward on that. And I'll just clean up here a little bit, but where are we in our workflow? What have we done so far? Well, we've got our data ready a little bit. We haven't turned it into tenses. So let's do that in this video, and then we'll keep pushing through all of these. So in here, I'm going to make this heading 1.1. Check input and output shapes. The reason we're focused a lot on input and output shapes is why, because machine learning deals a lot with numerical representations as tenses. And input and output shapes are some of the most common errors, like if you have a mismatch between your input and output shapes of a certain layer of an output layer, you're going to run into a lot of errors there. So that's why it's good to get acquainted with whatever data you're using, what are the input shapes and what are the output shapes you'd like. So in our case, we can go x dot shape and y dot shape. So we're working with NumPy arrays here if we just look at x. That's what the make circles function is created for us. We've got an array, but as our workflow says, we'd like it in tenses. If we're working with PyTorch, we want our data to be represented as PyTorch tenses of that data type. And so we've got a shape here, we've got a thousand samples, and x has two features, and y has no features. It's just a single number. It's a scalar. So it doesn't have a shape here. So there's a thousand samples of y, thousand samples of x, two samples of x equals one y label. Now, if you're working with a larger problem, you might have a thousand samples of x, but x is represented by 128 different numbers, or 200 numbers, or as high as you want, or just 10 or something like that. So just keep in mind that this number is quite flexible of how many features represent a label. Why is the label here? But let's keep going. So view the first example of features and labels. So let's make it explicit with what we've just been discussing. We'll write some code to do so. We'll get the first sample of x, which is the zero index, and we'll get the first sample of y, which is also the zero index. We could get really anyone because they're all of the same shape. But print values for one sample of x. What does this equal? X sample, and the same for y, which is y sample. And then we want to go print f string for one sample of x. We'll get the shape here. X sample dot shape, and the same for y, and then we'll get y sample dot shape. Beautiful. What's this going to do? Well, we've got one sample of x. So this sample here of these numbers, we've got a lot going on here. 75424625 and 0231 48074. I mean, you can try to find some patterns in those. If you do, all the best here, and the same for y. So this is, we have the y sample, this correlates to a number one, a label of one. And then we have shapes for one sample of x, which is two. So we have two features for y. It's a little bit confusing here because y is a scalar, which doesn't actually have a shape. It's just one value. So for me, in terms of speaking this, teaching it out loud, we'll be two features of x trying to predict one number for y. And so let's now create another heading, which is 1.2. Let's get our data into tenses, turn data into tenses. We have to convert them from NumPy. And we also want to create train and test splits. Now, even though we're working with a toy data set here, the principle of turning data into tenses and creating train and test splits will stay around for almost any data set that you're working with. So let's see how we can do that. So we want to turn data into tenses. And for this, we need to import torch, get pytorch and we'll check the torch version. It has to be at least 1.10. And I might just put this down in the next cell. Just make sure we can import pytorch. There we go, 1.10 plus CUDA 111. If your version is higher than that, that is okay. The code below should still work. And if it doesn't, let me know. So x equals torch dot from NumPy. Why are we doing this? Well, it's because x is a NumPy array. And if we go x dot, does it have a d type attribute float 64? Can we just go type or maybe type? Oh, there we go. NumPy and DRA. We can just go type x. NumPy and DRA. So we want it in a torch tensor. So we're going to go from NumPy. We saw this in the fundamental section. And then we're going to change it into type torch dot float. A float is an alias for float 32. We could type the same thing. These two are equivalent. I just going to type torch float for writing less code. And then we're going to go the same with why torch from NumPy. Now, why do we turn it into a torch float? Well, that's because if you recall, the default type of NumPy arrays is, if we go might just put out this in a comma x dot D type is float 64. There we go. However, pytorch, the default type is float 32. So we're changing it into pytorch's default type. Otherwise, if we didn't have this little section of code here dot type torch dot float, our tensors would be of float 64 as well. And that may cause errors later on. So we're just going for the default data type within pytorch. And so now let's have a look at the first five values of x and the first five values of y. What do we have? Beautiful. We have tensor data types here. And now if we check the data type of x and we check the data type of y, what do we have? And then one more, we'll just go type x. So we have our data into tensors. Wonderful. But now so it's torch dot tensor. Beautiful. But now we would like training and test sets. So let's go split data into training and test sets. And a very, very popular way to split data is a random split. So before I issued the challenge of how you would split this into a training and test set. So because these data points are kind of scattered all over the place, we could split them randomly. So let's see what that looks like. To do so, I'm going to use our faithful scikit learn again. Remember how I said scikit learn has a lot of beautiful methods and functions for a whole bunch of different machine learning purposes. Well, one of them is for a train test split. Oh my goodness, pytorch I didn't want auto correct there. Train test split. Now you might be able to guess what this does. These videos are going to be a battle between me and code labs auto correct. Sometimes it's good. Other times it's not. So we're going to set this code up. I'm going to write it or we're going to write it together. So we've got x train for our training features and X tests for our testing features. And then we also want our training labels and our testing labels. That order is the order that train test split works in. And then we have train test split. Now if we wrote this function and we wanted to find out more, I can press command ship space, which is what I just did to have this. But truly, I don't have a great time reading all of this. You might. But for me, I just like going train test split. And possibly one of the first functions that appears, yes, is scikit learn. How good is that? So scikit learn dot model selection dot train test split. Now split arrays or matrices into random train and test subsets. Beautiful. We've got a code example of what's going on here. You can read what the different parameters do. But we're going to see them in action. This is just another example of where machine learning libraries such as scikit learn, we've used matplotlib, we've used pandas, they all interact together to serve a great purpose. But now let's pass in our features and our labels. This is the order that they come in, by the way. Oh, and we have the returns splitting. So the order here, I've got the order goes x train x test y train y test took me a little while to remember this order. But once you've created enough training test splits with this function, you kind of know this off by heart. So just remember features first train first and then labels. And we jump back in here. So I'm going to put in the test size parameter of 0.2. This is percentage wise. So let me just write here 0.2 equals 20% of data will be test. And 80% will be train. If we wanted to do a 50 50 split, that kind of split doesn't usually happen, but you could go 0.5. But the test size says, hey, how big and percentage wise do you want your test data to be? And so behind the scenes train test split will calculate what's 20% of our x and y samples. So we'll see how many there is in a second. But let's also put a random state in here. Because if you recall back in the documentation, train test split splits data randomly into random train and test subsets. And random state, what does that do for us? Well, this is a random seed equivalent of very similar to torch dot manual seed. However, because we are using scikit learn, setting torch dot manual seed will only affect pytorch code rather than scikit learn code. So we do this so that we get similar random splits. As in, I get a similar random split to what your random split is. And in fact, they should be exactly the same. So let's run this. And then we'll check the length of x train. And length of x test. So if we have 1000 total samples, and I know that because above in our make circles function, we said we want 1000 samples, that could be 10,000, that could be 100. That's the beauty of creating your own data set. And we have length y train. If we have 20% testing values, how many samples are going to be dedicated to the test sample, 20% of 1000 years, 200, and 80%, which is because training is going to be training here. So 100 minus 20% is 80%. So 80% of 1000 years, let's find out. Run all beautiful. So we have 800 training samples, 200 testing samples. This is going to be the data set that we're going to be working with. So in the next video, we've now got training and test sets, we've started to move through our beautiful pytorch workflow here. We've got our data ready, we've turned it into tenses, we've created a training and test split. Now it's time to build or pick a model. So I think we're still in the building phase. Let's do that in the next video. Welcome back. In the last video, we split our data into training and test sets. And because we did 80 20 split, we've got about 800 samples to train on, and 200 samples to test on. Remember, the training set is so that the model can learn patterns, patterns that represent this data set here, the circles data set, red dots or blue dots. And the test data set is so that we can evaluate those patterns. And I took a little break before, but you can tell that because my notebook is disconnected. But if I wanted to reconnect it, what could I do? We can go here, run time, run before that's going to run all of the cells before. It shouldn't take too long because we haven't done any large computations. But this is good timing because we're up to part two, building a model. And so there's a fair few steps here, but nothing that we haven't covered before, we're going to break it down. So let's build a model to classify our blue and red dots. And to do so, we want to tenses. I want to not tenses. That's all right. So let me just make some space here. There we go. So number one, let's set up device agnostic code. So we get in the habit of creating that. So our code will run on an accelerator. I can't even spell accelerator. It doesn't matter. You know what I mean? GPU. If there is one. Two. What should we do next? Well, we should construct a model. Because if we want to build a model, we need a model. Construct a model. And we're going to go by subclassing and then dot module. Now we saw this in the previous section, we subclassed and then module. In fact, all models in PyTorch subclass and end up module. And let's go define loss function and optimizer. And finally, good collabs auto correct is not ideal. And then we'll create a training and test loop. Though this will probably be in the next section. We'll focus on building a model here. And of course, all of these steps are in line with what they're in line with this. So we don't have device agnostic code here, but we're just going to do it enough so that we have a habit. These are the main steps. Pick or build a pre-trained model, suit your problem, pick a loss function and optimizer, build a training loop. So let's have a look. How can we start this off? So we will import PyTorch. And and then we've already done this, but we're going to do it anyway for completeness, just in case you wanted to run your code from here, import and then. And we're going to make device agnostic code. So we'll set the device equal to CUDA if torch dot CUDA is available else CPU, which will be the default. The CPU is the default. If there's no GPU, which means that CUDA is available, all of our PyTorch code will default to using the CPU device. Now we haven't set up a GPU yet so far. You may have, but as you see, my target device is currently CPU. How about we set up a GPU? We can go into here runtime change runtime type GPU. And I'm going to click save. Now this is going to restart the runtime and reconnect. So once it reconnects beautiful, we could actually just run this code cell here. This is going to set up the GPU device, but because we're only running this cell, if we were to just set up X train, we've not been defined. So because we restarted our runtime, let's run all or we can just run before. So this is going to rerun all of these cells here. And do we have X train now? Let's have a look. Wonderful. Yes, we do. Okay, beautiful. So we've got device agnostic code. In the next video, let's get on to constructing a model. I'll see you there. Welcome back. In the last video, we set up some device agnostic code. So this is going to come in later on when we send our model to the target device, and also our data to the target device. This is an important step because that way, if someone else was able to run your code or you were to run your code in the future, because we've set it up to be device agnostic, quite a fault it will run on the CPU. But if there's an accelerator present, well, that means that it might go faster because it's using a GPU rather than just using a CPU. So we're up to step two here construct a model by subclassing and in module. I think we're going to write a little bit of text here just to plan out the steps that we're doing. Now we've set up device agnostic code. Let's create a model that we're going to break it down. We've got some sub steps up here. We're going to break it down even this one down into some sub-sub steps. So number one is we're going to subclass and then got module. And a reminder here, I want to make some space, just so we're coding in about the middle of the page. So almost all models in pytorch, subclass, and then got module because there's some great things that it does for us behind the scenes. And step two is we're going to create two and then dot linear layers. And we want these that are capable to handle our data. So that are capable of handling the shapes of our data. Step three, we want to define or defines a forward method. Why do we want to define a forward method? Well, because we're subclassing an end dot module, right? And so the forward method defines a forward method that outlines the forward pass or forward computation of the model. And number four, we want to instantiate, well, this doesn't really have to be the part of creating it, but we're going to do anyway, and instantiate an instance of our model class and send it to the target device. So I'm going to be a couple of little different steps here, but nothing too dramatic that we haven't really covered before. So let's go number one, construct a model that subclasses an end dot module. So I'm going to code this all out. Well, we're going to code this all out together. And then we'll go back through and discuss it, and then maybe draw a few pictures or something to check out what's actually happening. So circle model V one, because we're going to try and split some circles, red and blue circles. This is our data up here. This is why it's called circle model, because we're trying to separate the blue and red circle using a neural network. So we've subclassed an end dot module. And when we create a class in Python, we'll create a constructor here, a net, and then put in super dot underscore a net. And then inside the constructor, we're going to create our layers. So this is number two, create two and then linear layers, capable of handling the shapes of our data. So I'm going to write this down here to create two, two, and then dot linear layers, capable of handling the shapes of our data. And so if we have a look at X train, what are the shapes here? What's the input shape? Because X train is our features, right? Now features are going to go into our model. So we have 800 training samples. This is the first number here of size two each. So 800 of these and inside each is two numbers. Again, depending on the data set you're working with, your features may be 100 in length, a vector of 100, or maybe a different size tensor all together, or there may be millions. It really depends on what data set you're working with. Because we're working with a simple data set, we're going to focus on that. But the principal is still the same. You need to define a neural network layer that is capable of handling your input features. So we're going to make layer one equals an n dot linear. And then if we wanted to find out what's going on an n n dot linear, we could run shift command space on my computer, because it's a Mac, maybe shift control space if you're on Windows. So we're going to define the n features. What would n features be here? Well, we just decided that our X has two features. So n features are going to be two. And now what is the out features? This one is a little bit tricky. So in our case, we could have out features equal to one if we wanted to just pass a single linear layer, but we want to create two linear layers here. So why would out features be one? Well, that's because if we have a look at the first sample of Y train, we would want us to input, or maybe we'll look at the first five. We want to map one sample of X to one sample of Y and Y has a shape of one. Oh, well, really, it's nothing because it's a scalar, but we would still put one here so that it outputs just one number. But we're going to change this up. We're going to put it into five and we're going to create a second layer. Now, this is an important point of joining together neural networks in features here. What do you think the in features of our second layer is going to be? If we've produced an out feature of five here, now this number is arbitrary. We could do 128. We could do 256. Generally, it's multiples of 8, 64. We're just doing five now because we're keeping it nice and simple. We could do eight multiples of eight is because of the efficiency of computing. I don't know enough about computer hardware to know exactly why that's the case, but that's just a rule of thumb in machine learning. So the in features here has to match up with the out features of a previous layer. Otherwise, we'll get shape mismatch errors. And so let's go here out features. So we're going to treat this as the output layer. So this is the out features equals one. So takes in two features and upscales to five features. So five numbers. So what this does, what this layer is going to do is take in these two numbers of X, perform an end up linear. Let's have a look at what equation it does. An end up linear is going to perform this function here on the inputs. And it's going to upscale it to five features. Now, why would we do that? Well, the rule of thumb here, because this is denoted as a hidden unit, or how many hidden neurons there are. The rule of thumb is that the more hidden features there are, the more opportunity our model has to learn patterns in the data. So to begin with, it only has two numbers to learn patterns on, but at when we upscale it to five, it has five numbers to learn patterns on. Now, you might think, why don't we just go straight to like 10,000 or something? But there is like an upper limit here to sort of where the benefits start to trail off. We're just using five because it keeps it nice and simple. And then the in features of the next layer is five, so that these two line up. We're going to map this out visually in a moment, but let's keep coding. We've got in features two for X. And now this is the output layer. So takes in five features from previous layer and outputs a single feature. And now this is same shape. Same shape as why. So what is our next step? We want to define a Ford method, a Ford computation of Ford pass. So the Ford method is going to define the Ford computation. And as an input, it's going to take X, which is some form of data. And now here's where we can use layer one and layer two. So now let's just go return. Or we'll put a note here of what we're doing. Three, we're going to go define a Ford method that outlines the Ford pass. So Ford, and we're going to return. And here's some notation we haven't quite seen yet. And then we're going to go self layer two. And inside the brackets we'll have self layer one inside those brackets. We're going to have X. So the way this goes is X goes into layer one. And then the output of layer one goes into layer two. So whatever data we have, so our training data, X train goes into layer one performs the linear calculation here. And then it goes into layer two. And then layer two is going to output, go to the output. So X is the input, layer one computation layer two output. So we've done that. Now let's do step four, which is instantiate an instance of our model class. And send it to the target device. So this is our model class, circle model V zero. We're just going to create a model because it's the first model we've created up this section. Let's call it model zero. And we're going to go circle model V one. And then we're going to go to two. And we're going to pass in device, because that's our target device. Let's now have a look at model zero. And then Oh, typo. Yeah, classic. What did we get wrong here? Oh, did we not pass in self self? Oh, there we go. Little typo classic. But the beautiful thing about creating a class here is that we could put this into a Python file, such as model dot pi. And then we wouldn't necessarily have to rewrite this all the time, we could just call it. And so let's just check what the vice it's on. So target device is CUDA, because we've got a GPU, thank you, Google Colab. And then if we wanted to, let's go next model zero dot parameters, we'll call the parameters, and then we'll go device. CUDA beautiful. So that means our models parameters are on the CUDA device. Now we've covered enough code in here for this video. So if you want to understand it a little bit more, go back through it. But we're going to come back in the next video and make it a little bit more visual. So I'll see you there. Welcome back. In the last video, we did something very, very exciting. We created our first multi layer neural network. But right now, this is just code on a page. But truly, this is what the majority of building machine learning models in PyTorch is going to look like. You're going to create some layers, or a simple or as complex as you like. And then you're going to use those layers in some form of Ford computation to create the forward pass. So let's make this a little bit more visual. If we go over to the TensorFlow playground, and now TensorFlow is another deep learning framework similar to PyTorch, it just allows you to write code such as this, to build neural networks, fit them to some sort of data to find patterns and data, and then use those machine learning models in your applications. But let's create this. Oh, by the way, this is playground.tensorFlow.org. This is a neural network that we can train in the browser if we really wanted to. So that's pretty darn cool. But we've got a data set here, which is kind of similar to the data set that we're working with. We have a look at our circles one. Let's just say it's close enough. It's circular. That's what we're after. But if we increase this, we've got five neurons now. We've got two features here, X1 and X2. Where is this reminding you of what's happening? There's a lot of things going on here that we haven't covered yet, but don't worry too much. We're just focused on this neural network here. So we've got some features as the input. We've got five hidden units. This is exactly what's going on with the model that we just built. We pass in X1 and X2, our values. So if we go back to our data set, these are X1 and X2. We pass those in. So we've got two input features. And then we pass them to a hidden layer, a single hidden layer, with five neurons. What have we just built? If we come down into here to our model, we've got in features two, out features five. And then that feeds into another layer, which has in features five and out features one. So this is the exact same model that we've built here. Now, if we just turn this back to linear activation, because we're sticking with linear for now, we'll have a look at different forms of activation functions later on. And maybe we put the learning rate, we've seen the learning rate to 0.01. We've got epochs here, got classification. And we're going to try and fit this neural network to this data. Let's see what happens. Oh, the test loss, it's sitting about halfway 0.5. So about 50% loss. So if we only have two classes and we've got a loss of 50%, what does that mean? Well, the perfect loss was zero. And the worst loss was one. Then we just divide one by two and get 50%. But we've only got two classes. So that means if our model was just randomly guessing, it would get a loss of about 0.5, because you could just randomly guess whatever data point belongs to blue or orange in this case. So in a binary classification problem, if you have the same number of samples in each class, in this case, blue dots and orange dots, randomly guessing will get you about 50%. Just like tossing a coin, toss a coin 100 times and you get about 50 50 might be a little bit different, but it's around about that over the long term. So we've just fit for 3000 epochs. And we're still not getting any better loss. Hmm. I wonder if that's going to be the case for our neural network. And so to draw this in a different way, I'm going to come to a little tool called fig jam, which is just a whiteboard that we can put shapes on and it's based on the browser. So this is going to be nothing fancy. It's going to be a simple diagram. Say this is our input. And I'm going to make this green because my favorite color is green. And then we're going to have, let's make some different colored dots. I want a blue dot here. So this can be dot one, and dot two, I'll put another dot here. I'll zoom out a little so we have a bit more space. Well, maybe that was too much. 50% looks all right. So let me just move this around, move these up a little. So we're building a neural network here. This is exactly what we just built. And so we'll go here. Well, maybe we'll put this as input X one. So this will make a little bit more sense. And then we'll maybe we can copy this. Now this is X two. And then we have some form of output. Let's make this one. And we're going to color this orange. So output. Right. So you can imagine how we got connected dots here. They will connect these. So our inputs are going to go through all of these. I wonder if I can draw here. Okay, this is going to be a little bit more complex, but that's all right. So this is what we've done. We've got two input features here. And if we wanted to keep drawing these, we could all of these input features are going to go through all of these hidden units that we have. I just drew the same arrow twice. That's okay. But this is what's happening in the forward computation method. It can be a little bit confusing for when we coded it out. Why is that? Well, from here, it looks like we've only got an input layer into a single hidden layer in the blue. And an output layer. But truly, this is the same exact shape. You get the point. And then all of these go to the output. But we're going to see this computationally later on. So whatever data set you're working with, you're going to have to manufacture some form of input layer. Now this may be you might have 10 of these if you have 10 features. Or four of them if you have four features. And then if you wanted to adjust these, well, you could increase the number of hidden units or the number of out features of a layer. What just has to match up is that the layer it's going into has to have a similar shape as the what's coming out of here. So just keep that in mind as you're going on. And in our case, we only have one output. So we have the output here, which is why. So this is a visual version. We've got the TensorFlow playground. You could play around with that. You can change this to increase. Maybe you want five hidden layers with five neurons in each. This is a fun way to explore. This is a challenge, actually, go to playground.tensorflow.org, replicate this network and see if it fits on this type of data. What do you think, will it? Well, we're going to have to find out in the next few videos. So I'm going to show you in the next video another way to create the network that we just created. This one here with even less code than what we've done before. I'll see you there. Welcome back. In the last video, what we discussed, well, actually, in the previous video to last, we coded up this neural network here, circle model V zero. By subclassing an end or module, we created two linear layers, which are capable of handling the shape of our data in features two because why we have two X features. Out features were upscaling the two features to five so that it gives our network more of a chance to learn. And then because we've upscaled it to five features, the next subsequent layer has to be able to handle five features as input. And then we have one output feature because that's the same shape as our Y here. Then we got a little bit visual by using the TensorFlow playground. Did you try out that challenge, make five in layers with five neurons? Did it work? And then we also got a little bit visual in Figma as well. This is just another way of visualizing different things. You might have to do this a fair few times when you first start with neural networks. But once you get a bit of practice, you can start to infer what's going on through just pure code. So now let's keep pushing forward. How about we replicate this with a simpler way? Because our network is quite simple, that means it only has two layers. That means we can use. Let's replicate the model above using nn.sequential. And I'm going to code this out. And then we can look up what nn.sequential is. But I think you'll be able to comprehend what's happening by just looking at it. So nn, which is torch.nn. We can do torch.nn, but we've already imported nn. We're going to call nn.sequential. And then we're going to go nn.linear. And what was the in features of our nn.linear? Well, it was two because we have two in features. And then we're going to replicate the same out features. Remember, we could customize this to whatever we want 10, 100, 128. I'm going to keep it at five, nice and simple. And then we go nn.linear. And the in features of this next layer is going to be five because the out features of the previous layer was five. And then finally, the out features here is going to be one because we want one y value to our two x features. And then I'm going to send that to the device. And then I'm going to have a look at model zero. So this is, of course, going to override our previous model zero. But have a look. The only thing different is that this is from the circle model V zero class. We subclassed an n dot module. And the only difference is the name here. This is just from sequential. And so can you see what's going on here? So as you might have guessed sequential, it implements most of this code for us behind the scenes. Because we've told it that it's going to be sequential, it's just going to go, hey, step the code through this layer, and then step the code through this layer. And outputs basically the same model, rather than us creating our own forward method, you might be thinking, Daniel, why don't you show us this earlier? That looks like such an easy way to create a neural network compared to this. Well, yes, you're 100% right. That is an easier way to create a neural network. However, the benefit of subclassing, and that's why I started from here, is that when you have more complex operations, such as things you'd like to construct in here, and a more complex forward pass, it's important to know how to build your own subclasses of nn dot module. But for simple straightforward stepping through each layer one by one, so this layer first, and then this layer, you can use nn dot sequential. In fact, we could move this code up into here. So we could do this self dot, we'll call this two linear layers equals nn dot sequential. And we could have layer one, we could go self, self dot layer one. And or actually, we'll just recode it, we'll go nn dot linear. So it's so it's the same code is what we've got below in features. If I could type that'll be great, n features equals two, out features equals five. And then we go nn dot linear. And then we go n features equals what equals five, because it has to line up out features equals one. And then we've got two linear layers. And then if we wanted to get rid of this, return to linear layers, and we'll pass it X remake it. There we go. Well, because we've created these as well, let's get rid of that. Beautiful. So that's the exact same model, but just using nn dot sequential. Now I'm going to get rid of this so that our code is not too verbose. That means a lot going on. But this is the flexibility of PyTorch. So just keep in mind that there's a fair few ways to make a model. The simplest is probably sequential. And then subclassing is this is a little bit more complicated than what we've got. But this can extend to handle lot more complex neural networks, which you'll likely have to be building later on. So let's keep pushing forward. Let's see what happens if we pass some data through here. So we'll just rerun this cell to make sure we've got our model zero instantiated. We'll make some predictions with the model. So of course, if we have a look at our model zero dot state deck, oh, this will be a good experiment. So look at this. So we have weight, a weight tensor, a bias tensor, a weight tensor, and a bias tensor. So this is for the first of the zeroth layer, these two here with the zero dot, and then the one dot weight is four, of course, the first index layer. Now have a look inside here. Now you see how out features is five. Well, that's why our bias parameter has five values here. And the same thing for this weight value here. And the weight value here, why is this have 10 samples? One, two, three, four, five, six, seven, eight, nine, 10, because two times five equals 10. So this is just with a simple two layer network, look at all the numbers that are going on behind the scenes. Imagine coding all of these by hand. Like there's something like 20 numbers or something here. Now we've only done two layers here. Now the beauty of this is that in the previous section, we created all of the weight and biases using an end dot parameter and random values. You'll notice that these are all random two. Again, if yours are different to mine, don't worry too much, because they're going to be started randomly and we haven't set a random seed. But the thing to note here is that PyTorch is creating all of these parameters for us behind the scenes. And now when we do back propagation and gradient descent, when we code our training loop, the optimizer is going to change all of these values ever so slightly to try and better fit or better represent the data so that we can split our two circles. And so you can imagine how verbose this could get if we had say 50 layers with 128 different features of each. So let's change this up, see what happens. Watch how quickly the numbers get out of hand. Look at that. We just changed one value and look how many parameters our model has. So you might be able to calculate that by hand, but I personally don't want to. So we're going to let PyTorch take care of a lot of that for us behind the scenes. So for now we're keeping it simple, but that's how we can crack our models open and have a look at what's going on. Now that was a little detour. It's time to make some predictions with random numbers. I just wanted to highlight the fact that our model is in fact instantiated with random numbers here. So the untrained threads model zero, we're going to pass in X test. And of course, we have to send the test data to the device. Otherwise, if it's on a different device, we'll get errors because PyTorch likes to make calculations on the same device. So we'll go print. Let's do a nice print statement of length of predictions. We're going to go length or then untrained threads, we'll pass that in there. And then we'll go, oh no, we need to squiggle. And then we'll go shape. Shape is going to be untrained spreads dot shape. So this is again, following the data explorer's motto of visualize, visualize, visualize. And sometimes print is one of the best ones to do so. So length of test samples, you might already know this, or we've already checked this together, haven't we? X test. And then we're going to get the shape, which is going to be X test dot shape. Wonderful. And then we're going to print. What's our little error here? Oh no, collabs tricking me. So let's go first 10 predictions. And we're going to go untrained threads. So how do you think these predictions will fare? They're doing it with random numbers. And what are we trying to predict again? Well, we're trying to predict whether a dot is a red dot or a blue dot or zero or one. And then we'll go first 10 labels is going to be, we'll get this on the next line. And we'll go Y test. Beautiful. So let's have a look at this untrained predictions. So we have length of predictions is 200. Length of test samples is 200. But the shapes are different. What's going on here? Y test. And let's have a look at X test. Oh, well, I better just have a look at Y test. Why don't we have a two there? Oh, I've done X test dot shape. Oh, let's test samples. That's okay. And then the predictions are one. Oh, yes. So Y test. Let's just check the first 10 X test. So a little bit of clarification needed here with your shapes. So maybe we'll get this over here because I like to do features first and then labels. What did we miss here? Oh, X test 10 and Y test. See, we're troubleshooting on the fly here. This is what you're going to do with a lot of your code. So there's our test values. There's the ideal labels. But our predictions, they don't look like our labels. What's going on here? We can see that they're on the CUDA device, which is good. We said that. We can see that they got gradient tracking. Oh, we didn't with touch. We didn't do inference mode here. That's a poor habit of us. Excuse me. Let's inference mode this. There we go. So you notice that the gradient tracking goes away there. And so our predictions are nowhere near what our test labels are. But also, they're not even in the same like ball park. Like these are whole numbers, one or zero. And these are all floats between one and zero. Hmm. So maybe rounding them. Will that do something? So where's our threads here? So we go torch dot round. What happens there? Oh, they're all zero. Well, our model is probably going to get about 50% accuracy. Why is that? Because all the predictions look like they're going to be zero. And they've only got two options, basically head or tails. So when we create our model and when we evaluate it, we want our predictions to be in the same format as our labels. But we're going to cover some steps that we can take to do that in a second. What's important to take away from this is that there's another way to replicate the model we've made above using nn dot sequential. We've just replicated the same model as what we've got here. And n dot sequential is a simpler way of creating a pytorch model. But it's limited because it literally just sequentially steps through each layer in order. Whereas in here, you can get as creative as you want with the forward computation. And then inside our model, pytorch has behind the scenes created us some weight and bias tensors for each of our layers with regards to the shapes that we've set. And so the handy thing about this is that if we got quite ridiculous with our layers, pytorch would still do the same thing behind the scenes, create a whole bunch of random numbers for us. And because our numbers are random, it looks like our model isn't making very good predictions. But we're going to fix this in the next few videos when we move on to fitting the model to the data and making a prediction. But before we do that, we need to pick up a loss function and an optimizer and build a training loop. So let's get on to these two things. Welcome back. So over the past few videos, we've been setting up a classification model to deal with our specific shape of data. Now recall, depending on the data set that you're working with will depend on what layers you use for now we're keeping it simple and n dot linear is one of the most simple layers in pytorch. We've got two input features, we're upscaling that to five output features. So we have five hidden units, and then we have one output feature. And that's in line with the shape of our data. So two features of x equals one number for y. So now let's continue on modeling with where we're up to. We have build or pick a model. So we've built a model. Now we need to pick a loss function and optimizer. We're getting good at this. So let's go here, set up loss function and optimizer. Now here comes the question. If we're working on classification previously, we used, let's go to the next one, and an dot L one loss for regression, which is MAE mean absolute error, just a heads up that won't necessarily work with a classification problem. So which loss function or optimizer should you use? So again, this is problem specific. But with a little bit of practice, you'll get used to using different ones. So for example, for regression, you might want, which is regressions predicting a number. And I know it can get fusing because it looks like we're predicting a number here, we are essentially predicting a number. But this relates to a class. So for regression, you might want MAE or MSE, which is mean absolute absolute error, or mean squared error. And for classification, you might want binary cross entropy or categorical cross entropy, which is sometimes just referred to as cross entropy. Now, where would you find these things out? Well, through the internet, of course. So you could go, what is binary cross entropy? I'm going to leave you this for your extra curriculum to read through this. We've got a fair few resources here. Understanding binary cross entropy slash log loss by Daniel Godoy. Oh, yes. Great first name, my friend. This is actually the article that I would recommend to if you want to learn what's going on behind the scenes through binary cross entropy. For now, there's a lot of math there. We're going to be writing code to implement this. So PyTorch has done this for us. Essentially, what does a loss function do? Let's remind ourselves. Go down here. As a reminder, the loss function measures how wrong your models' predictions are. So I also going to leave a reference here to I've got a little table here in the book version of this course. So 0.2 neural network classification with PyTorch set up loss function and optimizer. So we've got some example loss functions and optimizers here, such as stochastic gradient descent or SGD optimizer, atom optimizer is also very popular. So I've got problem type here, and then the PyTorch code that we can implement this with. We've got binary cross entropy loss. We've got cross entropy loss, mean absolute error, MAE, mean squared error, MSE. So you want to use these two for regression. There are other different loss functions you could use, but these are some of the most common. That's what I'm focusing on, the most common ones that are going to get you through a fair few problems. We've got binary classification, multi-class classification. What are we working with? We're working with binary classification. So we're going to look at torch.nn BCE, which stands for binary cross entropy, loss with logits. What the hell is a logit? And BCE loss. Now this is confusing. Then trust me, when I first started using PyTorch, I got a little bit confused about why they have two here, but we're going to explore that anyway. So what is a logit? So if you search what is a logit, you'll get this and you'll get statistics and you'll get the log odds formula. In fact, if you want to read more, I would highly encourage it. So you could go through all of this. We're going to practice writing code for it instead. Luckily PyTorch does this for us, but logit is kind of confusing in deep learning. So if we go what is a logit in deep learning, it kind of means a different thing. It's kind of just a name of what yeah, there we go. What is the word logits in TensorFlow? As I said, TensorFlow is another deep learning framework. So let's close this. What do we got? We've got a whole bunch of definitions here. Logits layer. Yeah. This is one of my favorites. In context of deep learning, the logits layer means the layer that feeds into the softmax. So softmax is a form of activation. We're going to see all of this later on because this is just words on a page right now. Softmax or other such normalization. So the output of the softmax are the probabilities for the classification task and its input is the logit's layer. Whoa, there's a lot going on here. So let's just take a step back and get into writing some code. And for optimizers, I'm just going to complete this. And for optimizers, two of the most common and useful are SGD and Adam. However, PyTorch has many built in options. And as you start to learn more about the world of machine learning, you'll find that if you go to torch.optim or torch.nn. So if we have.nn, what do we have in here? Loss functions. There we go. Beautiful. That's what we're after. L1 loss, which is MAE, MSC loss, cross entropy loss, CTC loss, all of these different types of loss here will depend on the problem you're working on. But I'm here to tell you that for regression and classification, two of the most common of these. See, this is that confusion again. BCE loss, BCE with logit's loss. What the hell is a logit? My goodness. Okay, that's enough. And Optim, these are different optimizers. We've got probably a dozen or so here. Algorithms. Add a delta, add a grad. Adam, this can be pretty full on when you first get started. But for now, just stick with SGD and the atom optimizer. They're two of the most common. Again, they may not perform the best on every single problem, but they will get you fairly far just knowing those. And then you'll pick up some of these extra ones as you go. But let's just get rid of all of, maybe we'll, so I'll put this in here, this link. So we'll create our loss function. For the loss function, we're going to use torch.nn.bce with logit's loss. This is exciting. For more on what binary cross entropy, which is BCE, a lot of abbreviations in machine learning and deep learning is check out this article. And then for a definition on what a logit is, we're going to see a logit in a second in deep learning. Because again, deep learning is one of those fields, a machine learning, which likes to be a bit rebellious, you know, likes to be a bit different from the pure mathematics type of fields and statistics in general. It's this beautiful gestaltism and for different optimizers, see torch dot opt in. But we've covered a few of these things before. And finally, I'm going to put up here, and then for some common choices of loss functions and optimizers. Now, don't worry too much. This is why I'm linking all of these extra resources. A lot of this is covered in the book. So as we just said, set up loss function, optimizer, we just talked about these things. But I mean, you can just go to this book website and reference it. Oh, we don't want that. We want this link. Come on, I knew you can't even copy and paste. How are you supposed to code? I know I've been promising code this whole time, so let's write some. So let's set up the loss function. What did we say it was? We're going to call it L O double S F N for loss function. And we're going to call B C E with logit's loss. So B C E with logit's loss. This has the sigmoid activation function built in. And we haven't covered what the sigmoid activation function is, but we are going to don't you worry about that built in. In fact, if you wanted to learn what the sigmoid activation function is, how could you find out sigmoid activation function? But we're going to see it in action. Activation functions in neural networks. This is the beautiful thing about machine learning. There's so much stuff out there. People have written some great articles. You've got formulas here. PyTorch has implemented that behind the scenes for us. So thank you, PyTorch. But if you recall, sigmoid activation function built in, where did we discuss the architecture of a classification network? What do we have here? Right back in the zeroth chapter of this little online book thing that we heard here. Binary classification. We have output activation. Oh, oh, look at that. So sigmoid torch dot sigmoid and pytorch. All right. And then for multi class classification, we need the softmax. Okay. Names on a page again, but this is just a reference table so we can keep coming back to. So let's just keep going with this. I just want to highlight the fact that nn dot BCE loss also exists. So this requires BCE loss equals requires inputs to have gone through the sigmoid activation function prior to input to BCE loss. And so let's look up the documentation. I'm going to comment that out because we're going to stick with using this one. Now, why would we stick with using this one? Let's check out the documentation, hey, torch dot nn. And I realized this video is all over the place, but we're going to step back through BCE loss with logits. Did I even say this right? With logits loss. So with I got the width around the wrong way. So let's check this out. So this loss combines a sigmoid layer with the BCE loss in one single class. So if we go back to the code, BCE loss is this. So if we combined an n dot sequential, and then we passed in an n dot sigmoid, and then we went and then dot BCE loss, we'd get something similar to this. But if we keep reading in the documentation, because that's just I just literally read that it combines sigmoid with BCE loss. But if we go back to the documentation, why do we want to use it? So this version is more numerically stable than using a plain sigmoid by a BCE loss, followed by a BCE loss. As by combining the operations into one layer, we take advantage of the log sum x trick for numerical stability, beautiful. So if we use this log function, loss function for our binary cross entropy, we get some numeric stability. Wonderful. So there's our loss function. We've got the sigmoid activation function built in. And so we're going to see the difference between them later on, like in the flesh, optimizer, we're going to choose, hmm, let's stick with SGD, hey, old faithful stochastic gradient descent. And we have to set the parameters here, the parameters parameter params equal to our model parameters would be like, hey, stochastic gradient descent, please update. If we get another code cell behind here, please update our model parameters model with respect to the loss, because we'd like our loss function to go down. So these two are going to work in tandem again, when we write our training loop, and we'll set our learning rate to 0.1. We'll see where that gets us. So that's what the optimizer is going to do. It's going to optimize all of these parameters for us, which is amazing. And the principal would be the same, even if there was 100 layers here, and 10,000, a million different parameters here. So we've got a loss function, we've got an optimizer. And how about we create an evaluation metric. So let's calculate accuracy at the same time. Because that's very helpful with classification problems is accuracy. Now, what is accuracy? Well, we could look up formula for accuracy. So true positive over true positive plus true negative times 100. Okay, let's see if we can implement something similar to that just using pure pytorch. Now, why would we want accuracy? Because the accuracy is out of 100 examples. What percentage does our model get right? So for example, if we had a coin toss, and we did 100 coin tosses in our model predicted heads 99 out of 100 times, and it was right every single time, it might have an accuracy of 99%, because it got one wrong. So 99 out of 100, it gets it right. So dev accuracy FN accuracy function, we're going to pass it y true. So remember, any type of evaluation function or loss function is comparing the predictions to the ground truth labels. So correct equals, this is going to see how many of our y true or y threads are correct. So torch equal stands for, hey, how many of these samples y true are equal to y pred? And then we're going to get the sum of that, and we need to get the item from that because we want it as a single value in Python. And then we're going to calculate the accuracy, ACC stands for accuracy, equals correct, divided by the length of samples that we have as input. And then we're going to times that by 100, and then return the accuracy. Wonderful. So we now have an accuracy function, we're going to see how all the three of these come into play when we write a training loop, which we might as we get started on the next few videos, hey, I'll see you there. Welcome back. In the last video, we discussed some different loss function options for our classification models. So we learned that if we're working with binary cross entropy or binary classification problems, we want to use binary cross entropy. And pie torch has two different times of binary cross entropy, except one is a bit more numerically stable. That's the BCE with logit's loss, because it has a sigmoid activation function built in. So that's straight from the pie to its documentation. And that for optimizer wise, we have a few different choices as well. So if we check out this section here on the pie torch book, we have a few different loss functions and optimizers for different problems and the pie torch code that we can implement. But the premise is still the same across the board of different problems. The loss function measures how wrong our model is. And the goal of the optimizer is to optimize the model parameters in such a way that the loss function goes down. And we also implemented our own accuracy function metric, which is going to evaluate our models predictions using accuracy as an evaluation metric, rather than just loss. So let's now work on training a model. So what should we do first? Well, do you remember the steps in a pie torch training loop? So to train our model, we're going to need to build a training loop. So if you watch the video on the pie torch, so if you can Google unofficial pie torch song, you should find my, there we go, the unofficial pie torch optimization loop song. We're not going to watch that. That's going to be a little tidbit for the steps that we're going to code out. But that's just a fun little jingle to remember these steps here. So if we go into the book section, this is number three train model, exactly where we're up to here. But we have pie torch training loop steps. Remember, for an epoch in a range, do the forward pass, calculate the loss, optimizer zero grand, loss backward, optimizer step, step, step. We keep singing this all day. You could keep reading those steps all day, but it's better to code them. But let's write this out. So forward pass to calculate the loss, three, optimizer zero grad, four. What do we do? Loss backward. So back propagation, I'll just write that up in here back propagation. We've linked to some extra resources. If you'd like to find out what's going on in back propagation, we're focused on code here, and then gradient descent. So optimizer step. So build a training loop with the following steps. However, I've kind of mentioned a few things that need to be taken care of before we talk about the forward pass. So we've talked about logits. We looked up what the hell is a logit. So if we go into this stack overflow answer, we saw machine learning, what is a logit? How about we see that? We need to do a few steps. So I'm going to write this down. Let's get a bit of clarity about us, Daniel. We're kind of all over the place at the moment, but that's all right. That's the exciting part of machine learning. So let's go from going from raw logits to prediction probabilities to prediction labels. That's what we want. Because to truly evaluate our model, we want to so let's write in here our model outputs going to be raw logit. So that's the definition of a logit in machine learning and deep learning. You might read some few other definitions, but for us, the raw outputs of our model, model zero are going to be referred to as logits. So then model zero, so whatever comes out of here are logits. So we can convert these logits into prediction probabilities by passing them to some kind of activation function, e.g. sigmoid for binary cross entropy and softmax for multi-class classification. I've got binary class e-fication. I have to sound it out every time I spell it for binary classification. So class e-fication. So we're going to see multi-class classification later on, but we want some prediction probabilities. We're going to see what they look like in a minute. So we want to go from logits to prediction probabilities to prediction labels. Then we can convert our model's prediction probabilities to prediction labels by either rounding them or taking the argmax. So round is for binary classification and argmax will be for the outputs of the softmax activation function, but let's see it in action first. So I've called the logits are the raw outputs of our model with no activation function. So view the first five outputs of the forward pass on the test data. So of course, our model is still instantiated with random values. So we're going to set up a variable here, y logits, and model zero, we're going to pass at the test data. So x test, not text, two device, because our model is currently on our CUDA device and we need our test data on the same device or target device. Remember, that's why we're writing device agnostic codes. So this would work regardless of whether there's a GPU active or not. Let's have a look at the logits. Oh, okay. Right now, we've got some positive values here. And we can see that they're on the CUDA device. And we can see that they're tracking gradients. Now, ideally, we would have run torch dot inference mode here, because we're making predictions. And the rule of thumb is whenever you make predictions with your model, you turn it into a vowel mode. We just have to remember to turn it back to train when we want to train and you run torch dot inference mode. So we get a very similar set up here. We just don't have the gradients being tracked anymore. Okay. So these are called logits. The logits are the raw outputs of our model, without being passed to any activation function. So an activation function is something a little separate from a layer. So if we come up here, we've used layer. So in the neural networks that we start to build and the ones that you'll subsequently build are comprised of layers and activation functions, we're going to make the concept of an activation function a little bit more clear later on. But for now, just treat it all as some form of mathematical operation. So if we were to pass data through this model, what is happening? Well, it's going through the linear layer. Now recall, we've seen this a few times now torch and then linear. If we pass data through a linear layer, it's applying the linear transformation on the incoming data. So it's performing this mathematical operation behind the scenes. So why the output equals the input x multiplied by a weight tensor a this could really be w which is transposed so that this is doing a dot product plus a bias term here. And then if we jump into our model state deck, we've got weight and we've got bias. So that's the formula that's happening in these two layers. It will be different depending on the layer that we choose. But for now, we're sticking with linear. And so that the raw output of our data going through our two layers, the logits is going to be this information here. However, it's not in the same format as our test data. And so if we want to make a comparison to how good our model is performing, we need apples to apples. So we need this in the same format as this, which is not of course. So we need to go to a next step. Let's use the sigmoid. So use the sigmoid activation function on our model logits. So why are we using sigmoid? Well, recall in a binary classification architecture, the output activation is the sigmoid function here. So now let's jump back into here. And we're going to create some predprobs. And what this stands for on our model logits to turn them into prediction probabilities, probabilities. So why predprobs equals torch sigmoid, why logits? And now let's have a look at why predprobs. What do we get from this? Oh, when we still get numbers on a page, goodness gracious me. But the important point now is that they've gone through the sigmoid activation function, which is now we can pass these to a torch dot round function. Let's have a look at this torch dot round. And what do we get? Predprobs. Oh, the same format as what we've got here. Now you might be asking like, why don't we just put torch dot round here? Well, that's a little, this step is required to, we can't just do it on the raw logits. We need to use the sigmoid activation function here to turn it into prediction probabilities. And now what is a prediction probability? Well, that's a value usually between 0 and 1 for how likely our model thinks it's a certain class. And in the case of binary cross entropy, these prediction probability values, let me just write this out in text. So for our prediction probability values, we need to perform a range style rounding on them. So this is a decision boundary. So this will make more sense when we go why predprobs, if it's equal to 0.5 or greater than 0.5, we set y equal to one. So y equal one. So class one, whatever that is, a red dot or a blue dot, and then why predprobs, if it is less than 0.5, we set y equal to zero. So this is class zero. You can also adjust this decision boundary. So say, if you wanted to increase this value, so anything over 0.7 is one. And below that is zero. But generally, most commonly, you'll find it split at 0.5. So let's keep going. Let's actually see this in action. So how about we recode this? So find the predicted probabilities. And so we want no, sorry, we want the predicted labels, that's what we want. So when we're evaluating our model, we want to convert the outputs of our model, the outputs of our model are here, the logits, the raw outputs of our model are logits. And then we can convert those logits to prediction probabilities using the sigmoid function on the logits. And then we want to find the predicted labels. So we go raw logits output of our model, prediction probabilities after passing them through an activation function, and then prediction labels. This is the steps we want to take with the outputs of our model. So find the predicted labels. Let's go in here a little bit different to our regression problem previously, but nothing we can't handle. Torch round, we're going to go y-pred-probs. So I like to name it y-pred-probs for prediction probabilities and y-preds for prediction labels. Now let's go in full if we wanted to. So y-pred labels equals torch dot round torch dot sigmoid. So sigmoid activation function for binary cross entropy and model zero x test dot two device. Truly this should be within inference mode code, but for now we'll just leave it like this to have a single example of what's going on here. Now I just need to count one, two, there we want. That's where we want the index. We just want it on five examples. So check for equality. And we want print torch equal. We're going to check y-pred's dot squeeze is equal to y-pred labels. So just we're doing the exact same thing. And we need squeeze here to get rid of the extra dimension that comes out. You can try doing this without squeeze. So get rid of extra dimension once again. We want y-pred's dot squeeze. Fair bit of code there, but this is what's happened here. We create y-pred's. So we turn the y-pred probes into y-pred's. And then we just do the full step over again. So we make predictions with our model, we get the raw logits. So this is logits to pred probes to pred labels. So the raw outputs of our model are logits. We turn the logits into prediction probabilities using torch sigmoid. And we turn the prediction probabilities into prediction labels using torch dot round. And we fulfill this criteria here. So everything above 0.5. This is what torch dot round does. Turns it into a 1. Everything below 0.5 turns it into a 0. The predictions right now are going to be quite terrible because our model is using random numbers. But y-pred's found with the steps above is the same as y-pred labels doing the more than one hit. Thanks to this check for equality using torch equal y-pred's dot squeeze. And we just do the squeeze to get rid of the extra dimensions. And we have out here some labels that look like our actual y-test labels. They're in the same format, but of course they're not the same values because this model is using random weights to make predictions. So we've done a fair few steps here, but I believe we are now in the right space to start building a training a test loop. So let's write that down here 3.2 building a training and testing loop. You might want to have a go at this yourself. So we've got all the steps that we need to do the forward pass. But the reason we've done this step here, the logits, then the pred probes and the pred labels, is because the inputs to our loss function up here, this requires, so BCE with logits loss, requires what? Well, we're going to see that in the next video, but I'd encourage you to give it a go at implementing these steps here. Remember the jingle for an epoch in a range, do the forward pass, calculate the loss, which is BC with logits loss, optimise a zero grad, which is this one here, last backward, optimise a step, step, step. Let's do that together in the next video. Welcome back. In the last few videos, we've been working through creating a model for a classification problem. And now we're up to training a model. And we've got some steps here, but we started off by discussing the concept of logits. Logits are the raw output of the model, whatever comes out of the forward functions of the layers in our model. And then we discussed how we can turn those logits into prediction probabilities using an activation function, such as sigmoid for binary classification, and softmax for multi class classification. We haven't seen softmax yet, but we're going to stick with sigmoid for now because we have binary classification data. And then we can convert that from prediction probabilities to prediction labels. Because remember, when we want to evaluate our model, we want to compare apples to apples. We want our models predictions to be in the same format as our test labels. And so I took a little break after the previous video. So my collab notebook has once again disconnected. So I'm just going to run all of the cells before here. It's going to reconnect up here. We should still have a GPU present. That's a good thing about Google collab is that if you change the runtime type to GPU, it'll save that wherever it saves the Google collab notebook, so that when you restart it, it should still have a GPU present. And how can we check that, of course, while we can type in device, we can run that cell. And we can also check Nvidia SMI. It'll tell us if we have an Nvidia GPU with CUDA enabled ready to go. So what's our device? CUDA. Wonderful. And Nvidia SMI. Excellent. I have a Tesla P100 GPU. Ready to go. So with that being said, let's start to write a training loop. Now we've done this before, and we've got the steps up here. Do the forward pass, calculate the loss. We've spent enough on this. So we're just going to start jumping into write code. There is a little tidbit in this one, though, but we'll conquer that when we get to it. So I'm going to set a manual seed, torch top manual seed. And I'm going to use my favorite number 42. This is just to ensure reproducibility, if possible. Now I also want you to be aware of there is also another form of random seed manual seed, which is a CUDA random seed. Do we have the PyTorch? Yeah, reproducibility. So torch dot CUDA dot manual seed dot seed. Hmm. There is a CUDA seed somewhere. Let's try and find out. CUDA. I think PyTorch have just had an upgrade to their documentation. Seed. Yeah, there we go. Okay. I knew it was there. So torch dot CUDA dot manual seed. So if we're using CUDA, we have a CUDA manual seed as well. So let's see what happens if we put that to watch that CUDA dot manual seed 42. We don't necessarily have to put these. It's just to try and get as reproducible as numbers as possible on your screen and my screen. Again, what is more important is not necessarily the numbers exactly being the same lining up between our screens. It's more so the direction of which way they're going. So let's set the number of epochs. We're going to train for 100 epochs. epochs equals 100. But again, as you might have guessed, the CUDA manual seed is for if you're doing operations on a CUDA device, which in our case, we are. Well, then perhaps we'd want them to be as reproducible as possible. So speaking of CUDA devices, let's put the data to the target device because we're working with or we're writing data agnostic code here. So I'm going to write x train y train equals x train two device, comma y train dot two device, that'll take care of the training data. And I'm going to do the same for the testing data equals x test two device. Because if we're going to run our model on the CUDA device, we want our data to be there too. And the way we're writing our code, our code is going to be device agnostic. Have I said that enough yet? So let's also build our training and evaluation loop. Because we've covered the steps in here before, we're going to start working a little bit faster through here. And don't worry, I think you're up to it. So for an epoch in a range of epochs, what do we do? We start with training. So let me just write this. Training model zero dot train. That's the model we're working with. We call the train, which is the default, but we're going to do that anyway. And as you might have guessed, the code that we're writing here is, you can functionize this. So we're going to do this later on. But just for now, the next couple of videos, the next module or two, we're going to keep writing out the training loop in full. So this is the part, the forward pass, where there's a little bit of a tidbit here compared to what we've done previously. And that is because we're outputting raw logits here, if we just pass our data straight to the model. So model zero x train. And we're going to squeeze them here to get rid of an extra dimension. You can try to see what the output sizes look like without squeeze. But we're just going to call squeeze here. Remember, squeeze removes an extra one dimension from a tensor. And then to convert it into prediction labels, we go torch dot round. And torch dot sigmoid, because torch dot sigmoid is an activation function, which is going to convert logits into what convert the logits into prediction probabilities. So why logits? And I'm just going to put a note here. So this is going to go turn logits into pred probes into pred labels. So we've done the forward pass. So that's a little tidbit there. We could have done all of this in one step, but I'll show you why we broke this apart. So now we're going to calculate loss slash accuracy. We don't necessarily have to calculate the accuracy. But we did make an accuracy function up here. So that we can calculate the accuracy during training, we could just stick with only calculating the loss. But sometimes it's cool to visualize different metrics loss plus a few others while your model is training. So let's write some code to do that here. So we'll start off by going loss equals loss f n and y logits. Ah, here's the difference of what we've done before. Previously in the notebook zero one, up to zero two now, we passed in the prediction right here. But because what's our loss function? Let's have a look at our loss function. Let's just call that see what it returns. BCE with logits loss. So the BCE with logits expects logits as input. So as you might have guessed, loss function without logits. If we had nn dot BCE loss, notice how we haven't got with logits. And then we called loss f n, f n stands for function, by the way, without logits. What do we get? So BCE loss. So this loss expects prediction probabilities as input. So let's write some code to differentiate between these two. As I said, we're going to be sticking with this one. Why is that because if we look up torch BCE with logits loss, the documentation states that it's more numerically stable. So this loss combines a sigmoid layer and the BCE loss into one single class, and is more numerically stable. So let's come back here, we'll keep writing some code. And the accuracy is going to be accuracy f n. So our accuracy function, there's a little bit of a difference here is why true equals y train for the training data. So this will be the training accuracy. And then we have y pred equals y pred. So this is our own custom accuracy function that we wrote ourselves. This is a testament to the Pythonic nature of PyTorch as well. We've just got a pure Python function that we've slotted into our training loop, which is essentially what the loss function is behind the scenes. Now, let's write here, and then dot BCE with logits loss expects raw logits. So the raw output of our model as input. Now, what if we were using a BCE loss on its own here? Well, let's just write some code for that. So let's call loss function. And then we want to pass in y pred. Or we can just go why or torch sigmoid. So why would we pass in torch sigmoid on the logits here? Because remember, calling torch dot sigmoid on our logits turns our logits into prediction probabilities. And then we would pass in y train here. So if this was BCE loss expects this expects prediction probabilities as input. So does that make sense? That's the difference between with logits. So our loss function requires logits as input. Whereas if we just did straight up BCE loss, we need to call torch dot sigmoid on the logits because it expects prediction probabilities as input. Now, I'm going to comment that out because our loss function is BCE with logits loss. But just keep that in mind. For some reason, you stumble across some pytorch code that's using BCE loss, not BCE with logits loss. And you find that torch dot sigmoid is calling here, or you come across some errors, because your inputs to your loss function are not what it expects. So with that being said, we can keep going with our other steps. So we're up to optimizer zero grad. So optimizer dot zero grad. Oh, this is step three, by the way. And what's after this? Once we've zero grad the optimizer, we do number four, which is loss backward. We can go last backward. And then we go what's next? Optimizer step step step. So optimizer dot step. And I'm singing the unofficial pytorch optimization loop song there. This is back propagation. Calculate the gradients with respect to all of the parameters in the model. And the optimizer step is update the parameters to reduce the gradients. So gradient descent, hence the descent. Now, if we want to do testing, well, we know what to do here now, we go model zero, what do we do? We call model dot of al when we're testing. And if we're making predictions, that's what we do when we test, we make predictions on the test data set, using the patterns that our model has learned on the training data set, we turn on inference mode, because we're doing inference, we want to do the forward pass. And of course, we're going to compute the test logits, because logits are the raw output of our model with no modifications. X test dot squeeze, we're going to get rid of an extra one dimension there. Then we create the test pred, which is we have to do a similar calculation to what we've done here for the test pred, which is torch dot round. For our binary classification, we want prediction probabilities, which we're going to create by calling the sigmoid function on the test logits, prediction probabilities that are 0.5 or above to go to one, and prediction probabilities under 0.5 to go to level zero. So two is calculate the test loss, test loss slash accuracy. How would we do this? Well, just if we've done before, and we're going to go loss FN test logits, because our loss function, we're using what we're using BCE with logits loss, expects logits as input, where do we find that out in the documentation, of course, then we come back here, test logits, we're going to compare that to the Y test labels. And then for the test accuracy, what are we going to do? We're going to call accuracy FN on Y true equals Y test, and Y pred equals test pred. Now you might be thinking, why did I switch up the order here for these? Oh, and by the way, this is important to know with logits loss. So with these loss functions, the order here matters of which way you put in your parameters. So predictions come first, and then true labels for our loss function. You might be wondering why I've done it the reverse for our accuracy function, Y true and Y pred. That's just because I like to be confusing. Well, not really. It's because if we go to scikit-learn, I base a lot of my structured code of how scikit-learn structures things. The scikit-learn metrics accuracy score goes Y true Y pred. So I base it off that order, because the scikit-learn metrics package is very helpful. So I've based our metric evaluation metric function off this one. Whereas PyTorch's loss function does it in the reverse order, and it's important to get these in the right order. Exactly why they do it in that order. I couldn't tell you why. And we've got one final step, which is to print out what's happening. So how about we go, we're doing a lot of epochs here, 100 epochs. So we'll divide the epoch by 10 to print out every epoch or every 10th epoch, sorry. And we have a couple of different metrics that we can print out this time. So we're going to print out the epoch number epoch. And then we're going to print out the loss. So loss, how many decimal points? We'll go point five here. This is going to be the training loss. We'll also do the accuracy, which will be the training accuracy. We could write trainiac here for our variable to be a little bit, make them a little bit more understandable. And then we go here, but we're just going to leave it as loss and accuracy for now, because we've got test loss over here, test loss. And we're going to do the same five decimal points here. And then we're going to go test accuracy as well. Test act dot, we'll go to for the accuracy. And because it's accuracy, we want a percentage. This is the percent out of 100 guesses. What's the percentage that our model gets right on the training data and the testing data, as long as we've coded all the functions correctly. Now, we've got a fair few steps here. My challenge to you is to run this. And if there are any errors, try to fix them. No doubt there's probably one or two or maybe more that we're going to have to fix in the next video. But speaking of next videos, I'll see you there. Let's train our first classification model. Well, this is very exciting. I'll see you soon. Welcome back. In the last video, we wrote a mammoth amount of code, but nothing that we can't handle. We've been through a lot of these steps. We did have to talk about a few tidbits between using different loss functions, namely the BCE loss, which is binary cross entropy loss, and the BCE with logit's loss. We discussed that the BCE loss in PyTorch expects prediction probabilities as input. So we have to convert our model's logits. Logits are the raw output of the model to prediction probabilities using the torch dot sigmoid activation function. And if we're using BCE with logits loss, it expects raw logits as input as sort of the name hints at. And so we just pass it straight away the raw logits. Whereas our own custom accuracy function compares labels to labels. And that's kind of what we've been stepping through over the last few videos, is going from logits to predprobs to pred labels, because that's the ideal output of our model is some kind of label that we as humans can interpret. And so let's keep pushing forward. You may have already tried to run this training loop. I don't know if it works. We wrote all this code to get them in the last video. And it's probably an error somewhere. So you ready? We're going to train our first classification model together for 100 epochs. If it all goes to plan in three, two, one, let's run. Oh my gosh, it actually worked the first time. I promise you, I didn't change anything in here from the last video. So let's inspect what's going on. It trains pretty fast. Why? Well, because we're using a GPU, so it's going to be accelerated as much as it can anyway. And our data set is quite small. And our network is quite small. So you won't always get networks training this fast. They did 100 epochs in like a second. So the loss. Oh, 0.69973. It doesn't go down very much. The accuracy even starts high and then goes down. What's going on here? Our model doesn't seem to be learning anything. So what would an ideal accuracy be? An ideal accuracy is 100. And what's an ideal loss value? Well, zero, because lower is better for loss. Hmm, this is confusing. And now if we go, have a look at our blue and red dots. Where's our data? So I reckon, do we still have a data frame here? How many samples do we have of each? Let's inspect. Let's do some data analysis. Where do we create a data frame here? Now, circles, do we still have this instantiated circles dot label dot? We're going to call on pandas here, value counts. Is this going to output how many of each? Okay. Wow, we've got 500 of class one and 500 of class zero. So we have 500 red dots and blue dots, which means we have a balanced data set. So if we're getting, we're basically trying to predict heads or tails here. So if we're getting an accuracy of under 50%, or about 50%, if you rounded it up. Our model is basically doing as well as guessing. Well, what gives? Well, I think we should get visual with this. So let's make some predictions with our model, because these are just numbers on the page. It's hard to interpret what's going on. But our intuition now is because we have 500 samples of each, or in the case of the training data set, we have 400 of each because we have 800 samples in the training data set. And we have in the testing data set, we have 200 total samples. So we have 100 of each. We're basically doing a coin flip here. Our model is as good as guessing. So turn to investigate why our model is not learning. And one of the ways we can do that is by visualizing our predictions. So let's write down here from the metrics. It looks like our model isn't learning anything. So to inspect it, let's make some predictions and make them visual. And we're right down here. In other words, visualize, visualize, visualize. All right. So we've trained a model. We've at least got the structure for the training code here. But this is the right training code. We've written this code before. So you know that this set up for training code does allow a model to train. So there must be something wrong with either how we've built our model, the data set. But let's keep going and investigate together. So to do so, I've got a function that I've pre-built earlier. Did I mention that we're learning side by side of a machine learning cooking show? So this is an ingredient I prepared earlier, a part of a dish. So to do so, we're going to import a function called plot decision, or maybe I'll turn this into code, plot decision boundary. Welcome to the cooking show, cooking with machine learning. What model will we cook up today? So if we go to pytorch deep learning, well, it's already over here, but this is the home repo for the course, the link for this will be scattered everywhere. But there's a little function here called helper functions dot py, which I'm going to fill up with helper functions throughout the course. And this is the one I'm talking about here, plot decision boundary. Now we could just copy this into our notebook, or I'm going to write some code to import this programmatically, so we can use other functions from in here. Here's our plot predictions function that we made in the last section, zero one, but this plot decision boundary is a function that I got inspired by to create from madewithml.com. Now this is another resource, a little bit of an aside, I highly recommend going through this by Goku Mohandas. It gives you the foundations of neural networks and also ml ops, which is a field, which is based on getting your neural networks and machine learning models into applications that other people can use. So I can't recommend this resource enough. So please, please, please check that out if you want another resource for machine learning, but this is where this helper function came from. So thank you, Goku Mohandas. I've made a little bit of modifications for this course, but not too many. So we could either copy that, paste it in here, or we could write some code to import it for us magically, or using the power of the internet, right, because that's what we are. We're programmers, we're machine learning engineers, we're data scientists. So from pathlib, so the request module in Python is a module that allows you to make requests, a request is like going to a website, hey, I'd like to get this code from you, or this information from you, can you please send it to me? So that's what that allows us to do, and pathlib, we've seen pathlib before, but it allows us to create file parts. Because why? Well, we want to save this helper function dot pi script to our Google collab files. And so we can do this with a little bit of code. So download helper functions from learn pytorch repo. If it's not already downloaded. So let's see how we can do that. So we're going to write some if else code to check to see if the path of helper functions dot pi already exist, we don't want to download it again. So at the moment, it doesn't exist. So this if statement is going to return false. So let's just print out what it does if it returns true helper functions dot pi already exists. We might we could even probably do a try and accept looping about if else will help us out for now. So if it exists else, print downloading helper functions dot pi. So ours doesn't exist. So it's going to make a request or let's set up our request request dot get. And here's where we can put in a URL. But we need the raw version of it. So this is the raw version. If we go back, this is just pytorch deep learning the repo for this course slash helper functions. If I click raw, I'm going to copy that. Oh, don't want to go in there want to go into request get type that in this has to be in a string format. So we get the raw URL. And then we're going to go with open, we're going to open a file called helper functions dot pi. And we're going to set the context to be right binary, which is wb as file F is a common short version of writing file. Because we're going to call file dot write, and then request dot content. So this code is basically saying hey requests, get the information that's at this link here, which is of course, all of this code here, which is a Python script. And then we're going to create a file called helper functions dot pi, which gives us write permissions. We're going to name it F, which is short for file. And then we're going to call on it file dot write the content of the request. So instead of talking through it, how about we see it in action? We'll know if it works if we can from helper functions import plot predictions, we're going to use plot predictions later on, as well as plot decision boundary. So plot predictions we wrote in the last section. Wonderful. I'm going to write here, downloading helper functions dot pi did at work. We have helper functions dot pi. Look at that, we've done it programmatically. Can we view this in Google column? Oh my goodness, yes we can. And look at that. So this may evolve by the time you do the course, but these are just some general helper functions rather than writing all of this out. If you would like to know what's going on in plot decision boundary, I encourage you to read through here. And what's going on, you can step by step at yourself. There is nothing here that you can't tackle yourself. It's all just Python code, no secrets just Python code. We've got we're making predictions with a PyTorch model. And then we're testing for multi class or binary. So we're going to get out of that. But now let's see the ultimate test is if the plot decision boundary function works. So again, we could discuss plot decision boundary of the model. We could discuss what it does behind the scenes to the cows come home. But we're going to see it in real life here. I like to get visual. So fig size 12, six, we're going to create a plot here, because we are adhering to the data explorer's motto of visualize visualize visualize. And we want to subplot because we're going to compare our training and test sets here, train. And then we're going to go PLT, or actually we'll plot the first one, plot decision boundary. Now, because we're doing a training plot here, we're going to pass in model zero and X train and Y train. Now, this is the order that the parameters go in. If we press command shift space, I believe Google collab, if it's working with me, we'll put up a doc string. There we go, plot decision boundary. Look at the inputs that it takes model, which is torch and end up module. And we've got X, which is our X value, which is a torch tensor, and Y, which is our torch tensor value here. So that's for the training data. Now, let's do the same for the testing data, plot dot subplot. This is going to be one, two, two for the index. This is just number of rows of the plot, number of columns. And this is the index. So this plot will appear on the first slot. We're going to see this anyway. Anything below this code will appear on the second slot, PLT dot title. And we're going to call this one test. Then we're going to call plot decision boundary. If this works, this is going to be some serious magic. I love visualization functions in machine learning. Okay, you ready? Three, two, one, let's check it out. How's our model doing? Oh, look at that. Oh, now it's clear. So behind the scenes, this is the plots that plot decision boundary is making. Of course, this is the training data. This is the testing data, not as many dot points here, but the same sort of line of what's going on. So this is the line that our model is trying to draw through the data. No wonder it's getting about 50% accuracy and the loss isn't going down. It's just trying to split the data straight through the middle. It's drawing a straight line. But our data is circular. Why do you think it's drawing a straight line? Well, do you think it has anything to do with the fact that our model is just made with using pure linear layers? Let's go back to our model. What's it comprised on? Just a couple of linear layers. What's a linear line? If we look up linear line, is this going to work with me? I don't actually think it might. There we go. Linear line, all straight lines. So I want you to have a think about this, even if you're completely new to deep learning, can we? You can answer this question. Can we ever separate this circular data with straight lines? I mean, maybe we could if we drew straight lines here, but then trying to curve them around. But there's an easier way. We're going to see that later on. For now, how about we try to improve our model? So the model that we built, we've got 100 epochs. I wonder if our model will improve if we trained it for longer. So that's a little bit of a challenge before the next video. See if you can train the model for 1000 epochs. Does that improve the results here? And if it doesn't improve the results here, have a think about why that might be. I'll see you in the next video. Welcome back. In the last video, we wrote some code to download a series of helper functions from our helper functions dot pi. And later on, you'll see why this is quite standard practice as you write more and more code is to write some code, store them somewhere such as a Python script like this. And then instead of us rewriting everything that we have and helper functions, we just import them and then use them later on. This is similar to what we've been doing with PyTorch. PyTorch is essentially just a collection of Python scripts that we're using to build neural networks. Well, there's a lot more than what we've just done. I mean, we've got one here, but PyTorch is a collection of probably hundreds of different Python scripts. But that's beside the point. We're trying to train a model here to separate blue and red dots. But our current model is only drawing straight lines. And I got you to have a think about whether our straight line model, our linear model could ever separate this data. Maybe it could. And I issued the challenge to see if it could if you trained for 1000 epochs. So did it improve at anything? Is the accuracy any higher? Well, speaking of training for more epochs, we're up to section number five, improving a model. This is from a model perspective. So now let's discuss some ways. If you were getting results after you train a machine learning model or a deep learning model, whatever kind of model you're working with, and you weren't happy with those results. So how could you go about improving them? So this is going to be a little bit of an overview of what we're going to get into. So one way is to add more layers. So give the model more chances to learn about patterns in the data. Why would that help? Because if our model currently has two layers, model zero dot state dinked. Well, we've got however many numbers here, 20 or so. So this is zero flayer. This is the first layer. If we had 10 of these, well, we'd have 10 times the amount of parameters to try and learn the patterns in this data, a representation of this data. Another way is to add more hidden units. So what I mean by that is we created this model here, and each of these layers has five hidden units. The first one outputs, out features equals five, and this one takes in features equals five. So we could go from, go from five hidden units to 10 hidden units. The same principle as above applies here is that the more parameters our model has to represent our data, the potentially now I say potentially here because some of these things might not necessarily work. So our data sets quite simple. So maybe if we added too many layers, our models trying to learn things that are too complex, it's trying to adjust too many numbers for the data set that we have the same thing for more hidden units. What other options do we have? Well, we could fit for longer, give the model more of a chance to learn because every epoch is one pass through the data. So maybe 100 times looking at this data set wasn't enough. So maybe you could fit for 1000 times, which was the challenge. Then there's change in the activation functions, which we're using sigmoid at the moment, which is generally the activation function you use for a binary classification problem. But there are also activation functions you can put within your model. Hmm, there's a little hint that we'll get to that later. Then there's change the learning rate. So the learning rate is the amount the optimizer will adjust these every epoch. And if it's too small, our model might not learn anything because it's taking forever to change these numbers. But if also on the other side of things, if the learning rate is too high, these updates might be too large. And our model might just explode. There's an actual problem in machine learning called exploding gradient problem, where the numbers just get too large. On the other side, there's also a vanishing gradients problem, where the gradients just go basically to zero too quickly. And then there's also change the loss function. But I feel like for now, sigmoid and binary cross entropy, pretty good, pretty standard. So we're going to have a look at some options here, add more layers and fit for longer, maybe changing the learning rate. But let's just add a little bit of color to what we've been talking about. Right now, we've fit the model to the data and made a prediction. I'm just going to step through this. Where are we up to? We've done this, we've done this, we've done these two, we've built a training loop, we've fit the model to the data, made a prediction, we've evaluated our model visually, and we're not happy with that. So we're up to number five, we're going to improve through experimentation. We don't need to use TensorBoard just yet, we're going to talk about this as our high level. TensorBoard is a tool or a utility from PyTorch, which helps you to monitor experiments. We'll see that later on. And then we'll get to this, we won't save our model until we've got one that we're happy with. And so if we look at what we've just talked about improving a model from a model's perspective, let's talk about the things we've talked about with some color this time. So say we've got a model here, this isn't the exact model that we're working with, but it's similar structure. We've got one, two, three, four layers, we've got a loss function BC with Logit's loss, we've got an optimizer, optimizer stochastic gradient descent, and if we did write some training code, this is 10 epochs. And then the testing code here, I've just cut it out because it wouldn't fit on the slide. Then if we wanted to go to a larger model, let's add some color here so we can highlight what's happening, adding layers. Okay, so this one's got one, two, three, four, five, six layers. And we've got another color here, which is I'd say this is like a little bit of a greeny blue increase the number of hidden units. Okay, so the hidden units are these features here. We've gone from 100 to 128 to 128. Remember, the out features of a previous layer have to line up with the in features of a next layer. Then we've gone to 256. Wow. So remember how I said multiples of eight are pretty good generally in deep learning? Well, this is where these numbers come from. And then what else do we have change slash add activation functions? We haven't seen this before and end up relu. If you want to jump ahead and have a look at what and end up relu is, how would you find out about it? Well, I just Google and end up relu. But we're going to have a look at what this is later on. We can see here that this one's got one, but this larger model has some relu's scattered between the linear layers. Hmm, maybe that's a hint. If we combine a linear layer with a relu, what's a relu layer? I'm not going to spoil this. We're going to find out later on change the optimization function. Okay. So we've got SGD. Do you recall how I said Adam is another popular one that works fairly well across a lot of problems as well. So Adam might be a better option for us here. The learning rate as well. So maybe this learning rate was a little too high. And so we've divided it by 10. And then finally, fitting for longer. So instead of 10 epochs, we've gone to 100. So how about we try to implement some of these with our own model to see if it improves what we've got going on here? Because frankly, like, this isn't satisfactory. We're trying to build a neural network here. Neural networks are supposed to be these models that can learn almost anything. And we can't even separate some blue dots from some red dots. So in the next video, how about we run through writing some code to do some of these steps here? In fact, if you want to try yourself, I'd highly encourage that. So I'd start with trying to add some more layers and add some more hitting units and fitting for longer. You can keep all of the other settings the same for now. But I'll see you in the next video. Welcome back. In the last video, we discussed some options to improve our model from a model perspective. And namely, we're trying to improve it so that the predictions are better, so that the patterns it learns better represent the data. So we can separate blue dots from red dots. And you might be wondering why we said from a model perspective here. So let me just write these down. These options are all from a models perspective, because they deal directly with the model, rather than the data. So there's another way to improve a models results is if the model was sound already, in machine learning and deep learning, you may be aware that generally if you have more data samples, the model learns or gets better results because it has more opportunity to learn. There's a few other ways to improve a model from a data perspective, but we're going to focus on improving a model from a models perspective. So, and because these options are all values we as machine learning engineers and data scientists can change, they are referred to as hyper parameters. So a little bit of an important distinction here. Parameters are the numbers within a model. The parameters here, like these values, the weights and biases are parameters, are the values a model updates by itself. Hyper parameters are what we as machine learning engineers and data scientists, such as adding more layers, more hidden units, fitting for longer number of epochs, activation functions, learning rate, loss functions are hyper parameters because they're values that we can change. So let's change some of the hyper parameters of our model. So we'll create circle model v1. We're going to import from nn.module as well. We could write this model using nn.sequential, but we're going to subclass nn.module for practice. Why would we use nn.sequential? Well, because as you'll see, our model is not too complicated, but we subclass nn.module. In fact, nn.sequential. So if we write here, nn.sequential is also a version of nn.module. But we subclass nn.module here for one for practice and for later on, if we wanted to, or if you wanted to make more complex models, you're going to see a subclass of nn.module a lot in the wild. So the first change we're going to update is the number of hidden units. So out features, I might write this down before we do it. Let's try and improve our model by adding more hidden units. So this will go from five and we'll increase it to 10. And we want to increase the number of layers. So we want to go from two to three. We'll add an extra layer and then increase the number of epochs. So we're going to go from 100 to 1,000. Now, what can you, we're going to put on our scientist hats for a second. What would be the problem with the way we're running this experiment? If we're doing all three things in one hit, why might that be problematic? Well, because we might not know which one offered the improvement if there is any improvement or degradation. So just to keep in mind going forward, I'm just doing this as an example of how we can change all of these. But generally, when you're doing machine learning experiments, you'd only like to change one value at a time and track the results. So that's called experiment tracking and machine learning. We're going to have a look at experiment tracking a little later on in the course, but just keep that in mind. A scientist likes to change one variable of what's going on so that they can control what's happening. But we're going to create this next layer here layer two. And of course, it takes the same number of out features as in features as the previous layer. This is two because why our X train has. Let's look at just the first five samples has two features. So now we're going to create self layer three, which equals an n dot linear. The in features here is going to be 10. Why? Because the layer above has out features equals 10. So what we've changed here so far is we've got hidden units previously in the zero of this model was five. And now we've got a third layout, which previously before was two. So these are two of our main changes here. And out features equals one, because why? Let's have a look at speaking of why. Our why is just one number. So remember the shapes, the input and output shapes of a model is one of the most important things in deep learning. We're going to see different values for the shapes later on. But because we're working with this data set, we're focused on two in features and one out feature. So now that we've got our layers prepared, what's next? Well, we have to override the forward method, because every subclass of an n dot module has to implement a forward method. So what are we going to do here? Well, we could, let me just show you one option. We could go z, which would be z for logits. Logits is actually represented by z, fun fact. But you could actually put any variable here. So this could be x one, or you could reset x if you wanted to. I just look putting a different one because it's a little less confusing for me. And then we could go update z by going self layer two. And then the, because z above is the output of layer one, it now goes into here. And then if we go z, again, equals self layer three, what's this going to take? It's going to take z from above. So this is saying, hey, give me x, put it through layer one, assign it to z. And then create a new variable z or override z with self layer two with z from before as the input. And then we've got z again, the output of layer two has the input for layer three. And then we could return z. So that's just passing our data through each one of these layers here. But a way that you can leverage speedups in PyTorch is to call them all at once. So layer three, and we're going to put self dot layer two. And this is generally how I'm going to write them. But it also behind the scenes, because it's performing all the operations at once, you leverage whatever speed ups you can get. Oh, this should be layer one. So it goes in order here. So what's happening? Well, it's computing the inside of the brackets first. So layer one, x is going through layer one. And then the output of x into layer one is going into layer two. And then the same again, for layer three. So this way, this way of writing operations, leverages, speed ups, where possible behind the scenes. And so we've done our Ford method there. We're just passing our data through layers with an extra hidden units, and an extra layer overall. So now let's create an instance of circle model v one, which we're going to set to model one. And we're going to write circle model v one. And we're going to send it to the target device, because we like writing device agnostic code. And then we're going to check out model one. So let's have a look at what's going on there. Beautiful. So now we have a three layered model with more hidden units. So I wonder if we trained this model for longer, are we going to get improvements here? So my challenge to you is we've already done these steps before. We're going to do them over the next couple of videos for completeness. But we need to what create a loss function. So I'll give you a hint. It's very similar to the one we've already used. And we need to create an optimizer. And then once we've done that, we need to write a training and evaluation loop for model one. So give that a shot. Otherwise, I'll see you in the next video. We'll do this all together. Welcome back. In the last video, we subclassed nn.module to create circle model V one, which is an upgrade on circle model V zero. In the fact that we added more hidden units. So from five to 10. And we added a whole extra layer. And we've got an instance of it ready to go. So we're up to in the workflow. We've got our data. Well, we haven't changed the data. So we've built our new model. We now need to pick a loss function. And I hinted at before that we're going to use the same loss function as before. The same optimizer. You might have already done all of these steps. So you may know whether this model works on our data set or not. But that's what we're going to work towards finding out in this video. So we've built our new model. Now let's pick a loss function and optimizer. We could almost do all of this with our eyes closed now, build a training loop, fit the model to the data, make a prediction and evaluate the model. We'll come back here. And let's set up a loss function. And by the way, if you're wondering, like, why would adding more features here, we've kind of hinted at this before. And why would an extra layer improve our model? Well, again, it's back to the fact that if we add more neurons, if we add more hidden units, and if we add more layers, it just gives our model more numbers to adjust. So look at what's going on here, layer one, layer two. Look how many more we have compared to model zero dot state date. We have all of these. This is model zero. And we just upgraded it. Look how many more we have from just adding an extra layer and more hidden units. So now we have our optimizer can change these values to hopefully create a better representation of the data we're trying to fit. So we just have more opportunity to learn patterns in our target data set. So that's the theory behind it. So let's get rid of ease. Let's create a loss function. What are we going to use? Well, we're going to use nn dot BCE with logit's loss. And our optimizer is going to be what? We're going to keep that as the same as before, torch dot opt in dot SGD. But we have to be aware that because we're using a new model, we have to pass in params of model one. These are the parameters we want to optimize. And the LR is going to be 0.1. Is that the same LR we use before learning rate? 0.1. Oh, potentially that our learning rate may be too big. 0.1. Where do we create our optimizer? So we've written a lot of code here. Optimizer. There we go. 0.1. That's all right. So we'll keep it at 0.1 just to keep as many things the same as possible. So we're going to set up torch dot manual seed 42 to make training as reproducible as possible torch dot CUDA dot manual seed 42. Now, as I said before, don't worry too much if your numbers aren't exactly the same as mine. The direction is more important, whether it's good or bad direction. So now let's set up epochs. We want to train for longer this time as well. So 1000 epochs. This is one of our three improvements that we're trying to do. Adding more hidden units, increase the number of layers and increase the number of epochs. So we're going to give our model 1000 looks at the data to try and improve its patterns. So put data on the target device. We want to write device agnostic code. And yes, we've already done this, but we're going to write it out again for practice because even though we could functionize a lot of this, it's good while we're in still the foundation stages to practice what's going on here, because I want you to be able to do this with your eyes closed before we start to functionize it. So put the training data and the testing data to the target device, whatever it is, CPU or GPU. And then we're going to, well, what's our song? For an epoch in range. Let's loop through the epochs. We're going to start off with training. What do we do for training? Well, we set model one to train. And then what's our first step? Well, we have to forward pass. What's our outputs of the model? Well, the raw outputs of a model are logits. So model one, we're going to pass it the training data. We're going to squeeze it so that we get rid of an extra one dimension. If you don't believe me that we would like to get rid of that one dimension, try running the code without that dot squeeze. And why pred equals torch dot round. And torch dot sigmoid, why we're calling sigmoid on our logits to go from logits to prediction probabilities to prediction labels. And then what do we do next? Well, we calculate the loss slash accuracy to here. And remember, accuracy is optional, but loss is not optional. So we're going to pass in here, our loss function is going to take in. I wonder if it'll work with just straight up why pred? I don't think it will because we're using we need logits in here. Why logits and why train? Because why? Oh, Google collab correcting the wrong thing. We have why logits because we're using BCE with logits loss here. So let's keep pushing forward. We want our accuracy now, which is our accuracy function. And we're going to pass in the order here, which is the reverse of above, a little confusing, but I've kept the evaluation function in the same order as scikit loan. Why pred equals y pred? Three, we're going to zero the gradients of the optimizer, optimizer zero grad. And you might notice that we've started to pick up the pace a little. That is perfectly fine. If I'm typing too fast, you can always slow down the video, or you could just watch what we're doing and then code it out yourself afterwards, the code resources will always be available. We're going to take the last backward and perform back propagation. The only reason we're going faster is because we've covered these steps. So anything that we sort of spend time here, we've covered in a previous video, optimizer step. And this is where the adjustments to all of our models parameters are going to take place to hopefully create a better representation of the data. And then we've got testing. What's the first step that we do in testing? Well, we call model one dot a vowel to put it in evaluation mode. And because we're making predictions, we're going to turn on torch inference mode predictions. I call them predictions. Some other places call it inference. Remember machine learning has a lot of different names for the same thing. Forward pass. So we're going to create the test logits here. Equals model one X test. And we're going to squeeze them because we won't don't want the extra one dimension. Just going to add some code cells here so that we have more space and I'm typing in the middle of the screen. Then I'm going to put in test pred here. How do we get from logits to predictions? Well, we go torch dot round. And then we go torch dot sigmoid y sigmoid because we're working with a binary classification problem. And to convert logits from a binary classification problem to prediction probabilities, we use the sigmoid activation function. And then we're going to calculate the loss. So how wrong is our model on the test data? So test last equals loss function. We're going to pass it in the test logits. And then we're going to pass it in Y test for the ideal labels. And then we're going to also calculate test accuracy. And test accuracy is going to take in Y true equals Y test. So the test labels and Y pred equals test pred. So the test predictions test predictions here. And our final step is to print out what's happening. So print out what's happening. Oh, every tutorial needs a song. If I could, I'd teach everything with song. Song and dance. So because we're training for 1000 epochs, how about every 100 epochs we print out something. So print f string, and we're going to write epoch in here. So we know what epoch our models on. And then we're going to print out the loss. Of course, this is going to be the training loss. Because the test loss has test at the front of it. And then accuracy here. Now, of course, this is going to be the training accuracy. We go here. And then we're going to pipe. And we're going to print out the test loss. And we want the test loss here. We're going to take this to five decimal places. Again, when we see the printouts of the different values, do not worry too much about the exact numbers on my screen appearing on your screen, because that is inherent to the randomness of machine learning. So have we got the direction is more important? Have we got, we need a percentage sign here, because that's going to be a bit more complete for accuracy. Have we got any errors here? I don't know. I'm just, we've just all coded this free hand, right? There's a lot of code going on here. So we're about to train our next model, which is the biggest model we've built so far in this course, three layers, 10 hidden units on each layer. Let's see what we've got. Three, two, one, run. Oh, what? What? A thousand epochs, an extra hidden layer, more hidden units. And we still, our model is still basically a coin toss. 50%. Now, this can't be for real. Let's plot the decision boundary. Plot the decision boundary. To find out, let's get a bit visual. Plot figure, actually, to prevent us from writing out all of the plot code, let's just go up here, and we'll copy this. Now, you know, I'm not the biggest fan of copying code. But for this case, we've already written it. So there's nothing really new here to cover. And we're going to just change this from model zero to model one, because why it's our new model that we just trained. And so behind the scenes, plot decision boundary is going to make predictions with the target model on the target data set and put it into a nice visual representation for us. Oh, I said nice visual representation. What does this look like? We've just got a coin toss on our data set. Our model is just again, it's trying to draw a straight line to separate circular data. Now, why is this? Our model is based on linear, is our data nonlinear? Hmm, maybe I've revealed a few of my tricks. I've done a couple of reveals over the past few videos. But this is still quite annoying. And it can be fairly annoying when you're training models and they're not working. So how about we verify that this model can learn anything? Because right now it's just basically guessing for our data set. So this model looks a lot like the model we built in section 01. Let's go back to this. This is the learn pytorch.io book pytorch workflow fundamentals. Where did we create a model model building essentials? Where did we build a model? Linear regression model? Yeah, here. And then dot linear. But we built this model down here. So all we've changed from 01 to here is we've added a couple of layers. The forward computation is quite similar. If this model can learn something on a straight line, can this model learn something on a straight line? So that's my challenge to you is grab the data set that we created in this previous notebook. So data, you could just reproduce this in exact data set. And see if you can write some code to fit the model that we built here. This one here on the data set that we created in here. Because I want to verify that this model can learn anything. Because right now it seems like it's not learning anything at all. And that's quite frustrating. So give that a shot. And I'll see you in the next video. Welcome back. In the past few videos, we've tried to build a model to separate the blue from red dots yet. Our previous efforts have proven futile, but don't worry. We're going to get there. I promise you we're going to get there. And I may have a little bit of inside information here. But we're going to build a model to separate these blue dots from red dots, a fundamental classification model. And we tried a few things in the last couple of videos, such as training for longer, so more epochs. We added another layer. We increased the hidden units because we learned of a few methods to improve a model from a model perspective, such as upgrading the hyperparameters, such as number of layers, more hidden units, fitting for longer, changing the activation functions, changing the learning rate, we haven't quite done that one yet, and changing the loss function. One way that I like to troubleshoot problems is I'm going to put a subheading here, 5.1. We're going to prepare or preparing data to see if our model can fit a straight line. So one way to troubleshoot, this is my trick for troubleshooting problems, especially neural networks, but just machine learning in general, to troubleshoot a larger problem is to test out a smaller problem. And so why is this? Well, because we know that we had something working in a previous section, so 01, PyTorch, workflow fundamentals, we built a model here that worked. And if we go right down, we know that this linear model can fit a straight line. So we're going to replicate a data set to fit a straight line to see if the model that we're building here can learn anything at all, because right now it seems like it can't. It's just tossing a coin displayed between our data here, which is not ideal. So let's make some data. But yeah, this is the, let's create a smaller problem, one that we know that works, and then add more complexity to try and solve our larger problem. So create some data. This is going to be the same as notebook 01. And I'm going to set up weight equals 0.7 bias equals 0.3. We're going to move quite quickly through this because we've seen this in module one, but the overall takeaway from this is we're going to see if our model works on any kind of problem at all, or do we have something fundamentally wrong, create data. We're going to call it x regression, because it's a straight line, and we want it to predict a number rather than a class. So you might be thinking, oh, we might have to change a few things of our model architecture. Well, we'll see that in a second dot unsqueeze. And we're going to go on the first dimension here or dim equals one. And why regression, we're going to use the linear regression formula as well, wait times x, x regression, that is, because we're working with a new data set here, plus the bias. So this is linear regression formula. Without epsilon. So it's a simplified version of linear regression, but the same formula that we've seen in a previous section. So now let's check the data. Nothing we really haven't covered here, but we're going to do a sanity check on it to make sure that we're dealing with what we're dealing with. What we're dealing with is not just a load of garbage. Because it's all about the data and machine learning. I can't stress to you enough. That's the data explorer's motto is to visualize, visualize, visualize. Oh, what did we get wrong here? Unsqueeze. Did you notice that typo? Why didn't you say something? I'm kidding. There we go. Okay, so we've got 100 samples of x. We've got a different step size here, but that's all right. Let's have a little bit of fun with this. And we've got one x-value, which is, you know, a little bit more. One x value per y value is a very similar data set to what we use before. Now, what do we do once we have a data set? Well, if we haven't already got training and test splits, we better make them. So create train and test splits. And then we're going to go train split. We're going to use 80% equals int 0.8 times the length of, or we could just put 100 in there. But we're going to be specific here. And then we're going to go x train regression, y train regression equals. What are these equal? Well, we're going to go on x regression. And we're going to index up to the train split on the x. And then for the y, y regression, we're going to index up to the train split. Wonderful. And then we can do the same on the test or creating the test data. Nothing really new here that we need to discuss. We're creating training and test sets. What do they do for each of them? Well, the model is going to hopefully learn patterns in the training data set that is able to model the testing data set. And we're going to see that in a second. So if we check the length of each, what do we have? Length x train regression. We might just check x train x test regression. What do we have here? And then we're going to go length y train regression. Long variable names here. Excuse me for that. But we want to keep it separate from our already existing x and y data. What values do we have here? 80, 20, 80, 20, beautiful. So 80 training samples to 100 testing samples. That should be enough. Now, because we've got our helper functions file here. And if you don't have this, remember, we wrote some code up here before to where is it? To download it from the course GitHub, and we imported plot predictions from it. Now, if we have a look at helper functions.py, it contains the plot predictions function that we created in the last section, section 0.1. There we go. Plot predictions. So we're just running this exact same function here, or we're about to run it. It's going to save us from re typing out all of this. That's the beauty of having a helper functions.py file. So if we come down here, let's plot our data to visually inspected. Right now, it's just numbers on a page. And we're not going to plot really any predictions because we don't have any predictions yet. But we'll pass in the train data is equal to X train regression. And then the next one is the train labels, which is equal to Y train regression. And then we have the test data, which is equal to X test regression. And then we have the test labels. Now, I think this should be labels too. Yeah, there we go. Y test progression might be proven wrong as we try to run this function. Okay, there we go. So we have some training data and we have some testing data. Now, do you think that our model model one, we have a look what's model one could fit this data. Does it have the right amount of in and out features? We may have to adjust these slightly. So I'd like you to think about that. Do we have to change the input features to our model for this data set? And do we have to change the out features of our model for this data set? We'll find out in the next video. Welcome back. We're currently working through a little side project here, but really the philosophy of what we're doing. We just created a straight line data set because we know that we've built a model in the past back in section 01 to fit a straight line data set. And why are we doing this? Well, because the model that we've built so far is not fitting or not working on our circular data set here on our classification data set. And so one way to troubleshoot a larger problem is to test out a smaller problem first. So later on, if you're working with a big machine learning data set, you'd probably start with a smaller portion of that data set first. Likewise, with a larger machine learning model, instead of starting with a huge model, you'll start with a small model. So we're taking a step back here to see if our model is going to learn anything at all on a straight line data set so that we can improve it for a non-straight line data set. And there's another hint. Oh, we're going to cover it in a second. I promise you. But let's see how now we can adjust model one to fit a straight line. And I should do the question at the end of last video. Do we have to adjust the parameters of model one in any way shape or form to fit this straight line data? And you may have realized or you may not have that our model one is set up for our classification data, which has two X input features. Whereas this data, if we go X train regression, how many input features do we have? We just get the first sample. There's only one value. Or maybe we get the first 10. There's only one value per, let's remind ourselves, this is input and output shapes, one of the most fundamental things in machine learning and deep learning. And trust me, I still get this wrong all the time. So that's why I'm harping on about it. We have one feature per one label. So we have to adjust our model slightly. We have to change the end features to be one instead of two. The out features can stay the same because we want one number to come out. So what we're going to do is code up a little bit different version of model one. So same architecture as model one. But using NN dot sequential, we're going to do the faster way of coding a model here. Let's create model two and NN dot sequential. The only thing that's going to change is the number of input features. So this will be the exact same code as model one. And the only difference, as I said, will be features or in features is one. And then we'll go out features equals 10. So 10 hidden units in the first layer. And of course, the second layer, the number of features here has to line up with the out features of the previous layer. This one's going to output 10 features as well. So we're scaling things up from one feature to 10 to try and give our model as much of a chance or as many parameters as possible. Of course, we could make this number quite large. We could make it a thousand features if we want. But there is an upper bound on these things. And I'm going to let you find those in your experience as a machine learning engineer and a data scientist. But for now, we're keeping it nice and small. So we can run as many experiments as possible. Beautiful. Look at that. We've created a sequential model. What happens with NN dot sequential? Data goes in here, passes through this layer. Then it passes through this layer. Then it passes through this layer. And what happens when it goes through the layer? It triggers the layers forward method, the internal forward method. In the case of NN dot linear, we've seen it. It's got the linear regression formula. So if we go NN dot linear, it performs this mathematical operation, the linear transformation. But we've seen that before. Let's keep pushing forward. Let's create a loss and an optimizer loss and optimize. We're going to work through our workflow. So loss function, we have to adjust this slightly. We're going to use the L1 loss because why we're dealing with a regression problem here rather than a classification problem. And our optimizer, what can we use for our optimizer? How about we bring in just the exact same optimizer SGD that we've been using for our classification data. So model two dot params or parameters. Always get a little bit confused. And we'll give it an LR of 0.1 because that's what we've been using so far. This is the params here. So we want our optimizer to optimize our model two parameters here with a learning rate of 0.1. The learning rate is what? The amount each parameter will be or the multiplier that will be applied to each parameter each epoch. So now let's train the model. Do you think we could do that in this video? I think we can. So we might just train it on the training data set and then we can evaluate it on the test data set separately. So we'll set up both manual seeds, CUDA and because we've set our model to the device up here. So it should be on the GPU or whatever device you have active. So set the number of epochs. How many epochs should we set? Well, we set a thousand before, so we'll keep it at that. epochs equals a thousand. And now we're getting really good at this sort of stuff here. Let's put our data. Put the data on the target device. And I know we've done a lot of the similar steps before, but there's a reason for that. I've kept all these in here because I'd like you to buy the end of this course is to sort of know all of this stuff off by heart. And even if you don't know it all off my heart, because trust me, I don't, you know where to look. So X train regression, we're going to send this to device. And then we're going to go Y train regression, just a reminder or something to get you to think while we're writing this code. What would happen if we didn't put our data on the same device as a model? We've seen that error come up before, but what happens? Well, I've just kind of given away, haven't you Daniel? Well, that was a great question. Our code will air off. Oh, well, don't worry. There's plenty of questions I've been giving you that I haven't given the answer to yet. Device a beautiful. We've got a device agnostic code for the model and for the data. And now let's loop through epochs. So train. We're going to for epoch in range epochs for an epoch in a range. Do the forward pass. Calculate the loss. So Y pred equals model two. This is the forward pass. X train regression. It's all going to work out hunky Dory because our model and our data are on the same device loss equals what we're going to bring in our loss function. Then we're going to compare the predictions to Y train regression to the Y labels. What do we do next? Optimize a zero grad. Optimize a dot zero grad. We're doing all of this with our comments. Look at us go. Loss backward and what's next? Optimize a step, step, step. And of course, we could do some testing here. Testing. We'll go model two dot a vowel. And then we'll go with torch dot inference mode. We'll do the forward pass. We'll create the test predictions equals model two dot X test regression. And then we'll go the test loss equals loss FN on the test predictions and versus the Y test labels. Beautiful. Look at that. We've just done an optimization loop, something we spent a whole hour on before, maybe even longer, in about ten lines of code. And of course, we could shorten this by making these a function. But we're going to see that later on. I'd rather us give a little bit of practice while this is still a bit fresh. Print out what's happening. Let's print out what's happening. What should we do? So because we're training for a thousand epochs, I like the idea of printing out something every 100 epochs. That should be about enough of a step. Epoch. What do we got? We'll put in the epoch here with the F string and then we'll go to loss, which will be loss. And maybe we'll get the first five of those five decimal places that is. We don't have an accuracy, do we? Because we're working with regression. And we'll get the test loss out here. And that's going to be.5F as well. Beautiful. Have we got any mistakes? I don't think we do. We didn't even run this code cell before. We'll just run these three again, see if we got... Look at that. Oh my goodness. Is our loss... Our loss is going down. So that means our model must be learning something. Now, what if we adjusted the learning rate here? I think if we went 0.01 or something, will that do anything? Oh, yes. Look how low our loss gets on the test data set. But let's confirm that. We've got to make some predictions. Well, maybe we should do that in the next video. Yeah, this one's getting too long. But how good's that? We created a straight line data set and we've created a model to fit it. We set up a loss and an optimizer already. And we put the data on the target device. We trained and we tested so our model must be learning something. But I'd like you to give a shot at confirming that by using our plot predictions function. So make some predictions with our trained model. Don't forget to turn on inference mode. And we should see some red dots here fairly close to the green dots on the next plot. Give that a shot and I'll see you in the next video. Welcome back. In the last video, we did something very exciting. We solved a smaller problem that's giving us a hint towards our larger problem. So we know that the model that we've previously been building, model two, has the capacity to learn something. Now, how did we know that? Well, it's because we created this straight line data set. We replicated the architecture that we used for model one. Recall that model one didn't work very well on our classification data. But with a little bit of an adjustment such as changing the number of in features. And not too much different training code except for a different loss function because, well, we use MAE loss with regression data. And we changed the learning rate slightly because we found that maybe our model could learn a bit better. And again, I'd encourage you to play around with different values of the learning rate. In fact, anything that we've changed, try and change it yourself and just see what happens. That's one of the best ways to learn what goes on with machine learning models. But we trained for the same number of epochs. We set up device agnostic code. We did a training and testing loop. Look at this looks. Oh, my goodness. Well done. And our loss went down. So, hmm. What does that tell us? Well, it tells us that model two or the specific architecture has some capacity to learn something. So we must be missing something. And we're going to get to that in a minute, I promise you. But we're just going to confirm that our model has learned something and it's not just numbers on a page going down by getting visual. So turn on. We're going to make some predictions and plot them. And you may have already done this because I issued that challenge at the last of at the end of the last video. So turn on evaluation mode. Let's go model two dot eval. And let's make predictions, which are also known as inference. And we're going to go with torch dot inference mode inference mode with torch dot inference mode. Make some predictions. We're going to save them as why preds and we're going to use model two and we're going to pass it through ex test regression. This should all work because we've set up device agnostic code, plot data and predictions. To do this, we can of course use our plot predictions function that we imported via our helper functions dot pi function. The code for that is just a few cells above if you'd like to check that out. But let's set up the train data here. Train data parameter, which is x train regression. And my goodness. Google collab. I'm already typing fast enough. You don't have to slow me down by giving me the wrong auto corrects train label equals y train regression. And then we're going to pass in our test data equals ex test regression. And then we're going to pass in test labels, which is why test regression got too many variables going on here. My goodness gracious. We could have done better with naming, but this will do for now is why preds. And then if we plot this, what does it look like? Oh, no, we got an error. Now secretly, I kind of knew that that was coming ahead of time. That's the advantage of being the host of this machine learning cooking show. So type error. How do we fix this? Remember how I asked you in one of the last videos what would happen if our data wasn't on the same device as our model? Well, we get an error, right? But this is a little bit different as well. We've seen this one before. We've got CUDA device type tensa to NumPy. Where is this coming from? Well, because our plot predictions function uses mapplotlib. And behind the scenes, mapplotlib references NumPy, which is another numerical computing library. However, NumPy uses a CPU rather than the GPU. So we have to call dot CPU, this helpful message is telling us, call tensa dot CPU before we use our tensors with NumPy. So let's just call dot CPU on all of our tensor inputs here and see if this solves our problem. Wonderful. Looks like it does. Oh my goodness. Look at those red dots so close. Well, okay. So this just confirms our suspicions. What we kind of already knew is that our model did have some capacity to learn. It's just the data set when we changed the data set it worked. So, hmm. Is it our data that our model can't learn on? Like this circular data, or is the model itself? Remember, our model is only comprised of linear functions. What is linear? Linear is a straight line, but is our data made of just straight lines? I think it's got some nonlinearities in there. So the big secret I've been holding back will reveal itself starting from the next video. So if you want a head start of it, I'd go to torch and end. And if we have a look at the documentation, we've been speaking a lot about linear functions. What are these nonlinear activations? And I'll give you another spoiler. We've actually seen one of these nonlinear activations throughout this notebook. So go and check that out. See what you can infer from that. And I'll see you in the next video. Let's get started with nonlinearities. Welcome back. In the last video, we saw that the model that we've been building has some potential to learn. I mean, look at these predictions. You could get a little bit better, of course, get the red dots on top of the green dots. But we're just going to leave that the trend is what we're after. Our model has some capacity to learn, except this is straight line data. And we've been hinting at it a fair bit is that we're using linear functions. And if we look up linear data, what does it look like? Well, it has a quite a straight line. If we go linear and just search linear, what does this give us? Linear means straight. There we go, straight. And then what happens if we search for nonlinear? I kind of hinted at this as well. Nonlinear. Oh, we get some curves. We get curved lines. So linear functions. Straight. Nonlinear functions. Hmm. Now, this is one of the beautiful things about machine learning. And I'm not sure about you, but when I was in high school, I kind of learned a concept called line of best fit, or y equals mx plus c, or y equals mx plus b. And it looks something like this. And then if you wanted to go over these, you use quadratic functions and a whole bunch of other stuff. But one of the most fundamental things about machine learning is that we build neural networks and deep down neural networks are just a combination. It could be a large combination of linear functions and nonlinear functions. So that's why in torch.nn, we have nonlinear activations and we have all these other different types of layers. But essentially, what they're doing deep down is combining straight lines with, if we go back up to our data, non straight lines. So, of course, our model didn't work before because we've only given it the power to use linear lines. We've only given it the power to use straight lines. But our data is what? It's curved. Although it's simple, we need nonlinearity to be able to model this data set. And now, let's say we were building a pizza detection model. So let's look up some images of pizza, one of my favorite foods, images. Pizza, right? So could you model pizza with just straight lines? You're thinking, Daniel, you can't be serious. A computer vision model doesn't look for just straight lines in this. And I'd argue that, yes, it does, except we also add some curved lines in here. That's the beauty of machine learning. Could you imagine trying to write the rules of an algorithm to detect that this is a pizza? Maybe you could put in, oh, it's a curve here. And if you see red, no, no, no, no. Imagine if you're trying to do a hundred different foods. Your program would get really large. Instead, we give our machine learning models, if we come down to the model that we created. We give our deep learning models the capacity to use linear and nonlinear functions. We haven't seen any nonlinear layers just yet. Or maybe we've hinted at some, but that's all right. So we stack these on top of each other, these layers. And then the model figures out what patterns in the data it should use, what lines it should draw to draw patterns to not only pizza, but another food such as sushi. If we wanted to build a food image classification model, it would do this. The principle remains the same. So the question I'm going to pose to you, we'll get out of this, is, we'll come down here. We've unlocked the missing piece or about to. We're going to cover it over the next couple of videos, the missing piece of our model. And this is a big one. This is going to follow you out throughout all of machine learning and deep learning, nonlinearity. So the question here is, what patterns could you draw if you were given an infinite amount of straight and non straight lines? Or in machine learning terms, an infinite amount, but really it is finite. By infinite in machine learning terms, this is a technicality. It could be a million parameters. It could be as we've got probably a hundred parameters in our model. So just imagine a large amount of straight and non straight lines, an infinite amount of linear and nonlinear functions. You could draw some pretty intricate patterns, couldn't you? And that's what gives machine learning and especially neural networks the capacity to not only fit a straight line here, but to separate two different circles. But also to do crazy things like drive a self-driving car, or at least power the vision system of a self-driving car. Of course, after that, you need some programming to plan what to actually do with what you see in an image. But we're getting ahead of ourselves here. Let's now start diving into nonlinearity. And the whole idea here is combining the power of linear and nonlinear functions. Straight lines and non straight lines. Our classification data is not comprised of just straight lines. It's circles, so we need nonlinearity here. So recreating nonlinear data, red and blue circles. We don't need to recreate this, but we're going to do it anyway for completeness. So let's get a little bit of a practice. Make and plot data. This is so that you can practice the use of nonlinearity on your own. And that plot little bit dot pie plot as PLT. We're going to go a bit faster here because we've covered this code above. So import make circles. We're just going to recreate the exact same circle data set that we've created above. Number of samples. We'll create a thousand. And we're going to create x and y equals what? Make circles. Pass it in number of samples. Beautiful. Colab, please. I wonder if I can turn off autocorrect and colab. I'm happy to just see all of my errors in the flesh. See? Look at that. I don't want that. I want noise like that. Maybe I'll do that in the next video. We're not going to spend time here looking around how to do it. We can work that out on the fly later. For now, I'm too excited to share with you the power of nonlinearity. So here, x, we're just going to plot what's going on. We've got two x features and we're going to color it with the flavor of y because we're doing a binary classification. And we're going to use one of my favorite C maps, which is color map. And we're going to go PLT dot CM for C map and red blue. What do we get? Okay, red circle, blue circle. Hey, is it the same color as what's above? I like this color better. Did we get that right up here? Oh, my goodness. Look how much code we've written. Yeah, I like the other blue. I'm going to bring this down here. It's all about aesthetics and machine learning. It's not just numbers on a page, don't you? How could you be so crass? Let's go there. Okay, that's better color red and blue. That's small lively, isn't it? So now let's convert to train and test. And then we can start to build a model with nonlinearity. Oh, this is so good. Okay, convert data to tenses and then to train and test splits. Nothing we haven't covered here before. So import torch, but it never hurts to practice code, right? Import torch from sklearn dot model selection. Import train test split so that we can split our red and blue dots randomly. And we're going to turn data into tenses. And we'll go X equals torch from NumPy and we'll pass in X here. And then we'll change it into type torch dot float. Why do we do this? Well, because, oh, my goodness, autocorrect. It's getting the best of me here. You know, watching me live code this stuff and battle with autocorrect. That's what this whole course is. And we're really teaching pie torch. Am I just battling with Google collab's autocorrect? We are turning it into torch dot float with a type here because why NumPy's default, which is what makes circles users behind the scenes. NumPy is actually using a lot of other machine learning libraries, pandas, built on NumPy, scikit learn, does a lot of NumPy. Matplotlib, NumPy. That's just showing there. What's the word? Is it ubiquitous, ubiquity? I'm not sure, maybe. If not, you can correct me. The ubiquity of NumPy. And test sets, but we're using pie torch to leverage the power of autograd, which is what powers our gradient descent. And the fact that it can use GPUs. So we're creating training test splits here with train test split X Y. And we're going to go test size equals 0.2. And we're going to set random. Random state equals 42. And then we'll view our first five samples. Are these going to be? Tenses. Fingers crossed. We haven't got an error. Beautiful. We have tenses here. Okay. Now we're up to the exciting part. We've got our data set back. I think it's time to build a model with nonlinearity. So if you'd like to peek ahead, check out TorchNN again. This is a little bit of a spoiler. Go into the nonlinear activation. See if you can find the one that we've already used. That's your challenge. Can you find the one we've already used? And go into here and search what is our nonlinear function. So give that a go and see what comes up. I'll see you in the next video. Welcome back. Now put your hand up if you're ready to learn about nonlinearity. And I know I can't see your hands up, but I better see some hands up or I better feel some hands up because my hands up because nonlinearity is a magic piece of the puzzle that we're about to learn about. So let's title this section building a model with nonlinearity. So just to re-emphasize linear equals straight lines and in turn nonlinear equals non-straight lines. And I left off the end of the last video, giving you the challenge of checking out the TorchNN module, looking for the nonlinear function that we've already used. Now where would you go to find such a thing and oh, what do we have here? Nonlinear activations. And there's going to be a fair few things here, but essentially all of the modules within TorchNN are either some form of layer in a neural network if we recall. Let's go to a neural network. We've seen the anatomy of a neural network. Generally you'll have an input layer and then multiple hidden layers and some form of output layer. Well, these multiple hidden layers can be almost any combination of what's in TorchNN. And in fact, they can almost be any combination of function you could imagine. Whether they work or not is another question. But PyTorch implements some of the most common layers that you would have as hidden layers. And they might be pooling layers, padding layers, activation functions. And they all have the same premise. They perform some sort of mathematical operation on an input. And so if we look into the nonlinear activation functions, you might have find an n dot sigmoid. Where have we used this before? There's a sigmoid activation function in math terminology. It takes some input x, performs this operation on it. And here's what it looks like if we did it on a straight line, but I think we should put this in practice. And if you want an example, well, there's an example there. All of the other nonlinear activations have examples as well. But I'll let you go through all of these in your own time. Otherwise we're going to be here forever. And then dot relu is another common function. We saw that when we looked at the architecture of a classification network. So with that being said, how about we start to code a classification model with nonlinearity. And of course, if you wanted to, you could look up what is a nonlinear function. If you wanted to learn more, nonlinear means the graph is not a straight line. Oh, beautiful. So that's how I'd learn about nonlinear functions. But while we're here together, how about we write some code. So let's go build a model with nonlinear activation functions. And just one more thing before, just to re-emphasize what we're doing here. Before we write this code, I've got, I just remembered, I've got a nice slide, which is the question we posed in the previous video, the missing piece, nonlinearity. But the question I want you to think about is what could you draw if you had an unlimited amount of straight, in other words, linear, and non-straight, nonlinear line. So we've seen previously that we can build a model, a linear model to fit some data that's in a straight line, linear data. But when we're working with nonlinear data, well, we need the power of nonlinear functions. So this is circular data. And now, this is only a 2D plot, keep in mind there. Whereas neural networks and machine learning models can work with numbers that are in hundreds of dimensions, impossible for us humans to visualize, but since computers love numbers, it's a piece of cake to them. So from torch, import, and then we're going to create our first neural network with nonlinear activations. This is so exciting. So let's create a class here. We'll create circle model. We've got circle model V1 already. We're going to create circle model V2. And we'll inherit from an end dot module. And then we'll write the constructor, which is the init function, and we'll pass in self here. And then we'll go self, or super sorry, too many S words. Dot underscore underscore init, underscore. There we go. So we've got the constructor here. And now let's create a layer one, self dot layer one equals just the same as what we've used before. And then dot linear. We're going to create this quite similar to the model that we've built before, except with one added feature. And we're going to create in features, which is akin to the number of X features that we have here. Again, if this was different, if we had three X features, we might change this to three. But because we're working with two, we'll leave it as that. We'll keep out features as 10, so that we have 10 hidden units. And then we'll go layer two, and then dot linear. Again, these values here are very customizable because why, because they're hyper parameters. So let's line up the out features of layer two, and we'll do the same with layer three. Because layer three is going to take the outputs of layer two. So it needs in features of 10. And we want layer three to be the output layer, and we want one number as output, so we'll set one here. Now, here's the fun part. We're going to introduce a nonlinear function. We're going to introduce the relu function. Now, we've seen sigmoid. Relu is another very common one. It's actually quite simple. But let's write it out first, and then dot relu. So remember, torch dot nn stores a lot of existing nonlinear activation functions, so that we don't necessarily have to code them ourselves. However, if we did want to code a relu function, let me show you. It's actually quite simple. If we dive into nn dot relu, or relu, however you want to say it, I usually say relu, applies the rectified linear unit function element wise. So that means element wise on every element in our input tensor. And so it stands for rectified linear unit, and here's what it does. Basically, it takes an input. If the input is negative, it turns the input to zero, and it leaves the positive inputs how they are. And so this line is not straight. Now, you could argue, yeah, well, it's straight here and then straight there, but this is a form of a nonlinear activation function. So it goes boom, if it was linear, it would just stay straight there like that. But let's see it in practice. Do you think this is going to improve our model? Well, let's find out together, hey, forward, we need to implement the forward method. And here's what we're going to do. Where should we put our nonlinear activation functions? So I'm just going to put a node here. Relu is a nonlinear activation function. And remember, wherever I say function, it's just performing some sort of operation on a numerical input. So we're going to put a nonlinear activation function in between each of our layers. So let me show you what this looks like, self dot layer three. We're going to start from the outside in self dot relu, and then we're going to go self dot layer two. And then we're going to go self dot relu. And then there's a fair bit going on here, but nothing we can't handle layer one. And then here's the X. So what happens is our data goes into layer one, performs a linear operation with an end up linear. Then we pass the output of layer one to a relu function. So we, where's relu up here, we turn all of the negative outputs of our model of our of layer one to zero, and we keep the positives how they are. And then we do the same here with layer two. And then finally, the outputs of layer three stay as they are. We've got out features there. We don't have a relu on the end here, because we're going to pass the outputs to the sigmoid function later on. And if we really wanted to, we could put self dot sigmoid here equals an end dot sigmoid. But I'm going to, that's just one way of constructing it. We're just going to apply the sigmoid function to the logits of our model, because what are the logits, the raw output of our model. And so let's instantiate our model. This is going to be called model three, which is a little bit confusing, but we're up to model three, which is circle model V two, and we're going to send that to the target device. And then let's check model three. What does this look like? Wonderful. So it doesn't actually show us where the relu's appear, but it just shows us what are the parameters of our circle model V two. Now, I'd like you to have a think about this. And my challenge to you is to go ahead and see if this model is capable of working on our data, on our circular data. So we've got the data sets ready. You need to set up some training code. My challenge to you is write that training code and see if this model works. But we're going to go through that over the next few videos. And also, my other challenge to you is to go to the TensorFlow Playground and recreate our neural network here. You can have two hidden layers. Does this go to 10? Well, it only goes to eight. We'll keep this at five. So build something like this. So we've got two layers with five. It's a little bit different to ours because we've got two layers with 10. And then put the learning rate to 0.01. What do we have? 0.1 with stochastic gradient descent. We've been using 0.1, so we'll leave that. So this is the TensorFlow Playground. And then change the activation here. Instead of linear, which we've used before, change it to relu, which is what we're using. And press play here and see what happens. I'll see you in the next video. Welcome back. In the last video, I left off leaving the challenge of recreating this model here. It's not too difficult to do. We've got two hidden layers and five neurons. We've got our data set, which looks kind of like ours. But the main points here are have to learning rate of 0.1, which is what we've been using. But to change it from, we've previously used a linear activation to change it from linear to relu, which is what we've got set up here in the code. Now, remember, relu is a popular and effective nonlinear activation function. And we've been discussing that we need nonlinearity to model nonlinear data. And so that's the crux to what neural networks are. Artificial neural networks, not to get confused with the brain neural networks, but who knows? This might be how they work, too. I don't know. I'm not a neurosurgeon or a neuroscientist. Artificial neural networks are a large combination of linear. So this is straight and non-straight nonlinear functions, which are potentially able to find patterns in data. And so for our data set, it's quite small. It's just a blue and a red circle. But this same principle applies for larger data sets and larger models combined linear and nonlinear functions. So we've got a few tabs going on here. Let's get rid of some. Let's come back to here. Did you try this out? Does it work? Do you think it'll work? I don't know. Let's find out together. Ready? Three, two, one. Look at that. Almost instantly the training loss goes down to zero and the test loss is basically zero as well. Look at that. That's amazing. We can stop that there. And if we change the learning rate, maybe a little lower, let's see what happens. It takes a little bit longer to get to where it wants to go to. See, that's the power of changing the learning rate. Let's make it really small. What happens here? So that was about 300 epochs. The loss started to go down. If we change it to be really small, oh, we're getting a little bit of a trend. Is it starting to go down? We're already surpassed the epochs that we had. So see how the learning rate is much smaller? That means our model is learning much slower. So this is just a beautiful visual way of demonstrating different values of the learning rate. We could sit here all day and that might not get to lower, but let's increase it by 10x. And that was over 1,000 epochs and it's still at about 0.5, let's say. Oh, we got a better. Oh, we're going faster already. So not even at 500 or so epochs, we're about 0.4. That's the power of the learning rate. We'll increase it by another 10x. We'll reset. Start again. Oh, would you look at that much faster this time. That is beautiful. Oh, there's nothing better than watching a loss curve go down. In the world of machine learning, that is. And then we reset that again. And let's change it right back to what we had. And we get to 0 in basically under 100 epochs. So that's the power of the learning rate, little visual representation. Working on learning rates, it's time for us to build an optimizer and a loss function. So that's right here. We've got our nonlinear model set up loss and optimizer. You might have already done this because the code, this is code that we've written before, but we're going to redo it for completeness and practice. So we want a loss function. We're working with logits here and we're working with binary cross entropy. So what loss do we use? Binary cross entropy. Sorry, we're working with a binary classification problem. Blue dots or red dots, torch dot opt in. What are some other binary classification problems that you can think of? We want model three dot parameters. They're the parameters that we want to optimize this model here. And we're going to set our LR to 0.1, just like we had in the TensorFlow playground. Beautiful. So some other binary classification problems I can think of would be email. Spam or not spam credit cards. So equals fraud or not fraud. What else? You might have insurance claims. Equals who's at fault or not at fault. If someone puts in a claim speaking about a car crash, whose fault was it? Was the person submitting the claim? Were they at fault? Or was the person who was also mentioned in the claim? Are they not at fault? So there's many more, but they're just some I can think of up the top of my head. But now let's train our model with nonlinearity. Oh, we're on a roll here. Training a model with nonlinearity. So we've seen that if we introduce a nonlinear activation function within a model, remember this is a linear activation function, and if we train this, the loss doesn't go down. But if we just adjust this to add a relu in here, we get the loss going down. So hopefully this replicates with our pure PyTorch code. So let's do it, hey? So we're going to create random seeds. Because we're working with CUDA, we'll introduce the CUDA random seed as well. Torch.manual seed. Again, don't worry too much if your numbers on your screen aren't exactly what mine are. That's due to the inherent randomness of machine learning. In fact, stochastic gradient descent stochastic again stands for random. And we're just setting up the seeds here so that they can be as close as possible. But the direction is more important. So if my loss goes down, your loss should also go down on target device. And then we're going to go Xtrain. So this is setting up device agnostic code. We've done this before. But we're going to do it again for completeness. Just to practice every step of the puzzle. That's what we want to do. We want to have experience. That's what this course is. It's a momentum builder. So that when you go to other repos and machine learning projects that use PyTorch, you can go, oh, does this code set device agnostic code? What problem are we working on? Is it binary or multi-class classification? So let's go loop through data. Again, we've done this before, but we're going to set up the epochs. Let's do 1000 epochs. Why not? So we can go for epoch in range epochs. What do we do here? Well, we want to train. So this is training code. We set our model model three dot train. And I want you to start to think about how could we functionalize this training code? We're going to start to move towards that in a future video. So one is forward pass. We've got the logits. Why the logits? Well, because the raw output of our model without any activation functions towards the final layer. Classified as logits or called logits. And then we create y-pred as in prediction labels by rounding the output of torch dot sigmoid of the logits. So this is going to take us from logits to prediction probabilities to prediction labels. And then we can go to, which is calculate the loss. That's from my unofficial pytorch song. Calculate the last. We go loss equals loss FN y logits. Because remember, we've got BCE with logits loss and takes in logits as first input. And that's going to calculate the loss between our models, logits and the y training labels. And we will go here, we'll calculate accuracy using our accuracy function. And this one is a little bit backwards compared to pytorch, but we pass in the y training labels first. But it's constructed this way because it's in the same style as scikit line. Three, we go optimizer zero grad. We zero the gradients of the optimizer so that it can start from fresh. Calculating the ideal gradients every epoch. So it's going to reset every epoch, which is fine. Then we're going to perform back propagation pytorch is going to take care of that for us by calling loss backwards. And then we will perform gradient descent. So step the optimizer to see how we should improve our model parameters. So optimizer dot step. Oh, and I want to show you speaking of model parameters. Let's check our model three dot state dig. So the relu activation function actually doesn't have any parameters. So you'll notice here, we've got weight, we've got bias of layer one, layer two, and a layer three. So the relu function here doesn't have any parameters to optimize. If we go nn dot relu. Does it say what it implements? There we go. So it's just the maximum of zero or x. So it takes the input and takes the max of zero or x. And so when it takes the max of zero or x, if it's a negative number, zero is going to be higher than a negative number. So that's why it zeroes all of the negative inputs. And then it leaves the positive inputs how they are because the max of a positive input versus zero is the positive input. So this has no parameters to optimize. That's why it's so effective because you think about it. Every parameter in our model needs some little bit of computation to adjust. And so the more parameters we add to our model, the more compute that is required. So generally, the kind of trade-off in machine learning is that, yes, more parameters have more of an ability to learn, but you need more compute. So let's go model three dot a vowel. And we're going to go with torch dot inference mode. If I could spell inference, that'd be fantastic. We're going to do what? We're going to do the forward pass. So test logits equals model three on the test data. And then we're going to calculate the test pred labels by calling torch dot round on torch dot sigmoid on the test logits. And then we can calculate the test loss. How do we do that? And then we can also calculate the test accuracy. I'm just going to give myself some more space here. So I can code in the middle of the screen equals accuracy function on what we're going to pass in y true equals y test. We're going to pass in y true equals y test. And then we will pass in y pred equals test pred. Beautiful. A final step here is to print out what's happening. Now, this will be very important because one, it's fun to know what your model is doing. And two, if our model does actually learn, I'd like to see the loss values go down and the accuracy values go up. As I said, there's nothing much more beautiful in the world of machine learning than watching a loss function go down or a loss value go down and watching a loss curve go down. So let's print out the current epoch and then we'll print out the loss, which will just be the training loss. And we'll take that to four decimal places. And then we'll go accuracy here. And this will be a and we'll take this to two decimal places and we'll put a little percentage sign there and then we'll break it up by putting in the test loss here and we'll put in the test loss. Because remember our model learns patterns on the training data set and then evaluates those patterns on the test data set. So, and we'll pass in test act here and no doubt there might be an error or two within all of this code, but we're going to try and run this because we've seen this code before, but I think we're ready. We're training our first model here with non-linearities built into the model. You ready? Three, two, one, let's go. Oh, of course. Module torch CUDA has no attribute manuals are just a typo standard man you out. There we go. Have to sound that out. Another one. What do we get wrong here? Oh, target size must be same as input size. Where did it mess up here? What do we get wrong? Test loss, test logits on Y test. Hmm. So these two aren't matching up. Model three X test and Y test. What's the size of? So let's do some troubleshooting on the fly. Hey, not everything always works out as you want. So length of X test, we've got a shape issue here. Remember how I said one of the most common issues in deep learning is a shape issue? We've got the same shape here. Let's check test logits dot shape and Y test dot shape. We'll print this out. So 200. Oh, here's what we have to do. That's what we missed dot squeeze. Oh, see how I've been hinting at the fact that we needed to call dot squeeze. So this is where the discrepancy is. Our test logits dot shape. We've got an extra dimension here. And what are we getting here? A value error on the target size, which is a shape mismatch. So we've got target size 200 must be the same input size as torch size 201. So did we squeeze this? Oh, that's why the training worked. Okay, so we've missed this. Let's just get rid of this. So we're getting rid of the extra one dimension by using squeeze, which is the one dimension here. We should have everything lined up. There we go. Okay. Look at that. Yes. Now accuracy has gone up, albeit not by too much. It's still not perfect. So really we'd like this to be towards 100% lost to be lower. But I feel like we've got a better performing model. Don't you? Now that is the power of non linearity. All we did was we added in a relu layer or just two of them. Relu here, relu here. But what did we do? We gave our model the power of straight lines. Oh, straight linear of straight lines and non straight lines. So it can potentially draw a line to separate these circles. So in the next video, let's draw a line, plot our model decision boundary using our function and see if it really did learn anything. I'll see you there. Welcome back. In the last video, we trained our first model, and as you can tell, I've got the biggest smile on my face, but we trained our first model that harnesses both the power of straight lines and non straight lines or linear functions and non linear functions. And by the 1000th epoch, we look like we're getting a bit better results than just pure guessing, which is 50%. Because we have 500 samples of red dots and 500 samples of blue dots. So we have evenly balanced classes. Now, we've seen that if we added a relu activation function with a data set similar to ours with a TensorFlow playground, the model starts to fit. But it doesn't work with just linear. There's a few other activation functions that you could play around with here. You could play around with the learning rate, regularization. If you're not sure what that is, I'll leave that as extra curriculum to look up. But we're going to retire the TensorFlow program for now because we're going to go back to writing code. So let's get out of that. Let's get out of that. We now have to evaluate our model because right now it's just numbers on a page. So let's write down here 6.4. What do we like to do to evaluate things? It's visualize, visualize, visualize. So evaluating a model trained with nonlinear activation functions. And we also discussed the point that neural networks are really just a big combination of linear and nonlinear functions trying to draw patterns in data. So with that being said, let's make some predictions with our Model 3, our most recently trained model. We'll put it into a Val mode and then we'll set up inference mode. And then we'll go yprads equals torch dot round and then torch dot sigmoid. We could functionalize this, of course, Model 3 and then pass in X test. And you know what? We're going to squeeze these here because we ran into some troubles in the previous video. I actually really liked that we did because then we got to troubleshoot a shape error on the fly because that's one of the most common issues you're going to come across in deep learning. So yprads, let's check them out and then let's check out y test. You want y test 10. So remember, when we're evaluating predictions, we want them to be in the same format as our original labels. We want to compare apples to apples. And if we compare the format here, do these two things look the same? Yes, they do. They're both on CUDA and they're both floats. We can see that it's got this one wrong. Whereas the other ones look pretty good. Hmm, this might look pretty good if we visualize it. So now let's, you might have already done this because I issued the challenge of plotting the decision boundaries. Plot decision boundaries and let's go PLT dot figure and we're going to set up the fig size to equal 12.6 because, again, one of the advantages of hosting a machine learning cooking show is that you can code ahead of time. And then we can go PLT dot title is train. And then we're going to call our plot decision boundary function, which we've seen before. Plot decision boundary. And we're going to pass this one in. We could do model three, but we could also pass it in our older models to model one that doesn't use it on the reality. In fact, I reckon that'll be a great comparison. So we'll also create another plot here for the test data and this will be on index number two. So remember, subplot is a number of rows, number of columns, index where the plot appears. We'll give this one a title. Plot dot title. This will be test and Google Colab. I didn't want that. As I said, this course is also a battle between me and Google Colab's autocorrect. So we're going model three and we'll pass in the test data here. And behind the scenes, our plot decision boundary function will create a beautiful graphic for us, perform some predictions on the X, the features input, and then we'll compare them with the Y values. Let's see what's going on here. Oh, look at that. Yes, our first nonlinear model. Okay, it's not perfect, but it is certainly much better than the models that we had before. Look at this. Model one has no linearity. Model one equals no nonlinearity. I've got double negative there. Whereas model three equals has nonlinearity. So do you see the power of nonlinearity or better yet the power of linearity or linear straight lines with non straight lines? So I feel like we could do better than this, though. Here's your challenge is to can you improve model three to do better? What did we get? 79% accuracy to do better than 80% accuracy on the test data. I think you can. So that's the challenge. And if you're looking for hints on how to do so, where can you look? Well, we've covered this improving a model. So maybe you add some more layers, maybe you add more hidden units. Maybe you fit for longer. Maybe you if you add more layers, you put a relio activation function on top of those as well. Maybe you lower the learning rate because right now we've got 0.1. So give this a shot, try and improve it. I think you can do it. But we're going to push forward. That's going to be your challenge for some extra curriculum. I think in the next section, we've seen our nonlinear activation functions in action. Let's write some code to replicate them. I'll see you there. Welcome back. In the last video, I left off with the challenge of improving model three to do better than 80% accuracy on the test data. I hope you gave it a shot. But here are some of the things I would have done. As I potentially add more layers, I maybe increase the number of hidden units, and then if we needed to fit for longer and maybe lower the learning rate to 0.01. But I'll leave that for you to explore because that's the motto of the data scientists, right? Is to experiment, experiment, experiment. So let's go in here. We've seen our nonlinear activation functions in practice. Let's replicate them. So replicating nonlinear activation functions. And remember neural networks rather than us telling the model what to learn. We give it the tools to discover patterns in data. And it tries to figure out the best patterns on its own. And what are these tools? That's right down here. We've seen this in action. And these tools are linear and nonlinear functions. So a neural network is a big stack of linear and nonlinear functions. For us, we've only got about four layers or so, four or five layers. But as I said, other networks can get much larger. But the premise remains. Some form of linear and nonlinear manipulation of the data. So let's get out of this. Let's make our workspace a little bit more cleaner. Replicating nonlinear activation functions. So let's create a tensor to start with. Everything starts from the tensor. And we'll go A equals torch A range. And we're going to create a range from negative 10 to 10 with a step of one. And we can set the D type here to equal torch dot float 32. But we don't actually need to. That's going to be the default. So if we set A here, A dot D type. Then we've got torch float 32 and I'm pretty sure if we've got rid of that. Oh, we've got torch in 64. Why is that happening? Well, let's check out A. Oh, it's because we've got integers as our values because we have a step as one. If we turn this into a float, what's going to happen? We get float 32. But we'll keep it. Otherwise, this is going to be what? About a hundred numbers? Yeah, no, that's too many. Let's keep it at negative 10 to 10 and we'll set the D type here to torch float 32. Beautiful. So it looks like PyTorch's default data type for integers is in 64. But we're going to work with float 32 because float 32, if our data wasn't float 32 with the functions we're about to create, we might run into some errors. So let's visualize this data. I want you to guess, is this a straight line or non-straight line? You've got three seconds. One, two, three. Straight line. There we go. We've got negative 10 to positive 10 up here or nine. Close enough. And so how would we turn this straight line? If it's a straight line, it's linear. How would we perform the relu activation function on this? Now, we could of course call torch relu on A. Actually, let's in fact just plot this. PLT dot plot on torch relu. What does this look like? Boom, there we go. But we want to replicate the relu function. So let's go nn dot relu. What does it do? We've seen this before. So we need the max. We need to return based on an input. We need the max of zero and x. So let's give it a shot. We'll come here. Again, we need more space. There can never be enough code space here. I like writing lots of code. I don't know about you. But let's go relu. We'll take an input x, which will be some form of tensor. And we'll go return torch dot maximum. I think you could just do torch dot max. But we'll try maximum. Torch dot tensor zero. So the maximum is going to return the max between whatever this is. One option and whatever the other option is. So inputs must be tensors. So maybe we could just give a type hint here that this is torch dot tensor. And this should return a tensor too. Return torch dot tensor. Beautiful. You're ready to try it out. Let's see what our relu function does. Relu A. Wonderful. It looks like we got quite a similar output to before. Here's our original A. So we've got negative numbers. There we go. So recall that the relu activation function turns all negative numbers into zero because it takes the maximum between zero and the input. And if the input's negative, well then zero is bigger than it. And it leaves all of the positive values as they are. So that's the beauty of relu. Quite simple, but very effective. So let's plot relu activation function. Our custom one. We will go PLT dot plot. We'll call our relu function on A. Let's see what this looks like. Oh, look at us go. Well done. Just the exact same as the torch relu function. Easy as that. And what's another nonlinear activation function that we've used before? Well, I believe one of them is if we go down to here, what did we say before? Sigmoid. Where is that? Where are you, Sigmoid? Here we go. Hello, Sigmoid. Oh, this has got a little bit more going on here. One over one plus exponential of negative x. So Sigmoid or this little symbol for Sigmoid of x, which is an input. We get this. So let's try and replicate this. I might just bring this one in here. Right now, let's do the same for Sigmoid. So what do we have here? Well, we want to create a custom Sigmoid. And we want to have some sort of input, x. And we want to return one divided by, do we have the function in Sigmoid? One divided by one plus exponential. One plus torch dot exp for exponential on negative x. And we might put the bottom side in brackets so that it does that operation. I reckon that looks all right to me. So one divided by one plus torch exponential of negative x. Do we have that? Yes, we do. Well, there's only one real way to find out. Let's plot the torch version of Sigmoid. Torch dot Sigmoid and we'll pass in x. See what happens. And then, oh, we have a. My bad. A is our tensor. What do we get? We get a curved line. Wonderful. And then we go plt dot plot. And we're going to use our Sigmoid function on a. Did we replicate torch's Sigmoid function? Yes, we did. Ooh, now. See, this is what's happening behind the scenes with our neural networks. Of course, you could do more complicated activation functions or layers and whatnot. And you can try to replicate them. In fact, that's a great exercise to try and do. But we've essentially across the videos and the sections that we've done, we've replicated our linear layer. And we've replicated the relu. So we've actually built this model from scratch, or we could if we really wanted to. But it's a lot easier to use PyTorch's layers because we're building neural networks here like Lego bricks, stacking together these layers in some way, shape, or form. And because they're a part of PyTorch, we know that they've been error-tested and they compute as fast as possible behind the scenes and use GPU and get a whole bunch of benefits. PyTorch offers a lot of benefits by using these layers rather than writing them ourselves. And so this is what our model is doing. It's literally like to learn these values and decrease the loss function and increase the accuracy. It's combining linear layers and nonlinear layers or nonlinear functions. Where's our relu function here? A relu function like this behind the scenes. So just combining linear and nonlinear functions to fit a data set. And that premise remains even on our small data set and on very large data sets and very large models. So with that being said, I think it's time for us to push on. We've covered a fair bit of code here. But we've worked on a binary classification problem. Have we worked on a multi-class classification problem yet? Do we have that here? Where's my fun graphic? We have multi-class classification. I think that's what we cover next. We're going to put together all of the steps in our workflow that we've covered for binary classification. But now let's move on to a multi-class classification problem. If you're with me, I'll see you in the next video. Welcome back. In the last few videos we've been harnessing the power of nonlinearity. Specifically non-straight line functions and we replicated some here. And we learned that a neural network combines linear and nonlinear functions to find patterns in data. And for our simple red versus blue dots, once we added a little bit of nonlinearity, we found the secret source of to start separating our blue and red dots. And I also issued you the challenge to try and improve this and I think you can do it. So hopefully you've given that a go. But now let's keep pushing forward. We're going to reiterate over basically everything that we've done, except this time from the point of view of a multi-class classification problem. So I believe we're up to section eight, putting it all together with a multi-class classification problem. Beautiful. And recall the difference between binary classification equals one thing or another such as cat versus dog. If you were building a cat versus dog image classifier, spam versus not spam for say emails that were spam or not spam or even internet posts on Facebook or Twitter or one of the other internet services. And then fraud or not fraud for credit card transactions. And then multi-class classification is more than one thing or another. So we could have cat versus dog versus chicken. So I think we've got all the skills to do this. Our architecture might be a little bit different for a multi-class classification problem. But we've got so many building blocks now. It's not funny. Let's clean up this and we'll add some more code cells and just to reiterate. So we've gone over nonlinearity. The question is what could you draw if you had an unlimited amount of straight linear and non-straight, nonlinear lines, I believe you could draw some pretty intricate patterns. And that is what our neural networks are doing behind the scenes. And so we also learned that if we wanted to just replicate some of these nonlinear functions, some of the ones that we've used before, we could create a range. Linear activation is just the line itself. And then if we wanted to do sigmoid, we get this curl here. And then if we wanted to do relu, well, we saw how to replicate the relu function as one. These both are nonlinear. And of course, torch.nn has far more nonlinear activations where they came from just as it has far more different layers. And you'll get used to these with practice. And that's what we're doing here. So let's go back to the keynote. So this is what we're going to be working on. Multi-class classification. So there's one of the big differences here. We use the softmax activation function versus sigmoid. There's another big difference here. Instead of binary cross entropy, we use just cross entropy. But I think most of it's going to stay the same. We're going to see this in action in a second. But let's just describe our problem space. Just to go visual, we've covered a fair bit here. Well done, everyone. So binary versus multi-class classification. Binary one thing or another. Zero or one. Multi-class could be three things. Could be a thousand things. Could be 5,000 things. Could be 25 things. So more than one thing or another. But that's the basic premise we're going to go with. Let's create some data, hey? 8.1. Creating a 20 multi-class data set. And so to create our data set, we're going to import our dependencies. We're going to re-import torch, even though we already have it. Just for a little bit of completeness. And we're going to go map plotlib. So we can plot, as always, we like to get visual where we can. Visualize, visualize, visualize. We're going to import from scikitlearn.datasets. Let's get make blobs. Now, where would I get this from? SKlearn.datasets. What do we get? 20 data sets. Do we have classification? 20 data sets. Do we have blobs? If we just go make scikitlearn. Classification data sets. What do we get? Here's one option. There's also make blobs. Beautiful. Make blobs. This is a code for that. So let's just copy this in here. And make blobs. We're going to see this in action anyway. Make blobs. As you might have guessed, it makes some blobs for us. I like blobs. It's a fun word to say. Blobs. So we want train test split because we want to make a data set and then we want to split it into train and test. Let's set the number of hyper parameters. So set the hyper parameters for data creation. Now I got these from the documentation here. Number of samples. How many blobs do we want? How many features do we want? So say, for example, we wanted two different classes. That would be binary classification. Say, for example, you wanted 10 classes. You could set this to 10. And we're going to see what the others are in practice. But if you want to read through them, you can well and truly do that. So let's set up. We want num classes. Let's double what we've been working with. We've been working with two classes, red dots or blue dots. Let's step it up a notch. We'll go to four classes. Watch out, everyone. And we're going to go number of features will be two. So we have the same number of features. And then the random seed is going to be 42. You might be wondering why these are capitalized. Well, generally, if we do have some hyper parameters that we say set at the start of a notebook, you'll find it's quite common for people to write them as capital letters just to say that, hey, these are some settings that you can change. You don't have to, but I'm just going to introduce that anyway because you might stumble upon it yourself. So create multi-class data. We're going to use the make blobs function here. So we're going to create some x blobs, some feature blobs and some label blobs. Let's see what these look like in a second. I know I'm just saying blobs a lot. But we pass in here, none samples. How many do we want? Let's create a thousand as well. That could really be a hyper parameter, but we'll just leave that how it is for now. Number of features is going to be num features. Centres equals num classes. So we're going to create four classes because we've set up num classes equal to four. And then we're going to go center standard deviation. We'll give them a little shake up, add a little bit of randomness in here. Give the clusters a little shake up. We'll mix them up a bit. Make it a bit hard for our model. But we'll see what this does in a second. Random state equals random seed, which is our favorite random seed 42. Of course, you can set it whatever number you want, but I like 42. Oh, and we need a comma here, of course. Beautiful. Now, what do we have to do here? Well, because we're using scikit-learn and scikit-learn leverages NumPy. So let's turn our data into tenses. Turn data into tenses. And how do we do that? Well, we grab x blob and we call torch from NumPy from NumPy. If I could type, that would be fantastic. That's all right. We're doing pretty well today. Haven't made too many typos. We did make a few in a couple of videos before, but hey. I'm only human. So we're going to torch from NumPy and we're going to pass in the y blob. And we'll turn it into torch dot float because remember NumPy defaults as float 64, whereas PyTorch likes float 32. So split into training and test. And we're going to create x blob train y or x test. x blob test. We'll keep the blob nomenclature here. y blob train and y blob test. And here's again where we're going to leverage the train test split function from scikit-learn. So thank you for that scikit-learn. x blob and we're going to pass the y blob. So features, labels, x is the features, y are the labels. And a test size, we've been using a test size of 20%. That means 80% of the data will be for the training data. That's a fair enough split with our data set. And we're going to set the random seed to random seed because generally normally train test split is random, but because we want some reproducibility here, we're passing random seeds. Finally, we need to get visual. So let's plot the data. Right now we've got a whole bunch of code and a whole bunch of talking, but not too much visuals going on. So we'll write down here, visualize, visualize, visualize. And we can call in plot.figure. What size do we want? I'm going to use my favorite hand in poker, which is 10-7, because it's generally worked out to be a good plot size. In my experience, anyway, we'll go x blob. And we want the zero index here, and then we'll grab x blob as well. And you might notice that we're visualizing the whole data set here. That's perfectly fine. We could visualize, train and test separately if we really wanted to, but I'll leave that as a level challenge to you. And we're going to go red, yellow, blue. Wonderful. What do we get wrong? Oh, of course we got something wrong. Santa STD, did we spell center wrong? Cluster STD. That's what I missed. So, cluster STD. Standard deviation. What do we get wrong? Random seed. Oh, this needs to be random state. Oh, another typo. You know what? Just as I said, I wasn't getting too many typos. I'll get three. There we go. Look at that. Our first multi-class classification data set. So if we set this to zero, what does it do to our clusters? Let's take note of what's going on here, particularly the space between all of the dots. Now, if we set this cluster STD to zero, what happens? We get dots that are really just, look at that. That's too easy. Let's mix it up, all right? Now, you can pick whatever value you want here. I'm going to use 1.5, because now we need to build a model that's going to draw some lines between these four colors. Two axes, four different classes. But it's not going to be perfect because we've got some red dots that are basically in the blue dots. And so, what's our next step? Well, we've got some data ready. It's now time to build a model. So, I'll see you in the next video. Let's build our first multi-class classification model. Welcome back. In the last video, we created our multi-class classification data set, using scikit-learn's make-blobs function. And now, why are we doing this? Well, because we're going to put all of what we've covered so far together. But instead of using binary classification or working with binary classification data, we're going to do it with multi-class classification data. So, with that being said, let's get into building our multi-class classification model. So, we'll create a little heading here. Building a multi-class classification model in PyTorch. And now, I want you to have a think about this. We spent the last few videos covering non-linearity. Does this data set need non-linearity? As in, could we separate this data set with pure straight lines? Or do we need some non-straight lines as well? Have a think about that. It's okay if you're not sure, we're going to be building a model to fit this data anyway, or draw patterns in this data anyway. And now, before we get into coding a model, so for multi-class classification, we've got this. For the input layer shape, we need to define the in features. So, how many in features do we have for the hidden layers? Well, we could set this to whatever we want, but we're going to keep it nice and simple for now. For the number of neurons per hidden layer, again, this could be almost whatever we want, but because we're working with a relatively small data set, we've only got four different classes, we've only got a thousand data points, we'll keep it small as well, but you could change this. Remember, you can change any of these because they're hyper parameters. For the output layer shape, well, how many output features do we want? We need one per class, how many classes do we have? We have four clusters of different dots here, so we'll need four output features. And then if we go back, we have an output activation of softmax, we haven't seen that yet, and then we have a loss function, rather than binary cross entropy, we have cross entropy. And then optimizer as well is the same as binary classification, two of the most common are SGDs, stochastic gradient descent, or the atom optimizer, but of course, the torch.optim package has many different options as well. So let's push forward and create our first multi-class classification model. First, we're going to create, we're going to get into the habit of creating device agnostic code, and we'll set the device here, equals CUDA, nothing we haven't seen before, but again, we're doing this to put it all together, so that we have a lot of practice. Is available, else CPU, and let's go device. So we should have a GPU available, beautiful CUDA. Now, of course, if you don't, you can go change runtime type, select GPU here, that will restart the runtime, you'll have to run all of the code that's before this cell as well, but I'm going to be using a GPU. You don't necessarily need one because our data set's quite small, and our models aren't going to be very large, but we set this up so we have device agnostic code. And so let's build a multi-class classification model. Look at us go, just covering all of the foundations of classification in general here, and we now know that we can combine linear and non-linear functions to create neural networks that can find patterns in almost any kind of data. So I'm going to call my class here blob model, and it's going to, of course, inherit from nn.module, and we're going to upgrade our class here. We're going to take some inputs here, and I'll show you how to do this. If you're familiar with Python classes, you would have already done stuff like this, but we're going to set some parameters for our models, because as you write more and more complex classes, you'll want to take inputs here. And I'm going to pre-build the, or pre-set the hidden units parameter to eight. Because I've decided, you know what, I'm going to start off with eight hidden units, and if I wanted to change this to 128, I could. But in the constructor here, we've got some options. So we have input features. We're going to set these programmatically as inputs to our class when we instantiate it. The same with output features as well. And so here, we're going to call self. Oh, no, super. Sorry. I always get this mixed up dot init. And underscore underscore. Beautiful. So we could do a doc string here as well. So let's write in this. Initializes multi-class classification. If I could spell class e-fication model. Oh, this is great. And then we have some arcs here. This is just a standard way of writing doc strings. If you want to find out, this is Google Python doc string guide. There we go. Google Python style guide. This is where I get mine from. You can scroll through this. This is just a way to write Python code. Yeah, there we go. So we've got a little sentence saying what's going on. We've got arcs. We've got returns and we've got errors if something's going on. So I highly recommend checking that out. Just a little tidbit. So this is if someone was to use our class later on. They know what the input features are. Input features, which is an int, which is number of input features to the model. And then, of course, we've got output features, which is also an int. Which is number of output features of the model. And we've got the red line here is telling us we've got something wrong, but that's okay. And then the hidden features. Oh, well, this is number of output classes for the case of multi-class classification. And then the hidden units. Int and then number of hidden units between layers and then the default is eight. Beautiful. And then under that, we'll just do that. Is that going to fix itself? Yeah, there we go. We could put in what it returns. Returns, whatever it returns. And then an example use case, but I'll leave that for you to fill out. If you like. So let's instantiate some things here. What we might do is write self dot linear layer stack. Self dot linear layer stack. And we will set this as nn dot sequential. Ooh, we haven't seen this before. But we're just going to look at a different way of writing a model here. Previously, when we created a model, what did we do? Well, we instantiated each layer as its own parameter here. And then we called on them one by one, but we did it in a straightforward fashion. So that's why we're going to use sequential here to just step through our layers. We're not doing anything too fancy, so we'll just set up a sequential stack of layers here. And recall that sequential just steps through, passes the data through each one of these layers one by one. And because we've set up the parameters up here, input features can equal to input features. And output features, what is this going to be? Is this going to be output features or is this going to be hidden units? It's going to be hidden units because it's not the final layer. We want the final layer to output our output features. So input features, this will be hidden units because remember the subsequent layer needs to line up with the previous layer. Output features, we're going to create another one that outputs hidden units. And then we'll go in n.linear in features equals hidden units because it takes the output features of the previous layer. So as you see here, the output features of this feeds into here. The output features of this feeds into here. And then finally, this is going to be our final layer. We'll do three layers. Output features equals output features. Wonderful. So how do we know the values of each of these? Well, let's have a look at xtrain.shape and ytrain.shape. So in the case of x, we have two input features. And in the case of y, well, this is a little confusing as well because y is a scalar. But what do you think the values for y are going to be? Well, let's go NP. Or is there torch.unique? I'm not sure. Let's find out together, hey? Torch unique. Zero on one, ytrain. Oh, we need y blob train. That's right, blob. I'm too used to writing blob. And we need blob train, but I believe it's the same here. And then blob. There we go. So we have four classes. So we need an output features value of four. And now if we wanted to add nonlinearity here, we could put it in between our layers here like this. But I asked the question before, do you think that this data set needs nonlinearity? Well, let's leave it in there to begin with. And one of the challenges for you, oh, do we need commerce here? I think we need commerce here. One of the challenges for you will be to test the model with nonlinearity and without nonlinearity. So let's just leave it in there for the time being. What's missing from this? Well, we need a forward method. So def forward self X. What can we do here? Well, because we've created this as a linear layer stack using nn.sequential, we can just go return linear layer stack and pass it X. And what's going to happen? Whatever input goes into the forward method is just going to go through these layers sequentially. Oh, we need to put self here because we've initialized it in the constructor. Beautiful. And now let's create an instance of blob model and send it to the target device. We'll go model four equals blob model. And then we can use our input features parameter, which is this one here. And we're going to pass it a value of what? Two. And then output features. Why? Because we have two X features. Now, the output feature is going to be the same as the number of classes that we have for. If we had 10 classes, we'd set it to 10. So we'll go four. And then the hidden units is going to be eight by default. So we don't have to put this here, but we're going to put it there anyway. And then, of course, we're going to send this to device. And then we're going to go model four. What do we get wrong here? Unexpected keyword argument output features. Do we spell something wrong? No doubt. We've got a spelling mistake. Output features. Output features. Oh, out features. Ah, that's what we needed. Out features, not output. I've got a little confused there. Okay. There we go. Okay, beautiful. So just recall that the parameter here for an end up linear. Did you pick up on that? Is out features not output features. Output features, a little confusing here, is our final layout output layers number of features there. So we've now got a multi-class classification model that lines up with the data that we're using. So the shapes line up. Beautiful. Well, what's next? Well, we have to create a loss function. And, of course, a training loop. So I'll see you in the next few videos. And let's do that together. Welcome back. In the last video, we created our multi-class classification model. And we did so by subclassing an end up module. And we set up a few parameters for our class constructor here. So that when we made an instance of the blob model, we could customize the input features. The output features. Remember, this lines up with how many features X has. And the output features here lines up with how many classes are in our data. So if we had 10 classes, we could change this to 10. And it would line up. And then if we wanted 128 hidden units, well, we could change that. So we're getting a little bit more programmatic with how we create models here. And as you'll see later on, a lot of the things that we've built in here can also be functionalized in a similar matter. But let's keep pushing forward. What's our next step? If we build a model, if we refer to the workflow, you'd see that we have to create a loss function. And an optimizer for a multi-class classification model. And so what's our option here for creating a loss function? Where do we find loss functions in PyTorch? I'm just going to get out of this. And I'll make a new tab here. And if we search torch.nn Because torch.nn is the basic building box for graphs. In other words, neural networks. Where do we find loss functions? Hmm, here we go. Beautiful. So we've seen that L1 loss or MSE loss could be used for regression, predicting a number. And I'm here to tell you as well that for classification, we're going to be looking at cross entropy loss. Now, this is for multi-class classification. For binary classification, we work with BCE loss. And of course, there's a few more here, but I'm going to leave that as something that you can explore on your own. Let's jump in to cross entropy loss. So what do we have here? This criterion computes. Remember, a loss function in PyTorch is also referred to as a criterion. You might also see loss function referred to as cost function, C-O-S-T. But I call them loss functions. So this criterion computes the cross entropy loss between input and target. Okay, so the input is something, and the target is our target labels. It is useful when training a classification problem with C classes. There we go. So that's what we're doing. We're training a classification problem with C classes, C is a number of classes. If provided the optional argument, weight should be a 1D tensor assigning a weight to each of the classes. So we don't have to apply a weight here, but why would you apply a weight? Well, it says, if we look at weight here, this is particularly useful when you have an unbalanced training set. So just keep this in mind as you're going forward. If you wanted to train a dataset that has imbalanced samples, in our case we have the same number of samples for each class, but sometimes you might come across a dataset with maybe you only have 10 yellow dots. And maybe you have 500 blue dots and only 100 red and 100 light blue dots. So you have an unbalanced dataset. So that's where you can come in and have a look at the weight parameter here. But for now, we're just going to keep things simple. We have a balanced dataset, and we're going to focus on using this loss function. If you'd like to read more, please, you can read on here. And if you wanted to find out more, you could go, what is cross entropy loss? And I'm sure you'll find a whole bunch of loss functions. There we go. There's the ML cheat sheet. I love that. The ML glossary, that's one of my favorite websites. Towards data science, you'll find that website, Wikipedia. Machine learning mastery is also another fantastic website. But you can do that all in your own time. Let's code together, hey. We'll set up a loss function. Oh, and one more resource before we get into code is that we've got the architecture, well, the typical architecture of a classification model. The loss function for multi-class classification is cross entropy or torch.nn.cross entropy loss. Let's code it out. If in doubt, code it out. So create a loss function for multi-class classification. And then we go, loss fn equals, and then dot cross entropy loss. Beautiful. And then we want to create an optimizer. Create an optimizer for multi-class classification. And then the beautiful thing about optimizers is they're quite flexible. They can go across a wide range of different problems. So the optimizer. So two of the most common, and I say most common because they work quite well. Across a wide range of problems. So that's why I've only listed two here. But of course, within the torch dot opt in module, you will find a lot more different optimizers. But let's stick with SGD for now. And we'll go back and go optimizer equals torch dot opt in for optimizer SGD for stochastic gradient descent. The parameters we want our optimizer to optimize model four, we're up to our fourth model already. Oh my goodness. Model four dot parameters. And we'll set the learning rate to 0.1. Of course, you could change the learning rate if you wanted to. In fact, I'd encourage you to see what happens if you do because why the learning rate is a hyper parameter. I'm better at writing code than I am at spelling. You can change. Wonderful. So we've now got a loss function and an optimizer for a multi class classification problem. What's next? Well, we could start to build. Building a training loop. We could start to do that, but I think we have a look at what the outputs of our model are. So more specifically, so getting prediction probabilities for a multi class pie torch model. So my challenge to you before the next video is to have a look at what happens if you pass x blob test through a model. And remember, what is a model's raw output? What is that referred to as? Oh, I'll let you have a think about that before the next video. I'll see you there. Welcome back. In the last video, we created a loss function and an optimizer for our multi class classification model. And recall the loss function measures how wrong our model's predictions are. And the optimizer optimizer updates our model parameters to try and reduce the loss. So that's what that does. And I also issued the challenge of doing a forward pass with model four, which is the most recent model that we created. And oh, did I just give you some code that wouldn't work? Did I do that on purpose? Maybe, maybe not, you'll never know. So if this did work, what are the raw outputs of our model? Let's get some raw outputs of our model. And if you recall, the raw outputs of a model are called logits. So we got a runtime error expected. All tensors to be on the same device are of course. Why did this come up? Well, because if we go next model for dot parameters, and if we check device, what happens here? Oh, we need to bring this in. Our model is on the CUDA device, whereas our data is on the CPU still. Can we go X? Is our data a tensor? Can we check the device parameter of that? I think we can. I might be proven wrong here. Oh, it's on the CPU. Of course, we're getting a runtime error. Did you catch that one? If you did, well done. So let's see what happens. But before we do a forward pass, how about we turn our model into a vowel mode to make some predictions with torch dot inference mode? We'll make some predictions. We don't necessarily have to do this because it's just tests, but it's a good habit. Oh, why prads? Equals, what do we get? Why prads? And maybe we'll just view the first 10. What do we get here? Oh, my goodness. How much are numbers on a page? Is this the same format as our data or our test labels? Let's have a look. No, it's not. Okay. Oh, we need why blob test. Excuse me. We're going to make that mistake a fair few times here. So we need to get this into the format of this. Hmm. How can we do that? Now, I want you to notice one thing as well is that we have one value here per one value, except that this is actually four values. Now, why is that? We have one, two, three, four. Well, that is because we set the out features up here. Our model outputs four features per sample. So each sample right now has four numbers associated with it. And what are these called? These are the logits. Now, what we have to do here, so let's just write this down in order to evaluate and train and test our model. We need to convert our model's outputs, outputs which are logits to prediction probabilities, and then to prediction labels. So we've done this before, but for binary classification. So we have to go from logits to predprobs to pred labels. All right, I think we can do this. So we've got some logits here. Now, how do we convert these logits to prediction probabilities? Well, we use an activation function. And if we go back to our architecture, what's our output activation here? For a binary classification, we use sigmoid. But for multi-class classification, these are the two main differences between multi-class classification and binary classification. One uses softmax, one uses cross entropy. And it's going to take a little bit of practice to know this off by heart. It took me a while, but that's why we have nice tables like this. And that's why we write a lot of code together. So we're going to use a softmax function here to convert out logits. Our models raw outputs, which is this here, to prediction probabilities. And let's see that. So convert our models, logit outputs to prediction probabilities. So let's create why predprobs. So I like to call prediction probabilities predprobs for short. So torch dot softmax. And then we go why logits. And we want it across the first dimension. So let's have a look. If we print why logits, we'll get the first five values there. And then look at the conversion here. Why logits? Oh, why predprobs? That's what we want to compare. Predprobs. Five. Let's check this out. Oh, what did we get wrong here? Why logits? Do we have why logits? Oh, no. We should change this to why logits, because really that's the raw output of our model here. Why logits? Let's rerun that. Check that. We know that these are different to these, but we ideally want these to be in the same format as these, our test labels. These are our models predictions. And now we should be able to convert. There we go. Okay, beautiful. What's happening here? Let's just get out of this. And we will add a few code cells here. So we have some space. Now, if you wanted to find out what's happening with torch dot softmax, what could you do? We could go torch softmax. See what's happening. Softmax. Okay, so here's the function that's happening. We replicated some nonlinear activation functions before. So if you wanted to replicate this, what could you do? Well, if in doubt, code it out. You could code this out. You've got the tools to do so. We've got softmax to some X input takes the exponential of X. So torch exponential over the sum of torch exponential of X. So I think you could code that out if you wanted to. But let's for now just stick with what we've got. We've got some logits here, and we've got some softmax, some logits that have been passed through the softmax function. So that's what's happened here. We've passed our logits as the input here, and it's gone through this activation function. These are prediction probabilities. And you might be like, Daniel, these are still just numbers on a page. But you also notice that none of them are negative. Okay, and there's another little tidbit about what's going on here. If we sum one of them up, let's get the first one. Will this work? And if we go torch dot sum, what happens? Ooh, they all sum up to one. So that's one of the effects of the softmax function. And then if we go torch dot max of Y-pred probes. So this is a prediction probability. For multi class, you'll find that for this particular sample here, the 0th sample, this is the maximum number. And so our model, what this is saying is our model is saying, this is the prediction probability. This is how much I think it is class 0. This number here, it's in order. This is how much I think it is class 1. This is how much I think it is class 2. This is how much I think it is class 3. And so we have one value for each of our four classes, a little bit confusing because it's 0th indexed. But the maximum value here is this index. And so how would we get the particular index value of whatever the maximum number is across these values? Well, we can take the argmax and we get tensor 1. So for this particular sample, this one here, our model, and these guesses or these predictions aren't very good. Why is that? Well, because our model is still just predicting with random numbers, we haven't trained it yet. So this is just random output here, basically. But for now, the premise still remains that our model thinks that for this sample using random numbers, it thinks that index 1 is the right class or class number 1 for this particular sample. And then for this next one, what's the maximum number here? I think it would be the 0th index and the same for the next one. What's the maximum number here? Well, it would be the 0th index as well. But of course, these numbers are going to change once we've trained our model. So how do we get the maximum index value of all of these? So this is where we can go, convert our model's prediction probabilities to prediction labels. So let's do that. We can go ypreds equals torch dot argmax on ypredprobs. And if we go across the first dimension as well. So now let's have a look at ypreds. Do we have prediction labels in the same format as our ylob test? Beautiful. Yes, we do. Although many of them are wrong, as you can see, ideally they would line up with each other. But because our model is predicting or making predictions with random numbers, so they haven't been our model hasn't been trained. All of these are basically random outputs. So hopefully once we train our model, it's going to line up the values of the predictions are going to line up with the values of the test labels. But that is how we go from our model's raw outputs to prediction probabilities to prediction labels for a multi-class classification problem. So let's just add the steps here, logits, raw output of the model, predprobs, to get the prediction probabilities, use torch dot softmax or the softmax activation function, pred labels, take the argmax of the prediction probabilities. So we're going to see this in action later on when we evaluate our model, but I feel like now that we know how to go from logits to prediction probabilities to pred labels, we can write a training loop. So let's set that up. 8.5, create a training loop, and testing loop for a multi-class pytorch model. This is so exciting. I'll see you in the next video. Let's build our first training and testing loop for a multi-class pytorch model, and I'll give you a little hint. It's quite similar to the training and testing loops we've built before, so you might want to give it a shot. I think you can. Otherwise, we'll do it together in the next video. Welcome back. In the last video, we covered how to go from raw logits, which is the output of the model, the raw output of the model for a multi-class pytorch model. Then we turned our logits into prediction probabilities using torch.softmax, and then we turn those prediction probabilities into prediction labels by taking the argmax, which returns the index of where the maximum value occurs in the prediction probability. So for this particular sample, with these four values, because it outputs four values, because we're working with four classes, if we were working with 10 classes, it would have 10 values, the principle of these steps would still be the same. So for this particular sample, this is the value that's the maximum, so we would take that index, which is 1. For this one, the index 0 has the maximum value. For this sample, same again, and then same again, I mean, these prediction labels are just random, right? So they're quite terrible. But now we're going to change that, because we're going to build a training and testing loop for our multi-class model. Let's do that. So fit the multi-class model to the data. Let's go set up some manual seeds. Torch dot manual seed, again, don't worry too much if our numbers on the page are not exactly the same. That's inherent to the randomness of machine learning. We're setting up the manual seeds to try and get them as close as possible, but these do not guarantee complete determinism, which means the same output. But we're going to try. The direction is more important. Set number of epochs. We're going to go epochs. How about we just do 100? I reckon we'll start with that. We can bump it up to 1000 if we really wanted to. Let's put the data to the target device. What's our target device? Well, it doesn't really matter because we've set device agnostic code. So whether we're working with a CPU or a GPU, our code will use whatever device is available. I'm typing blog again. So we've got x blob train, y blob train. This is going to go where? It's going to go to the device. And y blob train to device. And we're going to go x blob test. And then y blob test equals x blob test to device. Otherwise, we'll get device issues later on, and we'll send this to device as well. Beautiful. Now, what do we do now? Well, we loop through data. Loop through data. So for an epoch in range epochs for an epoch in a range. Epox. I don't want that auto correct. Come on, Google Colab. Work with me here. We're training our first multi-class classification model. This is serious business. No, I'm joking. It's actually quite fun. So model four dot train. And let's do the forward pass. I'm not going to put much commentary here because we've been through this before. But what are the logits? The logits are raw outputs of our model. So we'll just go x blob train. And x test. I didn't want that. X blob train. Why did that do that? I need to turn off auto correct in Google Colab. I've been saying it for a long time. Y pred equals torch dot softmax. So what are we doing here? We're going from logits to prediction probabilities here. So torch softmax. Y logits. Across the first dimension. And then we can take the argmax of this and dim equals one. In fact, I'm going to show you a little bit of, oh, I've written blog here. Maybe auto correct would have been helpful for that. A little trick. You don't actually have to do the torch softmax. The logits. If you just took the argmax of the logits is a little test for you. Just take the argmax of the logits. And see, do you get the same similar outputs as what you get here? So I've seen that done before, but for completeness, we're going to use the softmax activation function because you'll often see this in practice. And now what do we do? We calculate the loss. So the loss FM. We're going to use categorical cross entropy here or just cross entropy loss. So if we check our loss function, what do we have? We have cross entropy loss. We're going to compare our models, logits to y blob train. And then what are we going to do? We're going to calculate the accuracy because we're working with the classification problem. It'd be nice if we had accuracy as well as loss. Accuracy is one of the main classification evaluation metrics. y pred equals y pred. y pred. And now what do we do? Well, we have to zero grab the optimizer. Optimizer zero grad. Then we go loss backward. And then we step the optimizer. Optimizer step, step, step. So none of these steps we haven't covered before. We do the forward pass. We calculate the loss and any evaluation metric we choose to do so. We zero the optimizer. We perform back propagation on the loss. And we step the optimizer. The optimizer will hopefully behind the scenes update the parameters of our model to better represent the patterns in our training data. And so we're going to go testing code here. What do we do for testing code? Well, or inference code. We set our model to a vowel mode. That's going to turn off a few things behind the scenes that our model doesn't need such as dropout layers, which we haven't covered. But you're more than welcome to check them out if you go torch and end. Dropout layers. Do we have dropout? Dropout layers. Beautiful. And another one that it turns off is match norm. Beautiful. And also you could search this. What does model dot a vowel do? And you might come across stack overflow question. One of my favorite resources. So there's a little bit of extra curriculum. But I prefer to see things in action. So with torch inference mode, again, this turns off things like gradient tracking and a few more things. So we get as fast as code as possible because we don't need to track gradients when we're making predictions. We just need to use the parameters that our model has learned. We want X blob test to go to our model here for the test logits. And then for the test preds, we're going to do the same step as what we've done here. We're going to go torch dot softmax on the test logits across the first dimension. And we're going to call the argmax on that to get the index value of where the maximum prediction probability value occurs. We're going to calculate the test loss or loss function. We're going to pass in what the test logits here. Then we're going to pass in why blob test compare the test logits behind the scenes. Our loss function is going to do some things that convert the test logits into the same format as our test labels and then return us a value for that. Then we'll also calculate the test accuracy here by passing in the why true as why blob test. And we have the y pred equals y pred. Wonderful. And then what's our final step? Well, we want to print out what's happening because I love seeing metrics as our model trains. It's one of my favorite things to watch. If we go if epoch, let's do it every 10 epochs because we've got 100 so far. It equals zero. Let's print out a nice f string with epoch. And then we're going to go loss. What do we put in here? We'll get our loss value, but we'll take it to four decimal places and we'll get the training accuracy, which will be acc. And we'll take this to two decimal places and we'll get a nice percentage sign there. And we'll go test loss equals test loss and we'll go there. And finally, we'll go test act at the end here, test act. Now, I'm sure by now we've written a fair few of these. You're either getting sick of them or you're like, wow, I can actually do the steps through here. And so don't worry, we're going to be functionalizing all of this later on, but I thought I'm going to include them as much as possible so that we can practice as much as possible together. So you ready? We're about to train our first multi-class classification model. In three, two, one, let's go. No typos. Of course. What do we get wrong here? Oh, this is a fun error. Runtime error. NLL loss for reduced CUDA kernel to the index not implemented for float. Okay, that's a pretty full on bunch of words there. I don't really know how to describe that. But here's a little hint. We've got float there. So we know that float is what? Float is a form of data. It's a data type. So potentially because that's our hint. We said not implemented for float. So maybe we've got something wrong up here. Our data is of the wrong type. Can you see anywhere where our data might be the wrong type? Well, let's print it out. Where's our issue here? Why logits? Why blob train? Okay. Why blob train? And why logits? What does why blob train look like? Why blob train? Okay. And what's the D type here? Float. Okay. So it's not implemented for float. Hmm. Maybe we have to turn them into a different data type. What if we went type torch long tensor? What happens here? Expected all tensors to be on the same device but found at least two devices. Oh, my goodness. What do we got wrong here? Type torch long tensor. Friends. Guess what? I found it. And so it was to do with this pesky little data type issue here. So if we run this again and now this one took me a while to find and I want you to know that, that behind the scenes, even though, again, this is a machine learning cooking show, it still takes a while to troubleshoot code and you're going to come across this. But I thought rather than spend 10 minutes doing it in a video, I'll show you what I did. So we went through this and we found that, hmm, there's something going on here. I don't quite know what this is. And that seems quite like a long string of words, not implemented for float. And then we looked back at the line where it went wrong. And so that we know that maybe the float is hinting at that one of these two tensors is of the wrong data type. Now, why would we think that it's the wrong data type? Well, because anytime you see float or int or something like that, it generally hints at one of your data types being wrong. And so the error is actually right back up here where we created our tensor data. So we turned our labels here into float, which generally is okay in PyTorch. However, this one should be of type torch dot long tensor, which we haven't seen before. But if we go into torch long tensor, let's have a look torch dot tensor. Do we have long tensor? Here we go. 64 bit integer signed. So why do we need torch dot long tensor? And again, this took me a while to find. And so I want to express this that in your own code, you probably will butt your head up against some issues and errors that do take you a while to find. And data types is one of the main ones. But if we look in the documentation for cross entropy loss, the way I kind of found this out was this little hint here. The performance of the criteria is generally better when the target contains class indices, as this allows for optimized computation. But I read this and it says target contains class indices. I'm like, hmm, alza indices already, but maybe they should be integers and not floats. But then if you actually just look at the sample code, you would find that they use d type equals torch dot long. Now, that's the thing with a lot of code around the internet is that sometimes the answer you're looking for is a little bit buried. But if in doubt, run the code and butt your head up against a wall for a bit and keep going. So let's just rerun all of this and see do we have an error here? Let's train our first multi-class classification model together. No arrows, fingers crossed. But what did we get wrong here? OK, so we've got different size. We're slowly working through all of the errors in deep learning here. Value error, input batch size 200 to match target size 200. So this is telling me maybe our test data, which is of size 200, is getting mixed up with our training data, which is of size 800. So we've got test loss, the test logits, model four. What's the size? Let's print out print test logits dot shape and wine blob test. So troubleshooting on the fly here, everyone. What do we got? Torch size 800. Where are our test labels coming from? Wine blob test equals, oh, there we go. Ah, did you catch that before? Maybe you did, maybe you didn't. But I think we should be right here. Now if we just comment out this line, so we've had a data type issue and we've had a shape issue. Two of the main and machine learning, oh, and again, we've had some issues. Wine blob test. What's going on here? I thought we just changed the shape. Oh, no, we have to go up and reassign it again because now this is definitely why blob, yes. Let's rerun all of this, reassign our data. We are running into every single error here, but I'm glad we're doing this because otherwise you might not see how to troubleshoot these type of things. So the size of a tensor much match the size. Oh, we're getting the issue here. Test spreads. Oh, my goodness. We have written so much code here. Test spreads. So instead of wire spread, this should be test spreads. Fingers crossed. Are we training our first model yet or what? There we go. Okay, I'm going to printing out some stuff. I don't really want to print out that stuff. I want to see the loss go down, so I'm going to. So friends, I hope you know that we've just been through some of the most fundamental troubleshooting steps. And you might say, oh, Daniel, there's a cop out because you're just coding wrong. And in fact, I code wrong all the time. But we've now worked out how to troubleshoot them shape errors and data type errors. But look at this. After all of that, thank goodness. Our loss and accuracy go in the directions that we want them to go. So our loss goes down and our accuracy goes up. Beautiful. So it looks like that our model is working on a multi-class classification data set. So how do we check that? Well, we're going to evaluate it in the next step by visualize, visualize, visualize. So you might want to give that a shot. See if you can use our plot decision boundary function. We'll use our model to separate the data here. So it's going to be much the same as what we did for binary classification. But this time we're using a different model and a different data set. I'll see you there. Welcome back. In the last video, we went through some of the steps that we've been through before in terms of training and testing a model. But we also butted our heads up against two of the most common issues in machine learning and deep learning in general. And that is data type issues and shape issues. But luckily we were able to resolve them. And trust me, you're going to run across many of them in your own deep learning and machine learning endeavors. So I'm glad that we got to have a look at them and sort of I could show you what I do to troubleshoot them. But in reality, it's a lot of experimentation. Run the code, see what errors come out, Google the errors, read the documentation, try again. But with that being said, it looks like that our model, our multi-class classification model has learned something. The loss is going down, the accuracy is going up. But we can further evaluate this by making and evaluating predictions with a PyTorch multi-class model. So how do we make predictions? We've seen this step before, but let's reiterate. Make predictions, we're going to set our model to what mode, a vowel mode. And then we're going to turn on what context manager, inference mode. Because we want to make inference, we want to make predictions. Now what do we make predictions on? Or what are the predictions? They're going to be logits because why? They are the raw outputs of our model. So we'll take model four, which we just trained and we'll pass it the test data. Well, it needs to be blob test, by the way. I keep getting that variable mixed up. We just had enough problems with the data, Daniel. We don't need any more. You're completely right. I agree with you. But we're probably going to come across some more problems in the future. Don't you worry about that. So let's view the first 10 predictions. Why logits? What do they look like? All right, just numbers on the page. They're raw logits. Now how do we go from go from logits to prediction probabilities? How do we do that? With a multi-class model, we go y-pred-probs equals torch.softmax on the y-logits. And we want to do it across the first dimension. And what do we have when we go pred-probs? Let's go up to the first 10. Are we apples to apples yet? What does our y-blog test look like? We're not apples to apples yet, but we're close. So these are prediction probabilities. You'll notice that we get some fairly different values here. And remember, the one closest to one here, the value closest to one, which looks like it's this, the index of the maximum value is going to be our model's predicted class. So this index is index one. And does it correlate here? Yes. One, beautiful. Then we have index three, which is the maximum value here. Three, beautiful. And then we have, what do we have here? Index two, yes. Okay, wonderful. But let's not step through that. We're programmers. We can do this with code. So now let's go from pred-probs to pred-labels. So y-pred-equals, how do we do that? Well, we can do torch.argmax on the y-pred-probs. And then we can pass dim equals one. We could also do it this way. So y-pred-probs call dot-argmax. There's no real difference between these two. But we're just going to do it this way, called torch.argmax. y-pred-es, let's view the first 10. Are we now comparing apples to apples when we go y-blob test? Yes, we are. Have a go at that. Look, one, three, two, one, zero, three, one, three, two, one, zero, three. Beautiful. Now, we could line these up and look at and compare them all day. I mean, that would be fun. But I know what something that would be even more fun. Let's get visual. So plot dot figure. And we're going to go fig size equals 12.6, just because the beauty of this being a cooking show is I kind of know what ingredients work from ahead of time. Despite what you saw in the last video with all of that trouble shooting. But I'm actually glad that we did that because seriously. Shape issues and data type issues. You're going to come across a lot of them. The two are the main issues I troubleshoot, aside from device issues. So let's go x-blob train and y-blob train. And we're going to do another plot here. We're going to get subplot one, two, two. And we're going to do this for the test data. Test and then plot decision boundary. Plot decision boundary with model four on x-blob test and y-blob test as well. Let's see this. Did we train a multi-class? Oh my goodness. Yes, we did. Our code worked faster than I can speak. Look at that beautiful looking plot. We've separated our data almost as best as what we could. Like there's some here that are quite inconspicuous. And now what's the thing about these lines? With this model have worked, I posed the question a fair few videos ago, whenever we created our multi-class model that could we separate this data without nonlinear functions. So how about we just test that? Since we've got the code ready, let's go back up. We've got nonlinear functions here. We've got relu here. So I'm just going to recreate our model there. So I just took relu out. That's all I did. Commented it out, this code will still all work. Or fingers crossed it will. Don't count your chickens before they hatch. Daniel, come on. We're just going to rerun all of these cells. All the code's going to stay the same. All we did was we took the nonlinearity out of our model. Is it still going to work? Oh my goodness. It still works. Now why is that? Well, you'll notice that the lines are a lot more straighter here. Did we get different metrics? I'll leave that for you to compare. Maybe these will be a little bit different. I don't think they're too far different. But that is because our data is linearly separable. So we can draw straight lines only to separate our data. However, a lot of the data that you deal with in practice will require linear and nonlinear. Hence why we spent a lot of time on that. Like the circle data that we covered before. And let's look up an image of a pizza. If you're building a food vision model to take photos of food and separate different classes of food, could you do this with just straight lines? You might be able to, but I personally don't think that I could build a model to do such a thing. And in fact, PyTorch makes it so easy to add nonlinearities to our model, we might as well have them in so that our model can use it if it needs it and if it doesn't need it, well, hey, it's going to build a pretty good model as we saw before if we included the nonlinearities in our model. So we could uncomment these and our model is still going to perform quite well. That is the beauty of neural networks, is that they decide the numbers that should represent outdated the best. And so, with that being said, we've evaluated our model, we've trained our multi-class classification model, we've put everything together, we've gone from binary classification to multi-class classification. I think there's just one more thing that we should cover and that is, let's go here, section number nine, a few more classification metrics. So, as I said before, evaluating a model, let's just put it here, to evaluate our model, our classification models, that is, evaluating a model is just as important as training a model. So, I'll see you in the next video. Let's cover a few more classification metrics. Welcome back. In the last video, we evaluated our multi-class classification model visually. And we saw that it did pretty darn well, because our data turned out to be linearly separable. So, our model, even without non-linear functions, could separate the data here. However, as I said before, most of the data that you deal with will require some form of linear and non-linear function. So, just keep that in mind, and the beauty of PyTorch is that it allows us to create models with linear and non-linear functions quite flexibly. So, let's write down here. If we wanted to further evaluate our classification models, we've seen accuracy. So, accuracy is one of the main methods of evaluating classification models. So, this is like saying, out of 100 samples, how many does our model get right? And so, we've seen our model right now is that testing accuracy of nearly 100%. So, it's nearly perfect. But, of course, there were a few tough samples, which I mean a little bit hard. Some of them are even within the other samples, so you can forgive it a little bit here for not being exactly perfect. What are some other metrics here? Well, we've also got precision, and we've also got recall. Both of these will be pretty important when you have classes with different amounts of values in them. So, precision and recall. So, accuracy is pretty good to use when you have balanced classes. So, this is just text on a page for now. F1 score, which combines precision and recall. There's also a confusion matrix, and there's also a classification report. So, I'm going to show you a few code examples of where you can access these, and I'm going to leave it to you as extra curriculum to try each one of these out. So, let's go into the keynote. And by the way, you should pay yourself on the back here because we've just gone through all of the PyTorch workflow for a classification problem. Not only just binary classification, we've done multi-class classification as well. So, let's not stop there, though. Remember, building a model, evaluating a model is just as important as building a model. So, we've been through non-linearity. We've seen how we could replicate non-linear functions. We've talked about the machine learning explorer's motto, visualize, visualize, visualize. Machine learning practitioners motto is experiment, experiment, experiment. I think I called that the machine learning or data scientist motto. Same thing, you know? And steps in modeling with PyTorch. We've seen this in practice, so we don't need to look at these slides. I mean, they'll be available on the GitHub if you want them, but here we are. Some common classification evaluation methods. So, we have accuracy. There's the formal formula if you want, but there's also code, which is what we've been focusing on. So, we wrote our own accuracy function, which replicates this. By the way, Tp stands for not toilet paper, it stands for true positive, Tn is true negative, false positive, Fp, false negative, Fn. And so, the code, we could do torch metrics. Oh, what's that? But when should you use it? The default metric for classification problems. Note, it is not the best for imbalanced classes. So, if you had, for example, 1,000 samples of one class, so, number one, label number one, but you had only 10 samples of class zero. So, accuracy might not be the best to use for then. For imbalanced data sets, you might want to look into precision and recall. So, there's a great article called, I think it's beyond accuracy, precision and recall, which gives a fantastic overview of, there we go. This is what I'd recommend. There we go, by Will Coestron. So, I'd highly recommend this article as some extra curriculum here. See this article for when to use precision recall. We'll go there. Now, if we look back, there is the formal formula for precision, true positive over true positive plus false positive. So, higher precision leads to less false positives. So, if false positives are not ideal, you probably want to increase precision. If false negatives are not ideal, you want to increase your recall metric. However, you should be aware that there is such thing as a precision recall trade-off. And you're going to find this in your experimentation. Precision recall trade-off. So, that means that, generally, if you increase precision, you lower recall. And, inversely, if you increase precision, you lower recall. So, check out that, just to be aware of that. But, again, you're going to learn this through practice of evaluating your models. If you'd like some code to do precision and recall, you've got torchmetrics.precision, or torchmetrics.recall, as well as scikit-learn. So scikit-learn has implementations for many different classification metrics. Torchmetrics is a PyTorch-like library. And then we have F1 score, which combines precision and recall. So, it's a good combination if you want something in between these two. And then, finally, there's a confusion matrix. I haven't listed here a classification report, but I've listed it up here. And we can see a classification report in scikit-learn. Classification report. Classification report kind of just puts together all of the metrics that we've talked about. And we can go there. But I've been talking a lot about torchmetrics. So let's look up torchmetrics' accuracy. Torchmetrics. So this is a library. I don't think it comes with Google Colab at the moment, but you can import torchmetrics, and you can initialize a metric. So we've built our own accuracy function, but the beauty of using torchmetrics is that it uses PyTorch-like code. So we've got metric, preds, and target. And then we can find out what the value of the accuracy is. And if you wanted to implement your own metrics, you could subclass the metric class here. But let's just practice this. So let's check to see if I'm going to grab this and copy this in here. If you want access to a lot of PyTorch metrics, see torchmetrics. So can we import torchmetrics? Maybe it's already in Google Colab. No, not here. But that's all right. We'll go pip install torchmetrics. So Google Colab has access to torchmetrics. And that's going to download from torchmetrics. It shouldn't take too long. It's quite a small package. Beautiful. And now we're going to go from torchmetrics import accuracy. Wonderful. And let's see how we can use this. So setup metric. So we're going to go torchmetric underscore accuracy. We could call it whatever we want, really. But we need accuracy here. We're just going to set up the class. And then we're going to calculate the accuracy of our multi-class model by calling torchmetric accuracy. And we're going to pass it Y threads and Y blob test. Let's see what happens here. Oh, what did we get wrong? Runtime error. Expected all tensors to be on the same device, but found at least two devices. Oh, of course. Now, remember how I said torchmetrics implements PyTorch like code? Well, let's check what device this is on. Oh, it's on the CPU. So something to be aware of that if you use torchmetrics, you have to make sure your metrics are on the same device by using device agnostic code as your data. So if we run this, what do we get? Beautiful. We get an accuracy of 99.5%, which is in line with the accuracy function that we coded ourselves. So if you'd like a lot of pre-built metrics functions, be sure to see either scikit-learn for any of these or torchmetrics for any PyTorch like metrics. But just be aware, if you use the PyTorch version, they have to be on the same device. And if you'd like to install it, what do we have? Where's the metrics? Module metrics? Do we have classification? There we go. So look how many different types of classification metrics there are from torchmetrics. So I'll leave that for you to explore. The resources for this will be here. This is an extracurricular article for when to use precision recall. And another extracurricular would be to go through the torchmetrics module for 10 minutes and have a look at the different metrics for classification. So with that being said, I think we've covered a fair bit. But I think it's also time for you to practice what you've learned. So let's cover some exercises in the next video. I'll see you there. Welcome back. In the last video, we looked at a few more classification metrics, a little bit of a high level overview for some more ways to evaluate your classification models. And I linked some extracurricular here that you might want to look into as well. But we have covered a whole bunch of code together. But now it's time for you to practice some of this stuff on your own. And so I have some exercises prepared. Now, where do you go for the exercises? Well, remember on the learnpytorch.io book, for each one of these chapters, there's a section. Now, just have a look at how much we've covered. If I scroll, just keep scrolling. Look at that. We've covered all of that in this module. That's a fair bit of stuff. But down the bottom of each one is an exercises section. So all exercises are focusing on practicing the code in the sections above, all of these sections here. I've got number one, two, three, four, five, six, seven. Yeah, seven exercises, nice, writing plenty of code. And then, of course, extracurricular. So these are some challenges that I've mentioned throughout the entire section zero two. But I'm going to link this in here. Exercises. But, of course, you can just find it on the learnpytorch.io book. So if we come in here and we just create another heading. Exercises. And extracurricular. And then we just write in here. See exercises and extracurricular. Here. And so if you'd like a template of the exercise code, you can go to the PyTorch deep learning repo. And then within the extras folder, we have exercises and solutions. You might be able to guess what's in each of these exercises. We have O2 PyTorch classification exercises. This is going to be some skeleton code. And then, of course, we have the solutions as well. Now, this is just one form of solutions. But I'm not going to look at those because I would recommend you looking at the exercises first before you go into the solutions. So we have things like import torch. Set up device agnostic code. Create a data set. Turn data into a data frame. And then et cetera, et cetera. For the things that we've done throughout this section. So give that a go. Try it on your own. And if you get stuck, you can refer to the notebook that we've coded together. All of this code here. You can refer to the documentation, of course. And then you can refer to as a last resort, the solutions notebooks. So give that a shot. And congratulations on finishing. Section 02 PyTorch classification. Now, if you're still there, you're still with me. Let's move on to the next section. We're going to cover a few more things of deep learning with PyTorch. I'll see you there. Hello, and welcome back. We've got another section. We've got computer vision and convolutional neural networks with. PyTorch. Now, computer vision is one of my favorite, favorite deep learning topics. But before we get into the materials, let's answer a very important question. And that is, where can you get help? So, first and foremost, is to follow along with the code as best you can. We're going to be writing a whole bunch of PyTorch computer vision code. And remember our motto. If and out, run the code. See what the inputs and outputs are of your code. And that's try it yourself. If you need the doc string to read about what the function you're using does, you can press shift command and space in Google CoLab. Or it might be control if you're on Windows. Otherwise, if you're still stuck, you can search for the code that you're running. You might come across stack overflow or the PyTorch documentation. We've spent a bunch of time in the PyTorch documentation already. And we're going to be referencing a whole bunch in the next module in section three. We're up to now. If you go through all of these four steps, the next step is to try it again. If and out, run the code. And then, of course, if you're still stuck, you can ask a question on the PyTorch deep learning repo. Discussions tab. Now, if we open this up, we can go new discussion. And you can write here section 03 for the computer vision. My problem is, and then in here, you can write some code. Be sure to format it as best you can. That way it'll help us answer it. And then go, what's happening here? Now, why do I format the code in these back ticks here? It's so that it looks like code and that it's easier to read when it's formatted on the GitHub discussion. Then you can select a category. If you have a general chat, an idea, a poll, a Q&A, or a show and tell of something you've made, or what you've learned from the course. For question and answering, you want to put it as Q&A. Then you can click start discussion. And it'll appear here. And that way, they'll be searchable and we'll be able to help you out. So I'm going to get out of this. And oh, speaking of resources, we've got the PyTorch deep learning repo. The links will be where you need the links. All of the code that we're going to write in this section is contained within the section 3 notebook. PyTorch computer vision. Now, this is a beautiful notebook annotated with heaps of text and images. You can go through this on your own time and use it as a reference to help out. If you get stuck on any of the code we write through the videos, check it out in this notebook because it's probably here somewhere. And then finally, let's get out of these. If we come to the book version of the course, this is learnpytorch.io. We've got home. This will probably be updated by the time you look at that. But we have section 03, which is PyTorch computer vision. It's got all of the information about what we're going to cover in a book format. And you can, of course, skip ahead to different subtitles. See what we're going to write here. All of the links you need and extra resources will be at learnpytorch.io. And for this section, it's PyTorch computer vision. With that being said, speaking of computer vision, you might have the question, what is a computer vision problem? Well, if you can see it, it could probably be phrased at some sort of computer vision problem. That's how broad computer vision is. So let's have a few concrete examples. We might have a binary classification problem, such as if we wanted to have two different images. Is this photo of steak or pizza? We might build a model that understands what steak looks like in an image. This is a beautiful dish that I cooked, by the way. This is me eating pizza at a cafe with my dad. And so we could have binary classification, one thing or another. And so our machine learning model may take in the pixels of an image and understand the different patterns that go into what a steak looks like and the same thing with a pizza. Now, the important thing to note is that we won't actually be telling our model what to learn. It will learn those patterns itself from different examples of images. Then we could step things up and have a multi-class classification problem. You're noticing a trend here. We've covered classification before, but classification can be quite broad. It can be across different domains, such as vision or text or audio. But if we were working with multi-class classification for an image problem, we might have, is this a photo of sushi, steak or pizza? And then we have three classes instead of two. But again, this could be 100 classes, such as what Nutrify uses, which is an app that I'm working on. We go to Nutrify.app. This is bare bones at the moment. But right now, Nutrify can classify up to 100 different foods. So if you were to upload an image of food, let's give it a try. Nutrify, we'll go into images, and we'll go into sample food images. And how about some chicken wings? What does it classify this as? Chicken wings. Beautiful. And then if we upload an image of not food, maybe. Let's go to Nutrify. This is on my computer, by the way. You might not have a sample folder set up like this. And then if we upload a photo of a Cybertruck, what does it say? No food found. Please try another image. So behind the scenes, Nutrify is using the pixels of an image and then running them through a machine learning model and classifying it first, whether it's food or not food. And then if it is food, classifying it as what food it is. So right now it works for 100 different foods. So if we have a look at all these, it can classify apples, artichokes, avocados, barbecue sauce. Each of these work at different levels of performance, but that's just something to keep in mind of what you can do. So the whole premise of Nutrify is to upload a photo of food and then learn about the nutrition about it. So let's go back to our keynote. What's another example? Well, we could use computer vision for object detection, where you might answer the question is, where's the thing we're looking for? So for example, this car here, I caught them on security camera, actually did a hit and run on my new car, wasn't that much of an expensive car, but I parked it on the street and this person, the trailer came off the back of their car and hit my car and then they just picked the trailer up and drove away. But I went to my neighbor's house and had to look at their security footage and they found this car. So potentially, you could design a machine learning model to find this certain type of car. It was an orange jute, by the way, but the images were in black and white to detect to see if it ever recognizes a similar car that comes across the street and you could go, hey, did you crash into my car the other day? I didn't actually find who it was. So sadly, it was a hit and run. But that's object detection, finding something in an image. And then you might want to find out whether the different sections in this image. So this is a great example at what Apple uses on their devices, iPhones and iPads and whatnot, to segregate or segment the different sections of an image, so person one, person two, skin tones, hair, sky, original. And then it enhances each of these sections in different ways. So that's a practice known as computational photography. But the whole premise is how do you segment different portions of an image? And then there's a great blog post here that talks about how it works and what it does and what kind of model that's used. I'll leave that as extra curriculum if you'd like to look into it. So if you have these images, how do you enhance the sky? How do you make the skin tones look how they should? How do you remove the background if you really wanted to? So all of this happens on device. So that's where I got that image from, by the way. Semantic Mars. And this is another great blog, Apple Machine Learning Research. So to keep this in mind, we're about to see another example for computer vision, which is Tesla Computer Vision. A lot of companies have websites such as Apple Machine Learning Research where they share a whole bunch of what they're up to in the world of machine learning. So in Tesla's case, they have eight cameras on each of their self-driving cars that fuels their full self-driving beta software. And so they use computer vision to understand what's going on in an image and then plan what's going on. So this is three-dimensional vector space. And what this means is they're basically taking these different viewpoints from the eight different cameras, feeding them through some form of neural network, and turning the representation of the environment around the car into a vector. So a long string of numbers. And why will it do that? Well, because computers understand numbers far more than they understand images. So we might be able to recognize what's happening here. But for a computer to understand it, we have to turn it into vector space. And so if you want to have a look at how Tesla uses computer vision, so this is from Tesla's AI Day video. I'm not going to play it all because it's three hours long, but I watched it and I really enjoyed it. So there's some information there. And there's a little tidbit there. If you go to two hours and one minute and 31 seconds on the same video, have a look at what Tesla do. Well, would you look at that? Where have we seen that before? That's some device-agnostic code, but with Tesla's custom dojo chip. So Tesla uses PyTorch. So the exact same code that we're writing, Tesla uses similar PyTorch code to, of course, they write PyTorch code to suit their problem. But nonetheless, they use PyTorch code to train their machine learning models that power their self-driving software. So how cool is that? And if you want to have a look at another example, there's plenty of different Tesla self-driving videos. So, oh, we can just play it right here. I was going to click the link. So look, this is what happens. If we have a look in the environment, Tesla, the cameras, understand what's going on here. And then it computes it into this little graphic here on your heads-up display in the car. And it kind of understands, well, I'm getting pretty close to this car. I'm getting pretty close to that car. And then it uses this information about what's happening, this perception, to plan where it should drive next. And I believe here it ends up going into it. It has to stop. Yeah, there we go. Because we've got a stop sign. Look at that. It's perceiving the stop sign. It's got two people here. It just saw a car drive pass across this street. So that is pretty darn cool. That's just one example of computer vision, one of many. And how would you find out what computer vision can be used for? Here's what I do. What can computer vision be used for? Plenty more resources. So, oh, there we go. 27 most popular computer vision applications in 2022. So we've covered a fair bit there. But what are we going to cover specifically with PyTorch code? Well, broadly, like that. We're going to get a vision data set to work with using torch vision. So PyTorch has a lot of different domain libraries. Torch vision helps us deal with computer vision problems. And there's existing data sets that we can leverage to play around with computer vision. We're going to have a look at the architecture of a convolutional neural network, also known as a CNN with PyTorch. We're going to look at an end-to-end multi-class image classification problem. So multi-class is what? More than one thing or another? Could be three classes, could be a hundred. We're going to look at steps at modeling with CNNs in PyTorch. So we're going to create a convolutional network with PyTorch. We're going to pick a last function and optimize it to suit our problem. We're going to train a model, training a model a model. A little bit of a typo there. And then we're going to evaluate a model, right? So we might have typos with our text, but we'll have less typos in the code. And how are we going to do this? Well, we could do it cook, so we could do it chemis. Well, we're going to do it a little bit of both. Part art, part science. But since this is a machine learning cooking show, we're going to be cooking up lots of code. So in the next video, we're going to cover the inputs and outputs of a computer vision problem. I'll see you there. So in the last video, we covered what we're going to cover, broadly. And we saw some examples of what computer vision problems are. Essentially, anything that you're able to see, you can potentially turn into a computer vision problem. And we're going to be cooking up lots of machine learning, or specifically pie torch, computer vision code. You see I fixed that typo. Now let's talk about what the inputs and outputs are of a typical computer vision problem. So let's start with a multi-classification example. And so we wanted to take photos of different images of food and recognize what they were. So we're replicating the functionality of Nutrify. So take a photo of food and learn about it. So we might start with a bunch of food images that have a height and width of some sort. So we have width equals 224, height equals 224, and then they have three color channels. Why three? Well, that's because we have a value for red, green and blue. So if we look at this up, if we go red, green, blue image format. So 24-bit RGB images. So a lot of images or digital images have some value for a red pixel, a green pixel and a blue pixel. And if you were to convert images into numbers, they get represented by some value of red, some value of green and some value of blue. That is exactly the same as how we'd represent these images. So for example, this pixel here might be a little bit more red, a little less blue, and a little less green because it's close to orange. And then we convert that into numbers. So what we're trying to do here is essentially what we're trying to do with all of the data that we have with machine learning is represented as numbers. So the typical image format to represent an image because we're using computer vision. So we're trying to figure out what's in an image. The typical way to represent that is in a tensor that has a value for the height, width and color channels. And so we might numerically encode these. In other words, represent our images as a tensor. And this would be the inputs to our machine learning algorithm. And in many cases, depending on what problem you're working on, an existing algorithm already exists for many of the most popular computer vision problems. And if it doesn't, you can build one. And then you might fashion this machine learning algorithm to output the exact shapes that you want. In our case, we want three outputs. We want one output for each class that we have. We want a prediction probability for sushi. We want a prediction probability for steak. And we want a prediction probability for pizza. Now in our case, in this iteration, looks like our model got one of them wrong because the highest value was assigned to the wrong class here. So for the second image, it assigned a prediction probability of 0.81 for sushi. Now, keep in mind that you could change these classes to whatever your particular problem is. I'm just simplifying this and making it three. You could have a hundred. You could have a thousand. You could have five. It's just, it depends on what you're working with. And so we might use these predicted outputs to enhance our app. So if someone wants to take a photo of their plate of sushi, our app might say, hey, this is a photo of sushi. Here's some information about those, the sushi rolls or the same for steak, the same for pizza. Now it might not always get it right because after all, that's what machine learning is. It's probabilistic. So how would we improve these results here? Well, we could show our model more and more images of sushi steak and pizza so that it builds up a better internal representation of said images. So when it looks at images it's never seen before or images outside its training data set, it's able to get better results. But just keep in mind this whole process is similar no matter what computer vision problem you're working with. You need a way to numerically encode your information. You need a machine learning model that's capable of fitting the data in the way that you would like it to be fit in our case classification. You might have a different type of model if you're working with object detection, a different type of model if you're working with segmentation. And then you need to fashion the outputs in a way that best suit your problem as well. So let's push forward. Oh, by the way, the model that often does this is a convolutional neural network. In other words, a CNN. However, you can use many other different types of machine learning algorithms here. It's just that convolutional neural networks typically perform the best with image data. Although with recent research, there is the transformer architecture or deep learning model that also performs fairly well or very well with image data. So just keep that in mind going forward. But for now we're going to focus on convolutional neural networks. And so we might have input and output shapes because remember one of the chief machine learning problems is making sure that your tensor shapes line up with each other, the input and output shapes. So if we encoded this image of stake here, we might have a dimensionality of batch size with height color channels. And now the ordering here could be improved. It's usually height then width. So alphabetical order. And then color channels last. So we might have the shape of none, two, two, four, two, four, three. Now where does this come from? So none could be the batch size. Now it's none because we can set the batch size to whatever we want, say for example 32. Then we might have a height of two to four and a width of two to four and three color channels. Now height and width are also customizable. You might change this to be 512 by 512. What that would mean is that you have more numbers representing your image. And in sense would take more computation to figure out the patterns because there is simply more information encoded in your image. But two, two, four, two, four is a common starting point for images. And then 32 is also a very common batch size, as we've seen in previous videos. But again, this could be changed depending on the hardware you're using, depending on the model you're using. You might have a batch size to 64. You might have a batch size of 512. It's all problem specific. And that's this line here. These will vary depending on the problem you're working on. So in our case, our output shape is three because we have three different classes for now. But again, if you have a hundred, you might have an output shape of a hundred. If you have a thousand, you might have an output shape of a thousand. The same premise of this whole pattern remains though. Numerically encode your data, feed it into a model, and then make sure the output shape fits your specific problem. And so, for this section, Computer Vision with PyTorch, we're going to be building CNNs to do this part. We're actually going to do all of the parts here, but we're going to focus on building a convolutional neural network to try and find patterns in data, because it's not always guaranteed that it will. Finally, let's look at one more problem. Say you had grayscale images of fashion items, and you have quite small images. They're only 28 by 28. The exact same pattern is going to happen. You numerically represent it, use it as inputs to a machine learning algorithm, and then hopefully your machine learning algorithm outputs the right type of clothing that it is. In this case, it's a t-shirt. But I've got dot dot dot here because we're going to be working on a problem that uses ten different types of items of clothing. And the images are grayscale, so there's not much detail. So hopefully our machine learning algorithm can recognize what's going on in these images. There might be a boot, there might be a shirt, there might be pants, there might be a dress, etc, etc. But we numerically encode our images into dimensionality of batch size, height with color channels. This is known as NHWC, or number of batches, or number of images in a batch, height with C, or color channels. This is color channels last. Why am I showing you two forms of this? Do you notice color channels in this one is color channels first? So color channels height width? Well, because you come across a lot of different representations of data full stop, but particularly image data in PyTorch and other libraries, many libraries expect color channels last. However, PyTorch currently at the time of recording this video may change in the future, defaults to representing image data with color channels first. Now this is very important because you will get errors if your dimensionality is in the wrong order. And so there are ways to go in between these two, and there's a lot of debate of which format is the best. It looks like color channels last is going to win over the long term, just because it's more efficient, but again, that's outside the scope, but just keep this in mind. We're going to write code to interact between these two, but it's the same data just represented in different order. And so we could rearrange these shapes to how we want color channels last or color channels first. And once again, the shapes will vary depending on the problem that you're working on. So with that being said, we've covered the input and output shapes. How are we going to see them with code? Well, of course we're going to be following the PyTorch workflow that we've done. So we need to get our data ready, turn it into tenses in some way, shape or form. We can do that with taught division transforms. Oh, we haven't seen that one yet, but we will. We can use torchutilsdata.datasetutils.data.data loader. We can then build a model or pick a pre-trained model to suit our problem. We've got a whole bunch of modules to help us with that, torchNN module, torchvision.models. And then we have an optimizer and a loss function. We can evaluate the model using torch metrics, or we can code our own metric functions. We can of course improve through experimentation, which we will see later on, which we've actually done that, right? We've done improvement through experimentation. We've tried different models, we've tried different things. And then finally, we can save and reload our trained model if we wanted to use it elsewhere. So with that being said, we've covered the workflow. This is just a high-level overview of what we're going to code. You might be asking the question, what is a convolutional neural network, or a CNN? Let's answer that in the next video. I'll see you there. Welcome back. In the last video, we saw examples of computer vision input and output shapes. And we kind of hinted at the fact that convolutional neural networks are deep learning models, or CNNs, that are quite good at recognizing patterns in images. So we left off the last video with the question, what is a convolutional neural network? And where could you find out about that? What is a convolutional neural network? Here's one way to find out. And I'm sure, as you've seen, there's a lot of resources for such things. A comprehensive guide to convolutional neural networks. Which one of these is the best? Well, it doesn't really matter. The best one is the one that you understand the best. So there we go. There's a great video from Code Basics. I've seen that one before, simple explanation of convolutional neural network. I'll leave you to research these things on your own. And if you wanted to look at images, there's a whole bunch of images. I prefer to learn things by writing code. Because remember, this course is code first. As a machine learning engineer, 99% of my time is spent writing code. So that's what we're going to focus on. But anyway, here's the typical architecture of a CNN. In other words, a convolutional neural network. If you hear me say CNN, I'm not talking about the news website. In this course, I'm talking about the architecture convolutional neural network. So this is some PyTorch code that we're going to be working towards building. But we have some hyperparameters slash layer types here. We have an input layer. So we have an input layer, which takes some in channels, and an input shape. Because remember, it's very important in machine learning and deep learning to line up your input and output shapes of whatever model you're using, whatever problem you're working with. Then we have some sort of convolutional layer. Now, what might happen in a convolutional layer? Well, as you might have guessed, as what happens in many neural networks, is that the layers perform some sort of mathematical operation. Now, convolutional layers perform convolving window operation across an image or across a tensor. And discover patterns using, let's have a look, actually. Let's go, nn.com2d. There we go. This is what happens. So the output of our network equals a bias plus the sum of the weight tensor over the convolutional channel out, okay, times input. Now, if you want to dig deeper into what is actually going on here, you're more than welcome to do that. But we're going to be writing code that leverages the torch nn.com2d. And we're going to fix up all of these hyperparameters here so that it works with our problem. Now, what you need to know here is that this is a bias term. We've seen this before. And this is a weight matrix. So a bias vector typically and a weight matrix. And they operate over the input. But we'll see these later on with code. So just keep that in mind. This is what's happening. As with every layer in a neural network, some form of operation is happening on our input data. These operations happen layer by layer until eventually, hopefully, they can be turned into some usable output. So let's jump back in here. Then we have an hidden activation slash nonlinear activation because why do we use nonlinear activations? Well, it's because if our data was nonlinear, non-straight lines, we need the help of straight and non-straight lines to model it, to draw patterns in it. Then we typically have a pooling layer. And I want you to take this architecture. I've said typical here for a reason because these type of architectures are changing all the time. So this is just one typical example of a CNN. It's about as basic as a CNN as you can get. So over time, you will start to learn to build more complex models. You will not only start to learn to build them, you will just start to learn to use them, as we'll see later on in the transfer learning section of the course. And then we have an output layer. So do you notice the trend here? We have an input layer and then we have multiple hidden layers that perform some sort of mathematical operation on our data. And then we have an output slash linear layer that converts our output into the ideal shape that we'd like. So we have an output shape here. And then how does this look in process? While we put in some images, they go through all of these layers here because we've used an end up sequential. And then hopefully this forward method returns x in a usable status or usable state that we can convert into class names. And then we could integrate this into our computer vision app in some way, shape or form. And here's the asterisk here. Note, there are almost an unlimited amount of ways you could stack together a convolutional neural network. This slide only demonstrates one. So just keep that in mind, only demonstrates one. But the best way to practice this sort of stuff is not to stare at a page. It's to if and out, code it out. So let's code, I'll see you in Google CoLab. Welcome back. Now, we've discussed a bunch of fundamentals about computer vision problems and convolutional neural networks. But rather than talk to more slides, well, let's start to code them out. I'm going to meet you at colab.research.google.com. She's going to clean up some of these tabs. And I'm going to start a new notebook. And then I'm going to name this one, this is going to be 03 PyTorch computer vision. And I'm going to call mine video. So just so it has the video tag, because if we go in here, if we go video notebooks of the PyTorch deep learning repo, the video notebooks are stored in here. They've got the underscore video tag. So the video notebooks have all of the code I write exactly in the video. But there are some reference notebooks to go along with it. Let me just write a heading here, PyTorch computer vision. And I'll put a resource here, see reference notebook. Now, of course, this is the one that's the ground truth. It's got all of the code that we're going to be writing. I'm going to put that in here. Explain with text and images and whatnot. And then finally, as we got see reference online book. And that is at learnpytorch.io at section number three, PyTorch computer vision. I'm going to put that in there. And then I'm going to turn this into markdown with command mm. Beautiful. So let's get started. I'm going to get rid of this, get rid of this. How do we start this off? Well, I believe there are some computer vision libraries that you should be aware of. Computer vision libraries in PyTorch. So this is just going to be a text based cell. But the first one is torch vision, which is the base domain library for PyTorch computer vision. So if we look up torch vision, what do we find? We have torch vision 0.12. That's the version that torch vision is currently up to at the time of recording this. So in here, this is very important to get familiar with if you're working on computer vision problems. And of course, in the documentation, this is just another tidbit. We have torch audio for audio problems. We have torch text for text torch vision, which is what we're working on torch rack for recommendation systems torch data for dealing with different data pipelines torch serve, which is for serving PyTorch models and PyTorch on XLA. So I believe that stands for accelerated linear algebra devices. You don't have to worry about these ones for now. We're focused on torch vision. However, if you would like to learn more about a particular domain, this is where you would go to learn more. So there's a bunch of different stuff that's going on here. Transforming and augmenting images. So fundamentally, computer vision is dealing with things in the form of images. Even a video gets converted to an image. We have models and pre-trained weights. So as I referenced before, you can use an existing model that works on an existing computer vision problem for your own problem. We're going to cover that in section, I think it's six, for transfer learning. And then we have data sets, which is a bunch of computer vision data sets, utils, operators, a whole bunch of stuff here. So PyTorch is really, really good for computer vision. I mean, look at all the stuff that's going on here. But that's enough talking about it. Let's just put it in here. Torch vision. This is the main one. I'm not going to link to all of these. All of the links for these, by the way, is in the book version of the course PyTorch Computer Vision. And we have what we're going to cover. And finally, computer vision libraries in PyTorch. Torch vision, data sets, models, transforms, et cetera. But let's just write down the other ones. So we have torch vision, not data sets, something to be aware of. So get data sets and data loading functions for computer vision here. Then we have torch vision. And from torch vision, models is get pre-trained computer vision. So when I say pre-trained computer vision models, we're going to cover this more in transfer learning, as I said. Pre-trained computer vision models are models that have been already trained on some existing vision data and have trained weights, trained patterns that you can leverage for your own problems, that you can leverage for your own problems. Then we have torch vision.transforms. And then we have functions for manipulating your vision data, which is, of course, images to be suitable for use with an ML model. So remember, what do we have to do when we have image data or almost any kind of data? For machine learning, we have to prepare it in a way so it can't just be pure images, so that's what transforms help us out with. Transforms helps to turn our image data into numbers so we can use it with a machine learning model. And then, of course, we have some, these are the torch utils. This is not vision specific, it's entirety of PyTorch specific, and that's data set. So if we wanted to create our own data set with our own custom data, we have the base data set class for PyTorch. And then we have finally torch utils data. These are just good to be aware of because you'll almost always use some form of data set slash data loader with whatever PyTorch problem you're working on. So this creates a Python iterable over a data set. Wonderful. I think these are most of the libraries that we're going to be using in this section. Let's import some of them, hey, so we can see what's going on. Let's go import PyTorch. Import PyTorch. So import torch. We're also going to get NN, which stands for neural network. What's in NN? Well, in NN, of course, we have lots of layers, lots of loss functions, a whole bunch of different stuff for building neural networks. We're going to also import torch vision. And then we're going to go from torch vision. Import data sets because we're going to be using data sets later on to get a data set to work with from torch vision. Well, import transforms. You could also go from torch vision dot transforms import to tensor. This is one of the main ones you'll see for computer vision problems to tensor. You can imagine what it does. But let's have a look. Transforms to tensor. Transforming and augmenting images. So look where we are. We're in pytorch.org slash vision slash stable slash transforms. Over here. So we're in the torch vision section. And we're just looking at transforming and augmenting images. So transforming. What do we have? Transforms are common image transformations of our and the transforms module. They can be trained together using compose. Beautiful. So if we have two tensor, what does this do? Convert a pill image on NumPy and the array to a tensor. Beautiful. That's what we want to do later on, isn't it? Well, this is kind of me giving you a spoiler is we want to convert our images into tensors so that we can use those with our models. But there's a whole bunch of different transforms here and actually one of your extra curriculum is to be to read through each of these packages for 10 minutes. So that's about an hour of reading, but it will definitely help you later on if you get familiar with using the pytorch documentation. After all, this course is just a momentum builder. We're going to write heaves of pytorch code. But fundamentally, you'll be teaching yourself a lot of stuff by reading the documentation. Let's keep going with this. Where were we up to? When we're getting familiar with our data, mapplotlib is going to be fundamental for visualization. Remember, the data explorer's motto, visualize, visualize, visualize, become one with the data. So we're going to import mapplotlib.pyplot as PLT. And then finally, let's check the versions. So print torch.version or underscore, underscore version and print torch vision. So by the time you watch this, there might be a newer version of each of these modules out. If there's any errors in the code, please let me know. But this is just a bare minimum version that you'll need to complete this section. I believe at the moment, Google Colab is running 1.11 for torch and maybe 1.10. We'll find out in a second. It just connected. So we're importing pytorch. Okay, there we go. So my pytorch version is 1.10 and it's got CUDA available and torch vision is 0.11. So just make sure if you're running in Google Colab, if you're running this at a later date, you probably have at minimum these versions, you might even have a later version. So these are the minimum versions required for this upcoming section. So we've covered the base computer vision libraries in pytorch. We've got them ready to go. How about in the next video, we cover getting a data set. I'll see you there. Welcome back. So in the last video, we covered some of the fundamental computer vision libraries in pytorch. The main one being torch vision and then modules that stem off torch vision. And then of course, we've got torch utils dot data dot data set, which is the base data set class for pytorch and data loader, which creates a Python irritable over a data set. So let's begin where most machine learning projects do. And that is getting a data set, getting a data set. I'm going to turn this into markdown. And the data set that we're going to be used to demonstrating some computer vision techniques is fashion amnest. Which is a take of the data set we'll be using is fashion amnest, which is a take on the original amnest data set, amnest database, which is modified national institute of standards and technology database, which is kind of like the hello world in machine learning and computer vision, which is these are sample images from the amnest test data set, which are grayscale images of handwritten digits. So this, I believe was originally used for trying to find out if you could use computer vision at a postal service to, I guess, recognize post codes and whatnot. I may be wrong about that, but that's what I know. Yeah, 1998. So all the way back at 1998, how cool is that? So this was basically where convolutional neural networks were founded. I'll let you read up on the history of that. But neural network started to get so good that this data set was quite easy for them to do really well. And that's when fashion amnest came out. So this is a little bit harder if we go into here. This is by Zalando research fashion amnest. And it's of grayscale images of pieces of clothing. So like we saw before the input and output, what we're going to be trying to do is turning these images of clothing into numbers and then training a computer vision model to recognize what the different styles of clothing are. And here's a dimensionality plot of all the different items of clothing. Visualizing where similar items are grouped together, there's the shoes and whatnot. Is this interactive? Oh no, it's a video. Excuse me. There we go. To serious machine learning researchers. We are talking about replacing amnest. Amnest is too easy. Amnest is overused. Amnest cannot represent modern CV tasks. So even now fashion amnest I would say has also been pretty much sold, but it's a good way to get started. Now, where could we find such a data set? We could download it from GitHub. But if we come back to the taught division documentation, have a look at data sets. We have a whole bunch of built-in data sets. And remember, this is your extra curricular to read through these for 10 minutes or so each. But we have an example. We could download ImageNet if we want. We also have some base classes here for custom data sets. We'll see that later on. But if we scroll through, we have image classification data sets. Caltech 101. I didn't even know what all of these are. There's a lot here. CFAR 100. So that's an example of 100 different items. So that would be a 100 class, multi-class classification problem. CFAR 10 is 10 classes. We have amnest. We have fashion amnest. Oh, that's the one we're after. But this is basically what you would do to download a data set from taughtvision.datasets. You would download the data in some way, shape, or form. And then you would turn it into a data loader. So ImageNet is one of the most popular or is probably the gold standard data set for computer vision evaluation. It's quite a big data set. It's got millions of images. But that's the beauty of taught vision is that it allows us to download example data sets that we can practice on. I don't even perform research on from a built-in module. So let's now have a look at the fashion amnest data set. How might we get this? So we've got some example code here, or this is the documentation. taughtvision.datasets.fashion amnest. We have to pass in a root. So where do we want to download the data set? We also have to pass in whether we want the training version of the data set or whether we want the testing version of the data set. Do we want to download it? Yes or no? Should we transform the data in any way shape or form? So we're going to be downloading images through this function call or this class call. Do we want to transform those images in some way? What do we have to do to images before we can use them with a model? We have to turn them into a tensor, so we might look into that in a moment. And target transform is do we want to transform the labels in any way shape or form? So often the data sets that you download from taughtvision.datasets are pre formatted in a way that they can be quite easily used with PyTorch. But that won't always be the case with your own custom data sets. However, what we're about to cover is just important to get an idea of what the computer vision workflow is. And then later on you can start to customize how you get your data in the right format to be used with the model. Then we have some different parameters here and whatnot. Let's just rather than look at the documentation, if and down, code it out. So we'll be using fashion MNIST and we'll start by, I'm going to just put this here, from taughtvision.datasets. And we'll put the link there and we'll start by getting the training data. Set up training data. I'm just going to make some code cells here so that I can code in the middle of the screen. Set up training data. Training data equals data sets dot fashion MNIST. Because recall, we've already from taughtvision. We don't need to import this again, I'm just doing it for demonstration purposes, but from taughtvision import data sets so we can just call data sets dot fashion MNIST. And then we're going to type in root. See how the doc string comes up and tells us what's going on. I personally find this a bit hard to read in Google Colab, so if I'm looking up the documentation, I like to just go into here. But let's code it out. So root is going to be data, so where to download data to. We'll see what this does in a minute. Then we're going to go train. We want the training version of the data set. So as I said, a lot of the data sets that you find in taughtvision.datasets have been formatted into training data set and testing data set already. So this Boolean tells us do we want the training data set? So if that was false, we would get the testing data set of fashion MNIST. Do we want to download it? Do we want to download? Yes, no. So yes, we do. We're going to set that to true. Now what sort of transform do we want to do? So because we're going to be downloading images and what do we have to do to our images to use them with a machine-loading model, we have to convert them into tensors. So I'm going to pass the transform to tensor, but we could also just go torchvision.transforms.to tensor. That would be the exact same thing as what we just did before. And then the target transform, do we want to transform the labels? No, we don't. We're going to see how they come, or the target, sorry. High torch, this is another way, another naming convention. Often uses target for the target that you're trying to predict. So using data to predict the target, which is I often use data to predict a label. They're the same thing. So how do we want to transform the data? And how do we want to transform the labels? And then we're going to do the same for the test data. So we're going to go data sets. You might know what to do here. It's going to be the exact same code as above, except we're going to change one line. We want to store it in data. We want to download the training data set as false because we want the testing version. Do we want to download it? Yes, we do. Do we want to transform it the data? Yes, we do, we want to use to tensor to convert our image data to tensors. And do we want to do a target transform? Well, no, we don't. We want to keep the label slash the targets as they are. Let's see what happens when we run this. Oh, downloading fashion, Evan is beautiful. So this is going to download all of the labels. What do we have? Train images, train labels, lovely, test images, test labels, beautiful. So that's how quickly we can get a data set by using torch vision data sets. Now, if we have a look over here, we have a data folder because we set the root to be data. Now, if we look what's inside here, we have fashion MNIST, exactly what we wanted. Then we have the raw, and then we have a whole bunch of files here, which torch vision has converted into data sets for us. So let's get out of that. And this process would be much the same if we used almost any data set in here. They might be slightly different depending on what the documentation says and depending on what the data set is. But that is how easy torch vision data sets makes it to practice on example computer vision data sets. So let's go back. Let's check out some parameters or some attributes of our data. How many samples do we have? So we'll check the lengths. So we have 60,000 training examples and 10,000 testing examples. So what we're going to be doing is we're going to be building a computer vision model to find patterns in the training data and then use those patterns to predict on the test data. And so let's see a first training example. See the first training example. So we can just index on the train data. Let's get the zero index and then we're going to have a look at the image and the label. Oh my goodness. A whole bunch of numbers. Now you see what the two tensor has done for us? So we've downloaded some images and thanks to this torch vision transforms to tensor. How would we find the documentation for this? Well, we could go and see what this does transforms to tensor. We could go to tensor. There we go. What does this do? Convert a pill image. So that's Python image library image on NumPy array to a tensor. This transform does not support torch script. So converts a pill image on NumPy array height with color channels in the range 0 to 255 to a torch float tensor of shape. See here? This is what I was talking about how PyTorch defaults with a lot of transforms to CHW. So color channels first height then width in that range of zero to one. So typically red, green and blue values are between zero and 255. But neural networks like things between zero and one. And in this case, it is now in the shape of color channels first, then height, then width. However, some other machine learning libraries prefer height, width, then color channels. Just keep that in mind. We're going to see this in practice later on. So we've got an image. We've got a label. Let's check out some more details about it. Remember how we discussed? Oh, there's our label, by the way. So nine, we can go traindata.classes, find some information about our class names. Class names. Beautiful. So number nine would be 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. So this particular tensor seems to relate to an ankle boot. How would we find that out? Well, one second. I'm just going to show you one more thing, class to IDX. Let's go traindata.class to IDX. What does this give us? Class to IDX. This is going to give us a dictionary of different labels and their corresponding index. So if our machine learning model predicted nine or class nine, we can convert that to ankle boot using this attribute of the train data. There are more attributes that you can have a look at if you like. You can go traindata.dot, then I just push tab to find out a bunch of different things. You can go data. That'll be the images, and then I believe you can also go targets. So targets, that's all the labels, which is one big long tensor. Now let's check the shape. Check the shape of our image. So image.shape and label.shape. What are we going to get from that? Oh, label doesn't have a shape. Why is that? Well, because it's only an integer. So oh, beautiful. Look at that. So our image shape is we have a color channel of one. So let me print this out in something prettier, print image shape, which is going to be image shape. Remember how I said it's very important to be aware of the input and output shapes of your models and your data. It's all part of becoming one with the data. So that is what our image shape is. And then if we go next, this is print image label, which is label, but we'll index on class names for label. And then we'll do that wonderful. So our image shape is currently in the format of color channels height width. We got a bunch of different numbers that's representing our image. It's black and white. It only has one color channel. Why do you think it only has one color channel? Because it's black and white, so if we jump back into the keynote, fashion, we've already discussed this, grayscale images have one color channel. So that means that for black, the pixel value is zero. And for white, it's some value for whatever color is going on here. So if it's a very high number, say it's one, it's going to be pure white. If it's like 0.001, it might be a faint white pixel. But if it's exactly zero, it's going to be black. So color images have three color channels for red, green and blue, grayscale have one color channel. But I think we've done enough of visualizing our images as numbers. How about in the next video, we visualize our image as an image? I'll see you there. Welcome back. So in the last video, we checked the input output shapes of our data, and we downloaded the fashion MNIST data set, which is comprised of images or grayscale images of T-shirts, trousers, pullovers, dress, coat, sandal, shirt, sneaker, bag, ankle boot. Now we want to see if we can build a computer vision model to decipher what's going on in fashion MNIST. So to separate, to classify different items of clothing based on their numerical representation. And part of becoming one with the data is, of course, checking the input output shapes of it. So this is a fashion MNIST data set from Zalando Research. Now if you recall, why did we look at our input and output shapes? Well, this is what we looked at before. We have 28 by 28 grayscale images that we want to represent as a tensor. We want to use them as input into a machine learning algorithm, typically a computer vision algorithm, such as a CNN. And we want to have some sort of outputs that are formatted in the ideal shape that we'd like. So in our case, we have 10 different types of clothing. So we're going to have an output shape of 10, but our input shape is what? So by default, PyTorch turns tensors into color channels first. So we have an input shape of none, one, 28, 28. So none is going to be our batch size, which of course we can set that to whatever we'd like. Now input shape format is in NCHW, or in other words, color channels first. But just remember, if you're working with some other machine learning libraries, you may want to use color channels last. So let's have a look at where that might be the case. We're going to visualize our images. So I make a little heading here, 1.2. Now this is all part of becoming one with the data. In other words, understanding its input and output shapes, how many samples there are, what they look like, visualize, visualize, visualize. Let's import mapplotlib. I'm just going to add a few code cells here, import mapplotlib.pyplot as PLT. Now let's create our image and label is our train data zero, and we're going to print the image shape so we can understand what inputs are going into our mapplotlib function. And then we're going to go plot.imshow, and we're going to pass in our image and see what happens, because recall what does our image look like, image? Our image is this big tensor of numbers. And we've got an image shape, 128, 128. Now what happens if we call plot.imshow? What happens there? Oh, we get an error in valid shape, 128, 128 for image data. Now as I said, this is one of the most common errors in machine learning is a shape issue. So the shape of your input tensor doesn't match the expected shape of that tensor. So this is one of those scenarios where our data format, so color channels first, doesn't match up with what mapplotlib is expecting. So mapplotlib expects either just height and width, so no color channel for gray style images, or it also expects the color channels to be last. So we'll see that later on, but for grayscale, we can get rid of that extra dimension by passing in image.squeeze. So do you recall what squeeze does? It's going to remove that singular dimension. If we have a look at what goes on now, beautiful, we get an ankle boot. Well, that's a very pixelated ankle boot, but we're only dealing with 28 by 28 pixels, so not a very high definition image. Let's add the title to it. We're going to add in the label. Beautiful. So we've got the number nine here. So where if we go up to here, that's an ankle boot. Now let's plot this in grayscale. How might we do that? We can do the same thing. We can go plotplt.imshow. We're going to pass in image.squeeze. And we're going to change the color map, C map equals gray. So in mapplotlib, if you ever have to change the colors of your plot, you want to look into the C map property or parameter, or sometimes it's also shortened to just C. But in this case, M show is C map, and we want to plot title, and we're going to pull it in class names and the label integer here. So we have a look at it now. We have an ankle boot, and we can remove the accesses to if we wanted to plot.access, and turn that off. That's going to remove the access. So there we go. That's the type of images that we're dealing with. But that's only a singular image. How about we harness the power of randomness and have a look at some random images from our data set? So how would we do this? Let's go plot more images. We'll set a random seed. So you and I are both looking at as similar as possible images, 42. Now we'll create a plot by calling plot.figure, and we're going to give it a size. We might create a nine by nine grid. So we want to see nine random images from our data set. So rows, calls, or sorry, maybe we'll do four by four. That'll give us 16. We're going to go four i in range, and we're going to go one to rows times columns plus one. So we can print i. What's that going to give us? We want to see 16 images. Oh, they're about. So 16 random images, but used with a manual C to 42 of our data set. This is one of my favorite things to do with any type of data set that I'm looking at, whether it be text, image, audio, doesn't matter. I like to randomly have a look at a whole bunch of samples at the start so that I can become one with the data. With that being said, let's use this loop to grab some random indexes. We can do so using tortures, rand, int, so random integer between zero and length of the training data. This is going to give us a random integer in the range of zero and however many training samples we have, which in our case is what, 60,000 or thereabouts. So we want to create the size of one, and we want to get the item from that so that we have a random index. What is this going to give us? Oh, excuse me, maybe we print that out. There we go. So we have random images. Now, because we're using manual seed, it will give us the same numbers every time. So we have three, seven, five, four, two, three, seven, five, four, two. And then if we just commented out the random seed, we'll get different numbers every time. But this is just to demonstrate, we'll keep the manual seed there for now. You can comment that out if you want different numbers or different images, different indexes each time. So we'll create the image and the label by indexing on the training data at the random index that we're generating. And then we'll create our plot. So Fig or we'll add a subplot, Fig add subplot, and we're going to go rows, calls, I. So at the if index, we're going to add a subplot. Remember, we set rows and columns up to here. And then we're going to go PLT dot in show, we're going to show what we're going to show our image, but we have to squeeze it to get rid of that singular dimension as the color channel. Otherwise, we end up with an issue with map plot lib. We're going to use a color map of gray. So it looks like the image we plotted above. And then for our title, it's going to be our class names indexed with our label. And then we don't want the accesses because that's going to clutter up our plot. Let's see what this looks like. Oh my goodness, look at that. It worked first. Go. Usually visualizations take a fair bit of trial and error. So we have ankle boots, we have shirts, we have bags, we have ankle boots, sandal, shirt, pull over. Oh, do you notice something about the data set right now, pull over and shirt? To me, they look quite similar. Do you think that will cause an issue later on when our model is trying to predict between a pull over and a shirt? How about if we look at some more images? We'll get rid of the random seed so we can have a look at different styles. So have a sandal ankle boot coat, t-shirt, top, shirt, oh, is that a little bit confusing that we have a class for t-shirt and top and shirt? Like I'm not sure about you, but what's the difference between a t-shirt and a shirt? This is just something to keep in mind as a t-shirt and top, does that look like it could be maybe even a dress? Like the shape is there. So this is just something to keep in mind going forward. The chances are if we get confused on our, like you and I looking at our data set, if we get confused about different samples and what they're labeled with, our model might get confused later on. So let's have a look at one more and then we'll go into the next video. So we have sneaker, trouser, shirt, sandal, dress, pull over, bag, bag, t-shirt, oh, that's quite a difficult one. It doesn't look like there's even much going on in that image. But the whole premise of building machine learning models to do this would be could you write a program that would take in the shapes of these images and figure out, write a rule-based program that would go, hey, if it's looked like a rectangle with a buckle in the middle, it's probably a bag? I mean, you probably could after a while, but I prefer to write machine learning algorithms to figure out patterns and data. So let's start moving towards that. We're now going to go on figuring out how we can prepare this data to be loaded into a model. I'll see you there. All right, all right, all right. So we've got 60,000 images of clothing that we'd like to build a computer vision model to classify into 10 different classes. And now that we've visualized a fair few of these samples, do you think that we could model these with just linear lines, so straight lines, or do you think we'll need a model with nonlinearity? So I'm going to write that down. So do you think these items of clothing images could be modeled with pure linear lines, or do you think we'll need nonlinearity? Don't have to answer that now. We could test that out later on. You might want to skip ahead and try to build a model yourself with linear lines or nonlinearities. We've covered linear lines and nonlinearities before, but let's now start to prepare our data even further to prepare data loader. So right now, our data is in the form of PyTorch data sets. So let's have a look at it. Same data. There we go. So we have data set, which is of fashion MNIST. And then if we go test data, we see a similar thing except we have a different number of data points. We have the same transform on each, we've turned them into tenses. So we want to convert them from a data set, which is a collection of all of our data, into a data loader. Paul, that a data loader, turns our data set into a Python iterable. So I'm going to turn this into Markdown, beautiful. More specifically, specific Galilee, can I spell right? I don't know, we want to just code right, we're not here to learn spelling. We want to turn our data into batches, or mini batches. Why would we do this? Well, we may get away with it by building a model to look at all 60,000 samples of our current data set, because it's quite small. It's only comprised of images of 28 by 28 pixels. And when I say quite small, yes, 60,000 images is actually quite small for a deep learning scale data set. Modern data sets could be in the millions of images. But if our computer hardware was able to look at 60,000 samples of 28 by 28 at one time, it would need a fair bit of memory. So we have RAM space up here, we have GPU memory, we have compute memory. But chances are that it might not be able to store millions of images in memory. So what you do is you break a data set from say 60,000 into groups of batches or mini batches. So we've seen batch size before, why would we do this? Well, one, it is more computationally efficient, as in your computing hardware may not be able to look store in memory at 60,000 images in one hit. So we break it down to 32 images at a time. This would be batch size of 32. Now again, 32 is a number that you can change. 32 is just a common batch size that you'll see with many beginner style problems. As you go on, you'll see different batch sizes. This is just to exemplify the concept of mini batches, which is very common in deep learning. And why else would we do this? The second point or the second main point is it gives our neural network more chances to update its gradients per epoch. So what I mean by this, this will make more sense when we write a training loop. But if we were to just look at 60,000 images at one time, we would per epoch. So per iteration through the data, we would only get one update per epoch across our entire data set. Whereas if we look at 32 images at a time, our neural network updates its internal states, its weights, every 32 images, thanks to the optimizer. This will make a lot more sense once we write our training loop. But these are the two of the main reasons for turning our data into mini batches in the form of a data loader. Now if you'd like to learn more about the theory behind this, I would highly recommend looking up Andrew Org mini batches. There's a great lecture on that. So yeah, large-scale machine learning, mini batch gradient descent, mini batch gradient descent. Yeah, that's what it's called mini batch gradient descent. If you look up some results on that, you'll find a whole bunch of stuff. I might just link this one, I'm going to pause that, I'm going to link this in there. So for more on mini batches, see here. Now to see this visually, I've got a slide prepared for this. So this is what we're going to be working towards. There's our input and output shapes. We want to create batch size of 32 across all of our 60,000 training images. And we're actually going to do the same for our testing images, but we only have 10,000 testing images. So this is what our data set's going to look like, batched. So we're going to write some code, namely using the data loader from torch.util.data. We're going to pass it a data set, which is our train data. We're going to give it a batch size, which we can define as whatever we want. For us, we're going to use 32 to begin with. And we're going to set shuffle equals true if we're using the training data. Why would we set shuffle equals true? Well, in case our data set for some reason has order, say we had all of the pants images in a row, we had all of the T-shirt images in a row, we had all the sandal images in a row. We don't want our neural network to necessarily remember the order of our data. We just want it to remember individual patterns between different classes. So we shuffle up the data, we mix it, we mix it up. And then it looks something like this. So we might have batch number zero, and then we have 32 samples. Now I ran out of space when I was creating these, but we got, that was fun up to 32. So this is setting batch size equals 32. So we look at 32 samples per batch. We mix all the samples up, and we go batch, batch, batch, batch, batch, and we'll have, however many batches we have, we'll have number of samples divided by the batch size. So 60,000 divided by 32, what's that, 1800 or something like that? So this is what we're going to be working towards. I did want to write some code in this video, but I think to save it getting too long, we're going to write this code in the next video. If you would like to give this a go on your own, here's most of the code we have to do. So there's the train data loader, do the same for the test data loader. And I'll see you in the next video, and we're going to batchify our fashion MNIST data set. Welcome back. In the last video, we had a brief overview of the concept of mini batches. And so rather than our computer looking at 60,000 images in one hit, we break things down. We turn it into batches of 32. Again, the batch size will vary depending on what problem you're working on. But 32 is quite a good value to start with and try out. And we do this for two main reasons, if we jump back to the code, why would we do this? It is more computationally efficient. So if we have a GPU with, say, 10 gigabytes of memory, it might not be able to store all 60,000 images in one hit. In our data set, because it's quite small, it may be hour or two, but it's better practice for later on to turn things into mini batches. And it also gives our neural network more chances to update its gradients per epoch, which will make a lot more sense once we write our training loop. But for now, we've spoken enough about the theory. Let's write some code to do so. So I'm going to import data loader from torch dot utils dot data, import data loader. And this principle, by the way, preparing a data loader goes the same for not only images, but for text, for audio, whatever sort of data you're working with, mini batches will follow you along or batches of data will follow you along throughout a lot of different deep learning problems. So set up the batch size hyper parameter. Remember, a hyper parameter is a value that you can set yourself. So batch size equals 32. And it's practice. You might see it typed as capitals. You won't always see it, but you'll see it quite often a hyper parameter typed as capitals. And then we're going to turn data sets into iterables. So batches. So we're going to create a train data loader here of our fashion MNIST data set. We're going to use data loader. We're going to see what the doc string is. Or actually, let's look at the documentation torch data loader. This is some extra curriculum for you too, by the way, is to read this data page torch utils not data because no matter what problem you're going with with deep learning or pytorch, you're going to be working with data. So spend 10 minutes just reading through here. I think I might have already assigned this, but this is just so important that it's worth going through again. Read through all of this. Even if you don't understand all of it, what's going on, it's just it helps you know where to look for certain things. So what does it take? Data loader takes a data set. We need to set the batch size to something is the default of one. That means that it would create a batch of one image at a time in our case. Do we want to shuffle it? Do we want to use a specific sampler? There's a few more things going on. Number of workers. Number of workers stands for how many cores on our machine do we want to use to load data? Generally the higher the better for this one, but we're going to keep most of these as the default because most of them are set to pretty good values to begin with. I'll let you read more into the other parameters here. We're going to focus on the first three data set batch size and shuffle true or false. Let's see what we can do. So data set equals our train data, which is 60,000 fashion MNIST. And then we have a batch size, which we're going to set to our batch size hyper parameter. So we're going to have a batch size of 32. And then finally, do we want to shuffle the training data? Yes, we do. And then we're going to do the same thing for the test data loader, except we're not going to shuffle the test data. Now, you can shuffle the test data if you want, but in my practice, it's actually easier to evaluate different models when the test data isn't shuffled. So you shuffle the training data to remove order. And so your model doesn't learn order. But for evaluation purposes, it's generally good to have your test data in the same order because our model will never actually see the test data set during training. We're just using it for evaluation. So the order doesn't really matter to the test data loader. It's just easier if we don't shuffle it, because then if we evaluate it multiple times, it's not been shuffled every single time. So let's run that. And then we're going to check it out, our train data loader and our test data loader. Beautiful. Instances of torch utils data, data loader, data loader. And now let's check out what we've created, hey, I always like to print different attributes of whatever we make, check out what we've created. This is all part of becoming one with the data. So print F, I'm going to go data loaders, and then pass in, this is just going to output basically the exact same as what we've got above. This data loader. And we can also see what attributes we can get from each of these by going train data loader. I don't need caps lock there, train data loader, full stop. And then we can go tab. We've got a whole bunch of different attributes. We've got a batch size. We've got our data set. Do we want to drop the last as in if our batch size overlapped with our 60,000 samples? Do we want to get rid of the last batch? Say for example, the last batch only had 10 samples. Do we want to just drop that? Do we want to pin the memory that's going to help later on if we wanted to load our data faster? A whole bunch of different stuff here. If you'd like to research more, you can find all the stuff about what's going on here in the documentation. But let's just keep pushing forward. What else do we want to know? So let's find the length of the train data loader. We will go length train data loader. So this is going to tell us how many batches there are, batches of, which of course is batch size. And we want print length of test data loader. We want length test data loader batches of batch size dot dot dot. So let's find out some information. What do we have? Oh, there we go. So just we're seeing what we saw before with this one. But this is more interesting here. Length of train data loader. Yeah, we have about 1,875 batches of 32. So if we do 60,000 training samples divided by 32, yeah, it comes out to 1,875. And if we did the same with 10,000 for testing samples of 32, it comes out at 313. This gets rounded up. So this is what I meant, that the last batch will have maybe not 32 because 32 doesn't divide evenly into 10,000, but that's okay. And so this means that our model is going to look at 1,875 individual batches of 32 images, rather than just one big batch of 60,000 images. Now of course, the number of batches we have will change if we change the batch size. So we have 469 batches of 128. And if we reduce this down to one, what do we get? We have a batch per sample. So 60,000 batches of 1, 10,000 batches of 1, we're going to stick with 32. But now let's visualize. So we've got them in train data loader. How would we visualize a batch or a single image from a batch? So let's show a sample. I'll show you how you can interact with a data loader. We're going to use randomness as well. So we'll set a manual seed and then we'll get a random index, random idx equals torch rand int. We're going to go from zero to length of train features batch. Oh, where did I get that from? Excuse me. Getting ahead of myself here. I want to check out what's inside the training data loader. We'll check out what's inside the training data loader because the test data load is going to be similar. So we want the train features batch. So I say features as in the images themselves and the train labels batch is going to be the labels of our data set or the targets in pytorch terminology. So next idar data loader. So because our data loader has 1875 batches of 32, we're going to turn it into an iterable with ita and we're going to get the next batch with next and then we can go here train features batch.shape and we'll get train labels batch.shape. What do you think this is going to give us? Well, there we go. Look at that. So we have a tensor. Each batch we have 32 samples. So this is batch size and this is color channels and this is height and this is width. And then we have 32 labels associated with the 32 samples. Now where have we seen this before, if we go back through our keynote input and output shapes. So we have shape equals 32, 28, 28, 1. So this is color channels last, but ours is currently in color channels first. Now again, I sound like a broken record here, but these will vary depending on the problem you're working with. If we had larger images, what would change or the height and width dimensions would change. If we had color images, the color dimension would change, but the premise is still the same. We're turning our data into batches so that we can pass that to a model. Let's come back. Let's keep going with our visualization. So we want to visualize one of the random samples from a batch and then we're going to go image label equals train features batch and we're going to get the random IDX from that and we'll get the train labels batch and we'll get the random IDX from that. So we're matching up on the, we've got one batch here, train features batch, train labels batch and we're just getting the image and the label at a random index within that batch. So excuse me, I need to set this equal there. And then we're going to go PLT dot in show, what are we going to show? We're going to show the image but we're going to have to squeeze it to remove that singular dimension and then we'll set the C map equal to gray and then we'll go PLT dot title, we'll set the title which is going to be the class names indexed by the label integer and then we can turn off the accesses. You can use off here or you can use false, depends on what you'd like to use. Let's print out the image size because you can never know enough about your data and then print, let's also get the label, label and label shape or label size. Our label will be just a single integer so it might not have a shape but that's okay. Let's have a look. Oh, bag. See, look, that's quite hard to understand. I wouldn't be able to detect that that's a bag. Can you tell me that you could write a program to understand that? That just looks like a warped rectangle to me. But if we had to look at another one, we'll get another random, oh, we've got a random seed so it's going to produce the same image each time. So we have a shirt, okay, a shirt. So we see the image size there, 128, 28. Now, recall that the image size is, it's a single image so it doesn't have a batch dimension. So this is just color channels height width. We'll go again, label four, which is a coat and we could keep doing this to become more and more familiar with our data. But these are all from this particular batch that we created here, coat and we'll do one more, another coat. We'll do one more just to make sure it's not a coat. There we go. We've got a bag. Beautiful. So we've now turned our data into data loaders. So we could use these to pass them into a model, but we don't have a model. So I think it's time in the next video, we start to build model zero. We start to build a baseline. I'll see you in the next video. Welcome back. So in the last video, we got our data sets or our data set into data loaders. So now we have 1,875 batches of 32 images off of the training data set rather than 60,000 in a one big data set. And we have 13 or 313 batches of 32 for the test data set. Then we learned how to visualize it from a batch. And we saw that we have still the same image size, one color channel, 28, 28. All we've done is we've turned them into batches so that we can pass them to our model. And speaking of model, let's have a look at our workflow. Where are we up to? Well, we've got our data ready. We've turned it into tensors through a combination of torch vision transforms, torch utils data dot data set. We didn't have to use that one because torch vision dot data sets did it for us with the fashion MNIST data set, but we did use that one. We did torch utils dot data, the data loader to turn our data sets into data loaders. Now we're up to building or picking a pre-trained model to suit your problem. So let's start simply. Let's build a baseline model. And this is very exciting because we're going to build our first model, our first computer vision model, albeit a baseline, but that's an important step. So I'm just going to write down here. When starting to build a series of machine learning modeling experiments, it's best practice to start with a baseline model. I'm going to turn this into markdown. A baseline model. So a baseline model is a simple model. You will try and improve upon with subsequent models, models slash experiments. So you start simply, in other words, start simply and add complexity when necessary because neural networks are pretty powerful, right? And so they have a tendency to almost do too well on our data set. That's a concept known as overfitting, which we'll cover a little bit more later. But we built a simple model to begin with, a baseline. And then our whole goal will be to run experiments, according to the workflow, improve through experimentation. Again, this is just a guide. It's not set in stone, but this is the general pattern of how things go. Get data ready, build a model, fit the model, evaluate, improve the model. So the first model that we build is generally a baseline. And then later on, we want to improve through experimentation. So let's start building a baseline. But I'm going to introduce to you a new layer that we haven't seen before. That is creating a flatten layer. Now what is a flatten layer? Well, this is best seen when we code it out. So let's create a flatten model, which is just going to be nn.flatten. And where could we find the documentation for this? We go nn flatten, flatten in pytorch, what does it do? Flattens a continuous range of dims into a tensor, for use with sequential. So there's an example there, but I'd rather, if and doubt, code it out. So we'll create the flatten layer. And of course, all nn.flatten or nn.modules could be used as a model on their own. So we're going to get a single sample. So x equals train features batch. Let's get the first one, zero. What does this look like? So it's a tensor, x, maybe we get the shape of it as well, x shape. What do we get? There we go. So that's the shape of x. Keep that in mind when we pass it through the flatten layer. Do you have an inkling of what flatten might do? So our shape to begin with is what, 128, 28. Now let's flatten the sample. So output equals, we're going to pass it to the flatten model, x. So this is going to perform the forward pass internally on the flatten layer. So perform forward pass. Now let's print out what happened. Print, shape before flattening equals x dot shape. And we're going to print shape after flattening equals output dot shape. So we're just taking the output of the flatten model and printing its shape here. Oh, do you notice what happened? Well we've gone from 128, 28 to 1784. Wow what does the output look like? Output. Oh, the values are now in all one big vector and if we squeeze that we can remove the extra dimension. So we've got one big vector of values. Now where did this number come from? Well, if we take this and this is what shape is it? We've got color channels. We've got height. We've got width and now we've flattened it to be color channels, height, width. So we've got one big feature vector because 28 by 28 equals what? We've got one value per pixel, 784. One value per pixel in our output vector. Now where did we see this before? If we go back to our keynote, if we have a look at Tesla's takes eight cameras and then it turns it into a three dimensional vector space, vector space. So that's what we're trying to do here. We're trying to encode whatever data we're working with in Tesla's case. They have eight cameras. Now theirs has more dimensions than ours because they have the time aspect because they're dealing with video and they have multiple different camera angles. We're just dealing with a single image here. But regardless, the concept is the same. We're trying to condense information down into a single vector space. And so if we come back to here, why might we do this? Well, it's because we're going to build a baseline model and we're going to use a linear layer as the baseline model. And the linear layer can't handle multi dimensional data like this. We want it to have a single vector as input. Now this will make a lot more sense after we've coded up our model. Let's do that from torch import and then we're going to go class, fashion, amnest, model V zero. We're going to inherit from an end dot module. And inside here, we're going to have an init function in the constructor. We're going to pass in self. We're going to have an input shape, which we'll use a type hint, which will take an integer because remember, input shape is very important for machine learning models. We're going to define a number of hidden units, which will also be an integer, and then we're going to define our output shape, which will be what do you think our output shape will be? How many classes are we dealing with? We're dealing with 10 different classes. So our output shape will be, I'll save that for later on. I'll let you guess for now, or you might already know, we're going to initialize it. And then we're going to create our layer stack. self.layer stack equals nn.sequential, recall that sequential, whatever you put inside sequential, if data goes through sequential, it's going to go through it layer by layer. So let's create our first layer, which is going to be nn.flatten. So that means anything that comes into this first layer, what's going to happen to it? It's going to flatten its external dimensions here. So it's going to flatten these into something like this. So we're going to flatten it first, flatten our data. Then we're going to pass in our linear layer. And we're going to have how many n features this is going to be input shape, because we're going to define our input shape here. And then we're going to go out features, equals hidden units. And then we're going to create another linear layer here. And we're going to set up n features, equals hidden units. Why are we doing this? And then out features equals output shape. Why are we putting the same out features here as the n features here? Well, because subsequent layers, the input of this layer here, its input shape has to line up with the output shape of this layer here. Hence why we use out features as hidden units for the output of this nn.linear layer. And then we use n features as hidden units for the input value of this hidden layer here. So let's keep going. Let's go def. We'll create the forward pass here, because if we subclass nn.module, we have to override the forward method. The forward method is going to define what? It's going to define the forward computation of our model. So we're just going to return self.layer stack of x. So our model is going to take some input, x, which could be here, x. In our case, it's going to be a batch at a time, and then it's going to pass each sample through the flatten layer. It's going to pass the output of the flatten layer to this first linear layer, and it's going to pass the output of this linear layer to this linear layer. So that's it. Our model is just two linear layers with a flatten layer. The flatten layer has no learnable parameters. Only these two do. And we have no nonlinearities. So do you think this will work? Does our data set need nonlinearities? Well, we can find out once we fit our model to the data, but let's set up an instance of our model. So torch dot manual seed. Let's go set up model with input parameters. So we have model zero equals fashion MNIST model, which is just the same class that we wrote above. And here's where we're going to define the input shape equals 784. Where will I get that from? Well, that's here. That's 28 by 28. So the output of flatten needs to be the input shape here. So we could put 28 by 28 there, or we're just going to put 784 and then write a comment here. This is 28 by 28. Now if we go, I wonder if nn.linear will tell us, nn.linear will tell us what it expects as in features. Size of each input sample, shape, where star means any number of dimensions, including none in features, linear weight, well, let's figure it out. Let's see what happens if in doubt coded out, hey, we'll see what we can do. In units equals, let's go with 10 to begin with. How many units in the hidden layer? And then the output shape is going to be what? Output shape is length of class names, which will be 1 for every class. Beautiful. And now let's go model zero. We're going to keep it on the CPU to begin with. We could write device-agnostic code, but to begin, we're going to send it to the CPU. I might just put that up here, actually, to CPU. And then let's have a look at model zero. Wonderful. So we can try to do a dummy forward pass and see what happens. So let's create dummy x equals torch, rand, we'll create it as the same size of image. Just a singular image. So this is going to be a batch of one, color channel one, height 28, height 28. And we're going to go model zero and pass through dummy x. So this is going to send dummy x through the forward method. Let's see what happens. Okay, wonderful. So we get an output of 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 logits. Beautiful. That's exactly what we want. We have one logit value per class that we have. Now what would happen if we got rid of flatten? Then we ran this, ran this, ran this. What do we get? Oh, mat one and mat two shapes cannot be multiplied. So we have 28 by 28 and 7. Okay, what happens if we change our input shape to 28? We're getting shape mismatches here. What happens here? Oh, okay, we get an interesting output, but this is still not the right shape, is it? So that's where the flatten layer comes in. What is the shape of this? Oh, we get 1, 1, 28, 10. Oh, so that's why we put in flatten so that it combines it into a vector. So we get rid of this, see if we just leave it in this shape? We get 28 different samples of 10, which is not what we want. We want to compress our image into a singular vector and pass it in. So let's reinstanceuate the flatten layer and let's make sure we've got the right input shape here, 28 by 28, and let's pass it through, torch size 110. That's exactly what we want, 1 logit per class. So this could be a bit fiddly when you first start, but it's also a lot of fun once you get it to work. And so just keep that in mind, I showed you what it looks like when you have an error. One of the biggest errors that you're going to face in machine learning is different tensor shape mismatches. So just keep in mind the data that you're working with and then have a look at the documentation for what input shape certain layers expect. So with that being said, I think it's now time that we start moving towards training our model. I'll see you in the next video. Welcome back. In the last video, we created model zero, which is going to be our baseline model for our computer vision problem of detecting different types of clothing in 28 by 28 gray scale images. And we also learned the concept of making sure our or we rehashed on the concept of making sure our input and output shapes line up with where they need to be. We also did a dummy forward pass with some dummy data. This is a great way to troubleshoot to see if your model shapes are correct. If they come out correctly and if the inputs are lining up with where they need to be. And just to rehash on what our model is going to be or what's inside our model, if we check model zero state dict, what we see here is that our first layer has a weight tensor. It also has a bias and our next layer has a weight tensor and it also has a bias. So these are of course initialized with random values, but the whole premise of deep learning and machine learning is to pass data through our model and use our optimizer to update these random values to better represent the features in our data. And I keep saying features, but I just want to rehash on that before we move on to the next thing. Featuring data could be almost anything. So for example, the feature of this bag could be that it's got a rounded handle at the top. It has a edge over here. It has an edge over there. Now, we aren't going to tell our model what features to learn about the data. The whole premise of it is to, or the whole fun, the whole magic behind machine learning is that it figures out what features to learn. And so that is what the weights and bias matrices or tensors will represent is different features in our images. And there could be many because we have 60,000 images of 10 classes. So let's keep pushing forward. It's now time to set up a loss function and an optimizer. Speaking of optimizers, so 3.1 set up loss optimizer and evaluation metrics. Now recall in notebook two, I'm going to turn this into markdown. We created, oh, I don't need an emoji there. So this is, by the way, we're just moving through this workflow. We've got our data ready into tensors. We've built a baseline model. It's now time to pick a loss function and an optimizer. So we go back to Google Chrome. That's right here. Loss function. What's our loss function going to be? Since we're working with multi-class data, our loss function will be NN dot cross entropy loss. And our optimizer, we've got a few options here with the optimizer, but we've had practice in the past with SGD, which stands for stochastic gradient descent and the atom optimizer. So our optimizer, let's just stick with SGD, which is kind of the entry level optimizer torch opt in SGD for stochastic gradient descent. And finally, our evaluation metric, since we're working on a classification problem, let's use accuracy as our evaluation metric. So recall that accuracy is a classification evaluation metric. Now, where can we find this? Well, if we go into learnpytorch.io, this is the beauty of having online reference material. In here, neural network classification with PyTorch, in this notebook, section 02, we created, do we have different classification methods? Yes, we did. So we've got a whole bunch of different options here for classification evaluation metrics. We've got accuracy, precision, recall, F1 score, a confusion matrix. Now we have some code that we could use. If we wanted to use torch metrics for accuracy, we could. And torch metrics is a beautiful library that has a lot of evaluation. Oh, it doesn't exist. What happened to torch metrics? Maybe I need to fix that. Link. Torch metrics has a whole bunch of different PyTorch metrics. So very useful library. But we also coded a function in here, which is accuracy FN. So we could copy this, straight into our notebook here. Or I've also, if we go to the PyTorch deep learning GitHub, I'll just bring it over here. I've also put it in helper functions.py. And this is a script of common functions that we've used throughout the course, including if we find accuracy function here. Calculate accuracy. Now, how would we get this helper functions file, this Python file, into our notebook? One way is to just copy the code itself, straight here. But let's import it as a Python script. So import request, and we're going to go from pathlib import path. So we want to download, and this is actually what you're going to see, very common practice in larger Python projects, especially deep learning and machine learning projects, is different functionality split up in different Python files. And that way, you don't have to keep rewriting the same code over and over again. Like you know how we've written a training and testing loop a fair few times? Well, if we've written it once and it works, we might want to save that to a.py file so we can import it later on. So let's now write some code to import this helper functions.py file into our notebook here. So download helper functions from learn pytorch repo. So we're going to check if our helper functions.py, if this already exists, we don't want to download it. So we'll print helper functions.py already exists, skipping download, skipping download .dot. And we're going to go else here. If it doesn't exist, so we're going to download it, downloading helper functions.py. And we're going to create a request here with the request library equals request.get. Now here's where we have to pass in the URL of this file. It's not this URL here. When dealing with GitHub, to get the actual URL to the files, many files, you have to click the raw button. So I'll just go back and show you, click raw here. And we're going to copy this raw URL. See how it's just text here? This is what we want to download into our co-lab notebook. And we're going to write it in there, request equals request.get. And we're going to go with open, and here's where we're going to save our helper functions .py. We're going to write binary as file, F is for file. We're going to go F.write, request.content. So what this is saying is Python is going to create a file called helper functions.py and give it write binary permissions as F, F is for file, short for file. And then we're going to say F.write, request, get that information from helper functions .py here, and write your content to this file here. So let's give that a shot. Beautiful. So downloading helper functions.py, let's have a look in here. Do we have helper functions.py? Yes, we do. Wonderful. We can import our accuracy function. Where is it? There we go. Import accuracy function. So this is very common practice when writing lots of Python code is to put helper functions into.py scripts. So let's import the accuracy metric. Accuracy metric from helper functions. Of course, we could have used torch metrics as well. That's another perfectly valid option, but I just thought I'd show you what it's like to import your own helper function script. Of course, you can customize helper functions.py to have whatever you want in there. So see this? We've got from helper functions, import accuracy function. What's this saying? Could not be resolved. Is this going to work? It did. And where you can go accuracy function, do we get a doc string? Hmm. Seems like colab isn't picking things up, but that's all right. It looks like it still worked. We'll find out later on if it actually works when we train our model. So set up loss function and optimizer. So I'm going to set up the loss function equals nn dot cross entropy loss. And I'm going to set up the optimizer here as we discussed before as torch dot opt-in dot SGD for stochastic gradient descent. The parameters I want to optimize are the parameters from model zero, our baseline model, which we had a look at before, which are all these random numbers. We'd like our optimizer to tweak them in some way, shape, or form to better represent our data. And then I'm going to set the learning rate here. How much should they be tweaked each epoch? I'm going to set it to 0.1. Nice and high because our data set is quite simple. It's 28 by 28 images. There are 60,000 of them. But again, if this doesn't work, we can always adjust this and experiment, experiment, experiment. So let's run that. We've got a loss function. Is this going to give me a doc string? There we go. So calculates accuracy between truth and predictions. Now, where does this doc string come from? Well, let's have a look, hope of functions. That's what we wrote before. Good on us for writing good doc strings, accuracy function. Well, we're going to test all these out in the next video when we write a training loop. So, oh, actually, I think we might do one more function before we write a training loop. How about we create a function to time our experiments? Yeah, let's give that a go in the next video. I'll see you there. Welcome back. In the last video, we downloaded our helper functions.py script and imported our accuracy function that we made in notebook two. But we could really beef this up, our helper functions.py file. We could put a lot of different helper functions in there and import them so we didn't have to rewrite them. That's just something to keep in mind for later on. But now, let's create a function to time our experiments. So creating a function to time our experiments. So one of the things about machine learning is that it's very experimental. You've probably gathered that so far. So let's write here. So machine learning is very experimental. Two of the main things you'll often want to track are, one, your model's performance such as its loss and accuracy values, et cetera. And two, how fast it runs. So usually you want a higher performance and a fast model, that's the ideal scenario. However, you could imagine that if you increase your model's performance, you might have a bigger neural network. It might have more layers. It might have more hidden units. It might degrade how fast it runs because you're simply making more calculations. So there's often a trade-off between these two. And how fast it runs will really be important if you're running a model, say, on the internet or say on a dedicated GPU or say on a mobile device. So these are two things to really keep in mind. So because we're tracking our model's performance with our loss value and our accuracy function, let's now write some code to check how fast it runs. And I did on purpose above, I kept our model on the CPU. So we're also going to compare later on how fast our model runs on the CPU versus how fast it runs on the GPU. So that's something that's coming up. Let's write a function here. We're going to use the time module from Python. So from time it, import the default timer, as I'm going to call it timer. So if we go Python default timer, do we get the documentation for, here we go, time it. So do we have default timer, wonderful. So the default timer, which is always time.perf counter, you can read more about Python timing functions in here. But this is essentially just going to say, hey, this is the exact time that our code started. And then we're going to create another stop for when our code stopped. And then we're going to compare the start and stop times. And that's going to basically be how long our model took to train. So we're going to go def print train time. This is just going to be a display function. So start, we're going to get the float type hint, by the way, start an end time. So the essence of this function will be to compare start and end time. And we're going to set the torch or the device here, we'll pass this in as torch dot device. And we're going to set that default to none, because we want to compare how fast our model runs on different devices. So I'm just going to write a little doc string here, prints, difference between start and end time. And then of course, we could add more there for the arguments, but that's a quick one liner. Tell us what our function does. So total time equals end minus start. And then print, we're going to write here train time on, whichever device we're using might be CPU, might be GPU. Total time equals, we'll go to three and we'll say seconds, three decimal places that is and return total time. Beautiful. So for example, we could do start time equals timer, and then end time equals timer. And then we can put in here some code between those two. And then if we go print train, oh, maybe we need a timer like this, we'll find out if and out code it out, you know, we'll see if it works. Start time and end equals end time and device equals. We're running on the CPU right now, CPU, let's see if this works, wonderful. So it's a very small number here. So train time on CPU, very small number, because the start time is basically on this exact line, comment basically it takes no time to run, then end time is on here, we get 3.304 times 10 to the power of negative five. So quite a small number, but if we put some modeling code in here, it's going to measure the start time of this cell, it's going to model our code in there, then we have the end time, and then we find out how long our model took the train. So with that being said, I think we've got all of the pieces of the puzzle for creating some training and testing functions. So we've got a loss function, we've got an optimizer, we've got a valuation metric, we've got a timing function, we've got a model, we've got some data. How about we train our first baseline computer vision model in the next video? I'll see you there. Good morning. Well might not be morning wherever you are in the world. It's nice and early here, I'm up recording some videos, because we have a lot of momentum going with this, but look at this, I took a little break last night, I have a runtime disconnected, but this is just what's going to happen if you're using Google Colab. Since I use Google Colab Pro, completely unnecessary for the course, but I just found it worth it for how much I use Google Colab, I get longer idle timeouts, so that means that my Colab notebook will stay persistent for a longer time. But of course overnight it's going to disconnect, so I click reconnect, and then if I want to get back to wherever we were, because we downloaded some data from torchvision.datasets, I have to rerun all of these cells. So a nice shortcut, we might have seen this before, is to just come down to where we were, and if all the code above works, oh there we go, I wrote myself some notes of where we're up to. Let's go run before, so this is just going to run all the cells above, and we're up to here, 3.3 creating a training loop, and training a model on batches of data. So that's going to be a little bit interesting, and I wrote myself another reminder here, this is a little bit of behind the scenes, the optimise will update a model's parameters once per batch rather than once per epoch. So let's hold myself to that note, and make sure I let you know. So we're going to make another title here. Let's go creating a training loop, and training a model on batches of data. So something a little bit different to what we may have seen before if we haven't created batches of data using data loader, and recall that just up above here, we've got something like 1800 there, there we go. So we've split our data into batches, rather than our model looking at 60,000 images of fashion MNIST data at one time, it's going to look at 1875 batches of 32, so 32 images at the time, of the training data set, and 313 batches of 32 of the test data set. So let's go to training loop and train our first model. So I'm going to write out a few steps actually, because we have to do a little bit differently to what we've done before. So one, we want to loop through epochs, so a number of epochs. Loop through training batches, and by the way, you might be able to hear some birds singing, the sun is about to rise, I hope you enjoy them as much as I do. So we're going to perform training steps, and we're going to calculate calculate the train loss per batch. So this is going to be one of the differences between our previous training loops. And this is going to, after number two, we're going to loop through the testing batches. So we'll train and evaluate our model at the same step, or same loop. And we're going to perform testing steps. And then we're going to calculate the test loss per batch as well, per batch. Wonderful, four, we're going to, of course, print out what's happening. You may have seen the unofficial PyTorch optimization loop theme song. And we're going to time it all for fun, of course, because that's what our timing function is for. So let's get started. There's a fair few steps here, but nothing that we can't handle. And remember the motto, if and out, code it out. Well, there's another one, if and out, run the code, but we haven't written any code to run just yet. So we're going to import TQDM for a progress bar. If you haven't seen TQDM before, it's a very good Python progress bar that you can add with a few lines of code. So this is just the GitHub. It's open source software, one of my favorite pieces of software, and it's going to give us a progress bar to let us know how many epochs our training loop has gone through. It doesn't have much overhead, but if you want to learn more about it, please refer to the TQDM GitHub. However, the beautiful thing is that Google CoLab has TQDM built in because it's so good and so popular. So we're going to import from TQDM.auto. So there's a few different types of TQDM progress bars.auto is just going to recognize what compute environment we're using. And it's going to give us the best type of progress bar for what we're doing. So for example, Google CoLab is running a Jupyter Notebook behind the scenes. So the progress bar for Jupyter Notebooks is a little bit different to Python scripts. So now let's set the seed and start the timer. We want to write all of our training loop in this single cell here. And then once it starts, once we run this cell, we want the timer to start so that we can time how long the entire cell takes to run. So we'll go train time start on CPU equals, we set up our timer before, beautiful. Now we're going to set the number of epochs. Now we're going to keep this small for faster training time so we can run more experiments. So we'll keep this small for faster training time. That's another little tidbit. Do you notice how quickly all of the cells ran above? Well, that's because we're using a relatively small data set. In the beginning, when you're running experiments, you want them to run quite quickly so that you can run them more often. So you can learn more about your data so that you can try different things, try different models. So this is why we're using number of epochs equals three. We start with three so that our experiment runs in 30 seconds or a minute or so. That way, if something doesn't work, we haven't wasted so much time waiting for a model to train. Later on, we could train it for 100 epochs if we wanted to. So we're going to create a training and test loop. So for epoch in TQDM range epochs, let's get this going. So for TQDM to work, we just wrap our iterator with TQDM and you'll see later on how this tracks the progress. So I'm going to put out a little print statement here. We'll go epoch. This is just going to say what epoch we're on. We'll go here. That's something that I like to do quite often is put little print statements here and there so that we know what's going on. So let's set up the training. We're going to have to instantiate the train loss. We're going to set that to zero to begin with. And we're going to cumulatively add some values to the train loss here and then we'll see later on how this accumulates and we can calculate the training loss per batch. Let's what we're doing up here, calculate the train loss per batch. And then finally, at the end of the loop, we will divide our training loss by the number of batches so we can get the average training loss per batch and that will give us the training loss per epoch. Now that's a lot of talking. If that doesn't make sense, remember. But if and out, code it out. So add a loop to loop through the training batches. So because our data is batchified now and I've got a crow or maybe a cooker bar sitting on the roof across from my apartment, it's singing its song this morning, lovely. So we're going to loop through our training batch data. So I've got four batch, comma x, y, because remember our training batches come in the form of X. So that's our data or our images and why, which is label. You could call this image label or target as part of which would, but it's convention to often call your features X and your labels Y. We've seen this before in we're going to enumerate the train data loader as well. We do this so we can keep track of the number of batches we've been through. So that will give us batch there. I'm going to set model zero to training mode because even though that's the default, we just want to make sure that it's in training mode. Now we're going to do the forward pass. If you remember, what are the steps in apply to our optimization loop? We do the forward pass. We calculate the loss of the minus zero grad, last backwards, up to minus a step, step, step. So let's do that. Hey, model zero, we'll put the features through there and then we're going to calculate the loss. We've been through these steps before. So we're not going to spend too much time on the exact steps here, but we're just going to practice writing them out. And of course, later on, you might be thinking, then you'll, how come we haven't functionalized this training loop already? We've seemed to write the same generic code over and over again. Well, that's because we like to practice writing PyTorch code, right? We're going to functionalize them later on. Don't you worry about that. So here's another little step that we haven't done before is we have the training loss. And so because we've set that to zero to begin with, we're going to accumulate the training loss values every batch. So we're going to just add it up here. And then later on, we're going to divide it by the total number of batches to get the average loss per batch. So you see how this loss calculation is within the batch loop here? So this means that one batch of data is going to go through the model. And then we're going to calculate the loss on one batch of data. And this loop is going to continue until it's been through all of the batches in the train data loader. So 1875 steps or whatever there was. So accumulate train loss. And then we're going to optimize a zero grad, optimizer dot zero grad. And then number four is what? Loss backward. Loss backward. We'll do the back propagation step. And then finally, we've got number five, which is optimizer step. So this is where I left my little note above to remind me and to also let you know, highlight that the optimizer will update a model's parameters once per batch rather than once per epoch. So you see how we've got a for loop inside our epoch loop here. So the batch loop. So this is what I meant that the optimizer, this is one of the advantages of using mini batches is not only is it more memory efficient because we're not loading 60,000 images into memory at a time. We are updating our model's parameters once per batch rather than waiting for it to see the whole data set with every batch. Our model is hopefully getting slightly better. So that is because the optimizer dot step call is within the batch loop rather than the epoch loop. So let's now print out what's happening. Print out what's happening. So if batch, let's do it every 400 or so batches because we have a lot of batches. We don't want to print out too often, otherwise we'll just fill our screen with numbers. That might not be a bad thing, but 400 seems a good number. That'll be about five printouts if we have 2000 batches. So print looked at, and of course you can adjust this to whatever you would like. That's the flexibility of PyTorch, flexibility of Python as well. So looked at how many samples have we looked at? So we're going to take the batch number, multiply it by X, the length of X is going to be 32 because that is our batch size. Then we're going to just write down here the total number of items that we've got now of data set, and we can access that by going train data loader dot data set. So that's going to give us length of the data set contained within our train data loader, which is you might be able to guess 60,000 or should be. Now we have to, because we've been accumulating the train loss, this is going to be quite high because we've been adding every single time we've calculated the loss, we've been adding it to the train loss, the overall value per batch. So now let's adjust if we wanted to find out, see how now we've got this line, we're outside of the batch loop. We want to adjust our training loss to get the average training loss per batch per epoch. So we're coming back to the epoch loop here. A little bit confusing, but you just line up where the loops are, and this is going to help you figure out what context you're computing in. So now we are in the epoch loop. So divide total train loss by length of train data loader, oh, this is so exciting, training our biggest model yet. So train loss equals or divide equals, we're going to reassign the train loss, we're going to divide it by the length of the train data loader. So why do we do this? Well, because we've accumulated the train loss here for every batch in the train data loader, but we want to average it out across how many batches there are in the train data loader. So this value will be quite high until we readjust it to find the average loss per epoch, because we are in the epoch loop. All right, there are a few steps going on, but that's all right, we'll figure this out, or what should happening in a minute, let's code up the testing loop. So testing, what do we have to do for testing? Well, let's set up a test loss variable. Why don't we do accuracy for testing as well? Did we do accuracy for training? We didn't do accuracy for training, but that's all right, we'll stick to doing accuracy for testing. We'll go model zero dot eval, we'll put it in evaluation mode, and we'll turn on our inference mode context manager with torch dot inference mode. Now we'll do the same thing for x, y in test data loader, we don't need to keep track of the batches here again in the test data loader. So we'll just loop through x, so features, images, and labels in our test data loader. We're going to do the forward pass, because the test loop, we don't have an optimization step, we are just passing our data through the model and evaluating the patterns it learned on the training data. So we're going to pass in x here. This might be a little bit confusing, let's do this x test, y test. That way we don't get confused with our x above for the training set. Now we're going to calculate the loss, a cum, relatively might small that wrong app to sound that out. What do we have here? So we've got our test loss variable that we just assigned to zero above, just up here. So we're going to do test loss plus equals. We're doing this in one step here. Test spread, y test. So we're comparing our test prediction to our y test labels, our test labels. Now we're going to back out of the for loop here, because that's all we have to do, the forward pass and calculate the loss for the test data set. Oh, I said we're going to calculate the accuracy. Silly me. So calculate accuracy. Let's go test act. And we've got plus equals. We can bring out our accuracy function here. That's what we downloaded from our helper functions dot pi before, y true equals y test. And then y pred equals test, pred dot arg max, dim equals one. Why do we do this? Well, because recall that the outputs of our model, the raw outputs of our model are going to be logits and our accuracy function expects our true labels and our predictions to be in the same format. If our test pred is just logits, we have to call arg max to find the logit value with the highest index, and that will be the prediction label. And so then we're comparing labels to labels. That's what the arg max does here. So we can back out of the batch loop now, and we're going to now calculate Cal queue length, the test loss, average per batch. So let's go here, test loss, divide equals length test data loader. So because we were in the context of the loop here of the batch loop, our test lost and test accuracy values are per batch and accumulated every single batch. So now we're just dividing them by how many batches we had, test data loader, and the same thing for the accuracy, calculate the ACK or test ACK average per batch. So this is giving us test loss and test accuracy per epoch, test ACK divided equals length, test data loader, wonderful, we're so close to finishing this up. And now we'll come back to where's our epoch loop. We can, these lines are very helpful in Google CoLab, we scroll down. I believe if you want them, you can go settings or something like that, yeah, settings. That's where you can get these lines from if you don't have them. So print out what's happening. We are going to print f equals n, let's get the train loss in here. Ten loss and we'll print that to four decimal places. And then we'll get the test loss, of course, test loss and we'll go, we'll get that to four decimal places as well. And then we'll get the test ACK, test accuracy, we'll get that to four decimal places as well. For f, wonderful. And then finally, one more step, ooh, we've written a lot of code in this video. We want to calculate the training time because that's another thing that we want to track. We want to see how long our model is taken to train. So train time end on CPU is going to equal the timer and then we're going to get the total train time model zero so we can set up a variable for this so we can compare our modeling experiments later on. We're going to go print train time, start equals train time, start on CPU and equals train time end on CPU. And finally, the device is going to be string next model zero dot parameters. So we're just, this is one way of checking where our model zero parameters live. So beautiful, all right. Have we got enough brackets there? I don't think we do. Okay. There we go. Whoo. I'll just show you what the output of this is. So next, model zero dot parameters, what does this give us? Oh, can we go device here? Oh, what do we have here? Model zero dot parameters. I thought this was a little trick. And then if we go next parameter containing. I thought we could get device, oh, there we go. Excuse me. That's how we get it. That's how we get the device that it's on. So let me just turn this. This is what the output of that's going to be CPU. That's what we're after. So troubleshooting on the fly here. Hopefully all of this code works. So we went through all of our steps. We're looping through epochs at the top level here. We looped through the training batches, performed the training steps. So our training loop, forward pass, loss calculation, optimizer zero grad, loss backwards, calculate the loss per batch, accumulate those. We do the same for the testing batches except without the optimizer steps and print out what's happening and we time it all for fun. A fair bit going on here, but if you don't think there's any errors, give that a go, run that code. I'm going to leave this one on a cliffhanger and we're going to see if this works in the next video. I'll see you there. Welcome back. The last video was pretty full on. We did a fair few steps, but this is all good practice. The best way to learn PyTorch code is to write more PyTorch code. So did you try it out? Did you run this code? Did it work? Did we probably have an error somewhere? Well, let's find out together. You ready? Let's train our biggest model yet in three, two, one, bomb. Oh, of course we did. What do we have? What's going on? Indentation error. Ah, classic. So print out what's happening. Do we not have an indent there? Oh, is that not in line with where it needs to be? Excuse me. Okay. Why is this not in line? So this is strange to me, enter. How did this all get off by one? I'm not sure, but this is just what you'll face. Like sometimes you'll write this beautiful code that should work, but the main error of your entire code is that it's off by a single space. I'm not sure how that happened, but we're just going to pull this all into line. We could have done this by selecting it all, but we're going to do it line by line just to make sure that everything's in the right order, beautiful, and we print out what's happening. Three, two, one, round two. We're going. Okay. So this is the progress bar I was talking about. Look at that. How beautiful is that? Oh, we're going quite quickly through all of our samples. I need to talk faster. Oh, there we go. We've got some good results. We've got the tests, the train loss, the test loss and the test accuracy is pretty darn good. Oh my goodness. This is a good baseline already, 67%. So this is showing us it's about seven seconds per iteration. Remember TQDM is tracking how many epochs. We're going through. So we have three epochs and our print statement is just saying, hey, we've looked at zero out of 60,000 samples and we looked at 12,000 out of 60,000 samples and we finished on an epoch two because it's zero indexed and we have a train loss of 0.4550 and a test loss 476 and a test accuracy 834265 and a training time about just over 21 seconds or just under 22. So keep in mind that your numbers may not be the exact same as mine. They should be in the same realm as mine, but due to inherent randomness of machine learning, even if we set the manual seed might be slightly different. So don't worry too much about that and what I mean by in the same realm, if your accuracy is 25 rather than 83, well then probably something's wrong there. But if it's 83.6, well then that's not too bad. And the same with the train time on CPU, this will be heavily dependent, how long it takes to train will be heavily dependent on the hardware that you're using behind the scenes. So I'm using Google Colab Pro. Now that may mean I get a faster CPU than the free version of Google Colab. It also depends on what CPU is available in Google's computer warehouse where Google Colab is hosting of how fast this will be. So just keep that in mind. If your time is 10 times that, then there's probably something wrong. If your time is 10 times less than that, well, hey, keep using that hardware because that's pretty darn good. So let's keep pushing forward. This will be our baseline that we try to improve upon. So we have an accuracy of 83.5 and we have a train time of 20 or so seconds. So we'll see what we can do with a model on the GPU later and then also later on a convolutional neural network. So let's evaluate our model where we up to what we just did. We built a training loop. So we've done that. That was a fair bit of code. But now we're up to we fit the model to the data and make a prediction. Let's do these two combined, hey, we'll evaluate our model. So we'll come back. Number four is make predictions and get model zero results. Now we're going to create a function to do this because we want to build multiple models and that way we can, if we have, say, model 0123, we can pass it to our function to evaluate that model and then we can compare the results later on. So that's something to keep in mind. If you're going to be writing a bunch of code multiple times, you probably want to functionize it and we could definitely do that for our training and last loops. But we'll see that later on. So let's go deaf of our model. So evaluate a given model, we'll pass it in a model, which will be a torch dot nn dot module, what of type. And we'll pass it in a data loader, which will be of type torch dot utils dot data dot data loader. And then we'll pass in the loss function so that it can calculate the loss. We could pass in an evaluation metric if we wanted to track that too. So this will be torch nn dot module as well. And then, oh, there we go. Speaking of an evaluation function, let's pass in our accuracy function as well. And I don't want L, I want that. So we want to return a dictionary containing the results of model predicting on data loader. So that's what we want. We're going to return a dictionary of model results. That way we could call this function multiple times with different models and different data loaders and then compare the dictionaries full of results depending on which model we passed in here. So let's set up loss and accuracy equals zero, zero, we'll start those off. We'll go, this is going to be much the same as our testing loop above, except it's going to be functionalized and we're going to return a dictionary. So we'll turn on our context manager for inferencing with torch dot inference mode. Now we're going to loop through the data loader and we'll get the x and y values. So the x will be our data, the y will be our ideal labels, we'll make predictions with the model. In other words, do the forward pass. So we'll go y pred equals model on x. Now we don't have to specify what model it is because we've got the model parameter up here. So we're starting to make our functions here or this function generalizable. So it could be used with almost any model and any data loader. So we want to accumulate the loss and accuracy values per batch because this is within the batch loop here per batch. And then we're going to go loss plus equals loss function, we'll pass it in the y pred and the y the true label and we'll do the same with the accuracy. So except this time we use our accuracy function, we'll send in y true equals y and y pred equals y pred dot argmax because the raw outputs of our model are logits. And if we want to convert them into labels, we could take the softmax for the prediction probabilities, but we could also take the argmax and just by skipping the softmax step, the argmax will get the index where the highest value load it is, dim equals one. And then we're going to make sure that we're still within the context manager here. So with torch inference mode, but outside the loop. So that'll be this line here. We're going to scale the loss and act to find the average loss slash act per batch. So loss will divide and assign to the length of the data loader. So that'll divide and reassign it to however many batches are in our data loader that we pass into our of our model function, then we'll do the same thing for the accuracy here. Length data loader, beautiful. And now we're going to return a dictionary here. So return, we can return the model name by inspecting the model. We get an attribute of the model, which is its class name. I'll show you how you can do that. So this is helpful to track if you've created multiple different models and given them different class names, you can access the name attribute. So this only works when model was created with a class. So you just have to ensure that your models have different class names. If you want to do it like that, because we're going to do it like that, we can set the model name to be its class name. We'll get the model loss, which is just this value here. After it's been scaled, we'll turn it into a single value by taking dot item. And then we'll go model dot act, or we'll get model underscore act for the models accuracy. We'll do the same thing here. Act. I don't think we need to take the item because accuracy comes back in a different form. We'll find out, if in doubt, code it out. So calculate model zero results on test data set. And I want to let you know that you can create your own functions here to do almost whatever you want. I've just decided that this is going to be helpful for the models and the data that we're building. But keep that in mind that your models, your data sets might be different and will likely be different in the future. So you can create these functions for whatever use case you need. Model zero results equals a vowel model. So we're just going to call our function that we've just created here. Model is going to equal model zero. The data loader is going to equal what? The test data loader, of course, because we want to evaluate it on the test data set. And we're going to send in our loss function, which is loss function that we assigned above just before our training loop. If we come up here, our loss function is up here, and then if we go back down, we have our accuracy function is equal to our accuracy function. We just pass another function in there, beautiful. And let's see if this works. Model zero results. Did you see any typos likely or errors in our code? How do you think our model did? Well, let's find out. Oh, there we go. We got model accuracy. Can you see how we could reuse this dictionary later on? So if we had model one results, model two results, we could use these dictionaries and compare them all together. So we've got our model name. Our version zero, the model has an accuracy of 83.42 and a loss of 0.47 on the test data loader. Again, your numbers may be slightly different. They should be in the same realm. But if they're not the exact same, don't worry too much. If they're 20 accuracy points less and the loss is 10 times higher, then you should probably go back through your code and check if something is wrong. And I believe if we wanted to do a progress bar here, could we do that? TQDM. Let's have a look, eh? Oh, look at that progress bar. That's very nice. So that's nice and quick because it's only on 313 batches. It goes quite quick. So now, what's next? Well, we've built model one, we've got a model zero, sorry, I'm getting ahead myself. We've got a baseline here. We've got a way to evaluate our model. What's our workflow say? So we've got our data ready. We've done that. We've picked or built a model. We've picked a loss function. We've built an optimizer. We've created a training loop. We've fit the model to the data. We've made a prediction. We've evaluated the model using loss and accuracy. We could evaluate it by making some predictions, but we'll save that for later on as in visualizing some predictions. I think we're up to improving through experimentation. So let's give that a go, hey? Do you recall that we trained model zero on the CPU? How about we build model one and start to train it on the GPU? So in the next section, let's create number five, is set up device agnostic code. So we've done this one together for using a GPU if there is one. So my challenge to you for the next video is to set up some device agnostic code. So you might have to go into CoLab if you haven't got a GPU active, change runtime type to GPU, and then because it might restart the runtime, you might have to rerun all of the cells above so that we get our helper functions file back and the data and whatnot. So set up some device agnostic code and I'll see you in the next video. How'd you go? You should give it a shot, did you set up some device agnostic code? I hope you gave it a go, but let's do it together. This won't take too long. The last two videos have been quite long. So if I wanted to set device agnostic code, I want to see if I have a GPU available, do I? I can check it from the video SMI. That fails because I haven't activated a GPU in CoLab yet. I can also check here, torch CUDA is available. That will PyTorch will check if there's a GPU available with CUDA and it's not. So let's fix these two because we want to start using a GPU and we want to set up device agnostic code. So no matter what hardware our system is running, PyTorch leverages it. So we're going to select GPU here, I'm going to click save and you'll notice that our Google CoLab notebook will start to reset and we'll start to connect. There we go. We've got a GPU on the back end, Python, three Google Compute Engine back end GPU. Do we have to reset this? NVIDIA SMI, wonderful, I have a Tesla T4 GPU with 16 gigabytes of memory, that is wonderful. And now do we have a GPU available? Oh, torch is not defined. Well, do you notice the numbers of these cells? One, two, that means because we've reset our runtime to have a GPU, we have to rerun all the cells above. So we can go run before, that's going to run all the cells above, make sure that we download the data, make sure that we download the helper functions file, we go back up, we should see our data may be downloading. It shouldn't take too long. That is another advantage of using a relatively small data set that is already saved on PyTorch data sets. Just keep in mind that if you use a larger data set and you have to re-download it into Google Colab, it may take a while to run, and if you build bigger models, they may take a while to run. So just keep that in mind for your experiments going forward, start small, increase when necessary. So we'll re-run this, we'll re-run this, and finally we're going to, oh, there we go, we've got a GPU, wonderful, but we'll write some device-agnostic code here, set up device-agnostic code. So import-torch, now realistically you quite often do this at the start of every notebook, but I just wanted to highlight how we might do it if we're in the middle, and I wanted to practice running a model on a CPU only before stepping things up and going to a GPU. So device equals CUDA, this is for our device-agnostic code, if torch dot CUDA is available, and it looks like this is going to return true, else use the CPU. And then we're going to check device, wonderful, CUDA. So we've got some device-agnostic code ready to go, I think it's time we built another model. And I asked the question before, do you think that the data set that we're working with requires nonlinearity? So the shirts, and the bags, and the shoes, do we need nonlinear functions to model this? Well it looks like our baseline model without nonlinearities did pretty well at modeling our data, so we've got a pretty good test accuracy value, so 83%, so out of 100 images it predicts the right one, 83% of the time, 83 times out of 100, it did pretty well without nonlinearities. Why don't we try a model that uses nonlinearities and it runs on the GPU? So you might want to give that a go, see if you can create a model with nonlinear functions, try nn.relu, run it on the GPU, and see how it goes, otherwise we'll do it together in the next video, I'll see you there. Hello everyone, and welcome back, we are making some terrific progress, let's see how far we've come, we've got a data set, we've prepared our data loaders, we've built a baseline model, and we've trained it, evaluated it, now it's time, oh, and the last video we set up device diagnostic code, but where are we in our little framework, we're up to improving through experimentation, and quite often that is building a different model and trying it out, it could be using more data, it could be tweaking a whole bunch of different things. So let's get into some coding, I'm going to write it here, model one, I believe we're up to section six now, model one is going to be building a better model with nonlinearity, so I asked you to do the challenge in the last video to give it a go, to try and build a model with nonlinearity, I hope you gave it a go, because if anything that this course, I'm trying to impart on you in this course, it's to give things a go, to try things out because that's what machine learning and coding is all about, trying things out, giving it a go, but let's write down here, we learned about the power of nonlinearity in notebook O2, so if we go to the learnpytorch.io book, we go to section number two, we'll just wait for this to load, and then if we come down here, we can search for nonlinearity, the missing piece nonlinearity, so I'm going to get this and just copy that in there, if you want to see what nonlinearity helps us do, it helps us model nonlinear data, and in the case of a circle, can we model that with straight lines, in other words, linear lines? All linear means straight, nonlinear means non-straight, and so we learned that through the power of linear and nonlinear functions, neural networks can model almost any kind of data if we pair them in the right way, so you can go back through and read that there, but I prefer to code things out and try it out on our data, so let's create a model with nonlinear and linear layers, but we also saw that our model with just linear layers can model our data, it's performing quite well, so that's where the experimentation side of things will come into play, sometimes you won't know what a model will do, whether it will work or won't work on your data set, but that is where we try different things out, so we come up here, we look at our data, hmm, that looks actually quite linear to me as a bag, like it's just some straight lines, you could maybe model that with just straight lines, but there are some things which you could potentially classify as nonlinear in here, it's hard to tell without knowing, so let's give it a go, let's write a nonlinear model which is going to be quite similar to model zero here, except we're going to interspurse some relu layers in between our linear layers, so recall that relu is a nonlinear activation function, and relu has the formula, if something comes in and it's a negative value, relu is going to turn that negative into a zero, and if something is positive, relu is just going to leave it there, so let's create another class here, fashion MNIST model V1, and we're going to subclass from nn.module, beautiful, and then we're going to initialize our model, it's going to be quite the same as what we created before, we want an input shape, that's going to be an integer, and then we want a number of hidden units, and that's going to be an int here, and then we want an output shape, int, and I want to stress as well that although we're creating a class here with these inputs, classes are as flexible as functions, so if you need different use cases for your modeling classes, just keep that in mind that you can build that functionality in, self dot layer stack, we're going to spell layer stack correctly, and we're going to set this equal to nn dot sequential, because we just want a sequential set of layers, the first one's going to be nn dot flatten, which is going to be flatten inputs into a single vector, and then we're going to go nn dot linear, because we want to flatten our stuff because we want it to be the right shape, if we don't flatten it, we get shape issues, input shape, and then the out features of our linear layer is going to be the hidden units, hidden units, I'm just going to make some code cells here so that my code goes into the middle of the screen, then here is where we're going to add a nonlinear layer, so this is where we're going to add in a relu function, and where might we put these? Well, generally, you'll have a linear function followed by a nonlinear function in the construction of neural networks. However, neural networks are as customizable as you can imagine, whether they work or not is a different question. So we'll go output shape here, as the out features, oh, do we miss this one up? Yes, we did. This needs to be hidden units. And why is that? Well, it's because the output shape of this linear layer here needs to match up with the input shape of this linear layer here. The relu layer won't change the shape of our data. And you could test that out by printing the different shapes if you'd like. And then we're going to finish off with another nonlinear layer at the end. Relu. Now, do you think that this will improve our model's results or not? Well, it's hard to tell without trying it out, right? So let's continue building our model. We have to override the forward method. Self X is going to be, we'll give a type in here, this is going to be a torch tensor as the input. And then we're just going to return what's happening here, we go self dot layer stack X. So that just means that X is going to pass through our layer stack here. And we could customize this, we could try it just with one nonlinear activation. This is actually our previous network, just with those commented out. All we've done is added in two relu functions. And so I'm going to run that beautiful. And so what should we do next? Well, we shouldn't stand shaded but previously we ran our last model model zero on if we go parameters. Do we run this on the GPU or the CPU? On the CPU. So how about we try out our fashion MNIST model or V one running on the device that we just set up which should be CUDA. Wonderful. So we can instantiate. So create an instance of model one. So we want model one or actually we'll set up a manual seed here so that whenever we create a new instance of a model, it's going to be instantiated with random numbers. We don't necessarily have to set a random seed, but we do so anyway so that our values are quite similar on your end and my end input shape is going to be 784. Where does that come from? Well, that's because this is the output of the flatten layer after our 28 by 28 image goes in. Then we're going to set up the hidden units. We're going to use the same number of hidden units as before, which is going to be 10. And then the output shape is what? We need one value, one output neuron for each of our classes. So length of the class names. And then we're going to send this to the target device so we can write send to the GPU if it's available. So now that we've set up device agnostic code in the last video, we can just put two device instead of hard coding that. And so if we check, so this was the output for model zero's device, let's now check model one's device, model one parameters, and we can check where those parameters live by using the device attribute. Beautiful. So our model one is now living on the GPU CUDA at index zero. Index zero means that it's on the first GPU that we have available. We only have one GPU available. So it's on this Tesla T for GPU. Now, we've got a couple more things to do. Now that we've created another model, we can recreate if we go back to our workflow, we've just built a model here. What do we have to do after we built a model? We have to instantiate a loss function and an optimizer. Now we've done both of those things for model zero. So that's what we're going to do in the next video. But I'd like you to go ahead and try to create a loss function for our model and optimizer for model one. The hint is that they can be the exact same loss function and optimizer as model zero. So give that a shot and I'll see you in the next video. Welcome back. In the last video, we created another model. So we're continuing with our modeling experiments. And the only difference here between fashion MNIST model V1 and V0 is that we've added in nonlinear layers. Now we don't know for now we could think or guess whether they would help improve our model. And with practice, you can start to understand how different functions will influence your neural networks. But I prefer to, if in doubt, code it out, run lots of different experiments. So let's continue. We now have to create a loss function, loss, optimizer, and evaluation metrics. So we've done this for model zero. So we're not going to spend too much time explaining what's going on here. And we've done this a fair few times now. So from helper functions, which is the script we downloaded before, we're going to import our accuracy function. And we're going to set up a loss function, which is we're working with multi class classification. So what loss function do we typically use? And then dot cross entropy loss. And as our optimizer is going to be torch dot opt in dot SGD. And we're going to optimize this time. I'll put in the params keyword here, model one dot parameters. And the learning rate, we're just going to keep it the same as our previous model. And that's a thing to keep a note for your experiments. When you're running fair few experiments, you only really want to tweak a couple of things or maybe just one thing per experiment, that way you can really narrow down what actually influences your model and what improves it slash what doesn't improve it. And a little pop quiz. What does a loss function do? This is going to measure how wrong our model is. And what does the optimizer do? Tries to update our models parameters to reduce the loss. So that's what these two functions are going to be doing. The accuracy function is of a course going to be measuring our models accuracy. We measure the accuracy because that's one of the base classification metrics. So we'll run this. Now what's next? We're getting quite good at this. We've picked a loss function and an optimizer. Now we're going to build a training loop. However, we spent quite a bit of time doing that in a previous video. If we go up here, that was our vowel model function. Oh, that was helpful. We turned it into a function. How about we do the same with these? Why don't we make a function for our training loop as well as our testing loop? So I think you can give this a go. We're going to make a function in the next video for training. We're going to call that train step. And we'll create a function for testing called test step. Now they'll both have to take in some parameters. I'll let you figure out what they are. But otherwise, we're going to code that up together in the next video. So I'll see you there. So we've got a loss function ready and an optimizer. What's our next step? Well, it's to create training and evaluation loops. So let's make a heading here. We're going to call this functionizing training and evaluation or slash testing loops because we've written similar code quite often for training and evaluating slash testing our models. Now we're going to start moving towards functionizing code that we've written before because that's not only a best practice, it helps reduce errors because if you're writing a training loop all the time, we may get it wrong. If we've got one that works for our particular problem, hey, we might as well save that as a function so we can continually call that over and over and over again. So how about we, and this is going to be very rare that I'm going to allow you to do this is that is we're going to copy this training and you might have already attempted to create this. That is the function called, let's create a function for one training loop. And we're going to call this train step. And we're going to create a function for the testing loop. You're going to call this test step. Now these are just what I'm calling them. You can call them whatever you want. I just understand it quite easily by calling it train step. And then we can for each epoch in a range, we call our training step. And then the same thing for each epoch in a range, we can call a testing step. This will make a lot more sense once we've coded it out. So let's put the training code here. To functionize this, let's start it off with train step. Now what parameters should our train step function take in? Well, let's think about this. We need a model. We need a data loader. We need a loss function. And we need an optimizer. We could also put in an accuracy function here if we wanted to. And potentially it's not here, but we could put in what target device we'd like to compute on and make our code device agnostic. So this is just the exact same code we went through before. We loop through a data loader. We do the forward pass. We calculate the loss. We accumulate it. We zero the optimizer. We perform backpropagation in respect to the loss with the parameters of the model. And then we step the optimizer to hopefully improve the parameters of our model to better predict the data that we're trying to predict. So let's craft a train step function here. We'll take a model, which is going to be torch nn.module, type hint. And we're going to put in a data loader, which is going to be of type torch utils dot data dot data loader. Now we don't necessarily need to put this in these type hints, but they're relatively new addition to Python. And so you might start to see them more and more. And it also just helps people understand what your code is expecting. So the loss function, we're going to put in an optimizer torch dot opt in, which is a type optimizer. We also want an accuracy function. We don't necessarily need this either. These are a lot of nice to habs. The first four are probably the most important. And then the device. So torch is going to be torch dot device equals device. So we'll just hard code that to be our already set device parameter. And we'll just write in here, performs training step with model, trying to learn on data loader. Nice and simple, we could make that more explanatory if we wanted to, but we'll leave it at that for now. And so right at the start, we're going to set up train loss and train act equals zero zero. We're going to introduce accuracy here. So we can get rid of this. Let's just go through this line by line. What do we need to do here? Well, we've got four batch XY in enumerate train data loader. But we're going to change that to data loader up here. So we can just change this to data loader. Wonderful. And now we've got model zero dot train. Do we want that? Well, no, because we're going to keep this model agnostic, we want to be able to use any model with this function. So let's get rid of this model dot train. We are missing one step here is put data on target device. And we could actually put this model dot train up here. Put model into training mode. Now, this will be the default for the model. But just in case we're going to call it anyway, model dot train, put data on the target device. So we're going to go XY equals X dot two device, Y dot two device. Wonderful. And the forward pass, we don't need to use model zero anymore. We're just going to use model that's up here. The loss function can stay the same because we're passing in a loss function up there. The train loss can be accumulated. That's fine. But we might also accumulate now the train accuracy, limit loss, and accuracy per batch. So train act equals or plus equals our accuracy function on Y true equals Y and Y pred equals Y pred. So the outputs here, Y pred, we need to take because the raw outputs, outputs, the raw logits from the model, because our accuracy function expects our predictions to be in the same format as our true values. We need to make sure that they are we can call the argmax here on the first dimension. This is going to go from logits to prediction labels. We can keep the optimizer zero grab the same because we're passing in an optimizer up here. We can keep the loss backwards because the loss is just calculated there. We can keep optimizer step. And we could print out what's happening. But we might change this up a little bit. We need to divide the total train loss and accuracy. I just want to type in accuracy here because now we've added in accuracy metric act. So train act divided equals length train data loader. Oh, no, sorry. We can just use the data loader here, data loader, data loader. And we're not going to print out per batch here. I'm just going to get rid of this. We'll make at the end of this step, we will make our print out here, print. Notice how it's at the end of the step because we're outside the for loop now. So we're going to here, we're accumulating the loss on the training data set and the accuracy on the training data set per batch. And then we're finding out at the end of the training steps. So after it's been through all the batches in the data loader, we're finding out what the average loss is per batch. And the average accuracy is per batch. And now we're going to go train loss is going to be the train loss on 0.5. And then we're going to go train act is going to be train act. And we're going to set that to 0.2 F. Get that there, percentage. Wonderful. So if all this works, we should be able to call our train step function and pass it in a model, a data loader, a loss function, an optimizer, an accuracy function and a device. And it should automatically do all of these steps. So we're going to find that out in a later video. In the next video, we're going to do the same thing we've just done for the training loop with the test step. But here's your challenge for this video is to go up to the testing loop code we wrote before and try to recreate the test step function in the same format that we've done here. So give that a go. And I'll see you in the next video. Welcome back. In the last video, we functionalized our training loop. So now we can call this train step function. And instead of writing all this training loop code again, well, we can train our model through the art of a function. Now let's do the same for our testing loop. So I issued you the challenge in the last video to give it a go. I hope you did because that's the best way to practice PyTorch code is to write more pytorch code. Let's put in a model, which is going to be torch and then dot module. And we're going to put in a data loader. Because we need a model and we need data, the data loader is going to be, of course, the test data load here, torch dot utils dot data dot data loader. And then we're going to put in a loss function, which is going to be torch and end up module as well. Because we're going to use an end up cross entropy loss. We'll see that later on. We're going to put in an accuracy function. We don't need an optimizer because we're not doing any optimization in the testing loop. We're just evaluating. And the device can be torch dot device. And we're going to set that as a default to the target device parameter. Beautiful. So we'll put a little doctoring here. So performs a testing loop step on model going over data loader. Wonderful. So now let's set up a test loss and a test accuracy, because we'll measure test loss and accuracy without testing loop function. And we're going to set the model into, I'll just put a comment here, put the model in a vowel mode. So model dot a vowel, we don't have to use any underscore here as in model zero, because we have a model coming in the top here. Now, what should we do? Well, because we're performing a test step, we should turn on inference mode. So turn on inference mode, inference mode context manager. Remember, whenever you're performing predictions with your model, you should put it in model dot a vowel. And if you want as many speedups as you can get, make sure the predictions are done within the inference mode. Because remember, inference is another word for predictions within the inference mode context manager. So we're going to loop through our data loader for X and Y in data loader. We don't have to specify that this is X test. For Y test, we could if we wanted to. But because we're in another function here, we can just go for X, Y in data loader, we can do the forward pass. After we send the data to the target device, target device, so we're going to have X, Y equals X dot two device. And the same thing with Y, we're just doing best practice here, creating device agnostic code. Then what should we do? Well, we should do the thing that I said before, which is the forward pass. Now that our data and model be on the same device, we can create a variable here test pred equals model, we're going to pass in X. And then what do we do? We can calculate the loss. So to calculate the loss slash accuracy, we're going to accumulate it per batch. So we'll set up test loss equals loss function. Oh, plus equals loss function. We're going to pass it in test pred and Y, which is our truth label. And then the test act where you will accumulate as well, using our accuracy function, we'll pass in Y true equals Y. And then Y pred, what do we have to do to Y pred? Well, our test pred, we have to take the argmax to convert it from. So this is going to outputs raw logits. Remember, a models raw output is referred to as logits. And then here, we have to go from logits to prediction labels. Beautiful. Oh, little typo here. Did you catch that one? Tab, tab. Beautiful. Oh, look how good this function is looking. Now we're going to adjust the metrics. So adjust metrics and print out. You might notice that we're outside of the batch loop here, right? So if we draw down from this line for and we write some code here, we're still within the context manager. This is important because if we want to adapt a value created inside the context manager, we have to modify it still with inside that context manager, otherwise pytorch will throw an error. So try to write this code if you want outside the context manager and see if it still works. So test loss, we're going to adjust it to find out the average test loss and test accuracy per batch across a whole step. So we're going to go length data loader. Now we're going to print out what's happening. Print out what's happening. So test loss, which we put in here, well, we're going to get the test loss. Let's get this to five decimal places. And then we're going to go test act. And we will get that to two decimal places. You could do this as many decimal as you want. You could even times it by 100 to get it in proper accuracy format. And we'll put a new line on the end here. Wonderful. So now it looks like we've got functions. I haven't run this cell yet for a training step and a test step. So how do you think we could replicate if we go back up to our training loop that we wrote before? How do you think we could replicate the functionality of this, except this time using our functions? Well, we could still use this for epoch and TQDM range epochs. But then we would just call our training step for this training code, our training step function. And we would call our testing step function, passing in the appropriate parameters for our testing loop. So that's what we'll do in the next video. We will leverage our two functions, train step and test step to train model one. But here's your challenge for this video. Give that a go. So use our training step and test step function to train model one for three epochs and see how you go. But we'll do it together in the next video. Welcome back. How'd you go? Did you create a training loop or a PyTorch optimization loop using our training step function and a test step function? Were there any errors? In fact, I don't even know. But how about we find out together? Hey, how do we combine these two functions to create an optimization loop? So I'm going to go torch dot manual seed 42. And I'm going to measure the time of how long our training and test loop takes. This time we're using a different model. So this model uses nonlinearities and it's on the GPU. So that's the main thing we want to compare is how long our model took on CPU versus GPU. So I'm going to import from time it, import default timer as timer. And I'm going to start the train time. Train time start on GPU equals timer. And then I'm just right here, set epochs. I'm going to set epochs equal to three, because we want to keep our training experiments as close to the same as possible. So we can see what little changes do what. And then it's create a optimization and evaluation loop using train step and test step. So we're going to loop through the epochs for epoch in TQDM. So we get a nice progress bar in epochs. Then we're going to print epoch. A little print out of what's going on. Epoch. And we'll get a new line. And then maybe one, two, three, four, five, six, seven, eight or something like that. Maybe I'm miscounted there. But that's all right. Train step. What do we have to do for this? Now we have a little doc string. We have a model. What model would we like to use? We'd like to use model one. We have a data loader. What data loader would we like to use? Well, we'd like to use our train data loader. We also have a loss function, which is our loss function. We have an optimizer, which is our optimizer. And we have an accuracy function, which is our accuracy function. And oops, forgot to put FM. And finally, we have a device, which equals device, but we're going to set that anyway. So how beautiful is that for creating a training loop? Thanks to the code that we've functionalized before. And just recall, we set our optimizer and loss function in a previous video. You could bring these down here if you really wanted to, so that they're all in one place, either way up. But we can just get rid of that because we've already set it. Now we're going to do the same thing for our test step. So what do we need here? Let's check the doc string. We could put a little bit more information in this doc string if we wanted to to really make our code more reusable, and so that if someone else was to use our code, or even us in the future knows what's going on. But let's just code it out because we're just still fresh in our minds. Model equals model one. What's our data loader going to be for the test step? It's going to be our test data loader. Then we're going to set in a loss function, which is going to be just the same loss function. We don't need to use an optimizer here because we are only evaluating our model, but we can pass in our accuracy function. Accuracy function. And then finally, the device is already set, but we can just pass it in anyway. Look at that. Our whole optimization loop in a few lines of code. Isn't that beautiful? So these functions are something that you could put in, like our helper functions dot pi. And that way you could just import it later on. And you don't have to write your training loops all over again. But we'll see a more of an example of that later on in the course. So let's keep going. We want to measure the train time, right? So we're going to create, once it's been through these steps, we're going to create train time end on CPU. And then we're going to set that to the timer. So all this is going to do is measure at value in time, once this line of code is run, it's going to run all of these lines of code. So it's going to perform the training and optimization loop. And then it's going to, oh, excuse me, this should be GPU. It's going to measure a point in time here. So once all this codes run, measure a point in time there. And then finally, we can go total train time for model one is equal to print train time, which is our function that we wrote before. And we pass it in a start time. And it prints the difference between the start and end time on a target device. So let's do that. Start equals what? Train time start on GPU. The end is going to be train time end on GPU. And the device is going to be device. Beautiful. So are you ready to run our next modeling experiment model one? We've got a model running on the GPU, and it's using nonlinear layers. And we want to compare it to our first model, which our results were model zero results. And we have total train time on model zero. Yes, we do. So this is what we're going for. Does our model one beat these results? And does it beat this result here? So three, two, one, do we have any errors? No, we don't. Okay. Train step got an unexpected keyword loss. Oh, did you catch that? I didn't type in loss function. Let's run it again. There we go. Okay, we're running. We've got a progress bar. It's going to output at the end of each epoch. There we go. Training loss. All right. Test accuracy, training accuracy. This is so exciting. I love watching neural networks train. Okay, we're improving per epoch. That's a good sign. But we've still got a fair way to go. Oh, okay. So what do we have here? Well, we didn't beat our, hmm, it looks like we didn't beat our model zero results with the nonlinear layers. And we only just slightly had a faster training time. Now, again, your numbers might not be the exact same as what I've got here. Right? So that's a big thing about machine learning is that it uses randomness. So your numbers might be slightly different. The direction should be quite similar. And we may be using different GPUs. So just keep that in mind. Right now I'm using a new video, SMI. I'm using a Tesla T4, which is at the time of recording this video, Wednesday, April 20, 2022 is a relatively fast GPU for making inference. So just keep that in mind. Your GPU in the future may be different. And your CPU that you run may also have a different time here. So if these numbers are like 10 times higher, you might want to look into seeing if your code is there's some error. If they're 10 times lower, well, hey, you're running it on some fast hardware. So it looks like my code is running on CUDA slightly faster than the CPU, but not dramatically faster. And that's probably akin to the fact that our data set isn't too complex and our model isn't too large. What I mean by that is our model doesn't have like a vast amount of layers. And our data set is only comprised of like, this is the layers our model has. And our data set is only comprised of 60,000 images that are 28 by 28. So as you can imagine, the more parameters in your model, the more features in your data, the higher this time is going to be. And you might sometimes even find that your model is faster on CPU. So this is the train time on CPU. You might sometimes find that your model's training time on a CPU is in fact faster for the exact same code running on a GPU. Now, why might that be? Well, let's write down this here. Let's go note. Sometimes, depending on your data slash hardware, you might find that your model trains faster on CPU than GPU. Now, why is this? So one of the number one reasons is that one, it could be that the overhead for copying data slash model to and from the GPU outweighs the compute benefits offered by the GPU. So that's probably one of the number one reasons is that you have to, for data to be processed on a GPU, you have to copy it because it is by default on the CPU. If you have to copy it to that GPU, you have some overhead time for doing that copy into the GPU memory. And then although the GPU will probably compute faster on that data once it's there, you still have that back and forth of going between the CPU and the GPU. And the number two reason is that the hardware you're using has a better CPU in terms of compute capability than the GPU. Now, this is quite a bit rarer. Usually if you're using a GPU like a fairly modern GPU, it will be faster at computing, deep learning or running deep learning algorithms than your general CPU. But sometimes these numbers of compute time are really dependent on the hardware that you're running. So you'll get the biggest benefits of speedups on the GPU when you're running larger models, larger data sets, and more compute intensive layers in your neural networks. And so if you'd like a great article on how to get the most out of your GPUs, it's a little bit technical, but this is something to keep in mind as you progress as a machine learning engineer is how to make your GPUs go burr. And I mean that burr from first principles. There we go. Making deep learning go burr as in your GPU is going burr because it's running so fast from first principles. So this is by Horace He who works on PyTorch. And it's great. It talks about compute as a first principle. So here's what I mean by copying memory and compute. There might be a fair few things you're not familiar with here, but that's okay. But just be aware bandwidth. So bandwidth costs are essentially the cost paid to move data from one place to another. That's what I was talking about copying stuff from the CPU to the GPU. And then also there's one more, where is it overhead? Overhead is basically everything else. I called it overhead. There are different terms for different things. This article is excellent. So I'm going to just copy this in here. And you'll find this in the resources, by the way. So for more on how to make your models compute faster, see here. Lovely. So right now our baseline model is performing the best in terms of results. And in terms of, or actually our model computing on the GPU is performing faster than our CPU. Again yours might be slightly different. For my case, for my particular hardware, CUDA is faster. Except model zero, our baseline is better than model one. So what's to do next? Well, it's to keep experimenting, of course. I'll see you in the next video. Welcome back. Now, before we move on to the next modeling experiment, let's get a results dictionary for our model one, a model that we trained on. So just like we've got one for model zero, let's create one of these for model one results. And we can create that without a vowel model function. So we'll go right back down to where we were. I'll just get rid of this cell. And let's type in here, get model one results dictionary. This is helpful. So later on, we can compare all of our modeling results, because they'll all be in dictionary format. So we're going to model one results equals a vowel model on a model equals model one. And we can pass in a data loader, which is going to be our test data loader. Then we can pass in a loss function, which is going to equal our loss function. And we can pass in our accuracy function equals accuracy function. Wonderful. And then if we check out our model one results, what do we get? Oh, no, we get an error. Do we get the code right? That looks right to me. Oh, what does this say runtime error expected all tensors to be on the same device, but found at least two devices, CUDA and CPU. Of course. So why did this happen? Well, let's go back up to our of our model function, wherever we defined that. Here we go. Ah, I see. So this is a little gotcha in pytorch or in deep learning in general. There's a saying in the industry that deep learning models fail silently. And this is kind of one of those ones. It's because our data and our model are on different devices. So remember how I said the three big errors are shape mismatches with your data and your model device mismatches, which is what we've got so far. And then data type mismatches, which is if your data is in the wrong data type to be computed on. So what we're going to have to do to fix this is let's bring down our vowel model function down to where we were. And just like we've done in our test step and train step functions, where we've created device agnostic data here, we've sent our data to the target device, we'll do that exact same thing in our vowel model function. And this is just a note for going forward. It's always handy to where you can create device agnostic code. So we've got our new of our model function here for x, y in our data loader. Let's make our data device agnostic. So just like our model is device agnostic, we've sent it to the target device, we will do the same here, x dot two device, and then y dot two device. Let's see if that works. We will just rerun this cell up here. I'll grab this, we're just going to write the exact same code as what we did before. But now it should work because we've sent our, we could actually also just pass in the target device here, device equals device. That way we can pass in whatever device we want to run it on. And we're going to just add in device here, device equals device. And let's see if this runs correctly. Beautiful. So if we compare this to our model zero results, it looks like our baseline's still out in front. But that's okay. We're going to in the next video, start to step things up a notch and move on to convolutional neural networks. This is very exciting. And by the way, just remember, if your numbers here aren't exactly the same as mine, don't worry too much. If they're out landishly different, just go back through your code and see if it's maybe a cell hasn't been run correctly or something like that. If there are a few decimal places off, that's okay. That's due to the inherent randomness of machine learning and deep learning. But with that being said, I'll see you in the next video. Let's get our hands on convolutional neural networks. Welcome back. In the last video, we saw that our second modeling experiment, model one, didn't quite beat our baseline. But now we're going to keep going with modeling experiments. And we're going to move on to model two. And this is very exciting. We're going to build a convolutional neural network, which are also known as CNN. CNNs are also known as com net. And CNNs are known for their capabilities to find patterns in visual data. So what are we going to do? Well, let's jump back into the keynote. We had a look at this slide before where this is the typical architecture of a CNN. There's a fair bit going on here, but we're going to step through it one by one. We have an input layer, just like any other deep learning model. We have to input some kind of data. We have a bunch of hidden layers in our case in a convolutional neural network, you have convolutional layers. You often have hidden activations or nonlinear activation layers. You might have a pooling layer. You generally always have an output layer of some sort, which is usually a linear layer. And so the values for each of these different layers will depend on the problem you're working on. So we're going to work towards building something like this. And you'll notice that a lot of the code is quite similar to the code that we've been writing before for other PyTorch models. The only difference is in here is that we're going to use different layer types. And so if we want to visualize a CNN in a colored block edition, we're going to code this out in a minute. So don't worry too much. We have a simple CNN. You might have an input, which could be this image of my dad eating some pizza with two thumbs up. We're going to preprocess that input. We're going to, in other words, turn it into a tensor in red, green and blue for an image. And then we're going to pass it through a combination of convolutional layers, relu layers and pooling layers. Now again, this is a thing to note about deep learning models. I don't want you to get too bogged down in the order of how these layers go, because they can be combined in many different ways. In fact, research is coming out almost every day, every week about how to best construct these layers. The overall principle is what's more important is how do you get your inputs into an idolized output? That's the fun part. And then of course, we have the linear output layer, which is going to output however many classes or value for however many classes that we have in the case of classification. And then if you want to make your CNN deeper, this is where the deep comes from deep learning, you can add more layers. So the theory behind this, or the practice behind this, is that the more layers you add to your deep learning model, the more chances it has to find patterns in the data. Now, how does it find these patterns? Well, each one of these layers here is going to perform, just like what we've seen before, a different combination of mathematical operations on whatever data we feed it. And each subsequent layer receives its input from the previous layer. In this case, there are some advanced networks that you'll probably come across later in your research and machine learning career that use inputs from layers that are kind of over here or the way down here or something like that. They're known as residual connections. But that's beyond the scope of what we're covering for now. We just want to build our first convolutional neural network. And so let's go back to Google Chrome. I'm going to show you my favorite website to learn about convolutional neural networks. It is the CNN explainer website. And this is going to be part of your extra curriculum for this video is to spend 20 minutes clicking and going through this entire website. We're not going to do that together because I would like you to explore it yourself. That is the best way to learn. So what you'll notice up here is we have some images of some different sort. And this is going to be our input. So let's start with pizza. And then we have a convolutional layer, a relu layer, a conv layer, a relu layer, max pool layer, com to relu to com to relu to max pool to this architecture is a convolutional neural network. And it's running live in the browser. And so we pass this image, you'll notice that it breaks down into red, green and blue. And then it goes through each of these layers and something happens. And then finally, we have an output. And you notice that the output has 10 different classes here, because we have one, two, three, four, five, six, seven, eight, nine, 10, different classes of image in this demo here. And of course, we could change this if we had 100 classes, we might change this to 100. But the pieces of the puzzle here would still stay quite the same. And you'll notice that the class pizza has the highest output value here, because our images of pizza, if we change to what is this one, espresso, it's got the highest value there. So this is a pretty well performing convolutional neural network. Then we have a sport car. Now, if we clicked on each one of these, something is going to happen. Let's find out. We have a convolutional layer. So we have an input of an image here that 64 64 by three. This is color channels last format. So we have a kernel. And this kernel, this is what happens inside a convolutional layer. And you might be going, well, there's a lot going on here. And yes, of course, there is if this is the first time you ever seen this. But essentially, what's happening is a kernel, which is also known as a filter, is going over our image pixel values, because of course, they will be in the format of a tensor. And trying to find small little intricate patterns in that data. So if we have a look here, and this is why it's so valuable to go through this and just play around with it, we start in a top left corner, and then slowly move along, you'll see on the output on the right hand side, we have another little square. And do you notice in the middle all of those numbers changing? Well, that is the mathematical operation that's happening as a convolutional layer convolves over our input image. How cool is that? And you might be able to see on the output there that there's some slight values for like, look around the headlight here. Do you notice on the right how there's some activation? There's some red tiles there? Well, that just means that potentially this layer or this hidden unit, and I want to zoom out for a second, is we have 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 hidden units. Each one of these is going to learn a different feature about the data. And now the beauty of deep learning, but also one of the curses of deep learning is that we don't actually control what each one of these learns. The magic of deep learning is that it figures it out itself what is best to learn. We go into here, notice that each one we click on has a different representation on the right hand side. And so this is what's going to happen layer by layer as it goes through the convolutional neural network. And so if you want to read about what is a convolutional neural network, you can go through here. But we're going to replicate this exact neural network here with PyTorch code. That's how I'd prefer to learn it. But if you want the intuition behind it, the math behind it, you can check out all of these resources here. That is your extra curriculum for this video. So we have an input layer, we have a convolutional layer, you can see how the input gets modified by some sort of mathematical operation, which is of course, the convolutional operation. And we have there all different numbers finding different patterns and data. This is a really good example here. You notice that the outputs eyes slightly changes, that'll be a trend throughout each layer. And then we can understand the different hyper parameters, but I'm going to leave this for you to explore on your own. In the next video, we're going to start to write PyTorch code to replicate everything that's going on here. So I'm going to link this in here to find out what's happening inside CNN. See this website here. So join me in the next video. This is super exciting. We're going to build our first convolutional neural network for computer vision. I'll see you there. Welcome back. In the last video, we went briefly through the CNN explainer website, which is my favorite resource for learning about convolutional neural networks. And of course, we could spend 20 minutes clicking through everything here to find out what's going on with a convolutional neural network, or we could start to code one up. So how about we do that? Hey, if and down, code it out. So we're going to create a convolutional neural network. And what I'm going to do is I'm going to build this, or we're going to build this model together in this video. And then because it's going to use layers or PyTorch layers that we haven't looked at before, we're going to spend the next couple of videos stepping through those layers. So just bear with me, as we code this entire model together, we'll go break it down in subsequent videos. So let's build our first convolutional neural network. That's a mouthful, by the way, I'm just going to probably stick to saying CNN. Fashion MNIST, we're up to model V2. We're going to subclass nn.module, as we always do when we're building a PyTorch model. And in here, we're going to say model architecture that replicates the tiny VGG. And you might be thinking, where did you get that from, Daniel? Model from CNN explainer website. And so oftentimes, when convolutional neural networks or new types of architecture come out, the authors of the research paper that present the model get to name the model. And so that way, in the future, you can refer to different types of model architectures with just a simple name, like tiny VGG. And people kind of know what's going on. So I believe somewhere on here, it's called tiny VGG, tiny VGG. We have nothing. Yeah, there we go. In tiny VGG. And do we have more than one tiny, tiny, yeah, tiny VGG. And if we look up VGG, conv net, VGG 16 was one of the original ones, VGG, very deep convolutional neural networks of VGG net. There's also ResNet, which is another convolutional neural network. You can also, I don't want to give you my location, Google, you can go popular CNN architectures. And this will give you a fair few options. Lynette is one of the first AlexNet, ZF net, whole bunch of different resources. And also, how could you find out more about a convolutional neural network? What is a convolutional neural network? You can go through that. But let's stop that for a moment. Let's code this one up together. So we're going to initialize our class here, def init. We're going to pass it in an input shape, just like we often do. We're going to put in a number of hidden units, which is an int. And we're going to put in an output shape, which is an int. Wonderful. So nothing to outlandish that we haven't seen before there. And we're going to go super dot init to initialize our initializer for lack of a better way of putting it. Now, we're going to create our neural network in a couple of blocks this time. And you might often hear in when you learn more about convolutional neural networks, or I'll just tell you that things are referred to are often referred to as convolutional blocks. So if we go back to our keynote, this here, this combination of layers might be referred to as a convolutional block. And a convolutional block, a deeper CNN, might be comprised of multiple convolutional blocks. So to add to the confusion, a block is comprised of multiple layers. And then an overall architecture is comprised of multiple blocks. And so the deeper and deeper your models get, the more blocks it might be comprised of, and the more layers those blocks may be comprised of within them. So it's kind of like Lego, which is very fun. So let's put together an an ensequential. Now, the first few layers here that we're going to create in conv block one, uh, nn.com 2d. Oh, look at that. Us writing us our first CNN layer. And we have to define something here, which is in channels. So this channels refers to the number of channels in your visual data. And we're going to put in input shape. So we're defining the input shape. This is going to be the first layer in our model. The input shape is going to be what we define when we instantiate this class. And then the out channels. Oh, what's the out channels going to be? Well, it's going to be hidden units, just like we've done with our previous models. Now the difference here is that in nn.com 2d, we have a number of different hyper parameters that we can set. I'm going to set some pretty quickly here, but then we're going to step back through them, not only in this video, but in subsequent videos. We've got a fair bit going on here. We've got in channels, which is our input shape. We've got out channels, which are our hidden units. We've got a kernel size, which equals three. Or this could be a tuple as well, three by three. But I just like to keep it as three. We've got a stride and we've got padding. Now, because these are values, we can set ourselves. What are they referred to as? Let's write this down. Values, we can set ourselves in our neural networks. In our nn's neural networks are called hyper parameters. So these are the hyper parameters of nn.com 2d. And you might be thinking, what is 2d for? Well, because we're working with two-dimensional data, our images have height and width. There's also com 1d for one-dimensional data, 3d for three-dimensional data. We're going to stick with 2d for now. And so what do each of these hyper parameters do? Well, before we go through what each one of them do, we're going to do that when we step by step through this particular layer. What we've just done is we've replicated this particular layer of the CNN explainer website. We've still got the relu. We've still got another conv and a relu and a max pool and a conv and a relu and a conv and a relu and a max pool. But this is the block I was talking about. This is one block here of this neural network, or at least that's how I've broken it down. And this is another block. You might notice that they're comprised of the same layers just stacked on top of each other. And then we're going to have an output layer. And if you want to learn about where the hyper parameters came from, what we just coded, where could you learn about those? Well, one, you could go, of course, to the PyTorch documentation, PyTorch, and then com 2d. You can read about it there. There's the mathematical operation that we talked about or briefly stepped on before, or touched on, stepped on. Is that the right word? So create a conv layer. It's there. But also this is why I showed you this beautiful website so that you can read about these hyper parameters down here. Understanding hyper parameters. So your extra curriculum for this video is to go through this little graphic here and see if you can find out what padding means, what the kernel size means, and what the stride means. I'm not going to read through this for you. You can have a look at this interactive plot. We're going to keep coding because that's what we're all about here. If and out, code it out. So we're going to now add a relu layer. And then after that, we're going to add another conv 2d layer. And the in channels here is going to be the hidden units, because we're going to take the output size of this layer and use it as the input size to this layer. We're going to keep going here. Out channels equals hidden units again in this case. And then the kernel size is going to be three as well. Stride will be one. Padding will be one. Now, of course, we can change all of these values later on, but just bear with me while we set them how they are. We'll have another relu layer. And then we're going to finish off with a nn max pool 2d layer. Again, the 2d comes from the same reason we use comf2d. We're working with 2d data here. And we're going to set the kernel size here to be equal to two. And of course, this can be a tuple as well. So it can be two two. Now, where could you find out about nn max pool 2d? Well, we go nn max pool 2d. What does this do? applies a 2d max pooling over an input signal composed of several input planes. So it's taking the max of an input. And we've got some parameters here, kernel size, the size of the window to take the max over. Now, where have we seen a window before? I'm just going to close these. We come back up. Where did we see a window? Let's dive into the max pool layer. See where my mouse is? Do you see that two by two? Well, that's a window. Now, look at the difference between the input and the output. What's happening? Well, we have a tile that's two by two, a window of four. And the max, we're taking the max of that tile. In this case, it's zero. Let's find the actual value. There we go. So if you look at those four numbers in the middle inside the max brackets, we have 0.07, 0.09, 0.06, 0.05. And the max of all those is 0.09. And you'll notice that the input and the output shapes are different. The output is half the size of the input. So that's what max pooling does, is it tries to take the max value of whatever its input is, and then outputs it on the right here. And so as our data, this is a trend in all of deep learning, actually. As our image moves through, this is what you'll notice. Notice all the different shapes here. Even if you don't completely understand what's going on here, you'll notice that the two values here on the left start to get smaller and smaller as they go through the model. And what our model is trying to do here is take the input and learn a compressed representation through each of these layers. So it's going to smoosh and smoosh and smoosh trying to find the most generalizable patterns to get to the ideal output. And that input is eventually going to be a feature vector to our final layer. So a lot going on there, but let's keep coding. What we've just completed is this first block. We've got a cons layer, a relu layer, a cons layer, a relu layer, and a max pool layer. Look at that, cons layer, relu layer, cons layer, relu layer, max pool. Should we move on to the next block? We can do this one a bit faster now because we've already coded the first one. So I'm going to do nn.sequential as well. And then we're going to go nn.com2d. We're going to set the in channels. What should the in channels be here? Well, we're going to set it to hidden units as well because our network is going to flow just straight through all of these layers. And the output size of this is going to be hidden units. And so we want the in channels to match up with the previous layers out channels. So then we're going to go out channels equals hidden units as well. We're going to set the kernel size, kernel size equals three, stride equals one, padding equals one, then what comes next? Well, because the two blocks are identical, the con block one and com two, we can just go the exact same combination of layers. And then relu and n.com2d in channels equals hidden units. Out channels equals, you might already know this, hidden units. Then we have kernel size equals three, oh, 32, don't want it that big, stride equals one, padding equals one, and what comes next? Well, we have another relu layer, relu, and then what comes after that? We have another max pool. And then max pool 2d, kernel size equals two, beautiful. Now, what have we coded up so far? We've got this block, number one, that's what this one on the inside here. And then we have com two, relu two, com two, relu two, max pool two. So we've built these two blocks. Now, what do we need to do? Well, we need an output layer. And so what did we do before when we made model one? We flattened the inputs of the final layer before we put them to the last linear layer. So flatten. So this is going to be the same kind of setup as our classifier layer. Now, I say that on purpose, because that's what you'll generally hear the last output layer in a classification model called is a classifier layer. So we're going to have these two layers are going to be feature extractors. In other words, they're trying to learn the patterns that best represent our data. And this final layer is going to take those features and classify them into our target classes. Whatever our model thinks best suits those features, or whatever our model thinks those features that it learned represents in terms of our classes. So let's code it out. We'll go down here. Let's build our classifier layer. This is our biggest neural network yet. You should be very proud. We have an end of sequential again. And we're going to pass in an end of flatten, because the output of these two blocks is going to be a multi-dimensional tensor, something similar to this size 131310. So we want to flatten the outputs into a single feature vector. And then we want to pass that feature vector to an nn.linear layer. And we're going to go in features equals hidden units times something times something. Now, the reason I do this is because we're going to find something out later on, or time zero, just so it doesn't error. But sometimes calculating what you're in features needs to be is quite tricky. And I'm going to show you a trick that I use later on to figure it out. And then we have out features relates to our output shape, which will be the length of how many classes we have, right? One value for each class that we have. And so with that being said, let's now that we've defined all of the components of our tiny VGG architecture. There is a lot going on, but this is the same methodology we've been using the whole time, defining some components, and then putting them together to compute in some way in a forward method. So forward self X. How are we going to do this? Are we going to set X is equal to self, comp block one X. So X is going to go through comp block one, it's going to go through the comp 2D layer, relu layer, comp 2D layer, relu layer, max pool layer, which will be the equivalent of an image going through this layer, this layer, this layer, this layer, this layer, and then ending up here. So we'll set it to that. And then we can print out X dot shape to get its shape. We'll check this later on. Then we pass X through comp block two, which is just going to go through all of the layers in this block, which is equivalent to the output of this layer going through all of these layers. And then because we've constructed a classifier layer, we're going to take the output of this block, which is going to be here, and we're going to pass it through our output layer, or what we've termed it, our classifier layer. I'll just print out X dot shape here, so we can track the shape as our model moves through the architecture. X equals self dot classifier X. And then we're going to return X. Look at us go. We just built our first convolutional neural network by replicating what's on a CNN explainer website. Now, that is actually very common practice in machine learning is to find some sort of architecture that someone has found to work on some sort of problem and replicate it with code and see if it works on your own problem. You'll see this quite often. And so now let's instantiate a model. Go torch dot manual C. We're going to instantiate our first convolutional neural network. Model two equals fashion amnest. We will go model V two. And we are going to set the input shape. Now, what will the input shape be? Well, I'll come to the layer up here. The input shape is the number of channels in our images. So do we have an image ready to go image shape? This is the number of color channels in our image. We have one. If we had color images, we would set the input shape to three. So the difference between our convolutional neural network, our CNN, tiny VGG, and the CNN explainer tiny VGG is that they are using color images. So their input is three here. So one for each color channel, red, green and blue. Whereas we have black and white images. So we have only one color channel. So we set the input shape to one. And then we're going to go hidden units equals 10, which is exactly the same as what tiny VGG has used. 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. So that sets the hidden units value of each of our layers. That's the power of creating an initializer with hidden units. And then finally, our output shape is going to be what we've seen this before. This is going to be the length of our class names, one value for each class in our data set. And of course, we're going to send this model to the device. We're going to hit shift and enter. Oh, no, what did we get wrong? Out channels, output shape. Where did I spell wrong? Out channels, out channels, out channels. I forgot an L. Of course, typo. Oh, kernel size and other typo. Did you notice that? Kernel size, kernel size, kernel size, kernel size. Where did we spell this wrong? Oh, here. Kernel size. Are there any other typos? Probably. A beautiful. There we go. Okay, what have we got? Initializing zero, obtenses and non-op. Oh, so we've got an issue here and error here because I've got this. But this is just to, there's a trick to calculating this. We're going to cover this in another video. But pay yourself on the back. We've written a fair bit of code here. This is a convolutional neural network that replicates the tiny VGG architecture on the CNN explainer website. Now, don't forget, your extra curriculum is to go through this website for at least 20 minutes and read about what's happening in our models. We're focused on code here. But this is particularly where you want to pay attention to. If you read through this understanding hyper parameters and play around with this, the next couple of videos will make a lot more sense. So read about padding, read about kernel size and read about stride. I'll see you in the next video. We're going to go through our network step by step. Welcome back. Now, I'm super stoked because in the last video, we coded together our first ever convolutional neural network in PyTorch. So well done. We replicated the tiny VGG architecture from the CNN explainer website, my favorite place for learning about CNNs in the browser. So now we introduced two new layers that we haven't seen before, conv2d and maxpool2d. But they all have the same sort of premise of what we've been doing so far is that they're trying to learn the best features to represent our data in some way, shape or form. Now, in the case of maxpool2d, it doesn't actually have any learnable parameters. It just takes the max, but we're going to step through that later on. Let's use this video to step through and then conv2d. We're going to do that with code. So I'll make a new heading here. 7.1 stepping through and then conv2d. Beautiful. Now, where could we find out what's going on in an end comp2d? Well, of course, we have the documentation and then comp2d. We've got PyTorch. So if you want to learn the mathematical operation that's happening, we have this value here, this operation here. Essentially, it's saying the output is equal to the bias term times something, plus the sum of the weight times something times the input. So do you see how just the weight matrix, the weight tensor and the bias value, manipulating our input in some way equals the output? Now, if we map this, we've got batch size, channels in, height, width, channels out, out, out, et cetera, et cetera. But we're not going to focus too much on this. If you'd like to read more into that, you can. Let's try it with code. And we're going to reproduce this particular layer here, the first layer of the CNN explainer website. And we're going to do it with a dummy input. In fact, that's one of my favorite ways to test things. So I'm just going to link here the documentation. See the documentation for an end comp2d here. And if you'd like to read through more of this, of course, this is a beautiful place to learn about what's going on. There's the shape how to calculate the shape, height out, width out, et cetera. That's very helpful if you need to calculate input and output shapes. But I'll show you my trick for doing so later on. We have here, let's create some dummy data. So I'm going to set torch manual seed. We need it to be the same size as our CNN explainer data. So 64, 64, 3. But we're going to do it pie torch style. This is color channels last. We're going to do color channels first. So how about we create a batch of images, we're going to be writing torch dot rand n. And we're going to pass in size equals 32, three, 64, 64. And then we're going to create a singular image by taking the first of that. So image is zero. Now, let's get the image batch shape. Because a lot of machine learning, as I've said before, and deep learning is making sure your data has the right shape. So let's check images dot shape. And let's check single image shape. We're going to go test image dot shape. And finally, we're going to print, what does the test image look like? We'll get this on a new line, hey, new line test image, this is of course not going to be an actual image is just going to be a collection of random numbers. And of course, that is what our model is currently comprised of model two, if we have a look at what's on the insides, we are going to see a whole bunch of random numbers. Look at all this. What do we have? We scroll up is going to give us a name for something. We have comp block two, two, we have a weight, we have a bias, keep going up, we go right to the top, we have another weight, keep going down, we have a bias, a weight, et cetera, et cetera. Now, our model is comprised of random numbers, and what we are trying to do is just like all of our other models is pass data in and adjust the random numbers within these layers to best represent our data. So let's see what happens if we pass some random data through one of our comp2d layers. So let's go here, we're going to create a single comp2d layer. So comp layer equals, what is it equal? And then comp2d, and we're going to set the in channels is equal to what? Oh, revealed the answer too quickly. Three. Why is it three? Well, it's because the in channels is the same number of color channels as our images. So if we have a look at our test image shape, what do we have? Three, it has three color channels. That is the same as the value here, except the order is reversed. This is color channels last, pytorch defaults to color channels first. So, or for now it does, in the future this may change. So just keep that in mind. So out channels equals 10. This is equivalent to the number of hidden units we have. One. Oh, I don't want that one just yet. One, two, three, four, five, six, seven, eight, nine, 10. So we have that 10 there. So we have 10 there. And then we have kernel size. Oh, what is the kernel? Well, it's not KFC. I can tell you that. And then we have stride. And then we have padding. We're going to step through these in a second. But let's check out the kernel. And this kernel can also be three by three. But it's a shortcut to just type in three. So that's what it actually means. If you just type in a single number, it's equivalent to typing in a tuple. Now, of course, you could find that out by reading through the documentation here. But where did I get that value? Well, let's dive into this beautiful website. And let's see what happening. So we have a kernel here, which is also called a filter. So the thing I'm talking about is this little square here, this kernel. Oh, we can see the weights there at the top. This is how beautiful this website is. So if we go over there, this is what's going to happen. This is a convolution. It starts with this little square, and it moves pixel by pixel across our image. And you'll notice that the output is creating some sort of number there. And you'll notice in the middle, we have a mathematical operation. This operation here is what's happening here. I wait times the input. That's what we've got there. Now, the beauty of PyTorch is it does all of this behind the scenes for us. So again, if you'd like to dig more into the mathematical operation behind the scenes, you've got the resource here. And you've also got plenty of other resources online. We're going to focus on code for now. So if we keep doing this across our entire image, we get this output over here. So that's the kernel. And now where did I get three by three from? Well, look at this. One, two, three, one, two, three, one, two, three, three by three, we have nine squares. Now, if we scroll down, this was your extracurricular for the last video, understanding hyperparameters. What happens if we change the kernel size to three by three? Have a look at the red square on the left. Now, if we change it to two by two, it changed again. Three by three. This is our kernel, or also known as a filter, passing across our image, performing some sort of mathematical operation. And now the whole idea of a convolutional layer is to try and make sure that this kernel performs the right operation to get the right output over here. Now, what do these kernels learn? Well, that is entirely up to the model. That's the beauty of deep learning is that it learns how to best represent our data, hopefully, on its own by looking at more data. And then so if we jump back in here, so that's the equivalent of setting kernel size three by three. What if we set the stride equal to one? Have we got this in the right order? It doesn't really matter. Let's go through stride next. If we go to here, what does stride say? Stride of the convolution of the convolving kernel. The default is one. Wonderful. Now, if we set the stride, or if we keep it at one, it's a default one, it's going to hop over, watch the red square on the left. It's going to hop over one pixel at a time. So the convolution, the convolving, happens one pixel at a time. That's what the stride sets. Now, watch what happens when I change the stride value to the output shape. Wow. Do you notice that it went down? So we have here, the kernel size is still the same. But now we're jumping over two pixels at a time. Notice how on the left, two pixels become available. And then if I jump over again, two pixels. So the reason why the output compresses is because we're skipping some pixels as we go across the image. And now this pattern happens throughout the entire network. That's one of the reasons why you see the size of our input or the size of each layer go down over time. What our convolutional layer is doing, and in fact, a lot of deep learning neural networks do, is they try to compress the input into some representation that best suits the data. Because it would be no point of just memorizing the exact patterns, you want to compress it in some way. Otherwise, you just might as well move your input data around. You want to learn generalizable patterns that you can move around. And so we keep going. We've got padding equals zero. Let's see what happens here. If we change the padding value, what happens? Up, down. Notice the size here. Oh, we've added two extra pixels around the edge. Now if we go down, one extra pixel. Now if we go zero, now why might we do that? If we add some padding on the end, well, that's so that our kernel can operate on what's going on here in the corner. In case there's some information on the edges of our image. Then you might be thinking, Daniel, there's a whole bunch of values here. How do we know what to set them? Well, you notice that I've just copied exactly what is going on here. There's a three by three kernel. There's no padding on the image. And the stride is just going one by one. And so that's often very common in machine learning, is that when you're just getting started and you're not sure what values to set these values to, you just copy some existing values from somewhere and see if it works on your own problem. And then if it doesn't, well, you can adjust them. So let's see what happens when we do that. So pass the data through the convolutional layer. So let's see what happens. Conv output equals conv layer. Let's pass it our test image. And we'll check the conv output. What happens? Oh no, we get an error. Of course we get a shape error. One of the most common issues of machine learning and deep learning. So this is saying that our input for the conv layer expects a four dimensional tensor, except it got a three dimensional input size of 364 64. Now, how do we add an extra dimension to our test image? Let's have a look. How would we add a batch dimension over on the left here? We can go unsqueeze zero. So now we have a four dimensional tensor. Now, just keep in mind that if you're running this layer and then com2d on a pytorch version, that is, I believe they fixed this or they changed it in pytorch. What am I on? I think this Google collab instance is on 1.10. I think you might not get this error if you're running 1.11. So just keep that in mind. Like this should work if you're running 1.11. But if it doesn't, you can always unsqueeze here. And let's see what happens. Look at that. We get another tensor output. Again, this is just all random numbers though, because our test image is just random numbers. And our conv layer is instantiated with random numbers. But we'll set the manual seed here. Now, if our numbers are different to what's, if your numbers are different to what's on my screen, don't worry too much. Why is that? Because our conv layer is instantiated with random numbers. And our test image is just random numbers as well. What we're paying attention to is the input and output shapes. Do you see what just happened? We put our input image in there with three channels. And now because we've set out channels to be 10, we've got 10. And we've got 62, 62. And this is just the batch size. It just means one image. So essentially our random numbers, our test image, have gone through the convolutional layer that we created, have gone through this mathematical operation with regards to all the values that we've set, we've put the weight tensor, well, actually PyTorch created that for us. PyTorch has done this whole operation for us. Thank you, PyTorch. It's gone through all of these steps across. You could code this all by hand if you want, but it's a lot easier and simpler to use a PyTorch layer. And it's done this. And now it's created this output. Now, whatever this output is, I don't know, it is random numbers, but this same process will happen if we use actual data as well. So let's see what happens if we change the values kernel size we increase. Notice how our output has gotten smaller because we're using a bigger kernel to convolve across the image. What if we put this to three, three back to what it was and stride of two? What do you think will happen? Well, our output size basically halves because we're skipping two pixels at a time. We'll put that back to one. What do you think will happen if we set padding to one? 64, 64. We get basically the same size because we've added an extra pixel around the edges. So you can play around with this. And in fact, I encourage you to do this is what we just did. Padding one, we just added an extra dummy zero pixel around the edges. So practice with this, see what happens as you pass our test image, random numbers, through a conv 2d layer with different values here. What do you think will happen if you change this to 64? Give that a shot and I'll see you in the next video. Who's ready to step through the nn max pool 2d layer? Put your hand up. I've got my hand up. So let's do it together, hey, we've got 7.2. Now you might have already given this a shot yourself. Stepping through nn max pool 2d. And this is this is what I do for a lot of different concepts that I haven't gone through before is I just write some test code and see what the inputs and outputs are. And so where could we find out about max pool 2d? Well, of course, we've got the documentation. I'm just going to link this in here. Max pool 2d. In the simplest case, the output value of layer with input size nchw output nch out w out. By the way, this is number of batches, color channels, height, width. And this is the output of that layer. And kernel size, which is a parameter up here, k h k w can be precisely described as out is going to be the max of some value, depending on the kernel size and the stride. So let's have a look at that in practice. And of course, you can read further through the documentation here. I'll just grab the link for this actually. So it's here. Wonderful. And let's now first try it with our test image that we created above. So just highlight what the test image is. A bunch of random numbers in the same shape as what a single image would be if we were to replicate the image size of the CNN explainer. By the way, we'll have a look at a visual in a second of max pool here. But you can go through that on your own time. Let's if in doubt, code it out. So we're going to print out the original image shape without unsqueezed dimension. Because recall that we had to add an extra dimension to pass it through our com2d layer. Now, if you're using a later version of PyTorch, you might not get an error if you only use a three dimensional image tensor and pass it through a comp layer. So we're going to pass it in test image, original shape, test image dot shape. So this is just going to tell us what the line of code in the cell above tells us. But that's fine. I like to make pretty printouts, you know, test image with unsqueezed dimension. So this is just going to be our test image. And we're going to see what happens when we unsqueeze a dimension, unsqueeze on zero for dimension. That is about to say first, but it's the zero. Now we're going to create a sample nn max pool 2d layer. Because remember, even layers themselves in torch dot nn are models of their own accord. So we can just create a single, this is like creating a single layer model here. We'll set the kernel size equal to two. And recall, if we go back to CNN explainer, kernel size equal to two results in a two by two square, a two by two kernel that's going to convolve over our image, like so. And this is an example input, an example output. And you can see the operation that max pooling does here. So just keep that in mind as we pass some sample data through our max pool layer. And now let's pass data through it. I actually will pass it through just the conv layer first, through just the conv layer. Because that's sort of how you might stack things, you might put a convolutional layer and then a max pool layer on top of that convolutional layer. So test image through conv. We'll create a variable here, equals our conv layer. Is going to take as an input, our test image dot unsqueeze on the zero dimension again. Beautiful. Now we're going to print out the shape here. This is just highlighting how I like to troubleshoot things is I do one step, print the shape, one step, print the shape, see what is happening as our data moves through various layers. So test image through conv.shape, we'll see what our conv layer does to the shape of our data. And then we're going to pass data through max pool layer, which is the layer we created a couple of lines above this one here. So let's see what happens. Test image through current type at the moment through conv and max pool. So quite a long variable name here, but this is to help us avoid confusion of what's going on. So we go test image through conv. So you notice how we're taking the output of our convolutional layer, this here, and we're passing it through our max pool layer, which has another typo. Wonderful. And finally, we'll print out the shape, shape after going through conv layer and max pool layer. What happens here? So we want test image through conv and max pool. Let's see how our max pool layer manipulates our test images shape. You ready? Three, two, one, let's go. What do we get? Okay. So we have the test image original shape, recall that our test image is just a collection of random numbers. And of course, our conv layer is going to be instantiated with random numbers. And max pool actually has no parameters. It just takes the maximum of a certain range of inner tensor. So when we unsqueeze the test image as the input, we get an extra dimension here. When we pass it through our conv layer. Oh, where did this 64 come from? 164 64 64 64. Let's go back up to our conv layer. Do you notice how that we get the 64 there because we changed the out channels value? If we change this back to 10, like what's in the CNN explainer model? One, two, three, four, five, six, seven, eight, nine, 10. What do you think will happen there? Well, we get a little highlight here. 10. Then we keep going. I'll just get rid of this extra cell. We don't need to check the version anymore. We'll check the test image shapes still three 64 64. But then as we pass it through the conv layer here, we get a different size now. So it originally had three channels as the input for color channels, but we've upscaled it to 10 so that we have 10 hidden units in our layer. And then we have 64 64. Now, again, these shapes will change if we change the values of what's going on here. So we might put padding to zero. What happens there? Instead of 64 64, we get 62 62. And then what happens after we pass it through the conv layer and then through the max pool layer? We've got 110 64 64. And now we have 110 32 32. Now, why is that? Well, let's go back into the CNN explainer, jump into this max pool layer here. Maybe this one because it's got a bit more going on. Do you notice on the left here is the input? And we've got a two by two kernel here. And so the max pooling layer, what it does is it takes the maximum of whatever the input is. So you'll notice the input is 60 60 in this case. Whereas the output over here is 30 30. Now, why is that? Well, because the max operation here is reducing it from section of four numbers. So let's get one with a few different numbers. There we go. That'll do. So it's taking it from four numbers and finding the maximum value within those four numbers here. Now, why would it do that? So as we've discussed before, what deep learning neural network is trying to do or in this case, a CNN is take some input data and figure out what features best represent whatever the input data is and compress them into a feature vector that is going to be our output. Now, the reason being for that is because you could consider it from a neural networks perspective is that intelligence is compression. So you're trying to compress the patterns that make up actual data into a smaller vector space, go from a higher dimensional space to a smaller vector space in terms of dimensionality of a tensor. But still, this smaller dimensionality space represents the original data and can be used to predict on future data. So that's the idea behind Max Paul is, hey, if we've got these learned features from our convolutional layers, will the patterns, will the most important patterns stay around if we just take the maximum of a certain section? So do you notice how the input here, we still have, you can still see the outline of the car here, albeit a little bit more pixelated, but just by taking the max of a certain region, we've got potentially the most important feature of that little section. And now, of course, you could customize this value here. If when we create our max pool layer, you could increase the kernel size to four by four. What do you think will happen if we can increase it to four? So here, we've got a two by two kernel. If we increase it to four by four, what happens? Ah, do you notice that we've gone from 62 to 15, we've essentially divided our feature space by four, we've compressed it even further. Now, will that work? Well, I'm not sure. That's part of the experimental nature of machine learning, but we're going to keep it at two for now. And so this is with our tensor here 6464. But now let's do the same as what we've done above, but we'll do it with a smaller tensor so that we can really visualize things. And we're going to just replicate the same operation that's going on here. So let's go here, we'll create another random tensor. We'll set up the manual seed first. And we're going to create a random tensor with a similar number of dimensions. Now, recall dimensions don't tell you, so this is a dimension 1364 64. That is a dimension. The dimensions can have different values within themselves. So we want to create a four dimensional tensor to our images. So what that means is, let me just show you it's way easy to explain things when we've got code is torch dot rand n. And we're going to set it up as size equals one, one, two, two. We can have a look at this random tensor. It's got four dimensions. One, two, three, four. So you could have a batch size, color channels, and height width, a very small image, but it's a random image here. But this is quite similar to what we've got going on here, right? Four numbers. Now, what do you think will happen if we create a max pool layer, just like we've done above, create a max pool layer. So we go max pool layer, just repeating the code that we have in the cell above, that's all right, a little bit of practice. Kernel size equals two. And then we're going to pass the random tensor through the max pool layer. So we'll go max pool tensor equals max pool layer. And we're going to pass it in the random tensor. Wonderful. And then we can print out some shapes and print out some tenses. As we always do to visualize, visualize, visualize. So we're going to write in here max pool tensor on a new line. We'll get in the max pool tensor. We'll see what this looks like. And we'll also print out max pool tensor shape. And we can probably print out random tensor itself, as well as its shape as well. We'll get the shape here, dot shape. And we'll do the same for the random tensor. So print, get a new line, random tensor, new line, random tensor. And then we'll get the shape. Random tensor shape, random tensor. Oh, a lot of coding here. That's, that's the fun part about machine learning, right? You get to write lots of code. Okay. So we're visualizing what's going on with our random tensor. This is what's happening within the max pool layer. We've seen this from a few different angles now. So we have a random tensor of numbers, and we've got a size here. But the max pool tensor, once we pass our random tensor, through the max pool layer, what happens? Well, we have 0.3367, 1288, 2345, 2303. Now, what's the max of all these? Well, it takes the max here is 3367. Oh, and we've got the random tensor down there. We don't want that. And see how we've reduced the shape from two by two to one by one. Now, what's going on here? Just for one last time to reiterate, the convolutional layer is trying to learn the most important features within an image. So if we jump into here, now, what are they? Well, we don't decide what a convolutional layer learns. It learns these features on its own. So the convolutional layer learns those features. We pass them through a relu nonlinear activation in case our data requires nonlinear functions. And then we pass those learned features through a max pool layer to compress them even further. So the convolutional layer can compress the features into a smaller space. But the max pooling layer really compresses them. So that's the entire idea. One more time, we start with some input data. We design a neural network, in this case, a convolutional neural network, to learn a compressed representation of what our input data is, so that we can use this compressed representation to later on make predictions on images of our own. And in fact, you can try that out if you wanted to click here and add your own image. So I'd give that a go. That's your extension for this video. But now we've stepped through the max pool 2D layer and the conv 2D layer. I think it's time we started to try and use our tiny VGG network. This is your challenge is to create a dummy tensor and pass it through this model. Pass it through its forward layer and see what happens to the shape of your dummy tensor as it moves through conv block 1 and conv block 2. And I'll show you my trick to calculating the in features here for this final layer, which is equivalent to this final layer here. I'll see you in the next video. Over the last few videos, we've been replicating the tiny VGG architecture from the CNN explainer website. And I hope you know that this is this actually quite exciting because years ago, this would have taken months of work. And we've just covered we've broken it down over the last few videos and rebuilt it ourselves with a few lines of PyTorch code. So that's just goes to show how powerful PyTorch is and how far the deep learning field has come. But we're not finished yet. Let's just go over to our keynote. This is what we've done. CNN explainer model. We have an input layer. We've created that. We have com2d layers. We've created those. We have relo activation layers. We've created those. And finally, we have pulling layers. And then we finish off with an output layer. But now let's see what happens when we actually pass some data through this entire model. And as I've said before, this is actually quite a common practice is you replicate a model that you found somewhere and then test it out with your own data. So we're going to start off by using some dummy data to make sure that our model works. And then we're going to pass through. Oh, I've got another slide for this. By the way, here's a breakdown of torch and N com2d. If you'd like to see it in text form, nothing here that we really haven't discussed before, but this will be in the slides if you would like to see it. Then we have a video animation. We've seen this before, though. And plus, I'd rather you go through the CNN explainer website on your own and explore this different values rather than me just keep talking about it. Here's what we're working towards doing. We have a fashion MNIST data set. And we have our inputs. We're going to numerically encode them. We've done that already. Then we have our convolutional neural network, which is a combination of convolutional layers, nonlinear activation layers, pooling layers. But again, these could be comprised in many different ways, shapes and forms. In our case, we've just replicated the tiny VGG architecture. And then finally, we want to have an output layer to predict what class of clothing a particular input image is. And so let's go back. We have our CNN model here. And we've got model two. So let's just practice a dummy forward pass here. We're going to come back up a bit to where we were. We'll make sure we've got model two. And we get an error here because I've times this by zero. So I'm going to just remove that and keep it there. Let's see what happens if we create a dummy tensor and pass it through here. Now, if you recall what our image is, do we have image? This is a fashion MNIST image. So I wonder if we can go plot dot M not M show image. And I'm going to squeeze that. And I'm going to set the C map equal to gray. So this is our current image. Wonderful. So there's our current image. So let's create a tensor. Or maybe we just try to pass this through the model and see what happens. How about we try that model image? All right, we're going to try the first pass forward pass. So pass image through model. What's going to happen? Well, we get an error. Another shape mismatch. We've seen this before. How do we deal with this? Because what is the shape of our current image? 128, 28. Now, if you don't have this image instantiated, you might have to go back up a few cells. Where did we create image? I'll just find this. So just we created this a fairly long time ago. So I'm going to probably recreate it down the bottom. My goodness, we've written a lot of code. Well, don't do us. We could create a dummy tensor if we wanted to. How about we do that? And then if you want to find, oh, right back up here, we have an image. How about we do that? We can just do it with a dummy tensor. That's fine. We can create one of the same size. But if you have image instantiated, you can try that out. So there's an image. Let's now create an image that is, or a random tensor, that is the same shape as our image. So rand image tensor equals what torch dot rand n. And we're going to pass in size equals 128, 28. Then if we get rand image tensor, we check its shape. What do we get? So the same shape as our test image here, but it's just going to be random numbers. But that's okay. We just want to highlight a point here of input and output shapes. We want to make sure our model works. Can our random image tensor go all the way through our model? That's what we want to find out. So we get an error here. We have four dimensions, but our image is three dimensions. How do we add an extra dimension for batch size? Now you might not get this error if you're running a later version of pie torch. Just keep that in mind. So unsqueeze zero. Oh, expected all tensors to be on the same device, but found at least two devices. Again, we're going through all the three major issues in deep learning. Shape mismatch, device mismatch, data type mismatch. So let's put this on the device, two target device, because we've set up device agnostic code. That one and that two shapes cannot be multiplied. Oh, but we can output here. That is very exciting. So what I might do is move this a couple of cells up so that we can tell what's going on. I'm going to delete this cell. So where do these shapes come from? Well, we printed out the shapes there. And so this is what's happened when our, I'll just create our random tensor. I'll bring our random tensor up a bit too. Let's bring this up. There we go. So we pass our random to image tensor through our model, and we've made sure it's got four dimensions by unsqueeze zero. And we make sure it's on the same device as our model, because our model has been sent to the GPU. And this is what happens as we pass our random image tensor. We've got 12828 instead of previously we've seen 6464.3, which is going to clean this up a bit. And we get different shapes here. So you'll notice that as our input, if it was 6464.3 goes through these layers, it gets shaped into different values. Now this is going to be universal across all of the different data sets you work on, you will be working with different shapes. So it's important to, and also quite fun, to troubleshoot what shapes you need to use for your different layers. So this is where my trick comes in. To find out the shapes for different layers, I often construct my models, how we've done here, as best I can with the information that I've got, such as replicating what's here. But I don't really know what the output shape is going to be before it goes into this final layer. And so I recreate the model as best I can. And then I pass data through it in the form of a dummy tensor in the same shape as my actual data. So we could customize this to be any shape that we wanted. And then I print the shapes of what's happening through each of the forward past steps. And so if we pass it through this random tensor through the first column block, it goes through these layers here. And then it outputs a tensor with this size. So we've got 10, because that's how many output channels we've set. And then 14, 14, because our 2828 tensor has gone through a max pool 2d layer and gone through a convolutional layer. And then it goes through the next block, column block two, which is because we've put it in the forward method here. And then it outputs the shape. And if we go back down, we have now a shape of one 10, seven, seven. So our previous tensor, the output of column block one, has gone from 1414 to seven seven. So it's been compressed. So let me just write this down here, output shape of column block one, just so we get a little bit more information. And I'm just going to copy this, put it in here, that will become block two. And then finally, I want to know if I get an output shape of classifier. So if I rerun all of this, I don't get an output shape of classifier. So my model is running into trouble. Once it gets to, so I get the output of conv block one, I don't get an output of classifier. So this is telling me that I have an issue with my classifier layer. Now I know this, but I'm not. Now I know this because, well, I've coded this model before, and the in features here, we need a special calculation. So what is going on with our shapes? Mat one and mat two shapes cannot be multiplied. So do you see here, what is the rule of matrix multiplication? The inner dimensions here have to match. We've got 490. Where could that number have come from? And we've got 10 times 10. Now, okay, I know I've set hidden units to 10. So maybe that's where that 10 came from. And what is the output layer of the output shape of conv block two? So if we look, we've got the output shape of conv block two. Where does that go? The output of conv block two goes into our classifier model. And then it gets flattened. So that's telling us something there. And then our NN linear layer is expecting the output of the flatten layer as it's in features. So this is where my trick comes into play. I pass the output of conv block two into the classifier layer. It gets flattened. And then that's what my NN not linear layer is expecting. So what happens if we flatten this shape here? Do we get this value? Let's have a look. So if we go 10 times seven times seven, 490. Now, where was this 10? Well, that's our hidden units. And where were these sevens? Well, these sevens are the output of conv block two. So that's my trick. I print the shapes of previous layers and see whether or not they line up with subsequent layers. So if we go time seven times seven, we're going to have hidden units equals 10 times seven times seven. Where do we get the two sevens? Because that is the output shape of conv block two. Do you see how this can be a little bit hard to calculate ahead of time? Now, you could calculate this by hand if you went into n conv 2d. But I prefer to write code to calculate things for me. You can calculate that value by hand. If you go through, H out W out, you can add together all of the different parameters and multiply them and divide them and whatnot. You can calculate the input and output shapes of your convolutional layers. You're more than welcome to try that out by hand. But I prefer to code it out. If and out code it out. Now, let's see what happens if we run our random image tensor through our model. Now, do you think it will work? Well, let's find out. All we've done is we've added this little line here, times seven times seven. And we've calculated that because we've gone, huh, what if we pass a tensor of this dimension through a flattened layer? And what is our rule of matrix multiplication? The inner dimensions here must match. And why do we know that these are matrices? Well, mat one and mat two shapes cannot be multiplied. And we know that inside a linear layer is a matrix multiplication. So let's now give this a go. We'll see if it works. Oh, ho ho. Would you look at that? That is so exciting. We have the output shape of the classifier is one and 10. We have a look, we have one number one, two, three, four, five, six, seven, eight, nine, 10, one number for each class in our data set. Wow. Just like the CNN explain a website, we have 10 outputs here. We just happen to have 10 classes as well. Now, this number again could be whatever you want. It could be 100, could be 30, could be three, depending on how many classes you have. But we have just figured out the input and output shapes of each layer in our model. So that's very exciting. I think it's now time we've passed a random tensor through. How about we pass some actual data through our model? In the next video, let's use our train and test step functions to train our first convolutional neural network. I'll see you there. Well, let's get ready to train our first CNN. So what do we need? Where are we up to in the workflow? Well, we've built a model and we've stepped through it. We know what's going on, but let's really see what's going on by training this CNN or see if it trains because we don't always know if it will on our own data set, which is of fashion MNIST. So we're going to set up a loss function and optimizer for model two. And just as we've done before, model two, turn that into markdown. I'll just show you the workflow again. So this is what we're doing. We've got some inputs. We've got a numerical encoding. We've built this architecture and hopefully it helps us learn or it helps us make a predictive model that we can input images such as grayscale images of clothing and predict. And if we look where we are at the PyTorch workflow, we've got our data ready. We've built our next model. Now here's where we're up to picking a loss function and an optimizer. So let's do that, hey, loss function, or we can do evaluation metrics as well. So set up loss function slash eval metrics slash optimizer. And we want from helper functions, import accuracy function, we don't need to reimport it, but we're going to do it anyway for completeness. Loss function equals nn dot cross entropy loss, because we are working with a multi class classification problem. And the optimizer, we're going to keep the same as what we've used before, torch dot opt in SGD. And we'll pass it in this time, the params that we're trying to optimize are the parameters of model two parameters. And we'll use a learning rate of 0.1. Run that. And just to reiterate, here's what we're trying to optimize model two state dig. We have a lot of random weights in model two. Have a look at all this. There's the bias, there's the weight. We're going to try and optimize these to help us predict on our fashion MNIST data set. So without any further ado, let's in the next video, go to the workflow, we're going to build our training loop. But thanks to us before, we've now got functions to do this for us. So if you want to give this a go, use our train step and test step function to train model two. Try that out. And we'll do it together in the next video. We're getting so close to training our model. Let's write some code to train our first thing in that model. Training and testing, I'm just going to make another heading here. Model two, using our training and test functions. So we don't have to rewrite all of the steps in a training loop and a testing loop, because we've already created that functionality before through our train step function. There we go. Performs the training, or this should be performs a training step with model trying to learn on data loader. So let's set this up. We're going to set up torch manual seed 42, and we can set up a CUDA manual seed as well. Just to try and make our experiments as reproducible as possible, because we're going to be using CUDA, we're going to measure the time because we want to compare our models, not only their performance in evaluation metrics, but how long they take to train from time it, because there's no point having a model that performs really, really well, but takes 10 times longer to train. Well, maybe there is, depending on what you're working on. Model two equals timer, and we're going to train and test model, but the time is just something to be aware of, is that usually a better performing model will take longer to train. Not always the case, but just something to keep in mind. So for epoch in, we're going to use TQDM to measure the progress. We're going to create a range of epochs. We're just going to train for three epochs, keeping our experiment short for now, just to see how they work, epoch, and we're going to print a new line here. So for an epoch in a range, we're going to do the training step, which is our train step function. The model is going to be equal to model two, which is our convolutional neural network, our tiny VGG. The data loader is just going to be equal to the train data loader, the same one we've used before. The loss function is going to be equal to the loss function that we've set up above, loss FN. The optimizer as well is going to be the optimizer in our case, stochastic gradient descent, optimizer equals optimizer, then we set up the accuracy function, which is going to be equal to our accuracy function, and the device is going to be the target device. How easy was that? Now we do the same for the train or the testing step, sorry, the model is going to be equal to model two, and then the data loader is going to be the test data loader, and then the loss function is going to be our same our same loss function. And then we have no optimizer for this, we're just going to pass in the accuracy function here. And then of course, the device is going to be equal to the device. And then what do we do now? Well, we can measure the end time so that we know how long the code here took to run. So let's go train time end for model two. This will be on the GPU, by the way, but this time it's using a convolutional neural network. And the total train time, total train time for model two is going to be equal to print train time, our function that we created before as well, to help us measure start and end time. So we're going to pass in train to time start model two, and then end is going to be train time end model two. And then we're going to print out the device that it's using as well. So you're ready? Are you ready to train our first convolutional neural network? Hopefully this code works. We've created these functions before, so it should be all right. But if and out, code it out, if and out, run the code, let's see what happens. Oh my goodness. Oh, of course. Oh, we forgot to comment out the output shapes. So we get a whole bunch of outputs for our model, because what have we done? Back up here, we forgot to. So this means every time our data goes through the forward pass, it's going to be printing out the output shapes. So let's just comment out these. And I think this cell is going to take quite a long time to run because it's got so many printouts. Yeah, see, streaming output truncated to the last 5,000 lines. So we're going to try and stop that. Okay, there we go. Beautiful. That actually worked. Sometimes it doesn't stop so quickly. So we're going to rerun our fashion MSV to model cell so that we comment out these print lines. And then we'll just rerun these cells down here. Just go back through fingers crossed, there's no errors. And we'll train our model again. Beautiful. Not as many printouts this time. So here we go. Our first CNN is training. How do you think it'll go? Well, that's what we have printouts, right? So we can see the progress. So you can see here all the functions that are being called behind the scenes from PyTorch. So thank you to PyTorch for that. There's our, oh, our train step function was in there. Train step. Wonderful. Beautiful. So there's epoch zero. Oh, we get a pretty good test accuracy. How good is that? Test accuracy is climbing as well. Have we beaten our baseline? We're looking at about 14 seconds per epoch here. And then the final epoch. What do we finish at? Oh, 88.5. Wow. In 41.979 or 42 there about seconds. Again, your mileage may vary. Don't worry too much if these numbers aren't exactly the same on your screen and same with the training time because we might be using slightly different hardware. What GPU do I have today? I have a Tesla P100 GPU. You might not have the same GPU. So the training time, if this training time is something like 10 times higher, you might want to look into what's going on. And if these values are like 10% lower or 10% higher, you might want to see what's going on with your code as well. But let's now calculate our Model 2 results. I think it is the best performing model that we have so far. Let's get a results dictionary. Model 2 results is so exciting. We're learning the power of convolutional neural networks. Model 2 results equals a vowel model. And this is a function that we've created before. So returns a dictionary containing the results of a model predicting on data loader. So now let's pass in the model, which will be our trained model to, and then we'll pass in the data loader, which will be our test data loader. And then, oops, excuse me, typo, our loss function will be, of course, our loss function. And the accuracy function will be accuracy function. And the device is already set, but we can reset anyway, device equals device. And we'll check out the Model 2 results. Make some predictions. Oh, look at that. Model accuracy 88. Does that beat our baseline? Model 0 results. Oh, we did beat our baseline with a convolutional neural network. All right. So I feel like that's, uh, that's quite exciting. But now let's keep going on. And, uh, let's start to compare the results of all of our models. I'll see you in the next video. Welcome back. Now, in the last video, we trained our first convolutional neural network. And from the looks of things, it's improved upon our baseline. But let's make sure by comparing, this is another important part of machine learning experiments is comparing the results across your experiments. So and training time. Now, we've done that in a way where we've got three dictionaries here of our model zero results, model one results, model two results. So how about we create a data frame comparing them? So let's import pandas as PD. And we're going to compare results equals PD dot data frame. And because our model results dictionaries, uh, all have the same keys. Let's pass them in as a list. So model zero results, model one results, and model two results to compare them. Wonderful. And what it looks like when we compare the results. All righty. So recall our first model was our baseline V zero was just two linear layers. And so we have an accuracy of 83.4 and a loss of 0.47. The next model was we trained on the GPU and we introduced nonlinearities. So we actually found that that was worse off than our baseline. But then we brought in the big guns. We brought in the tiny VGG architecture from the CNN explainer website and trained our first convolutional neural network. And we got the best results so far. But there's a lot more experiments that we could do. We could go back through our tiny VGG and we could increase the number of hidden units. Where do we create our model up here? We could increase this to say 30 and see what happens. That would be a good experiment to try. And if we found that nonlinearities didn't help with our second model, we could comment out the relu layers. We could of course change the kernel size, change the padding, change the max pool. A whole bunch of different things that we could try here. We could train it for longer. So maybe if we train it for 10 epochs, it would perform better. But these are just things to keep in mind and try out. I'd encourage you to give them a go yourself. But for now, we've kept all our experiments quite the same. How about we see the results we add in the training time? Because that's another important thing that we've been tracking as well. So we'll add training time to results comparison. So the reason why we do this is because if this model is performing quite well, even compared to our CNN, so a difference in about 5% accuracy, maybe that's tolerable in the space that we're working, except that this model might actually train and perform inference 10 times faster than this model. So that's just something to be aware of. It's called the performance speed trade off. So let's add another column here, compare results. And we're going to add in, oh, excuse me, got a little error there. That's all right. Got trigger happy on the shift and enter. Training time equals, we're going to add in, we've got another list here is going to be total train time for model zero, and total train time for model one, and total train time for model two. And then we have a look at our how compare results dictionary, or sorry, compare results data frame. Wonderful. So we see, and now this is another thing. I keep stressing this to keep in mind. If your numbers aren't exactly of what I've got here, don't worry too much. Go back through the code and see if you've set up the random seeds correctly, you might need a koodle random seed. We may have missed one of those. If your numbers are out landishly different to these numbers, then you should go back through your code and see if there's something wrong. And again, the training time will be highly dependent on the compute environment you're using. So if you're running this notebook locally, you might get faster training times. If you're running it on a different GPU to what I have, NVIDIA SMI, you might get different training times. So I'm using a Tesla P100, which is quite a fast GPU. But that's because I'm paying for Colab Pro, which generally gives you faster GPUs. And model zero was trained on the CPU. So depending on what compute resource Google allocates to you with Google Colab, this number might vary here. So just keep that in mind. These values training time will be very dependent on the hardware you're using. But if your numbers are dramatically different, well, then you might want to change something in your code and see what's going on. And how about we finish this off with a graph? So let's go visualize our model results. And while we're doing this, have a look at the data frame above. Is the performance here 10 seconds longer training time worth that extra 5% of the results on the accuracy? Now in our case, we're using a relatively toy problem. What I mean by toy problem is quite a simple data set to try and test this out. But in your practice, that may be worth doing. If your model takes longer to train, but gets quite a bit better performance, it really depends on the problem you're working with. Compare results. And we're going to set the index as the model name, because I think that's what we want our graph to be, not the model name. And then we're going to plot, we want to compare the model accuracy. And we want to plot, the kind is going to be equal to bar h, horizontal bar chart. We've got p x label, we're going to get accuracy as a percentage. And then we're going to go py label. This is just something that you could share. If someone was asking, how did your modeling experiments go on fashion MNIST? Well, here's what I've got. And then they ask you, well, what's the fashion MNIST model V2? Well, you could say that's a convolutional neural network that trained, that's replicates the CNN explainer website that trained on a GPU. How long did that take to train? Well, then you've got the training time here. We could just do it as a vertical bar chart. I did it as horizontal so that this looks a bit funny to me. So horizontal like that. So the model names are over here. Wonderful. So now I feel like we've got a trained model. How about we make some visual predictions? Because we've just got numbers on a page here, but our model is trained on computer vision data. And the whole point of making a machine learning model on computer vision data is to be able to visualize predictions. So let's give that a shot, hey, in the next video, we're going to use our best performing model, fashion MNIST model V2 to make predictions on random samples from the test data set. You might want to give that a shot, make some predictions on random samples from the test data set, and plot them out with their predictions as the title. So try that out. Otherwise, we'll do it together in the next video. In the last video, we compared our models results. We tried three experiments. One was a basic linear model. One was a linear model with nonlinear activations. And fashion MNIST model V2 is a convolutional neural network. And we saw that from an accuracy perspective, our convolutional neural network performed the best. However, it had the longest training time. And I just want to exemplify the fact that the training time will vary depending on the hardware that you run on. We spoke about this in the last video. However, I took a break after finishing the last video, reran all of the cells that we've written, all of the code cells up here by coming back to the notebook and going run all. And as you'll see, if you compare the training times here to the last video, we get some different values. Now, I'm not sure exactly what hardware Google collab is using behind the scenes. But this is just something to keep in mind, at least from now on, we know how to track our different variables, such as how long our model takes to train and what its performance values are. But it's time to get visual. So let's create another heading, make and evaluate. This is one of my favorite steps after training a machine learning model. So make and evaluate random predictions with the best model. So we're going to follow the data explorer's model of getting visual visual visual or visualize visualize visualize. Let's make a function called make predictions. And it's going to take a model, which will be a torch and end module type. It's also going to take some data, which can be a list. It'll also take a device type, which will be torch dot device. And we'll set that by default to equal the default device that we've already set up. And so what we're going to do is create an empty list for prediction probabilities. Because what we'd like to do is just take random samples from the test data set, make predictions on them using our model, and then plot those predictions. We want to visualize them. And so we'll also turn our model into evaluation mode, because if you're making predictions with your model, you should turn on evaluation mode. We'll also switch on the inference mode context manager, because predictions is another word for inference. And we're going to loop through for each sample in data. Let's prepare the sample. So this is going to take in a single image. So we will unsqueeze it, because we need to add a batch size dimension on the sample, we'll set dim equals to zero, and then we'll pass that to the device. So add a batch dimension, that's with the unsqueeze, and pass to target device. That way, our data and model are on the same device. And we can do a forward pass. Well, we could actually up here go model dot two device. That way we know that we've got device agnostic code there. Now let's do the forward pass, forward pass model outputs raw logits. So recall that if we have a linear layer at the end of our model, it outputs raw logits. So pred logit for a single sample is going to equal model. We pass the sample to our target model. And then we're going to get the prediction probability. How do we get the prediction probability? So we want to go from logit to prediction probability. Well, if we're working with a multi class classification problem, we're going to use the softmax activation function on our pred logit. And we're going to squeeze it so it gets rid of an extra dimension. And we're going to pass in dim equals zero. So that's going to give us our prediction probability for a given sample. Now let's also turn our prediction probabilities into prediction labels. So get pred. Well, actually, I think we're just going to return the pred probes. Yeah, let's see what that looks like, because we've got a an empty list up here for pred probes. So for matplotlib, we're going to have to use our data on the CPU. So let's make sure it's on the CPU, because matplotlib doesn't work with the GPU. So get pred prob off GPU for further calculations. So we're just hard coded in here to make sure that our prediction probabilities off the GPU. So pred probs, which is our list up here. We're going to append the pred prob that we just calculated. But we're going to put it on the CPU. And then let's go down here. And we're going to. So if we've done it right, we're going to have a list of prediction probabilities relating to particular samples. So we're going to stack the pred probs to turn list into a tensor. So this is only one way of doing things. There are many different ways that you could make predictions and visualize them. I'm just exemplifying one way. So we're going to torch stack, which is just going to say, hey, concatenate everything in the list to a single tensor. So we might need to tab that over, tab, tab. Beautiful. So let's try this function in action and see what happens. I'm going to import random. And then I'm going to set the random seed to 42. And then I'm going to create test samples as an empty list, because we want an empty or we want a list of test samples to iterate through. And I'm going to create test labels also as an empty list. So that remember, when we are evaluating predictions, we want to compare them to the ground truth. So we want to get some test samples. And then we want to get their actual labels so that when our model makes predictions, we can compare them to their actual labels. So for sample, comma label, in, we're going to use random to sample the test data. Now note that this is not the test data loader. This is just test data. And we're going to set k equals to nine. And recall, if you want to have a look at test data, what do we do here? We can just go test data, which is our data set, not converted into a data loader yet. And then if we wanted to get the first 10 samples, can we do that? Only one element tensors can be converted into Python scalars. So if we get the first zero, and maybe we can go up to 10. Yeah, there we go. And what's the shape of this? Tuple has no object shape. Okay, so we need to go image label equals that. And then can we check the shape of the image label? Oh, because the labels are going to be integers. Wonderful. So that's not the first 10 samples, but that's just what we get if we iterate through the test data, we get an image tensor, and we get an associated label. So that's what we're doing with this line here, we're just randomly sampling nine samples. And this could be any number you want. I'm going to use nine, because this is a spoiler for later on, we're going to create a three by three plot. So that just nine is just a fun number. So get some random samples from the test data set. And then we can go test samples dot append sample. And we will go test labels dot append label. And then let's go down here, view the first, maybe we go first sample shape. So test samples zero dot shape. And then if we get test samples, zero, we're going to get a tensor of image values. And then if we wanted to plot that, can we go PLT, M show, C map, equals gray. And we may have to squeeze this, I believe, to remove the batch tensor. Let's see what happens batch dimension. There we go. Beautiful. So that's to me, a shoe, a high heel shoe of some sort. If we get the title, PLT dot title, test labels, let's see what this looks like. It's a five, which is, of course, class names will index on that. Sandal. Okay, beautiful. So we have nine random samples, nine labels that are associated with that sample. Now let's make some predictions. So make predictions. And this is one of my favorite things to do. I can't stress it enough is to randomly pick data samples from the test data set and predict on them and do it over and over and over again to see what the model is doing. So not only at the start of a problem, I'll just get the prediction probabilities here. We're going to call our make predictions function. So not only at the start of a problem should you become one with the data, even after you've trained a model, you'll want to further become one with the data, but this time become one with your models predictions on the data and see what happens. So view the first two prediction probabilities list. So we're just using our make predictions function that we created before, passing at the model, the train model to, and we're passing at the data, which is the test samples, which is this list that we just created up here, which is comprised of random samples from the test data set. Wonderful. So let's go. Pred probes. Oh, we don't want to view them all. That's going to give us Oh, we want to the prediction probabilities for a given sample. And so how do we convert prediction probabilities into labels? Because if we're trying to, if we have a look at test labels, if we're trying to compare apples to apples, when we're evaluating our model, we want to, we can't really necessarily compare the prediction probabilities straight to the test labels. So we need to convert these prediction probabilities into prediction labels. So how can we do that? Well, we can use argmax to take whichever value here, the index, in this case, this one, the index of whichever value is the highest of these prediction probabilities. So let's see that in action. Convert prediction probabilities to labels. So we'll go pred classes equals pred probes, and we'll get the argmax across the first dimension. And now let's have a look at the pred classes. Wonderful. So are they in the same format as our test labels? Yes, they are. So if you'd like to go ahead, in the next video, we're going to plot these and compare them. So we're going to write some code to create a mapplotlib plotting function that's going to plot nine different samples, along with their original labels, and their predicted label. So give that a shot, we've just written some code here to make some predictions on random samples. If you'd like them to be truly random, you can comment out the seed here, but I've just kept the seed at 42. So that our random dot sample selects the same samples on your end and on my end. So in the next video, let's plot these. Let's now continue following the data explorer's motto of visualize visualize visualize. We have some prediction classes. We have some labels we'd like to compare them to. You can compare them visually. It looks like our model is doing pretty good. But let's, since we're making predictions on images, let's plot those images along with the predictions. So I'm going to write some code here to plot the predictions. I'm going to create a matplotlib figure. I'm going to set the fig size to nine and nine. Because we've got nine random samples, you could, of course, change this to however many you want. I just found that a three by three plot works pretty good in practice. And I'm going to set n rows. So for my matplotlib plot, I want three rows. And I want three columns. And so I'm going to enumerate through the samples in test samples. And then I'm going to create a subplot for each sample. So create a subplot. Because this is going to create a subplot because it's within the loop. Each time it goes through a new sample, create a subplot of n rows and calls. And the index it's going to be on is going to be i plus one, because it can't start at zero. So we just put i plus one in there. What's going on here? Enumerate. Oh, excuse me. In enumerate, wonderful. So now we're going to plot the target image. We can go plot dot in show, we're going to get sample dot squeeze. Because we need to remove the batch dimension. And then we're going to set the C map is equal to gray. What's this telling me up here? Oh, no, that's correct. Next, we're going to find the prediction label in text form, because we don't want it in a numeric form, we could do that. But we want to look at things visually with human readable language, such as sandal for whatever class sandal is, whatever number class that is. So we're going to set the pred label equals class names. And we're going to index using the pred classes I value. So right now we're going to plot our sample. We're going to find its prediction. And now we're going to get the truth label. So we also want this in text form. And what is the truth label going to be? Well, the truth label is we're going to have to index using class names and index on that using test labels I. So we're just matching up our indexes here. Finally, we're going to create a title, create a title for the plot. And now here's what I like to do as well. If we're getting visual, well, we might as well get really visual, right? So I think we can change the color of the title text, depending if the prediction is right or wrong. So I'm going to create a title using an F string, pred is going to be a pred label, and truth label. We could even plot the prediction probabilities here if we wanted to. That might be an extension that you might want to try. And so here we're going to check for equality between pred and truth and change color of title text. So what I mean by this, it's going to be a lot easier to explain if we just if and doubt coded out. So if the pred label equals the truth label, so they're equal, I want the plot dot title to be the title text. But I want the font size, well, the font size can be the same 10. I want the color to equal green. So if they're so green text, if prediction, same as truth, and else I'm going to set the plot title to have title text font size equals 10. And the color is going to be red. So does that make sense? All we're doing is we're enumerating through our test samples that we got up here, test samples that we found randomly from the test data set. And then each time we're creating a subplot, we're plotting our image, we're finding the prediction label by indexing on the class names with our pred classes value, we're getting the truth label, and we're creating a title for the plot that compares the pred label to the truth. And we're changing the color of the title text, depending if the pred label is correct or not. So let's see what happens. Did we get it right? Oh, yes, we did. Oh, I'm going to do one more thing. I want to turn off the accesses, just so we get more real estate. I love these kind of plots. It helps that our model got all of these predictions right. So look at this, pred sandal, truth, sandal, pred trouser, truth trouser. So that's pretty darn good, right? See how, for me, I much appreciate, like, I much prefer visualizing things numbers on a page look good, but there's something, there's nothing quite like visualizing your machine learning models predictions, especially when it gets it right. So how about we select some different random samples up here, we could functionize this as well to do like all of this code in one hit, but that's all right. We'll be a bit hacky for now. So this is just going to randomly sample with no seed at all. So your samples might be different to mine, nine different samples. So this time we have an ankle boot, we'll make some predictions, we'll just step through all of this code here. And oh, there we go. It got one wrong. So all of these are correct. But this is more interesting as well is where does your model get things wrong? So it predicted address, but this is a coat. Now, do you think that this could be potentially address? To me, I could see that as being addressed. So I kind of understand where the model's coming from there. Let's make some more random predictions. We might do two more of these before we move on to the next video. Oh, all correct. We're interested in getting some wrong here. So our model seems to be too good. All correct again. Okay, one more time. If we don't get any wrong, we're going on to the next video. But this is just really, oh, there we go. Too wrong. Beautiful. So predicted address, and that's a shirt. Okay. I can kind of see where the model might have stuffed up there. It's a little bit long for a shirt for me, but I can still understand that that would be a shirt. And this is a pullover, but the truth is a coat. So maybe, maybe there's some issues with the labels. And that's probably what you'll find in a lot of data sets, especially quite large ones. Just with a sheer law of large numbers, there may be some truth labels in your data sets that you work with that are wrong. And so that's why I like to see, compare the models predictions versus the truth on a bunch of random samples to go, you know what, is our models results better or worse than they actually are. And that's what visualizing helps you do is figure out, you know what, our model is actually, it says it's good on the accuracy. But when we visualize the predictions, it's not too good. And vice versa, right? So you can keep playing around with this, try, look at some more random samples by running this again. We'll do one more for good luck. And then we'll move on to the next video. We're going to go on to another way. Oh, see, this is another example. Some labels here could be confusing. And speaking of confusing, well, that's going to be a spoiler for the next video. But do you see how the prediction is a t-shirt top, but the truth is a shirt? To me, that label is kind of overlapping. Like, I don't know, what's the difference between a t-shirt and a shirt? So that's something that you'll find as you train models is maybe your model is going to tell you about your data as well. And so we hinted that this is going to be confused. The model is confused between t-shirt top and shirt. How about we plot a confusion matrix in the next video? I'll see you there. We're up to a very exciting point in evaluating our machine learning model. And that is visualizing, visualizing, visualizing. And we saw that in the previous video, our model kind of gets a little bit confused. And in fact, I would personally get confused at the difference between t-shirt slash top and a shirt. So these kind of insights into our model predictions can also give us insights into maybe some of our labels could be improved. And another way to check that is to make a confusion matrix. So let's do that, making a confusion matrix for further prediction evaluation. Now, a confusion matrix is another one of my favorite ways of evaluating a classification model, because that's what we're doing. We're doing multi class classification. And if you recall, if we go back to section two of the lone pytorch.io book, and then if we scroll down, we have a section here, more classification evaluation metrics. So accuracy is probably the gold standard of classification evaluation. There's precision, there's recall, there's F1 score, and there's a confusion matrix here. So how about we try to build one of those? I want to get this and copy this. So, and write down a confusion matrix is a fantastic way of evaluating your classification models visually. Beautiful. So we're going to break this down. First of all, we need to plot a confusion matrix. We need to make predictions with our trained model on the test data set. Number two, we're going to make a confusion matrix. And to do so, we're going to leverage torch metrics tricks have to figure out how to spell metrics and confusion matrix. So recall that torch metrics we've touched on this before is a great package torch metrics for a whole bunch of evaluation metrics of machine learning models in pytorch flavor. So if we find we've got classification metrics, we've got audio image detection. Look how this is beautiful, a bunch of different evaluation metrics. And if we go down over here, we've got confusion matrix. So I only touched on five here, but or six. But if you look at torch metrics, they've got, how many is that about 25 different classification metrics? So if you want some extra curriculum, you can read through these. But let's go to confusion matrix. And if we look at some code here, we've got torch metrics, confusion matrix, we need to pass in number of classes. We can normalize if we want. And do you notice how this is quite similar to the pytorch documentation? Well, that's the beautiful thing about torch metrics is that it's created with pytorch in mind. So let's try out if you wanted to try it out on some tester code, you could do it here. But since we've already got some of our own code, let's just bring in this. And then number three is to plot it. We've got another helper package here, plot the confusion matrix using ML extend. So this is another one of my favorite helper libraries for machine learning things. It's got a lot of functionality that you can code up yourself, but you often find yourself coding at a few too many times, such as plotting a confusion matrix. So if we look up ML extend plot confusion matrix, this is a wonderful library. I believe it was it was created by Sebastian Rushka, who's a machine learning researcher and also author of a great book. There he is. Yeah, this is a side note machine learning with pytorch and scikit loan. I just got this book it just got released in the start of 2022. And it's a great book. So that's a little side note for learning more about machine learning with pytorch and scikit loan. So shout out to Sebastian Rushka. Thank you for this package as well. This is going to just help us plot a confusion matrix like this. So we'll have our predicted labels on the bottom and our true labels on the side here. But we can just copy this code in here. Link sorry, and then confusion matrix, we can copy that in here. The thing is that torch metrics doesn't come with Google Colab. So if you're using Google Colab, I think ML extend does, but we need a certain version of ML extend that Google Colab doesn't yet have yet. So we actually need version 0.19.0. But we're going to import those in a second. Let's first make some predictions across our entire test data set. So previously, we made some predictions only on nine random samples. So random sample, we selected nine. You could, of course, change this number to make it on more. But this was only on nine samples. Let's write some code to make predictions across our entire test data set. So import tqdm.auto for progress bar tracking. So tqdm.auto. We don't need to re-import it. I believe we've already got it above, but I'm just going to do it anyway for completeness. And so we're going to make, this is step one, above, make predictions, make predictions with trained model. Our trained model is model two. So let's create an empty predictions list. So we can add our predictions to that. We're going to set our model into evaluation mode. And we're going to set with torch inference mode as our context manager. And then inside that, let's just build the same sort of code that we used for our testing loop, except this time we're going to append all of our predictions to a list. So we're going to iterate through the test data loader. And we can give our tqdm description. We're going to say making predictions dot dot dot. You'll see what that looks like in a minute. And here we are going to send the data and targets to target device. So x, y equals x to device and y to device. Wonderful. And we're going to do the forward pass. So we're going to create y logit. Remember, the raw outputs of a model with a linear layer at the end are referred to as logits. And we don't need to calculate the loss, but we want to turn predictions from logits to prediction probabilities to prediction labels. So we'll set here y pred equals torch dot softmax. You could actually skip the torch softmax step if you wanted to and just take the argmax of the logits. But we will just go from prediction probabilities to pred labels for completeness. So squeeze and we're going to do it across the first dimension or the zeroth dimension. And then we'll take the argmax of that across the first dimension as well. And a little tidbit. If you take different dimensions here, you'll probably get different values. So just check the inputs and outputs of your code to make sure you're using the right dimension here. And so let's go put predictions on CPU for evaluation. Because if we're going to plot anything, that plot lib will want them on the CPU. So we're going to append our predictions to y preds, y pred dot CPU. Beautiful. And because we're going to have a list of different predictions, we can use concatenate a list of predictions into a tensor. So let's just print out y preds. And so I can show you what it looks like. And then if we go y pred tensor, this is going to turn our list of predictions into a single tensor. And then we'll go y pred tensor. And we'll view the first 10. Let's see if this works. So making predictions. Oh, would you look at that? Okay, so yeah, here's our list of predictions. A big list of tensors. Right, we don't really want it like that. So if we get rid of that, and there's our progress bar, it's going through each batch in the test data load, so there's 313 batches of 32. So if we comment out print y preds, this line here torch dot cat y preds is going to turn this these tensors into a single tensor, or this list of tensors into a single tensor concatenate. Now, if we have a look, there we go, beautiful. And if we have a look at the whole thing, we're making predictions every single time here, but that's all right. They are pretty quick. There we go. One big long tensor. And then if we check length y pred tensor, there should be one prediction per test sample. 10,000 beautiful. So now we're going to, we need to install torch metrics because torch metrics doesn't come with Google Colab at the time of recording. So let me just show you if we tried to import torch metrics. It doesn't, it might in the future, so just keep that in mind, it might come with Google Colab because it's a pretty useful package. But let's now install see if required packages are installed. And if not, install them. So we'll just install torch metrics. We'll finish off this video by trying to import. We'll set up a try and accept loop. So Python is going to try import torch metrics and ML extend. I write it like this, because you may already have to which metrics and ML extend if you're running this code on a local machine. But if you're running it in Google Colab, which I'm sure many of you are, we are going to try and import it anyway. And if it doesn't work, we're going to install it. So ML extend, I'm just going to check the version here because we need version for our plot confusion matrix function. This one, we need version 0.19.0 or higher. So I'm just going to write a little statement here. Assert int ML extend dot version. So if these two, if this condition in the try loop is or try block is accepted, it will skip the next step dot split. And I'm just going to check the first index string equals is greater than or equal to 19. Otherwise, I'm going to return an error saying ML extend version should be 0.19.0 or higher. And so let me just show you what this looks like. If we run this here, string and int, did I not turn it into a string? Oh, excuse me. There we go. And I don't need that bracket on the end. There we go. So that's what I'm saying. So this is just saying, hey, the version of ML extend that you have should be 0 or should be 19 or higher. Because right now Google Colab by default has 14, this may change in the future. So let's finish off this accept block. If the above condition fails, which it should, we are going to pip install. So we're going to install this into Google Colab torch metrics. We're going to do it quietly. And we're also going to pass the U tag for update ML extend. So import torch metrics, ML extend afterwards, after it's been installed and upgraded. And print, we're going to go ML extend version, going to go ML extend underscore version. And let's see what happens if we run this. So we should see, yeah, some installation happening here. This is going to install torch metrics. Oh, do we not have ML extend the upgraded version? Let's have a look. We may need to restart our Google Colab instance. Ah, okay, let's take this off. Quiet. Is this going to tell us to restart Google Colab? Well, let's restart our runtime. After you've run this cell, if you're using Google Colab, you may have to restart your runtime to reflect the fact that we have the updated version of ML extend. So I'm going to restart my runtime now. Otherwise, we won't be able to plot our confusion matrix. We need 0.19.0. And I'm going to run all of these cells. So I'm going to pause the video here, run all of the cells by clicking run all. Note, if you run into any errors, you will have to run those cells manually. And then I'm going to get back down to this cell and make sure that I have ML extend version 0.1.9. I'll see in a few seconds. I'm back. And just a little heads up. If you restart your runtime and click run all, your Colab notebook will stop running cells if it runs into an error. So this is that error we found in a previous video where our data and model were on different devices. So to skip past that, we can just jump to the next cell and we can click run after. There we go. And it's going to run all of the cells after for us. It's going to retrain our models. Everything's going to get rerun. And then we're going to come right back down to where we were before trying to install the updated version of ML extend. I'm going to write some more code while our code is running import ML extend. And then I'm going to just make sure that we've got the right version here. You may require a runtime restart. You may not. So just try to see after you've run this install of torch metrics and upgrade of ML extend. See if you can re import ML extend. And if you have the version 0.19.0 or above, we should be able to run the code. Yeah, there we go. Wonderful. ML extend 0.19.0. And we've got ML extend version, assert, import. Beautiful. So we've got a lot of extra code here. In the next video, let's move forward with creating a confusion matrix. I just wanted to show you how to install and upgrade some packages in Google Colab if you don't have them. But now we've got predictions across our entire test data set. And we're going to be moving towards using confusion matrix function here to compare our predictions versus the target data of our test data set. So I'll see in the next video, let's plot a confusion matrix. Welcome back. In the last video, we wrote a bunch of code to import some extra libraries that we need for plotting a confusion matrix. This is really helpful, by the way. Google Colab comes with a lot of prebuilt installed stuff. But definitely later on down the track, you're going to need to have some experience installing stuff. And this is just one way that you can do it. And we also made predictions across our entire test data set. So we've got 10,000 predictions in this tensor. And what we're going to do with a confusion matrix is confirm or compare these predictions to the target labels in our test data set. So we've done step number one. And we've prepared ourselves for step two and three, by installing torch metrics, and installing ML extend or the later version of ML extend. So now let's go through step two, making a confusion matrix, and step three plotting that confusion matrix. This is going to look so good. I love how good confusion matrix is look. So because we've got torch metrics now, we're going to import the confusion matrix class. And from our ML extend, we're going to go into the plotting module, and import plot confusion matrix. Recall that the documentation for both of these are within torch metrics here, and within ML extend here. Let's see what they look like. So number two is set up confusion matrix instance, and compare predictions to targets. That's what evaluating a model is, right? Comparing our models predictions to the target predictions. So I'm going to set up a confusion matrix under the variable conf mat, then I'm going to call the confusion matrix class from torch metrics. And to set up an instance of it, I need to pass in the number of classes that we have. So because we have 10 classes, they are all contained within class names. Recall that class names is a list of all of the different classes that we're working with. So I'm just going to pass in the number of classes as the length of our class names. And then I can use that conf mat instance, confusion matrix instance, to create a confusion matrix tensor by passing into conf mat, which is what I've just created up here. Conf mat, just like we do with our loss function, I'm going to pass in preds equals our Y pred tensor, which is just above Y pred tensor that we calculated all of the predictions on the test data set. There we go. That's our preds. And our target is going to be equal to test data dot targets. And this is our test data data set that we've seen before. So if we go test data and press tab, we've got a bunch of different attributes, we can get the classes. And of course, we can get the targets, which is the labels. PyTorch calls labels targets. I usually refer to them as labels, but the target is the test data target. So we want to compare our models predictions on the test data set to our test data targets. And so let's keep going forward. We're up to step number three now. So this is going to create our confusion matrix tensor. Oh, let's see what that looks like, actually. Conf mat tensor. Oh, okay. So we've got a fair bit going on here. But let's turn this into a pretty version of this. So along the bottom is going to be our predicted labels. And along the side here is going to be our true labels. But this is where the power of ML extend comes in. We're going to plot our confusion matrix. So let's create a figure and an axes. We're going to call the function plot confusion matrix that we've just imported above. And we're going to pass in our conf mat equals our conf mat tensor. But because we're working with map plot lib, it'll want it as NumPy. So I'm just going to write here, map plot lib likes working with NumPy. And we're going to pass in the class names so that we get labels for each of our rows and columns. Class names, this is just a list of our text based class names. And then I'm going to set the fig size to my favorite hand and poker, which is 10, seven. Also happens to be a good dimension for Google Colab. Look at that. Oh, that is something beautiful to see. Now a confusion matrix. The ideal confusion matrix will have all of the diagonal rows darkened with all of the values and no values here, no values here. Because that means that the predicted label lines up with the true label. So in our case, we have definitely a very dark diagonal here. But let's dive into some of the highest numbers here. It looks like our model is predicting shirt when the true label is actually t shirt slash top. So that is reflective of what we saw before. Do we still have that image there? Okay, we don't have an image there. But in a previous video, we saw that when we plotted our predictions, the model predicted t shirt slash top when it was actually a shirt. And of course, vice versa. So what's another one here? Looks like our model is predicting shirt when it's actually a coat. And now this is something that you can use to visually inspect your data to see if the the errors that your model is making make sense from a visual perspective. So it's getting confused by predicting pull over when the actual label is coat, predicting pull over when the actual label is shirt. So a lot of these things clothing wise and data wise may in fact look quite the same. Here's a relatively large one as well. It's predicting sneaker when it should be an ankle boot. So it's confusing two different types of shoes there. So this is just a way to further evaluate your model and start to go. Hmm, maybe our labels are a little bit confusing. Could we expand them a little bit more? So keep that in mind, a confusion matrix is one of the most powerful ways to visualize your classification model predictions. And a really, really, really helpful way of creating one is to use torch metrics confusion matrix. And to plot it, you can use plot confusion matrix from ML extend. However, if you're using Google Colab for these, you may need to import them or install them. So that's a confusion matrix. If you'd like more classification metrics, you've got them here. And you've got, of course, more in torch metrics. So give that a look. I think in the next video, we've done a fair bit of evaluation. Where are we up to in our workflow? I believe it's time we saved and loaded our best trained model. So let's give that a go. I'll see you in the next video. In the last video, we created a beautiful confusion matrix with the power of torch metrics and ML extend. But now it's time to save and load our best model. Because if we, if we evaluated it, our convolutional neural network and go, you know what, this model is pretty good. Let's export it to a file so we can use it somewhere else. Let's see how we do that. And by the way, if we go into our keynote, we've got a value at model torch metrics. We've been through this a fair few times now. We've improved through experimentation. We haven't used tensor board yet, but that'll be in a later video and save and reload your trained model. So here's where we're up to. If we've gone through all these steps enough times and we're like, you know what, let's save our model so we can use it elsewhere. And we can reload it in to make sure that it's, it's saved correctly. Let's go through with this step. We want number 11. We're going to go save and load best performing model. You may have already done this before. So if you've been through the other parts of the course, you definitely have. So if you want to give that a go, pause the video now and try it out yourself. I believe we did it in notebook number one. We have here we go, saving and loading a pie torch model. You can go through this section of section number one on your own and see if you can do it. Otherwise, let's code it out together. So I'm going to start from with importing path from path lib, because I like to create a model directory path. So create model directory path. So my model path is going to be set equal to path. And I'm going to save it to models. This is where I want to, I want to create file over here called models and save my models to their model path dot MKD for make directory parents. Yes, I wanted to make the parent directories if they don't exist and exist. Okay. Also equals true. So if we try to create it, but it's already existing, we're not going to get an error. That's fine. And next, we're going to create a model save path. Just going to add some code cells here. So we have more space. Let's pass in here a model name. Going to set this equal to, since we're on section three, I'm going to call this O three pie torch, computer vision, model two is our best model. And I'm going to save it to PTH for pie torch. You can also save it to dot PT. I like to use PTH. And we're going to go model save path equal model path slash model name. So now if we have a look at this, we're going to have a path called model save path. But it's going to be a POSIX path in models O three pie torch computer vision, model two dot PTH. And if we have a look over here, we should have, yeah, we have a models directory now. That's not going to have anything in it at the moment. We've got our data directory that we had before there's fashion MNIST. This is a good way to start setting up your directories, break them down data models, helper function files, etc. But let's keep going. Let's save, save the model state dict. We're going to go print, saving model to just going to give us some information about what's happening. Model save path. And we can save a model by calling torch dot save. And we pass in the object that we want to save using the object parameter, OBJ. When we get a doc string there, we're going to go model two, we want to save the state dict, recall that the state dict is going to be our models what our models learned parameters on the data set, so that all the weights and biases and all that sort of jazz. Beautiful. So when we first created model two, these were all random numbers. They've been or since we trained model two on our training data, these have all been updated to represent the training images. And we can leverage these later on, as you've seen before, to make predictions. So I'm not going to go through all those, but that's what we're saving. And the file path is going to be our model save path. So let's run this and see what happens. Beautiful. We're saving our model to our model directory. And now let's have a look in here. Do we have a model? Yes, we do. Beautiful. So that's how quickly we can save a model. Of course, you can customize what the name is, where you save it, et cetera, et cetera. Now, let's see what happens when we load it in. So create a new instance, because we only saved the state dict of model two, we need to create a new instance of our model two, or how it was created, which was with our class fashion MNIST V two. If we saved the whole model, we could just import it to a new variable. But I'll let you read back more on that on the different ways of saving a model in here. There's also a link to the pytorch documentation would highly recommend that. But let's see it in action, we need to create a new instance of our fashion MNIST model V two, which is our convolution or neural network. So I'm going to set the manual seed. That way when we create a new instance, it's instantiated with the same random numbers. So we're going to set up loaded model two, equals fashion MNIST V two. And it's important here that we set it up with the same parameters as our original saved model. So fashion MNIST V two. Oh, we've got a typo here. I'll fashion MNIST model V two. Wonderful. So the input shape is going to be one, because that is the number of color channels in our test, in our images, test image dot shape. Do we still have a test image should be? Oh, well, we've created a different one, but our image size, our image shape is 12828 image shape for color channels height width. Then we create it with hidden units, we use 10 for hidden units. So we can just set that here. This is important, they just have to otherwise if the shapes aren't the same, what are we going to get? We're going to get a shape mismatch error. And our output shape is what is also going to be 10 or length of class names. If you have the class names variable instantiated, that is. So we're going to load in the saved state dict, the one that we just saved. So we can go loaded model two, dot load state dict. And we can pass in torch dot load in here. And the file that we want to load or the file path is model save path up here. This is why I like to just save my path variables to a variable so that I can just use them later on, instead of re typing out this all the time, which is definitely prone to errors. So we're going to send the model to the target device. Loaded model two dot two device. Beautiful. Let's see what happens here. Wonderful. So let's now evaluate the loaded model. So evaluate loaded model. The results should be very much the same as our model two results. So model two results. So this is what we're looking for. We want to make sure that our saved model saved these results pretty closely. Now I say pretty closely because you might find some discrepancies in this lower these lower decimals here, just because of the way files get saved and something gets lost, et cetera, et cetera. So that's just to do with precision and computing. But as long as the first few numbers are quite similar, well, then we're all gravy. So let's go torch manual seed. Remember, evaluating a model is almost as well is just as important as training a model. So this is what we're doing. We're making sure our model save correctly. Before we deployed it, if it didn't if we deployed it, it didn't save correctly. Well, then we'd get our we would get less than ideal results, wouldn't we? So model equals loaded model two, we're going to use our same of our model function, by the way. And of course, we're going to evaluate it on the same test data set that we've been using test data loader. And we're going to create a loss function or just put in our loss function that we've created before. And our accuracy function is the accuracy function we've been using throughout this notebook. So now let's check out loaded model two results. They should be quite similar to this one. We're going to make some predictions. And then if we go down, do we have the same numbers? Yes, we do. So we have five, six, eight, two, nine, five, six, eight, two, nine, wonderful. And three, one, three, five, eight, three, one, three, five, eight, beautiful. It looks like our loaded model gets the same results as our previously trained model before we even saved it. And if you wanted to check if they were close, you can also use torch dot is close, check if model results, if you wanted to check if they were close programmatically, that is, because we just looked at these visually, check if model results are close to each other. Now we can go torch is close, we're going to pass in torch dot tensor, we have to turn these values into a tensor. We're going to go model two results. And we'll compare the model loss. How about we do that? We want to make sure the loss values are the same. Or very close, that is with torch dot is close. Torch dot tensor model. Or we want this one to be loaded model two results. Model loss. Another bracket on the end there. And we'll see how close they are true, wonderful. Now, if this doesn't return true, you can also adjust the tolerance levels in here. So we go atal equals, this is going to be the absolute tolerance. So if we do one to the negative eight, it's saying like, Hey, we need to make sure our results are basically the same up to eight decimal points. That's probably quite low. I would say just make sure they're at least within two. But if you're getting discrepancies here between your saved model and your loaded model, or sorry, this model here, the original one and your loaded model, if they are quite large, so they're like more than a few decimal points off in this column or even here, I'd go back through your code and make sure that your model is saving correctly, make sure you've got random seeds set up. But if they're pretty close, like in terms of within three or two decimal places of each other, well, then I'd say that's that's close enough. But you can also adjust the tolerance level here to check if your model results are close enough, programmatically. Wow, we have covered a fair bit here. We've gone through this entire workflow for a computer vision problem. Let's in the next video, I think that's enough code for this section, section three, pytorch computer vision. I've got some exercises and some extra curriculum lined up for you. So let's have a look at those in the next video. I'll see you there. My goodness. Look how much computer vision pytorch code we've written together. We started off right up the top. We looked at the reference notebook and the online book. We checked out computer vision libraries and pytorch, the main one being torch vision. Then we got a data set, namely the fashion MNIST data set. There are a bunch more data sets that we could have looked at. And in fact, I'd encourage you to try some out in the torch vision dot data sets, use all of the steps that we've done here to try it on another data set. We repaired our data loaders. So turned our data into batches. We built a baseline model, which is an important step in machine learning, because the baseline model is usually relatively simple. And it's going to serve as a baseline that you're going to try and improve upon through just go back to the keynote through various experiments. We then made predictions with model zero. We evaluated it. We timed our predictions to see if running our models on the GPU was faster when we learned that sometimes a GPU won't necessarily speed up code if it's a relatively small data set because of the overheads between copying data from CPU to GPU. We tried a model with non-linearity and we saw that it didn't really improve upon our baseline model. But then we brought in the big guns, a convolutional neural network, replicating the CNN explainer website. And by gosh, didn't we spend a lot of time here? I'd encourage you as part of your extra curriculum to go through this again and again. I still even come back to refer to it too. I referred to it a lot making the materials for this video section and this code section. So be sure to go back and check out the CNN explainer website for more of what's going on behind the scenes of your CNNs. But we coded one using pure pytorch. That is amazing. We compared our model results across different experiments. We found that our convolutional neural network did the best, although it took a little bit longer to train. And we also learned that the training time values will definitely vary depending on the hardware you're using. So that's just something to keep in mind. We made an evaluated random predictions with our best model, which is an important step in visualizing, visualizing, visualizing your model's predictions, because you could get evaluation metrics. But until you start to actually visualize what's going on, well, in my case, that's how I best understand what my model is thinking. We saw a confusion matrix using two different libraries torch metrics and ML extend a great way to evaluate your classification models. And we saw how to save and load the best performing model to file and made sure that the results of our saved model weren't too different from the model that we trained within the notebook. So now it is time I'd love for you to practice what you've gone through. This is actually really exciting now because you've gone through an end-to-end computer vision problem. I've got some exercises prepared. If you go to the learn pytorch.io website in section 03, scroll down. You can read through all of this. This is all the materials that we've just covered in pure code. There's a lot of pictures in this notebook too that are helpful to learn things what's going on. We have some exercises here. So all of the exercises are focused on practicing the code and the sections above. We have two resources. We also have some extra curriculum that I've put together. If you want an in-depth understanding of what's going on behind the scenes in the convolutional neural networks, because we've focused a lot on code, I'd highly recommend MIT's induction to deep computer vision lecture. You can spend 10 minutes clicking through the different options in the pytorch vision library, torch vision, look up most common convolutional neural networks in the torch vision model library, and then for a larger number of pre-trained pytorch computer vision models, and if you get deeper into computer vision, you're probably going to run into the torch image models library, otherwise known as 10, but I'm going to leave that as extra curriculum. I'm going to just link this exercises section here. Again, it's at learn pytorch.io in the exercises section. We come down. There we go. But there is also resource here, an exercise template notebook. So we've got one, what are three areas in industry where computer vision is being currently used. Now this is in the pytorch deep learning repo, extras exercises number three. I've put out some template code here for you to fill in these different sections. So some of them are code related. Some of them are just text based, but they should all be able to be completed by referencing what we've gone through in this notebook here. And just as one more, if we go back to pytorch deep learning, this will probably be updated by the time you get here, you can always find the exercise in extra curriculum by going computer vision, go to exercise in extra curriculum, or if we go into the extras file, and then we go to solutions. I've now also started to add video walkthroughs of each of the solutions. So this is me going through each of the exercises myself and coding them. And so you'll get to see the unedited videos. So they're just one long live stream. And I've done some for O2, O3, and O4, and there will be more here by the time you watch this video. But if you'd like to see how I figure out the solutions to the exercises, you can watch those videos and go through them yourself. But first and foremost, I would highly recommend trying out the exercises on your own first. And then if you get stuck, refer to the notebook here, refer to the pytorch documentation. And finally, you can check out what I would have coded as a potential solution. So there's number three, computer vision, exercise solutions. So congratulations on going through the pytorch computer vision section. I'll see you in the next section. We're going to look at pytorch custom data sets, but no spoilers. I'll see you soon. Hello, hello, hello, and welcome to section number four of the Learn pytorch for deep learning course. We have custom data sets with pytorch. Now, before we dive into what we're going to cover, let's answer the most important question. Where can you get help? Now, we've been through this a few times now, but it's important to reiterate. Follow along with the code as best you can. We're going to be writing a bunch of pytorch code. Remember the motto, if and out, run the code. That's in line with try it for yourself. If you'd like to read or read the doxtring, you can press shift command plus space in Google Colab. Or if you're on Windows, command might be control. Then if you're still stuck, you can search for it. Two of the resources you will probably come across is stack overflow or the wonderful pytorch documentation, which we've had a lot of experience with so far. Then, of course, try again, go back through your code, if and out, code it out, or if and out, run the code. And then finally, if you're still stuck, ask a question on the pytorch deep learning discussions GitHub page. So if I click this link, we come to Mr. D Burke slash pytorch deep learning, the URL is here. We've seen this before. If you have a trouble or a problem with any of the course, you can start a discussion and you can select the category, general ideas, polls, Q and A, and then we can go here, video, put the video number in. So 99, for example, my code doesn't do what I'd like it to. So say your problem and then come in here, write some code here, code here, and then my question is something, something, something, click start discussion, and then we can help out. And then if we come back to the discussions, of course, you can search for what's going on. So if you have an error and you feel like someone else might have seen this error, you can, of course, search it and find out what's happening. Now, I just want to highlight again, the resources for this course are at learn pytorch.io. We are up to section four. This is a beautiful online book version of all the materials we are going to cover in this section. So spoiler alert, you can use this as a reference. And then, of course, in the GitHub, we have the same notebook here, pytorch custom data sets. This is the ground truth notebook. So check that out if you get stuck. So I'm just going to exit out of this. We've got pytorch custom data sets at learn pytorch.io. And then, of course, the discussions tab for the Q&A. Now, if we jump back to the keynote, what do we have? We might be asking, what is a custom data set? Now, we've built a fair few pytorch deeplining neural networks so far on various data sets, such as fashion MNIST. But you might be wondering, hey, I've got my own data set, or I'm working on my own problem. Can I build a model with pytorch to predict on that data set? And the answer is yes. However, you do have to go through a few pre processing steps to make that data set compatible with pytorch. And that's what we're going to be covering in this section. And so I'd like to highlight the pytorch domain libraries. Now, we've had a little bit of experience before with torch vision, such as if we wanted to classify whether a photo was a pizza, steak, or sushi. So a computer vision image classification problem. Now, there's also text, such as if these reviews are positive or negative. And you can use torch text for that. But again, these are only just one problem within the vision space within the text space. I want you to just understand that if you have any type of vision data, you probably want to look into torch vision. And if you have any kind of text data, you probably want to look into torch text. And then if you have audio, such as if you wanted to classify what song was playing, this is what Shazam does, it uses the input sound of some sort of music, and then runs a neural network over it to classify it to a certain song, you can look into torch audio for that. And then if you'd like to recommend something such as you have an online store, or if your Netflix or something like that, and you'd like to have a homepage that updates for recommendations, you'd like to look into torch rec, which stands for recommendation system. And so this is just something to keep in mind. Because each of these domain libraries has a data sets module that helps you work with different data sets from different domains. And so different domain libraries contain data loading functions for different data sources. So torch vision, let's just go into the next slide, we have problem space vision for pre built data sets, so existing data sets like we've seen with fashion MNIST, as well as functions to load your own vision data sets, you want to look into torch vision dot data sets. So if we click on this, we have built in data sets, this is the pie torch documentation. And if we go here, we have torch audio, torch text, torch vision, torch rec, torch data. Now, at the time of recording, which is April 2022, this is torch data is currently in beta. But it's going to be updated over time. So just keep this in mind, updated over time to add even more ways to load different data resources. But for now, we're just going to get familiar with torch vision data sets. If we went into torch text, there's another torch text dot data sets. And then if we went into torch audio, we have torch audio dot data sets. And so you're noticing a trend here that depending on the domain you're working in, whether it be vision, text, audio, or your data is recommendation data, you'll probably want to look into its custom library within pie torch. And of course, the bonus is torch data. It contains many different helper functions for loading data, and is currently in beta as of April 2022. So 2022. So the by the time you watch this torch data may be out of beta. And then that should be something that's extra curriculum on top of what we're going to cover in this section. So let's keep going. So this is what we're going to work towards building food vision mini. So we're going to load some data, namely some images of pizza, sushi, and steak from the food 101 data set, we're going to build an image classification model, such as the model that might power a food vision recognition app or a food image recognition app. And then we're going to see if it can classify an image of pizza as pizza, an image of sushi as sushi, and an image of steak as steak. So this is what we're going to focus on. We want to load, say we had images existing already of pizza, sushi, and steak, we want to write some code to load these images of food. So our own custom data set for building this food vision mini model, which is quite similar to if you go to this is the project I'm working on personally, neutrify.app. This is a food image recognition model. Here we go. So it's still a work in progress as I'm going through it, but you can upload an image of food and neutrify will try to classify what type of food it is. So do we have steak? There we go. Let's upload that. Beautiful steak. So we're going to be building a similar model to what powers neutrify. And then there's the macro nutrients for the steak. If you'd like to find out how it works, I've got all the links here, but that's at neutrify.app. So let's keep pushing forward. We'll go back to the keynote. This is what we're working towards. As I said, we want to load these images into PyTorch so that we can build a model. We've already built a computer vision model. So we want to figure out how do we get our own data into that computer vision model. And so of course we'll be adhering to our PyTorch workflow that we've used a few times now. So we're going to learn how to load a data set with our own custom data rather than an existing data set within PyTorch. We'll see how we can build a model to fit our own custom data set. We'll go through all the steps that's involved in training a model such as picking a loss function and an optimizer. We'll build a training loop. We'll evaluate our model. We'll improve through experimentation. And then we can see save and reloading our model. But we're also going to practice predicting on our own custom data, which is a very, very important step whenever training your own models. So what we're going to cover broadly, we're going to get a custom data set with PyTorch. As we said, we're going to become one with the data. In other words, preparing and visualizing it. We'll learn how to transform data for use with a model, very important step. We'll see how we can load custom data with pre-built functions and our own custom functions. We'll build a computer vision model, aka food vision mini, to classify pizza, steak, and sushi images. So a multi-class classification model. We'll compare models with and without data augmentation. We haven't covered that yet, but we will later on. And finally, we'll see how we can, as I said, make predictions on custom data. So this means data that's not within our training or our test data set. And how are we going to do it? Well, we could do it cooks or chemists. But I like to treat machine learning as a little bit of an art, so we're going to be cooking up lots of code. With that being said, I'll see you in Google Colab. Let's code. Welcome back to the PyTorch cooking show. Let's now learn how we can cook up some custom data sets. I'm going to jump into Google Colab. So colab.research.google.com. And I'm going to click new notebook. I'm just going to make sure this is zoomed in enough for the video. Wonderful. So I'm going to rename this notebook 04 because we're up to section 04. And I'm going to call it PyTorch custom data sets underscore video because this is going to be one of the video notebooks, which has all the code that I write during the videos, which is of course contained within the video notebooks folder on the PyTorch deep learning repo. So if you'd like the resource or the ground truth notebook for this, I'm going to just put a heading here. 04 PyTorch custom data sets video notebook, make that bigger, and then put resources. So book version of the course materials for 04. We'll go there, and then we'll go ground truth version of notebook 04, which will be the reference notebook that we're going to use for this section. Come into PyTorch custom data sets. And then we can put that in there. Wonderful. So the whole synopsis of this custom data sets section is we've used some data sets with PyTorch before, but how do you get your own data into PyTorch? Because that's what you want to start working on, right? You want to start working on problems of your own. You want to come into any sort of data that you've never worked with before, and you want to figure out how do you get that into PyTorch. So one of the ways to do so is via custom data sets. And then I want to put a note down here. So we're going to go zero section zero is going to be importing PyTorch and setting up device agnostic code. But I want to just stress here that domain libraries. So just to reiterate what we went through last video. So depending on what you're working on, whether it be vision, text, audio, recommendation, something like that, you'll want to look into each of the PyTorch domain libraries for existing data loader or data loading functions and customizable data loading functions. So just keep that in mind. We've seen some of them. So if we go torch vision, which is what we're going to be looking at, torch vision, we've got data sets, and we've got documentation, we've got data sets for each of the other domain libraries here as well. So if you're working on a text problem, it's going to be a similar set of steps to what we're going to do with our vision problem when we build food vision mini. What we have is a data set that exists somewhere. And what we want to do is bring that into PyTorch so we can build a model with it. So let's import the libraries that we need. So we're going to import torch and we'll probably import an N. So we'll import that from PyTorch. And I'm just going to check the torch version here. So note, we need PyTorch 1.10.0 plus is required for this course. So if you're using Google Colab at a later date, you may have a later version of PyTorch. I'm just going to show you what version I'm using. Just going to let this load. We're going to get this ready. We're going to also set up device agnostic code right from the start this time because this is best practice with PyTorch. So this way, if we have a CUDA device available, our model is going to use that CUDA device. And our data is going to be on that CUDA device. So there we go. Wonderful. We've got PyTorch 1.10.0 plus CUDA. 111. Maybe that's 11.1. So let's check if CUDA.is available. Now, I'm using Google Colab. We haven't set up a GPU yet. So it probably won't be available yet. Let's have a look. Wonderful. So because we've started a new Colab instance, it's going to use the CPU by default. So how do we change that? We come up to runtime, change runtime type. I'm going to go hard there accelerator GPU. We've done this a few times now. I am paying for Google Colab Pro. So one of the benefits of that is that it our Google Colab reserves faster GPUs for you. You do don't need Google Colab Pro. As I've said to complete this course, you can use the free version, but just recall Google Colab Pro tends to give you a better GPU just because GPUs aren't free. Wonderful. So now we've got access to a GPU CUDA. What GPU do I have? Nvidia SMI. I have a Tesla P100 with 16 gigabytes of memory, which will be more than enough for the problem that we're going to work on in this video. So I believe that's enough to cover for the first coding video. Let's in the next section, we are working with custom datasets after all. Let's in the next video. Let's get some data, hey. Now, as I said in the last video, we can't cover custom datasets without some data. So let's get some data and just remind ourselves what we're going to build. And that is food vision mini. So we need a way of getting some food images. And if we go back to Google Chrome, torch vision datasets has plenty of built-in datasets. And one of them is the food 101 dataset. Food 101. So if we go in here, this is going to take us to the original food 101 website. So food 101 is 101 different classes of food. It has a challenging dataset of 101 different food categories with 101,000 images. So that's a quite a beefy dataset. And so for each class, 250 manually reviewed test images are provided. So we have per class, 101 classes, 250 testing images, and we have 750 training images. Now, we could start working on this entire dataset straight from the get go. But to practice, I've created a smaller subset of this dataset, and I'd encourage you to do the same with your own problems. Start small and upgrade when necessary. So I've reduced the number of categories to three and the number of images to 10%. Now, you could reduce this to an arbitrary amount, but I've just decided three is enough to begin with and 10% of the data. And then if it works, hey, you could upscale that on your own accord. And so I just want to show you the notebook that I use to create this dataset and as extra curriculum, you could go through this notebook. So if we go into extras, 04 custom data creation, this is just how I created the subset of data. So making a dataset to use with notebook number four, I created it in custom image data set or image classification style. So we have a top level folder of pizza, steak, and sushi. We have a training directory with pizza, steak, and sushi images. And we have a test directory with pizza, steak, and sushi images as well. So you can go through that to check it out how it was made. But now, oh, and also, if you go to loan pytorch.io section four, there's more information here about what food 101 is. So get data. Here we go. There's all the information about food 101. There's some resources, the original food 101 data set, torch vision data sets, food 101, how I created this data set, and actually downloading the data. But now we're going to write some code, because this data set, the smaller version that I've created is on the pytorch deep learning repo, under data. And then we have pizza, steak, sushi.zip. Oh, this one is a little spoiler for one of the exercises for this section. But you'll see that later. Let's go in here. Let's now write some code to get this data set from GitHub, pizza, steak, sushi.zip. And then we'll explore it, we'll become one with the data. So I just want to write down here, our data set is a subset of the food 101 data set. Food 101 starts with 101 different classes of food. So we could definitely build computer vision models for 101 classes, but we're going to start smaller. Our data set starts with three classes of food, and only 10% of the images. So what's right here? And 1000 images per class, which is 750 training, 250 testing. And we have about 75 training images per class, and about 25 testing images per class. So why do this? When starting out ML projects, it's important to try things on a small scale and then increase the scale when necessary. The whole point is to speed up how fast you can experiment. Because there's no point trying to experiment on things that if we try to train on 100,000 images to begin with, our models might train take half an hour to train at a time. So at the beginning, we want to increase the rate that we experiment at. And so let's get some data. We're going to import requests so that we can request something from GitHub to download this URL here. Then we're also going to import zip file from Python, because our data is in the form of a zip file right now. Then we're going to get path lib, because I like to use paths whenever I'm dealing with file paths or directory paths. So now let's set up a path to a data folder. And this, of course, will depend on where your data set lives, what you'd like to do. But I typically like to create a folder over here called data. And that's just going to store all of my data for whatever project I'm working on. So data path equals path data. And then we're going to go image path equals data path slash pizza steak sushi. That's how we're going to have images from those three classes. Pizza steak and sushi are three of the classes out of the 101 in food 101. So if the image folder doesn't exist, so if our data folder already exists, we don't want to redownload it. But if it doesn't exist, we want to download it and unzip it. So if image path is der, so we want to print out the image path directory already exists skipping download. And then if it doesn't exist, we want to print image path does not exist, creating one. Beautiful. And so we're going to go image path dot mk der to make a directory. We want to make its parents if we need to. So the parent directories and we want to pass exist, okay, equals true. So we don't get any errors if it already exists. And so then we can write some code. I just want to show you what this does if we run it. So our target directory data slash pizza steak sushi does not exist. It's creating one. So then we have now data and inside pizza steak sushi. Wonderful. But we're going to fill this up with some images so that we have some data to work with. And then the whole premise of this entire section will be loading this data of just images into PyTorch so that we can build a computer vision model on it. But I just want to stress that this step will be very similar no matter what data you're working with. You'll have some folder over here or maybe it'll live on the cloud somewhere. Who knows wherever your data is, but you'll want to write code to load it from here into PyTorch. So let's download pizza steak and sushi data. So I'm going to use width. I'll just X over here. So we have more screen space with open. I'm going to open the data path slash the file name that I'm trying to open, which will be pizza steak sushi dot zip. And I'm going to write binary as F. So this is essentially saying I'm doing this in advance because I know I'm going to download this folder here. So I know the the file name of it, pizza steak sushi dot zip. I'm going to download that into Google collab and I want to open it up. So request equals request dot get. And so when I want to get this file, I can click here. And then if I click download, it's going to what do you think it's going to do? Well, let's see. If I wanted to download it locally, I could do that. And then I could come over here. And then I could click upload if I wanted to. So upload the session storage. I could upload it from that. But I prefer to write code so that I could just run this cell over again and have the file instead of being download to my local computer. It just goes straight into Google collab. So to do that, we need the URL from here. And I'm just going to put that in there. It needs to be as a string. Excuse me. I'm getting trigger happy on the shift and enter. Wonderful. So now I've got a request to get the content that's in here. And GitHub can't really show this because this is a zip file of images, spoiler alert. Now let's keep going. We're going to print out that we're downloading pizza, stake and sushi data dot dot dot. And then I'm going to write to file the request dot content. So the content of the request that I just made to GitHub. So that's request is here. Using the Python request library to get the information here from GitHub. This URL could be wherever your file has been stored. And then I'm going to write the content of that request to my target file, which is this. This here. So if I just copy this, I'm going to write the data to here data path slash pizza, stake sushi zip. And then because it's a zip file, I want to unzip it. So unzip pizza, stake sushi data. Let's go with zip file. So we imported zip file up there, which is a Python library to help us deal with zip files. We're going to use zip file dot zip file. We're going to pass it in the data path. So just the path that we did below, data path slash pizza, stake sushi dot zip. And this time, instead of giving it right permissions, so that's what wb stands for, stands for right binary. I'm going to give it read permissions. So I want to read this target file instead of writing it. And I'm going to go as zip ref. We can call this anything really, but zip ref is kind of, you'll see this a lot in different Python examples. So we're going to print out again. So unzipping pizza, stake, and sushi data. Then we're going to go zip underscore ref dot extract all. And we're going to go image path. So what this means is it's taking the zip ref here. And it's extracting all of the information that's within that zip ref. So within this zip file, to the image path, which is what we created up here. So if we have a look at image path, let's see that. Image path. Wonderful. So that's where all of the contents of that zip file are going to go into this file. So let's see it in action. You're ready. Hopefully it works. Three, two, one, run. File is not a zip file. Oh, no, what do we get wrong? So did I type this wrong? Got zip data path. Oh, we got the zip file here. Pizza, stake, sushi, zip, read data path. Okay, I found the error. So this is another thing that you'll have to keep in mind. And I believe we've covered this before, but I like to keep the errors in these videos so that you can see where I get things wrong, because you never write code right the first time. So we have this link in GitHub. We have to make sure that we have the raw link address. So if I come down to here and copy the link address from the download button, you'll notice a slight difference if we come back into here. So I'm just going to copy that there. So if we step through this GitHub, Mr. D Burke pytorch deep learning, we have raw instead of blob. So that is why we've had an error is that our code is correct. It's just downloading the wrong data. So let's change this to the raw. So just keep that in mind, you must have raw here. And so let's see if this works. Do we have the correct data? Oh, we might have to delete this. Oh, there we go. Test. Beautiful. Train. Pizza steak sushi. Wonderful. So it looks like we've got some data. And if we open this up, what do we have? We have various JPEGs. Okay. So this is our testing data. And if we click on there, we've got an image of pizza. Beautiful. So we're going to explore this a little bit more in the next video. But that is some code that we've written to download data sets or download our own custom data set. Now, just recall that we are working specifically on a pizza steak and sushi problem for computer vision. However, our whole premise is that we have some custom data. And we want to convert these. How do we get these into tenses? That's what we want to do. And so the same process will be for your own problems. We'll be loading a target data set and then writing code to convert whatever the format the data set is in into tenses for PyTorch. So I'll see you in the next video. Let's explore the data we've downloaded. Welcome back. In the last video, we wrote some code to download a target data set, our own custom data set from the PyTorch deep learning data directory. And if you'd like to see how that data set was made, you can go to PyTorch deep learning slash extras. It's going to be in the custom data creation notebook here for 04. So I've got all the code there. All we've done is take data from the food 101 data set, which you can download from this website here, or from torch vision. So if we go to torch vision, food 101. We've got the data set built into PyTorch there. So I've used that data set from PyTorch and broken it down from 101 classes to three classes so that we can start with a small experiment. So there we go. Get the training data, data sets food 101, and then I've customized it to be my own style. So if we go back to CoLab, we've now got pizza steak sushi, a test folder, which will be our testing images, and a train folder, which will be our training images. This data is in standard image classification format. But we'll cover that in a second. All we're going to do in this video is kick off section number two, which is becoming one with the data, which is one of my favorite ways to refer to data preparation and data exploration. So we're coming one with the data. And I'd just like to show you one of my favorite quotes from Abraham loss function. So if I had eight hours to build a machine learning model, I'd spend the first six hours preparing my data set. And that's what we're going to do. Abraham loss function sounds like he knows what is going on. But since we've just downloaded some data, let's explore it. Hey, and we'll write some code now to walk through each of the directories. How you explore your data will depend on what data you've got. So we've got a fair few different directories here with a fair few different folders within them. So how about we walk through each of these directories and see what's going on. If you have visual data, you probably want to visualize an image. So we're going to do that in the second two, write a little doc string for this helper function. So walks through the path, returning its contents. Now, just in case you didn't know Abraham loss function does not exist as far as I know. But I did make up that quote. So we're going to use the OS dot walk function, OS dot walk. And we're going to pass it in a dirt path. And what does walk do? We can get the doc string here. Directory tree generator. For each directory in the directory tree rooted at the top, including top itself, but in excluding dot and dot dot, yields a three tuple, derpath, der names, and file names. You can step through this in the Python documentation, if you'd like. But essentially, it's just going to go through our target directory, which in this case will be this one here. And walk through each of these directories printing out some information about each one. So let's see that in action. This is one of my favorite things to do if we're working with standard image classification format data. So there are lane, length, der names, directories. And let's go land, land, file names. We say at length, like I've got the G on the end, but it's just land images in, let's put in here, derpath. So a little bit confusing if you've never used walk before, but it's so exciting to see all of the information in all of your directories. Oh, we didn't read and run it. Let's check out function now walk through der. And we're going to pass it in the image path, which is what? Well, it's going to show us. How beautiful. So let's compare what we've got in our printout here. There are two directories and zero images in data, pizza, steak sushi. So this one here, there's zero images, but there's two directories test and train wonderful. And there are three directories in data, pizza, steak, sushi, test. Yes, that looks correct. Three directories, pizza, steak, sushi. And then we have zero directories and 19 images in pizza, steak, sushi, slash test, steak. We have a look at this. So that means there's 19 testing images for steak. Let's have a look at one of them. There we go. Now, again, these are from the food 101 data set, the original food 101 data set, which is just a whole bunch of images of food, 100,000 of them. There's some steak there. Wonderful. And we're trying to build a food vision model to recognize what is in each image. Then if we jump down to here, we have three directories in the training directory. So we have pizza, steak, sushi. And then we have 75 steak images, 72 sushi images and 78 pizza. So slightly different, but very much the same numbers. They're not too far off each other. So we've got about 75 or so training images, and we've got about 25 or so testing images per class. Now these were just randomly selected from the food 101 data set 10% of three different classes. So let's keep pushing forward. And we're going to set up our training and test parts. So I just want to show you, we'll just set up this, and then I'll just show you the standard image classification setup, image path.train. And we're going to go tester. So if you're working on image classification problem, we want to set this up as test. And then if we print out the trainer and the tester, this is what we're going to be trying to do. We're going to write some code to go, Hey, look at this path for our training images. And look at this path for our testing images. And so this is the standard image classification data format is that you have your overall data set folder. And then you have a training folder dedicated to all of the training images that you might have. And then you have a testing folder dedicated to all of the testing images that you might have. And you could have a validation data set here as well if you wanted to. But to label each one of these images, the class name is the folder name. So all of the pizza images live in the pizza directory, the same for steak, and the same for sushi. So depending on your problem, your own data format will depend on whatever you're working on, you might have folders of different text files or folders of different audio files. But the premise remains, we're going to be writing code to get our data here into tenses for use with PyTorch. And so where does this come from? This image data classification format. Well, if we go to the torch vision dot data sets documentation, as you start to work with more data sets, you'll start to realize that there are standardized ways of storing specific types of data. So if we come down to here, base classes for custom data sets, we'll be working towards using this image folder data set. But this is a generic data loader where the images are arranged in this way by default. So I've specifically formatted our data to mimic the style that this pre built data loading function is for. So we've got a root directory here in case of we were classifying dog and cat images, we have root, then we have a dog folder, then we have various images. And the same thing for cat, this would be dog versus cat. But the only difference for us is that we have food images, and we have pizza steak sushi. If we wanted to use the entire food 101 data set, we would have 101 different folders of images here, which is totally possible. But to begin with, we're keeping things small. So let's keep pushing forward. As I said, we're dealing with a computer vision problem. So what's another way to explore our data, other than just walking through the directories themselves. Let's visualize an image, hey? But we've done that before with just clicking on the file. How about we write some code to do so. We'll replicate this but with code. I'll see you in the next video. Welcome back. In the last video, we started to become one with the data. And we learned that we have about 75 images per training class and about 25 images per testing class. And we also learned that the standard image classification data structure is to have the steak images within the steak folder of the training data set and the same for test, and the pizza images within the pizza folder, and so on for each different image classification class that we might have. So if you want to create your own data set, you might format it in such a way that your training images are living in a directory with their classification name. So if you wanted to classify photos of dogs and cats, you might create a training folder of train slash dog train slash cat, put images of dogs in the dog folder, images of cats in the cat folder, and then the same for the testing data set. But the premise remains, I'm going to sound like a broken record here. We want to get our data from these files, whatever files they may be in, whatever data structure they might be in, into tenses. But before we do that, let's keep becoming one with the data. And we're going to visualize an image. So visualizing an image, and you know how much I love randomness. So let's select a random image from all of the files that we have in here. And let's plot it, hey, because we could just click through them and visualize them. But I like to do things with code. So specifically, let's let's plan this out. Let's write some code to number one is get all of the image paths. We'll see how we can do that with the path path lib library. We then want to pick a random image path using we can use Python's random for that. Python's random dot choice will pick a single image random dot choice. Then we want to get the image class name. And this is where part lib comes in handy. Class name, recall that whichever target image we pick, the class name will be whichever directory that it's in. So in the case of if we picked a random image from this directory, the class name would be pizza. So we can do that using, I think it's going to be path lib dot path. And then we'll get the parent folder, wherever that image lives. So the parent image parent folder that parent directory of our target random image. And we're going to get the stem of that. So we have stem, stem is the last little bit here. Number four, what should we do? Well, we want to open the image. So since we're working with images, let's open the image with Python's pill, which is Python image library, but we'll actually be pillow. So if we go Python pillow, a little bit confusing when I started to learn about Python image manipulation. So pillow is a friendly pill for, but it's still called pill. So just think of pillow as a way to process images with Python. So pill is the Python imaging library by Frederick Lund. And so Alex Clark and contributors have created pillow. So thank you, everyone. And let's go to number five. What do we want to do as well? We want to, yeah, let's get some metadata about the image. We'll then show the image and print metadata. Wonderful. So let's import random, because machine learning is all about harnessing the power of randomness. And I like to use randomness to explore data as well as model it. So let's set the seed. So we get the same image on both of our ends. So random dot seed. I'm going to use 42. You can use whatever you'd like. But if you'd like to get the same image as me, I'd suggest using 42 as well. Now let's get all the image paths. So we can do this because our image path list, we want to get our image path. So recall that our image path is this. So this folder here, I'm just going to close all this. So this is our image path, this folder here, you can also go copy path if you wanted to, we're just going to get something very similar there. That's going to error out. So I'll just comment that. So it doesn't error. That's our path. But we're going to keep it in the POSIX path format. And we can go list. Let's create a list of image path dot glob, which stands for grab. I don't actually know what glob stands for. But to me, it's like glob together. All of the images that are all of the files that suit a certain pattern. So glob together for me means stick them all together. And you might be able to correct me if I've got the wrong meaning there. I'd appreciate that. And so we're going to pass in a certain combination. So we want star slash star. And then we want star dot jpg. Now why are we doing this? Well, because we want every image path. So star is going to be this first directory here. So any combination, it can be train or test. And then this star means anything for what's inside tests. And let's say this first star is equal to test. This second star is equal to anything here. So it could be any of pizza, steak or sushi. And then finally, this star, let's say it was test pizza. This star is anything in here. And that is before dot jpg. So it could be any one of these files here. Now this will make more sense once we print it out. So image path list, let's have a look. There we go. So now we've got a list of every single image that's within pizza steak sushi. And this is just another way that I like to visualize data is to just get all of the paths and then randomly visualize it, whether it be an image or text or audio, you might want to randomly listen to it. Recall that each each of the domain libraries have different input and output methods for different data sets. So if we come to torch vision, we have utils. So we have different ways to draw on images, reading and writing images and videos. So we could load an image via read image, we could decode it, we could do a whole bunch of things. I'll let you explore that as extra curriculum. But now let's select a random image from here and plot it. So we'll go number two, which was our step up here, pick a random image. So pick a random image path. Let's get rid of this. And so we can go random image path equals random dot choice, harness the power of randomness to explore our data. Let's get a random image from image path list, and then we'll print out random image path, which one was our lucky image that we selected. Beautiful. So we have a test pizza image is our lucky random image. And because we've got a random seed, it's going to be the same one each time. Yes, it is. And if we comment out the random seed, we'll get a different one each time. We've got a stake image. We've got another stake image. Another stake image. Oh, three in a row, four in a row. Oh, pizza. Okay, let's keep going. So we'll get the image class from the path name. So the image class is the name of the directory, because our image data is in standard image classification format, where the image is stored. So let's do that image class equals random image path dot parent dot stem. And then we're going to print image class. What do we get? So we've got pizza. Wonderful. So the parent is this folder here. And then the stem is the end of that folder, which is pizza. Beautiful. Well, now what are we up to now? We're working with images. Let's open up the image so we can open up the image using pill. We could also open up the image with pytorch here. So with read image, but we're going to use pill to keep things a little bit generic for now. So open image, image equals image. So from pill import image, and the image class has an open function. And we're just going to pass it in here, the random image path. Note if this is corrupt, if your images corrupt, this may error. So then you could potentially use this to clean up your data set. I've imported a lot of images with image dot open of our target data set here. I don't believe any of them are corrupt. But if they are, please let me know. And we'll find out later on when our model tries to train on it. So let's print some metadata. So when we open our image, we get some information from it. So let's go our random image path is what? Random image path. We're already printing this out, but we'll do it again anyway. And then we're going to go the image class is equal to what will be the image class. Wonderful. And then we can print out, we can get some metadata about our images. So the image height is going to be IMG dot height. We get that metadata from using the pill library. And then we're going to print out image width. And we'll get IMG dot width. And then we'll print the image itself. Wonderful. And we can get rid of this, and we can get rid of this. Let's now have a look at some random images from our data set. Lovely. We've got an image of pizza there. Now I will warn you that the downsides of working with food data is it does make you a little bit hungry. So there we've got some sushi. And then we've got some more sushi. Some steak. And we have a steak, we go one more for good luck. And we finish off with some sushi. Oh, that could be a little bit confusing to me. I thought that might be steak to begin with. And this is the scene. Now we'll do one more. Why it's important to sort of visualize your images randomly, because you never know what you're going to come across. And this way, once we visualize enough images, you could do this a hundred more times. You could do this 20 more times until you feel comfortable to go, Hey, I feel like I know enough about the data now. Let's see how well our model goes on this sort of data. So I'll finish off on this steak image. And now I'll set your little challenge before the next video is to visualize an image like we've done here. But this time do it with matplotlib. So try to visualize an image with matplotlib. That's your little challenge before the next video. So give that a go. We want to do a random image as well. So quite a similar set up to this. But instead of printing out things like this, we want to visualize it using matplotlib. So try that out and we'll do it together in the next video. Oh, we are well on the way to creating our own PyTorch custom data set. We've started to become one with the data. But now let's continue to visualize another image. I set you the challenge in the last video to try and replicate what we've done here with the pill library with matplotlib. So now let's give it a go. Hey, and why use matplotlib? Well, because matplotlib and I'm going to import numpy as well, because we're going to have to convert this image into an array. That was a little trick that I didn't quite elaborate on. But I hope you tried to decode it out and figure it out from the errors you received. But matplotlib is one of the most fundamental data science libraries. So you're going to see it everywhere. So it's just important to be aware of how to plot images and data with matplotlib. So turn the image into an array. So we can go image as array. And I'm going to use the numpy method NP as array. We're going to pass it in the image, recall that the image is the same image that we've just set up here. And we've already opened it with pill. And then I'm going to plot the image. So plot the image with matplotlib. plt.figure. And then we can go fig size equals 10, seven. And then we're going to go plt.im show image as array, pass it in the array of numbers. I'm going to set the title here as an f string. And then I'm going to pass in image class, equals image class. Then I'm going to pass in image shape. So we can get the shape here. Now this is another important thing to be aware of of your different datasets when you're exploring them is what is the shape of your data? Because what's one of the main errors in machine learning and deep learning? It's shape mismatch issues. So if we know the shape of our data where we can start to go, okay, I kind of understand what shape I need my model layers to be in what what shape I need my other data to be in. And I'm going to turn the axes off here. Beautiful. So look at what we've got. Now I've just thrown this in here without really explaining it. But we've seen this before in the computer vision section. As our image shape is 512 3063. Now the dimensions here are height is 512 pixels. The width is 306 pixels. And it has three color channels. So what format is this? This is color channels last, which is the default for the pill library. There's also the default for map plot lib. But pytorch recall is default if we put the color channels at the start color channels first. Now there is a lot of debate as I've said over which is the best order. It looks like it's leading towards going towards this. But for now pytorch defaults to color channels first. But that's okay. Because we can manipulate these dimensions to what we need for whatever code that we're writing. And the three color channels is what red, green and blue. So if you combine red, green and blue in some way, shape or form, you get the different colors here that represent our image. And so if we have a look at our image as a ray. Our image is in numerical format. Wonderful. So okay. We've got one way to do this for one image. I think we start moving towards scaling this up to do it for every image in our data folder. So let's just finish off this video by visualizing one more image. What do we get? Same premise. The image is now as an array, different numerical values. We've got a delicious looking pizza here of shave 512 512 with color channels last. And we've got the same thing up here. So that is one way to become one with the data is to visualize different images, especially random images. You could do the same thing visualizing different text samples that you're working with or listening to different audio samples. It depends what domain you're working in. So now in the next video, let's start working towards turning all of the images in here. Now that we visualize some of them and become one with the data, we've seen that the shapes are varying in terms of height and width. But they all look like they have three color channels because we have color images. But now we want to write code to turn all of these images into pytorch tenses. So let's start moving towards that. I'll see you in the next video. Hello and welcome back. In the last video, we converted an image to a NumPy array. And we saw how an image can be represented as an array. But what if we'd like to get this image from our custom data set over here, pizza steak sushi into pytorch? Well, let's cover that in this video. So I'm going to create a new heading here. And it's going to be transforming data. And so what we'd like to do here is I've been hinting at the fact the whole time is we want to get our data into tensor format, because that is the data type that pytorch accepts. So let's write down here before we can use our image data with pytorch. Now this goes for images, other vision data, it goes for text, it goes to audio, basically whatever kind of data set you're working with, you need some way to turn it into tenses. So that's step number one. Turn your target data into tenses. In our case, it's going to be a numerical representation of our images. And number two is turn it into a torch dot utils dot data dot data set. So recall from a previous video that we've used the data set to house all of our data in tensor format. And then subsequently, we've turned our data sets, our pytorch data sets into torch dot utils dot data dot data loader. And a data loader creates an iterable or a batched version of our data set. So for short, we're going to call these data set and data loader. Now, as I discussed previously, if we go to the pytorch documentation torch vision for torch vision, this is going to be quite similar for torch audio torch text, torch rec torch data eventually when it comes out of beta, there are different ways to create such data sets. So we can go into the data sets module, and then we can find built-in data sets, and then also base classes for custom data sets. But if we go into here, image folder, there's another parameter I'd like to show you, and this is going to be universal across many of your different data types is the transform parameter. Now, the transform parameter is a parameter we can use to pass in some transforms on our data. So when we load our data sets from an image folder, it performs a transform on those data samples that we've sent in here as the target data folder. Now, this is a lot more easier to understand through illustration, rather than just talking about it. So let's create a transform. And the main transform we're going to be doing is transforming our data, and we're turning it into tenses. So let's see what that looks like. So we're going to just going to re import all of the main libraries that we're going to use. So from torch utils dot data, let's import data loader. And we're going to import from torch vision. I'm going to import data sets. And I'm also going to import transforms. Beautiful. And I'm going to create another little heading here, this is going to be 3.1, transforming data with torch vision dot transform. So the main transform we're looking to here is turning out images from JPEGs. If we go into train, and then we go into any folder, we've got JPEG images. And we want to turn these into tensor representation. So there's some pizza there. We'll get out of this. Let's see what we can do. How about we create a transform here, write a transform for image. And let's start off by calling it data transform. And I'm going to show you how we can combine a few transforms together. If you want to combine transforms together, you can use transforms dot compose. You can also use an n dot sequential to combine transforms. But we're going to stick with transforms dot compose for now. And it takes a list. And so let's just write out three transforms to begin with. And then we can talk about them after we do so. So we want to resize our images to 6464. Now, why might we do this? Well, do you recall in the last section computer vision, we use the tiny VGG architecture. And what size were the images that the tiny VGG architecture took? Well, we replicated the CNN website version or the CNN explainer website version, and they took images of size 6464. So perhaps we want to leverage that computer vision model later on. So we're going to resize our images to 6464. And then we're going to create another transform. And so this is, I just want to highlight how transforms can help you manipulate your data in a certain way. So if we wanted to flip the images, which is a form of data augmentation, in other words, artificially increasing the diversity of our data set, we can flip the images randomly on the horizontal. So transforms dot random horizontal flip. And I'm going to put a probability in here of p equals 0.5. So that means 50% of the time, if an image goes through this transform pipeline, it will get flipped on the horizontal axis. As I said, this makes a lot more sense when we visualize it. So we're going to do that very shortly. And finally, we're going to turn the image into a torch tensor. So we can do this with transforms dot to tensor. And now where might you find such transforms? So this transform here says to tensor, if we have a look at the doc string, we got convert a pill image, which is what we're working with right now, or a NumPy array to a tensor. This transform does not support torch script. If you'd like to find out what that is, I'd like to read the documentation for that. It's essentially turning your pytorch code into a Python script. It converts a pill image or a NumPy array from height with color channels in the range 0 to 255, which is what our values are up here. They're from 0 to 255, red, green and blue, to a torch float tensor of shape color channels height width in the range 0 to 1. So it will take our tensor values here or our NumPy array values from 0 to 255 and convert them into a torch tensor in the range 0 to 1. We're going to see this later on in action. But this is our first transform. So we can pass data data through that. In fact, I'd encourage you to try that out. See what happens when you pass in data transform. What happens when you pass it in our image as a ray? Image as a ray. Let's see what happens. Hey, oh, image should be pill image got class NumPy array. What if we just pass in our straight up image? So this is a pill image. There we go. Beautiful. So if we look at the shape of this, what do we get? 3 64 64. There's 64. And if what if we wanted to change this to 224, which is another common value for computer vision models to 24 to 24. Do you see how powerful this is? This little transforms module, the torch vision library will change that back to 64 64. And then if we have a look at what D type of our transform tensor is, we get torch float 32. Beautiful. So now we've got a way to transform our images into tensors. And so, but we're still only doing this with one image. How about we progress towards doing it for every image in our data folder here? But before we do that, I'd like to visualize what this looks like. So in the next video, let's write some code to visualize what it looks like to transform multiple images at a time. And I think it'd be a good idea to compare the transform that we're doing to the original image. So I'll see you in the next video. Let's write some visualization code. Let's now follow our data explorer's motto of visualizing our transformed images. So we saw what it looks like to pass one image through a data transform. And if we wanted to find more documentation on torch vision transforms, where could we go? There is a lot of these. So transforming and augmenting images, this is actually going to be your extra curriculum for this video. So transforms are common image transformations available in the transforms module. They can be chained together using compose, which is what we've already done. Beautiful. And so if you'd like to go through all of these, there's a whole bunch of different transforms that you can do, including some data augmentation transforms. And then if you'd like to see them visually, I'd encourage you to check out illustration of transforms. But let's write some code to explore our own transform visually first. So I'll leave this as a link. So I'm going up here, right here, transforms help you get your images ready to be used with a model slash perform data augmentation. Wonderful. So we've got a way to turn images into tenses. That's what we want for our model. We want our images as pytorch tenses. The same goes for any other data type that you're working with. But now I'd just like to visualize what it looks like if we plot a number of transformed images. So we're going to make a function here that takes in some image paths, a transform, a number of images to transform at a time and a random seed here, because we're going to harness the power of randomness. And sometimes we want to set the seed. Sometimes we don't. So we have an image path list that we've created before, which is just all of the image paths that we have of our data set. So data, pizza, steak sushi. Now how about we select some random image paths and then take the image from that path, run it through our data transform, and then compare the original image of what it looks like and the transformed image and what that looks like. Let's give it a try, hey? So I'm going to write a doc string of what this does, and then selects random images from a path of images and loads slash transforms them, then plots the original verse, the transformed version. So that's quite a long doc string, but that'll be enough. We can put in some stuff for the image paths, transforms, and seed. We'll just code this out. Let's go random seed, we'll create the seed. Maybe we do it if seed, random seed. Let's put that, and we'll set seed to equal none by default. That way we can, we'll see if this works, hey, if in doubt, coded out random image paths, and then we're going to go random sample from the image paths and the number of sample that we're going to do. So random sample is going to, this will be a list on which part in here that this is a list. So we're going to randomly sample k, which is going to be n. So three images from our image path list. And then we're going to go for image path, we're going to loop through the randomly sampled image parts. You know how much I love harnessing the power of randomness for visualization. So for image path in random image paths, let's open up that image using pill image dot open image path as f. And then we're going to create a figure and an axes. And we're going to create a subplot with my plot lib. So subplots. And we want it to create one row. So it goes n rows and calls. One row and n calls equals two. And then on the first or the zeroth axis, we're going to plot the original image. So in show, we're just going to pass it straight in f. And then if we want to go x zero, we're going to set the title. So set title, we're going to set it to be the original. So we'll create this as an f string, original, and then new line will create a size variable. And this is going to be f dot size. So we're just getting the size attribute from our file. So we'll keep going, and we'll turn off the axes here. So axis, and we're going to set that to false. Now let's transform on the first axes plot. We're going to transform and plot target image. This is so that our images are going to be side by side, the original and the transformed version. So there's one thing that we're going to have to do. I'll just, I'll code it out in a wrong way first. I think that'll be a good way to illustrate what's going on. f. So I'm just going to put a note here. Note, we will need to change shape for matplotlib, because we're going to come back here. Because what does this do? What have we noticed that our transform does? If we check the shape here, oh, excuse me, it converts our image to color channels first. Whereas matplotlib prefers color channels last. So just keep that in mind for when we're going forward. This code, I'm writing it, it will error on purpose. So transformed image. And then we're going to go axe one as well. We're going to set the title, which is going to be transformed. And then we'll create a new line and we'll say size is going to be transformed image dot shape. Or probably a bit of, yeah, we could probably go shape here. And then finally, we're going to go axe one, we're going to turn the axis, we're going to set that to false. You can also set it to off. So you could write false, or you could write off, you might see that different versions of that somewhere. And I'm going to write a super title here, which we'll see what this looks like class is going to be image path. So we're getting the target image path. And we're just going to get the attribute or the parent attribute, and then the stem attribute from that, just like we did before, to get the class name. And then I'm going to set this to a larger font size, so that we make some nice looking plots, right? If we're going to visualize our data, we might as well make our plots visually appealing. So let's plot some transformed data or transformed images. So image paths, we're going to set this to image part list, which is just the variable we have down below, which is the part list, a list containing all of our image paths. Our transform, we're going to set our transform to be equal to our data transform. So this just means that if we pass the transform in, our image is going to go through that transform, and then go through all of these is going to be resized, it's going to be randomly horizontally flipped, and it's going to be converted to a tensor. And then so we're going to set that data transfer there or data transform, sorry, and is going to be three. So we plot three images, and we'll set the seed to 42 to begin with. Let's see if this works. Oh, what did we get wrong? We have invalid shape. As I said, I love seeing this error, because we have seen this error many times, and we know what to do with it. We know that we have to rearrange the shapes of our data in some way, shape or form. Wow, I said shape a lot there. That's all right. Let's go here, permute. This is what we have to do. We have to permute, we have to swap the order of the axes. So right now, our color channels is first. So we have to bring this color channel axis or dimension to the end. So we need to shuffle these across. So 64 into here, 64 into here, and three on the end. We need to, in other words, turn it from color channels first to color channels last. So we can do that by permuting it to have the first axis come now in the zero dimension spot. And then number two was going to be in the first dimension spot. And then number zero was going to be at the back end. So this is essentially going from C H W, and we're just changing the order to be H W C. So the exact same data is going to be within that tensor. We're just changing the order of the dimensions. Let's see if this works. Look at that. Oh, I love seeing some manipulated data. We have a class of pizza and the original image is there, and it's 512 by 512. But then we've resized it using our transform. Notice that it's a lot more pixelated now, but that makes sense because it's only 64 64 pixels. Now, why might we do such a thing? Well, one, if is this image still look like that? Well, to me, it still does. But the most important thing will be does it look like that to our model? Does it still look like the original to our model? Now 64 by 64, there is less information encoded in this image. So our model will be able to compute faster on images of this size. However, we may lose some performance because not as much information is encoded as the original image. Again, the size of an image is something that you can control. You can set it to be a hyper parameter. You can tune the size to see if it improves your model. But I've just decided to go 60 64 64 3 in line with the CNN explainer website. So a little hint, we're going to be re replicating this model that we've done before. Now you notice that our images are now the same size 64 64 3 as what the CNN explainer model uses. So that's where I've got that from. But again, you could change this to size to whatever you want. And we see, oh, we've got a stake image here. And you notice that our image has been flipped on the horizontal. So the horizontal access, our image has just been flipped same with this one here. So this is the power of torch transforms. Now there are a lot more transforms, as I said, you can go through them here to have a look at what's going on. Illustrations of transforms is a great place. So there's resize, there's center crop, you can crop your images, you can crop five different locations, you can do grayscale, you can change the color, a whole bunch of different things. I'd encourage you to check this out. That's your extra curriculum for this video. But now that we've visualized a transform, this is what I hinted at before that we're going to use this transform for when we load all of our images in, using into a torch data set. So I just wanted to make sure that they had been visualized first. We're going to use our data transform in the next video when we load all of our data using a torch vision dot data sets helper function. So let's give that a go. I'll see you in the next video. Have a look at that beautiful plot. We've got some original images and some transformed images. And the beautiful thing about our transformed images is that they're in tensor format, which is what we need for our model. That's what we've been slowly working towards. We've got a data set. And now we've got a way to turn it into tensors ready for a model. So let's just visualize what another, I'll turn the seed off here so we can look at some more random images. There we go. Okay, so we've got stake pixelated because we're downsizing 64, 64, 3. Same thing for this one. And it's been flipped on the horizontal. And then same thing for this pizza image and we'll do one more to finish off. Wonderful. So that is the premise of transforms turning our images into tensors and also manipulating those images if we want to. So let's get rid of this. I'm going to make another heading. We're up to section or part four now. And this is going to be option one. So loading image data using image folder. And now I'm going to turn that into markdown. And so let's go torch vision data sets. So recall how each one of the torch vision domain libraries has its own data sets module that has built in functions for helping you load data. In this case, we have an image folder. And there's a few others here if you'd like to look into those. But an image folder, this class is going to help us load in data that is in this format, the generic image classification format. So this is a prebuilt data sets function. Just like there's prebuilt data sets, we can use prebuilt data set functions. Now option two later on, this is a spoiler, is we're going to create our own custom version of a data set loader. But we'll see that in a later video. So let's see how we can use image folder to load all of our custom data, our custom images into tensors. So this is where the transform is going to come in helpful. So let's write here, we can load image classification data using, let's write this, let's write the full path name, torch vision dot data sets dot image folder. Put that in there, beautiful. And so let's just start it out, use image folder to create data sets. Now in a previous video, I hinted at the fact that we can pass a transform to our image folder class. That's going to be right here. So let's see what that looks like in practice. So from torch vision, I'm going to import data sets, because that's where the image folder module lives. And then we can go train data equals data sets dot image folder. And we're going to pass in the root, which is our train der, because we're going to do it for the training directory first. And then we're going to pass in a transform, which is going to be equal to our data transform. And then we're going to pass in a target transform, but we're going to leave this as none, which is the default, I believe, we go up to here. Yeah, target transform is optional. So what this means is this is going to be a transform for the data. And this is going to be a transform for the label slash target. PyTorch likes to use target, I like to use label, but that's okay. So this means that we don't need a target transform, because our labels are going to be inferred by the target directory where the images live. So our pizza images are in this directory, and they're going to have pizza as the label, because our data set is in standard image classification format. Now, if your data set wasn't in a standard image classification format, you might use a different data loader here. A lot of them will have a transform for the data. So this transform is going to run our images, whatever images are loaded from these folders, through this transform that we've created here, it's going to resize them, randomly flip them on the horizontal, and then turn them into tenses, which is exactly how we want them for our PyTorch models. And if we wanted to transform the labels in some way, shape or form, we could pass in a target transform here. But in our case, we don't need to transform the labels. So let's now do the same thing for the test data. And so that's why I wanted to visualize our transforms in the previous videos, because otherwise we're just passing them in as a transform. So really, what's going to happen behind the scenes is all of our images are going to go through these steps. And so that's what they're going to look like when we turn them into a data set. So let's create the test data here or the test data set. The transform, we're going to transform the test data set in the same way we've transformed our training data set. And we're just going to leave that like that. So let's now print out what our data sets look like, train data, and test data. Beautiful. So we have a data set, a torch data set, which is an image folder. And we have number of data points. This is going to be for the training data set. We have 225. So that means about 75 images per class. And we have the root location, which is the folder we've loaded them in from, which is our training directory. We've set these two up before, trained and tester. And then we have a transform here, which is a standard transform, a resize, followed by random horizontal flip, followed by two tensor. Then we've got basically the same output here for our test directory, except we have less samples there. So let's get a few little attributes from the image folder. This is one of the benefits of using a pytorch prebuilt data loader, is that or data set loader is that it comes with a fair few attributes. So we could go to the documentation, find this out from in here, inherits from data set folder, keep digging into there, or we could just come straight into Google collab. Let's go get class names as a list. Can we go train data dot and then press tab? Beautiful. So we've got a fair few things here that are attributes. Let's have a look at classes. This is going to give us a list of the class names, class names. This is very helpful later on. So we've got pizza steak sushi. We're trying to do everything with code here. So if we have this attribute of train data dot classes, we can use this list later on for when we plot images straight from our data set, or make predictions on them and we want to label them. You can also get class names as a dictionary, map to their integer index, that is, so we can go train data dot and press tab. We've got class to ID X. Let's see what this looks like. Class decked. Wonderful. So then we've got our string class names mapped to their integer. So we've got pizza is zero, steak is one, sushi is two. Now, this is where the target transform would come into play. If you wanted to transform those these labels here in some way, shape or form, you could pass a transform into here. And then if we keep going, let's check the lengths of what's going on. Check the lengths of our data set. So we've seen this before, but this is going to just give us how many samples that we have length, train data, length, test data, beautiful. And then of course, if you'd like to explore more attributes, you can go train data dot, and then we've got a few other things, functions, images, loader, samples, targets. If you wanted to just see the images, you can go dot samples. If you wanted to see just the labels, you can go dot targets. This is going to be all of our labels. Look at that. And I believe they're going to be an order. So we're going to have zero, zero, zero, one, one, one, two, two, and then if we wanted to have a look, let's say we have a look at the first sample, hey, we have data, pizza, steak sushi, train, pizza. There's the image path, and it's a label zero for pizza. Wonderful. So now we've done that. How about we, we've been visualizing this whole time. So let's keep up that trend. And let's visualize a sample and a label from the train data data set. So in this video, we've used image folder to load our images into tenses. And because our data is already in standard image classification format, we can use one of torch vision dot data sets prebuilt functions. So let's do some more visualization in the next video. I'll see you there. Welcome back. In the last video, we used data sets dot image folder to turn all of our image data into tenses. And we did that with the help of our data transform, which is a little pipeline up here to take in some data, or specifically an image, resize it to a value that we've set in our k6464 randomly flip it along the horizontal. We don't necessarily need this, but I've just put that in there to indicate what happens when you pass an image through a transforms pipeline. And then most importantly, we've turned our images into a torch tensor. So that means that our data, our custom data set, this is so exciting, is now compatible to be used with a pytorch model. So let's keep pushing forward. We're not finished yet. We're going to visualize some samples from the train data data set. So let's, how can we do this? Let's get, we can index on the train data data set to get a single image and a label. So if we go, can we do train data zero? What does that give us? Okay, so this is going to give us an image tensor. And it's associated label. In this case, it's an image of pizza, because why it's associated label is pizza. So let's take the zero zero. So this is going to be our image. And the label is going to be train data zero. And we're just going to get the first index item there, which is going to be one. And then if we have a look at them separately, image and label, beautiful. So now one of our target images is in tensor format, exactly how we want it. And it's label is in numeric format as well, which is also exactly how we want it. And then if we wanted to convert this back to a non label, we can go class names and index on that. And we see pizza. And I mean, non label is in non numeric, we can get it back to string format, which is human understandable. We can just index on class names. So let's print out some information about what's going on here. Print F, we're going to go image tensor. I love F strings if you haven't noticed yet. Image tensor. And we're going to set in new line, we're going to pass it in our image, which is just the image that we've got here. Then we'll print in some more information about that. This is still all becoming one with the data right where we're slowly finding out information about our data set so that if errors arise later on, we can go, hmm, our image or we're getting a shape error. And I know our images are of this shape or we're getting a data type error, which is why I've got the dot D type here. And that might be why we're getting a data type issue. So let's do one more with the image label, label, oh, well, actually, we'll do one more. We'll do print, we'll get the label data type as well. Label, this will be important to take note of later on. Type, as I said, three big issues. Shape mismatch, device mismatch, and data type mismatch. Can we get the type of our label? Beautiful. So we've got our image tensor and we've got its shape. It's of torch size 36464. That's exactly how we want it. The data type is torch float 32, which is the default data type in PyTorch. Our image label is zero and the label data type is of integer. So let's try and plot this and see what it looks like, hey, using matplotlib. So first of all, what do we have to do? Well, we have to rearrange the order of dimensions. In other words, matplotlib likes color channels last. So let's see what looks this looks like. We'll go image per mute. We've done this before, image.permute 120 means we're reordering the dimensions. Zero would usually be here, except that we've taken the zero dimension, the color channels and put it on the end and shuffled the other two forward. So let's now print out different shapes. I love printing out the change in shapes. It helps me really understand what's going on. Because sometimes I look at a line like this and it doesn't really help me. But if I print out something of what the shapes were originally and what they changed to, well, hey, that's a big help. That's what Jupiter notebooks are all about, right? So this is going to be color channels first, height, width. And depending on what data you're using, if you're not using images, if you're using text, still knowing the shape of your data is a very good thing. We're going to go image per mute.shape and this should be everything going right is height with color channels on the end here. And we're just going to plot the image. You can never get enough plotting practice. Plot the image. You're going to go PLT dot figure, we'll pass in fig size equals 10, 7. And then we're going to PLT dot in show. We'll pass in the permuted image, image underscore permutes, and then we'll turn off the axes. And we will set the title to be class names. And we're going to index on the label, just as we did before. And we're going to set the font size equal to 14. So it's nice and big. Here we go. Beautiful. There is our image of pizza. It is very pixelated because we're going from about 512 as the original size 512 by 512 to 64, 64. I would encourage you to try this out. Potentially, you could use a different image here. So we've indexed on sample zero. Maybe you want to change this to just be a random image and go through these steps here. And then if you'd like to see different transforms, I'd also encourage you to try changing this out, our transform pipeline here, maybe increase the size and see what it looks like. And if you're feeling really adventurous, you can go into torch vision and look at the transforms library here and then try one of these and see what it does to our images. But we're going to keep pushing forward. We are going to look at another way. Or actually, I think for completeness, let's now turn, we've got a data set. We want to, we wrote up here before that we wanted to turn our images into a data set, and then subsequently a torch utils data data loader. So we've done this before, by batching our images, or batching our data that we've been working with. So I'd encourage you to give this a shot yourself. Try to go through the next video and create a train data loader using our train data, wherever that is train data, and a test data loader using our test data. So give that a shot and we'll do it together in the next video. We'll turn our data sets into data loaders. Welcome back. How'd you go? In the last video, I issued you the challenge to turn our data sets into data loaders. So let's do that together now. I hope you gave it a shot. That's the best way to practice. So turn loaded images into data loaders. So we're still adhering to our PyTorch workflow here. We've got a custom data set. We found a way to turn it into tenses in the form of data sets. And now we're going to turn it into a data loader. So we can turn our data sets into iterables or batchify our data. So let's write down here, a data loader is going to help us turn our data sets into iterables. And we can customize the batch size, write this down. So our model can see batch size images at a time. So this is very important. As we touched on in the last section computer vision, we create a batch size because if we had 100,000 images, chances are if they were all in one data set, there's 100,000 images in the food 101 data set. We're only working with about 200. If we try to load all 100,000 in one hit, chances are our hardware may run out of memory. And so that's why we matchify our images. So if we have a look at this, NVIDIA SMI, our GPU only has 16 gigabytes. I'm using a Tesla T4 right now, well, has about 15 gigabytes of memory. So if we tried to load 100,000 images into that whilst also computing on them with a PyTorch model, potentially we're going to run out of memory and run into issues. So instead, we can turn them into a data loader so that our model looks at 32 images at a time and can leverage all of the memory that it has rather than running out of memory. So let's turn our train and test data sets into data loaders, turn train and test data sets into data loaders. Now, this is not just for image data. This is for all kinds of data in PyTorch. Images, text, audio, you name it. So import data loader, then we're going to create a train data loader. We're going to set it equal to data loader. We're going to pass in a data set. So let's set this to train data. Let's set the batch size. What should we set the batch size to? I'm going to come up here and set a laser capital variable. I'm going to use 32 because 32 is a good batch size. So we'll go 32 or actually, let's start small. Let's just start with a batch size of one and see what happens. Batch size one, number of workers. So this parameter is going to be, this is an important one. I'm going to, I potentially have covered it before, but I'm going to introduce it again. Is this going to be how many cores or how many CPU cores that is used to load your data? So the higher the better usually and you can set this via OS CPU count, which will count how many CPUs your compute hardware has. So I'll just show you how this works. Import OS and this is a Python OS module. We can do CPU count to find out how many CPUs our Google Colab instance has. Mine has two, your number may vary, but I believe most Colab instances have two CPUs. If you're running this on your local machine, you may have more. If you're running it on dedicated deep learning hardware, you may even have even more, right? So generally, if you set this to one, it will use one CPU core, but if you set it to OS dot CPU count, it will use as many as possible. So we're just going to leave this as one right now. You can customize this to however you want. And I'm going to shuffle the training data because I don't want my model to recognize any order in the training data. So I'm going to mix it up. And then I'm going to create the test data loader. Data set equals test data. And batch size equals one, num workers, I'm going to set this to equal one as well. Again, you can customize each of these, their hyper parameters to whatever you want. Number of workers generally the more the better. And then I'm going to set shuffle equals false for the test data so that if we want to evaluate our models later on, our test data set is always in the same order. So now let's have a look at train data loader, see what happens. And test data loader. Wonderful. So we get two instances of torch utils dot data dot data loader. And now we can see if we can visualize something from the train data loader, as well as the test data loader. I actually maybe we just visualize something from one of them. So we're not just double handling everything. We get a length here. Wonderful. Because we're using a batch size of one, our lengths of our data loaders are the same as our data sets. Now, of course, this would change if we set, oh, we didn't even set this to the batch size parameter batch size. Let's come down here and do the same here batch size. So we'll watch this change. If we wanted to look at 32 images at a time, we definitely could do that. So now we have eight batches, because 22, 225 divided by 32 equals roughly eight. And then 75 divided by 32 also equals roughly three. And remember, these numbers are going to be rounded if there are some overlaps. So let's get rid of, we'll change this back to one. And we'll keep that there. We'll get rid of these two. And let's see what it looks like to plot an image from our data loader. Or at least have a look at it. Check out the shapes. That's probably the most important point at this time. We've already plotted in our things. So let's iterate through our train data loader. And we'll grab the next one. We'll grab the image and the label. And we're going to print out here. So batch size will now be one. You can change the batch size if you like. This is just again, another way of getting familiar with the shapes of our data. So image shape. Let's go image dot shape. And we're going to write down here. This shape is going to be batch size. This is what our data loader is going to add to our images is going to add a batch dimension, color channels, height, width. And then print. Let's check out that label shape. Same thing with the labels. It's going to add a batch dimension. Label. And let's see what happens. Oh, we forgot the end of the bracket. Beautiful. So we've got image shape. Our label shape is only one because we have a batch size of one. And so now we've got batch size one, color channels three, height, width. And if we change this to 32, what do you think's going to happen? We get a batch size of 32, still three color channels, still 64, still 64. And now we have 32 labels. So that means within each batch, we have 32 images. And we have 32 labels. We could use this with a model. I'm going to change this back to one. And I think we've covered enough in terms of loading our data sets. How cool is this? We've come a long way. We've downloaded a custom data set. We've loaded it into a data set using image folder turned it into tenses using our data transform and now batchified our custom data set in data loaders. We've used these with models before. So if you wanted to, you could go right ahead and build a convolutional neural network to try and find patterns in our image tenses. But in the next video, let's pretend we didn't have this data loader, this image folder class available to us. How could we load our image data set so that it's compatible? Like our image data set here, how could we replicate this image folder class? So that we could use it with a data loader. Because data load is part of torch utils.data, you're going to see these everywhere. Let's pretend we didn't have the torch vision.data sets image folder helper function. And we'll see in the next video, how we can replicate that functionality. I'll see you there. Welcome back. So over the past few videos, we've been working out how to get how to get our data from our data folder, pizza, steak, and sushi. We've got images of different food data here. And we're trying to get it into Tensor format. So we've seen how to do that with an existing data loader helper function or data set function in image folder. However, what if image folder didn't exist? And we need to write our own custom data loading function. Now the premise of this is although it does exist, it's going to be good practice because you might come across a case where you're trying to use a data set where a prebuilt function doesn't exist. So let's replicate the functionality of image folder by creating our own data loading class. So we want a few things. We want to be able to get the class names as a list from our loaded data. And we want to be able to get our class names as a dictionary as well. So the whole goal of this video is to start writing a function or a class that's capable of loading data from here into Tensor format, capable of being used with the PyTorch's data loader class, like we've done here. So we want to create a data set. Let's start it off. We're going to create another heading here. This is going to be number five, option two, loading image data with a custom data set. So we want a few functionality steps here. Number one is one, two, be able to load images from file to one, two, be able to get class names from the data set, and three, one, two, be able to get classes as dictionary from the data set. And so let's briefly discuss the pros and cons of creating your own custom data set. We saw option one was to use a pre-existing data set loader helping function from torch vision. And it's going to be quite similar if we go torch vision data sets. Quite similar if you're using other domain libraries here, there we're going to be data loading utilities. But at the base level of PyTorch is torchutils.data.dataset. Now this is the base data set class. So we want to build on top of this to create our own image folder loading class. So what are the pros and cons of creating your own custom data set? Well, let's discuss some pros. So one pro would be you can create a data set out of almost anything as long as you write the right code to load it in. And another pro is that you're not limited to PyTorch pre-built data set functions. A couple of cons would be that even though this is to point number one. So even though you could create a data set out of almost anything, it doesn't mean that it will automatically work. It will work. And of course, you can verify this through extensive testing, seeing if your model actually works, if it actually loads data in the way that you want it. And another con is that using a custom data set requires us to write more code. So often results in us writing more code, which could be prone to errors or performance issues. So typically if something makes it into the PyTorch standard library or the PyTorch domain libraries, if functionality makes it into here, it's generally been tested many, many times. And it can kind of be verified that it works quite well with, or if you do use it, it works quite well. Whereas if we write our own code, sure, we can test it ourselves, but it hasn't got the robustness to begin with, that is, we could fix it over time, as something that's included in say the PyTorch standard library. Nonetheless, it's important to be aware of how we could create such a custom data set. So let's import a few things that we're going to use. We'll import OS, because we're going to be working with Python's file system over here. We're going to import path lib, because we're going to be working with file paths. We'll import torch, we don't need to again, but I'm just doing this for completeness. We're going to import image from pill, the image class, because we want to be opening images. I'm going to import from torch utils dot data. I'm going to import data set, which is the base data set. And as I said over here, we can go to data sets, click on torch utils data dot data set. This is an abstract class representing a data set. And you'll find that this data set links to itself. So this is the base data set class. Many of the data sets in PyTorch, the prebuilt functions, subclass this. So this is what we're going to be doing it. And as a few notes here, all subclasses should overwrite get item. And you should optionally overwrite land. These two methods, we're going to see this in a future video. For now, we're just we're just setting the scene here. So from torch vision, we're going to import transforms, because we want to not only import our images, but we want to transform them into tenses. And from the Python's typing module, I'm going to import tuple dict and list. So we can put type hints when we create our class and loading functions. Wonderful. So this is our instance of torch vision dot data sets image folder, torch vision dot data sets dot image folder. Let's have a look at the train data. So we want to write a function that can replicate getting the classes from a particular directory, and also turning them into an index or dictionary that is. So let's build a helper function to replicate this functionality here. In other words, I'd like to write a helper function that if we pass it in a file path, such as pizza steak sushi or this data folder, it's going to go in here. And it's going to return the class names as a list. And it's also going to turn them into a dictionary, because it's going to be helpful for later on when we'd like to access the classes and the class to ID X. And if we really want to completely recreate image folder, well, image folder has this functionality. So we'd like that too. So this is just a little high level overview of what we're going to be doing. I might link in here that we're going to subclass this. So all custom data sets in pie torch, often subclass this. So here's what we're going to be doing. Over the next few videos, we want to be able to load images from a file. Now you could replace images with whatever data that you're working with the same premise will be here. You want to be able to get the class names from the data set and want to be able to get classes as a dictionary from the data set. So we're going to map our samples, our image samples to that class name by just passing a file path to a function that we're about to write. And some pros and cons of creating a custom data set. We've been through that. Let's in the next video, start coding up a helper function to retrieve these two things from our target directory. In the last video, we discussed the exciting concept of creating a custom data set. And we wrote down a few things that we want to get. We discussed some pros and cons. And we learned that many custom data sets inherit from torch dot utils dot data data set. So that's what we'll be doing later on. In this video, let's focus on writing a helper function to recreate this functionality. So I'm going to title this 5.1, creating a helper function to get class names. I'm going to turn this into markdown. And if I go into here, so we want to function to let's write down some steps and then we'll code it out. So we'll get the class names, we're going to use OS dot scanner. So it's going to scanner directory to traverse a target directory. And ideally, the directory is in standard image classification format. So just like the image folder class, our custom data class is going to require our data already be formatted. In the standard image classification format, such as train and test for training and test images, and then images for a particular class are in a particular directory. So let's keep going. And number two, what else do we want it to do? We want it to raise an error if the class names aren't found. So if this happens, there might be, we want this to enter the fact that there might be something wrong with the directory structure. And number three, we also want to turn the class names into our dict and a list and return them. Beautiful. So let's get started. Let's set up the path directory for the target directory. So our target directory is going to be what the directory we want to load directory, if I could spell, we want to load our data from, let's start with the training der, just for an example. So target directory, what do we get? So we're just going to use the training folder as an example to begin with. And we'll go print target der, we'll put in the target directory, just want to exemplify what we're doing. And then we're going to get the class names from the target directory. So I'll show you the functionality of our scanner. Of course, you could look this up in the Python documentation. So class names found, let's set this to be sorted. And then we'll get the entry name, entry dot name for entry in list. So we're going to get OS list scanner of the image path slash target directory. Let's see what happens when we do this. Target directory have we got the right brackets here. Now, is this going to work? Let's find out. Oh, image path slash target directory. What do we get wrong? Oh, we don't need the image path there. Let's put, let's just put target directory there. There we go. Beautiful. So we set up our target directory as been the training to. And so if we just go, let's just do list. What happens if we just run this function here? Oh, a scanner. Yeah, so there we go. So we have three directory entries. So this is where we're getting entry dot name for everything in the training directory. So if we look in the training directory, what do we have train? And we have one entry for pizza, one entry for sushi, one entry for steak. Wonderful. So now we have a way to get a list of class names. And we could quite easily turn this into a dictionary, couldn't we? Which is exactly what we want to do. We want to recreate this, which we've done. And we want to recreate this, which is also done. So now let's take this functionality here. And let's turn that into a function. All right, what can we do? What do we call this? I'm going to call this def fine classes. And I'm going to say that it takes in a directory which is a string. And it's going to return. This is where I imported typing from Python type and imported tuple. And I'm going to return a list, which is a list of strings and a dictionary, which is strings map to integers. Beautiful. So let's keep going. We want to, we want this function to return given a target directory, we want it to return these two things. So we've seen how we can get a list of the directories in a target directory by using OS scanner. So let's write finds the classes are the class folder names in a target directory. Beautiful. And we know that it's going to return a list and a dictionary. So let's do step number one, we want to get the class names by scanning the target directory. We'll go classes, just we're going to replicate the functionality we've done about, but for any given directory here. So classes equals sorted entry dot name for entry in OS scanner. And we're going to pass at the target directory. If entry dot is dirt, we're just going to make sure it's a directory as well. And so if we just return classes and see what happens. So find classes, let's pass it in our target directory, which is our training directory. What do we get? Beautiful. So we need to also return class to ID X. So let's keep going. So number two is let's go raise an error. If class names could not be found. So if not classes, let's say raise file, we're going to raise a file not found error. And then let's just write in here F couldn't find any classes in directory. So we're just writing some error checking code here. So if we can't find a class list within our target directory, we're going to raise this error and say couldn't find any classes in directory, please check file structure. And there's another checkup here that's going to help us as well to check if the entry is a directory. So finally, let's do number three. What do we want to do? So we want to create a dictionary of index labels. So computers, why do we do this? Well, computers prefer numbers rather than strings as labels. So we can do this, we've already got a list of classes. So let's just create class to ID X equals class name, I for I class name in enumerate classes. Let's see what this looks like. So we go class names, and then class to ID X, or we can just return it actually. Do we spell enumerate role? Yes, we did. So what this is going to do is going to map a class name to an integer or to I for I class name in enumerate classes. So it's going to go through this, and it's going to go for I. So the first one zero is going to be pizza. Ideally, one will be steak, two will be sushi. Let's see how this goes. Beautiful. Look at that. We've just replicated the functionality of image folder. So now we can use this helper function in our own custom data set, find classes to traverse through a target directory, such as train, we could do the same for test if we wanted to to. And that way, we've got a list of classes. And we've also got a dictionary mapping those classes to integers. So now let's in the next video move towards sub classing torch utils dot data dot data set. And we're going to fully replicate image folder. So I'll see you there. In the last video, we wrote a great helper function called find classes that takes in a target directory and returns a list of classes and a dictionary mapping those class names to an integer. So let's move forward. And this time, we're going to create a custom data set. To replicate image folder. Now we don't necessarily have to do this, right, because image folder already exists. And if something already exists in the pie torch library, chances are it's going to be tested well, it's going to work efficiently. And we should use it if we can. But if we needed some custom functionality, we can always build up our own custom data set by sub classing torch dot utils dot data data set. Or if a pre built data set function didn't exist, well, we're probably going to want to subclass torch utils data dot data set anyway. And if we go into the documentation here, there's a few things that we need to keep in mind when we're creating our own custom data set. All data sets that represent a map from keys to data samples. So that's what we want to do. We want to map keys, in other words, targets or labels to data samples, which in our case are food images. So we should subclass this class here. Now to note, all subclasses should overwrite get item. So get item is a method in Python, which is going to get an item or get a sample, supporting fetching a data sample for a given key. So for example, if we wanted to get sample number 100, this is what get item should support and should return us sample number 100. And subclasses could also optionally override land, which is the length of a data set. So return the size of the data set by many sampler implementations and the default options of data loader, because we want to use this custom data set with data loader later on. So we should keep this in mind when we're building our own custom subclasses of torch utils data data set. Let's see this hands on, we're going to break it down. It's going to be a fair bit of code, but that's all right. Nothing that we can't handle. So to create our own custom data set, we want to number one, first things first is we're going to subclass subclass torch dot utils dot data dot data set. Two, what do we want to do? We want to init our subclass with target directory. So the directory we'd like to get data from, as well as a transform, if we'd like to transform our data. So just like when we used image folder, we could pass a transform to our data set, so that we could transform the data that we were loading. We want to do the same thing. And we want to create several attributes. Let's write them down here. We want paths, which will be the parts of our images. What else do we want? We want transform, which will be the transform we'd like to use. We want classes, which is going to be a list of the target classes. And we want class to ID X, which is going to be a dict of the target classes, mapped to integer labels. Now, of course, these attributes will differ depending on your data set. But we're replicating image folder here. So these are just some of the things that we've seen that come with image folder. But regardless of what data set you're working with, there are probably some things that you want to cross them universal. You probably want all the paths of where your data is coming from, the transforms you'd like to perform on your data, what classes you're working with, and a map of those classes to an index. So let's keep pushing forward. We want to create a function to load images, because after all, we want to open some images. So this function will open an image. Number five, we want to overwrite the LAN method to return the length of our data set. So just like it said in the documentation, if you subclass using torch.utils.data, the data set, you should overwrite get item, and you should optionally overwrite LAN. So we're going to, instead of optionally, we are going to overwrite length. And number six, we want to overwrite the get item method to return a given sample when passed an index. Excellent. So we've got a fair few steps here. But if they don't make sense now, it's okay. Let's code it out. Remember our motto, if and doubt, code it out. And if and doubt, run the code. So we're going to write a custom data set. This is so exciting, because when you work with prebuilt data sets, it's pretty cool in machine learning. But when you can write code to create your own data sets, and that's, well, that's magic. So number one is we're going to, or number zero is we're going to import torch utils data set, we don't have to rewrite this, we've already imported it, but we're going to do it anyway for completeness. Now step number one is to subclass it subclass torch utils data, the data set. So just like when we built a model, we're going to subclass and in module, but in this time, we're going to call us our class image folder custom. And we're going to inherit from data set. This means that all the functionality that's contained within torch utils data data set, we're going to get for our own custom class. Number two, let's initialize. So we're going to initialize our custom data set. And there's a few things that we'd like, and into our subclass with the target directory, the directory we'd like to get data from, as well as the transform if we'd like to transform our data. So let's write a knit function, a knit, and we're going to go self, target, and target is going to be a string. And we're going to set a transform here, we'll set it equal to none. Beautiful. So this way we can pass in a target directory of images that we'd like to load. And we can also pass in a transform, just similar to the transforms that we've created previously. So now we're up to number three, which is create several attributes. So let's see what this looks like, create class attributes. So we'll get all of the image paths. So we can do this just like we've done before, self paths equals list, path lib dot path, because what's our target directory going to be? Well, I'll give you a spoiler alert, it's going to be a path like the test directory, or it's going to be the train directory. Because we're going to use this once for our test directory and our train directory, just like we use the original image folder. So we're going to go through the target directory and find out all of the paths. So this is getting all of the image paths that support or that follow the file name convention of star star dot jpg. So if we have a look at this, we passed in the test folder. So test is the folder star would mean any of these 123 pizza steak sushi, that's the first star, then slash would go into the pizza directory. The star here would mean any of the file combinations here that end in dot jpg. So this is getting us a list of all of the image paths within a target directory. In other words, within the test directory and within the train directory, when we call these two separately. So let's keep going, we've got all of the image parts, what else did we have to do? We want to create transforms. So let's set up transforms, self dot transforms equals transform. Oh, we'll just call that transform actually, set up transform equals transform. So we're going to get this from here. And I put it as none because it transform can be optional. So let's create classes and class to ID X attributes, which is the next one on our list, which is here classes and class to ID X. Now, lucky us, in the previous video, we created a function to return just those things. So let's go self dot classes and self dot class to ID X equals find classes. And we're going to pass in the target der or the target der from here. Now, what's next? We've done step number three, we need number four is create a function to load images. All right, let's see what this looks like. So number four, create a function to load images. So let's call it load image. And we're going to pass in self. And we'll also pass in an index. So the index of the image we'd like to load. And this is going to return an image dot image. So where does that come from? Well, previously, we imported from pill. So we're going to use Python image library or pillow to import our images. So we're going to give on a file path from here, such as pizza, we're going to import it with the image class. And we can do that using, I believe it's image dot open. So let's give that a try. I'll just write a note in here, opens an image via a path and returns it. So let's write image path equals self. This is why we got all of the image paths above. So self dot paths. And we're going to index it on the index. Beautiful. And then let's return image dot open image path. So we're going to get a particular image path. And then we're just going to open it. So now we're up to step number five, override the land method to return the length of our data set. This is optional, but we're going to do it anyway. So overwrite. Len. So this just wants to return how many samples we have in our data set. So let's write that def, Len. So if we call Len on our data set instance, it's going to return just how many numbers there are. So let's write this down. Returns the total number of samples. And this is just going to be simply return length or Len of self dot paths. So for our target directory, if it was the training directory, we'd return the number of image paths that this code has found out here. And same for the test directory. So next, I'm going to go number six is we want to overwrite, we put this up here, the get item method. So this is required if we want to subclass torch utils data data set. So this is in the documentation here. All subclasses should override get item. So we want get item to, if we pass it an index to our data set, we want it to return that particular item. So let's see what this looks like. Override the get item method to return our particular sample. And now this method is going to leverage get item, all of the code that we've created above. So this is going to go take in self, which is the class itself. And it's going to take in an index, which will be of an integer. And it's going to return a tuple of torch dot tensor and an integer, which is the same thing that gets returned when we index on our training data. So if we have a look image label equals train data, zero, get item is going to replicate this. We pass it an index here. Let's check out the image and the label. This is what we have to replicate. So remember train data was created with image folder from torch vision dot data sets. And so we will now get item to return an image and a label, which is a tuple of a torch tensor, where the image is of a tensor here. And the label is of an integer, which is the label here, the particular index as to which this image relates to. So let's keep pushing forward. I'm going to write down here, returns one sample of data, data and label, X and, or we'll just go XY. So we know that it's a tuple. Beautiful. So let's set up the image. What do we want the image to be? Well, this is where we're going to call on our self dot load image function, which is what we've created up here. Do you see the customization capabilities of creating your own class? So we've got a fair bit of code here, right? But essentially, all we're doing is we're just creating functions that is going to help us load our images into some way, shape or form. Now, again, I can't stress this enough, regardless of the data that you're working on, the pattern here will be quite similar. You'll just have to change the different functions you use to load your data. So let's load an image of a particular index. So if we pass in an index here, it's going to load in that image. Then what do we do? Well, we want to get the class name, which is going to be self dot paths. And we'll get the index here, and we can go parent dot name. So this expects path in format data, folder slash class name slash image dot JPG. That's just something to be aware of. And the class ID X is going to be self dot class to ID X. And we will get the class name here. So now we have an image by loading in the image here. We have a class name by because our data is going to be or our data is currently in standard image classification format. You may have to change this depending on the format your data is in, we can get the class name from that, and we can get the class ID X by indexing on our attribute up here, our dictionary of class names to indexes. Now we have one small little step. This is transform if necessary. So remember our transform parameter up here. If we want to transform our target image, well, let's put in if self dot transform if the transform exists, let's pass the image through that transform, transform image and then we're going to also return the class ID X. So do you notice how we've returned a tuple here? This is going to be a torch tensor. If our transform exists and the class ID X is also going to be returned, which is what we want here, X and Y, which is what gets returned here, image as a tensor label as an integer. So return data label X, Y, and then if the transform doesn't exist, let's just return image class ID X, return untransformed image and label. Beautiful. So that is a fair bit of code there. So you can see the pro of subclassing torch utils data that data set is that we can customize this in almost any way we wanted to to load whatever data that we're working with, well, almost any data. However, because we've written so much code, this may be prone to errors, which we're going to find out in the next video to see if it actually works. But essentially, all we've done is we've followed the documentation here torch dot utils data dot data set to replicate the functionality of an existing data loader function, namely image folder. So if we scroll back up, ideally, if we've done it right, we should be able to write code like this, passing in a root directory, such as a training directory, a particular data transform. And we should get very similar instances as image folder, but using our own custom data set class. So let's try that out in the next video. So now we've got a custom image folder class that replicates the functionality of the original image folder, data loader class, or data set class, that is, let's test it out. Let's see if it works on our own custom data. So we're going to create a transform here so that we can transform our images raw jpeg images into tenses, because that's the whole goal of importing data into pytorch. So let's set up a train transforms compose. We're going to set it to equal to transforms dot compose. And I'm going to pass in a list here, that it's going to be transforms, we're going to resize it to 6464. Whatever the image size will reduce it down to 6464. Then we're going to go transforms dot random horizontal flip. We don't need to necessarily flip them, but we're going to do it anyway, just to see if it works. And then let's put in here transforms dot to tensor, because our images are getting opened as a pill image, using image dot open. But now we're using the to transform transform from pytorch or torch visions dot transforms. So I'll just put this here. From torch vision dot transforms, that way you know where importing transforms there. And let's create one for the test data set as well, test transforms, we'll set this up. Oh, excuse me, I need to just go import transforms. And let's go transforms dot compose. And we'll pass in another list, we're going to do the exact same as above, we'll set up resize, and we'll set the size equal to 6464. And then transforms, we're going to go dot to tensor, we're going to skip the data augmentation for test data. Because typically, you don't manipulate your test data in terms of data augmentation, you just convert it into a tensor, rather than manipulate its orientation, shape, size, etc, etc. So let's run this. And now let's see how image folder custom class works. Test out image folder custom. Let's go, we'll set up the train data custom is equal to image folder custom. And then we'll set up the target, which is equal to the training directory. And then we'll pass in the transform, which is equal to the train transforms, which we just created above train transforms. And then we're going to, I think that's all we need, actually, we only had two parameters that we're not going to use a target transform, because our labels, we've got to help a function to transform our labels. So test data custom is going to be image folder custom. And I'm going to set up the target to be equal to the test directory. And the transform is going to be the test transforms from the cell above there. And what's co lab telling me there? Oh, I'm going to set that up. Did we spell something? Oh, we spelled it wrong train transforms. There we go. Beautiful. Now let's have a look at our train data and test data custom. See if it worked. What do we have? Or we have an image folder custom. Well, it doesn't give us as much rich information as just checking it out as it does for the train data. But that's okay. We can still inspect these. So this is our original one made with image folder. And we've got now train data custom and test data custom. Let's see if we can get some information from there. So let's check the original length of the train data and see if we can use the land method on our train data custom. Did that work? Wonderful. Now how about we do it for the original test data made with image folder and our custom version made with test data or image folder custom. Beautiful. That's exactly what we want. And now let's have a look at the train data custom. Let's see if the classes attribute comes up. Dot classes. And we'll just leave that there. We'll do the class dot ID X. Yes, it is. So this attribute here is I wonder if we get information from Google co lab loading. What do we get? Oh, classes to ID X classes load image paths transform. So if we go back up here, all these attributes are from here paths transform classes class to ID X as well as load image. So this is all coming from the code that we wrote our custom data set class. So let's keep pushing forward. Let's have a look at the class to ID X. Do we get the same as what we wanted before? Yes, we do beautiful a dictionary containing our string names and the integer associations. So let's now check for equality. We can do this by going check for equality between original image folder data set and image folder custom data set. Now we've kind of already done that here, but let's just try it out. Let's go print. Let's go train data custom dot classes. Is that equal to train? Oh, I don't want three equals train data. The original one classes and also print. Let's do test data custom dot classes. Is this equal to test data? The original one classes. True and true. Now you could try this out. In fact, it's a little exercise to try it out to compare the others. But congratulations to us, we have replicated the main functionality of the image folder data set class. And so the takeaways from this is that whatever data you have, PyTorch gives you a base data set class to inherit from. And then you can write a function or a class that somehow interacts with whatever data you're working with. So in our case, we load in an image. And then you, as long as you override the land method and the get item method and return some sort of values, well, you can create your own data set loading function. How beautiful is that? So that's going to help you work with your own custom data sets in PyTorch. So let's keep pushing forward. We've seen analytically that our custom data set is quite similar to the original PyTorch, torch vision dot data sets image folder data set. But you know what I like to do? I like to visualize things. So let's in the next video, create a function to display some random images from our trained data custom class. It's time to follow the data explorer's motto of visualize, visualize, visualize. So let's create another section. I'm going to write here a title called create a function to display random images. And sure, we've, we've had a look at the different attributes of our custom data set. We see that it gives back a list of different class names. We see that the lengths are similar to the original, but there's nothing quite like visualizing some data. So let's go in here. We're going to write a function, a helper function. So step number one, we need to take in a data set. So one of the data sets that we just created, whether it be trained data custom or trained data. And a number of other parameters, such as class names and how many images to visualize. And then step number two is to prevent the display getting out of hand. Let's cap the number of images to see at 10. Because look, if our data set is going to be thousands of images and we want to put in a number of images to look at, let's just make sure it's the maximum is 10. That should be enough. So we'll set the random seed for reproducibility. Number four is, let's get a list of random samples. So we want random sample indexes, don't just get rid of this s from what do we want it from from the target data set. So we want to take in a data set, and we want to count the number of images we're seeing, we want to set a random seed. And do you see how much I use randomness here to really get an understanding of our data? I really, really, really love harnessing the power of randomness. So we want to get a random sample of indexes from all of our data set. And then we're going to set up a matplotlib plot. Then we want to loop through the random sample images. And plot them with matplotlib. And then as a side to this one, step seven is we need to make sure the dimensions of our images line up with matplotlib. So matplotlib needs a height width color channels. All right, let's take it on, hey? So number one is create a function to take in a data set. So we're going to call this def, let's call it def display random images going to be one of our helper functions. We've created a few type of functions like this. But let's take in a data set, which is torch utils of type that is of type data set. Then we're going to take in classes, which is going to be a list of different strings. So this is going to be our class names for whichever data set we're using. I'm going to set this equal to none. And then we're going to take in n, which is the number of images we'd like to plot. And I'm going to set this to 10 by default. So we can see 10 images at a time, 10 random images, that is, do we want to display the shape? Let's set that equal to true, so that we can display what the shape of the images, because we're passing it through our transform as it goes into a data set. So we want to see what the shape of our images are just to make sure that that's okay. And we can also let's set up a seed, which is going to be an integer, and we'll set that to none to begin with as well. Okay, so step number two, what do we have above? We have to prevent the display getting out of hand, let's cap the number of images to see at 10. So we've got n is by default, it's going to be 10, but let's just make sure that it stays there. Adjust display, if n is too high. So if n is greater than 10, let's just readjust this, let's set n equal to 10, and display shape, we'll turn off the display shape, because if we have 10 images, our display may get out of hand. So just print out here for display purposes, and shouldn't be larger than 10, setting to 10, and removing shape display. Now I only know this because I've had experience cooking this dish before. In other words, I've written this type of code before. So you can customize the beautiful thing about Python and PyTorch, as you can customize these display functions in any way you see fit. So step number three, what are we doing? Set the random seed for reproducibility. Okay, set the seed. So if seed, let's set random dot seed equal to that seed value, and then we can keep and then we can keep going. So number four is let's get some random sample indexes. So we can do that by going get random sample indexes, which is step number four here. So we've got a target data set that we want to inspect. We want to get some random samples from that. So let's create a random samples IDX list. And I'm going to randomly sample from a length of our data set, or sorry, a range of the length of our data set. And I'll show you what this means in a second. And the K, excuse me, have we got enough brackets there? I always get confused with the brackets. The K is going to be n. So in this case, I want to randomly sample 10 images from the length of our data set or 10 indexes. So let's just have a look at what this looks like. We'll put in here, our train data custom here. So this is going to take a range of the length of our train data custom, which is what 225. We looked at that before, just up here, length of this. So between zero and 255, we're going to get 10 indexes if we've done this correctly. Beautiful. So there's 10 random samples from our train data custom, or 10 random indexes, that is. So we're up to step number five, which was loop through the random sample images or indexes. Let's create this to indexes, indexes and plot them with matplotlib. So this is going to give us a list here. So let's go loop through random indexes and plot them with matplotlib. Beautiful. So for i tug sample in enumerate, let's enumerate through the random, random samples, idx list. And then we're going to go tug image and tug label, because all of the samples in our target data set are in the form of tuples. So we're going to get the target image and the target label, which is going to be data set tug sample. We'll take the index. So it might be one of these values here. We'll index on that. And the zero index will be the image. And then we'll go on the data set as well. We'll take the tug sample index. And then the index number one will be the label of our target sample. And then number seven, oh, excuse me, we've missed a step. That should be number six. Did you catch that? Number five is setup plot. So we can do this quite easily by going plot figure. This is so that each time we iterate through another sample, we're going to have quite a big figure here. So we set up the plot outside the loop so that we can add a plot to this original plot here. And now this is number seven, where we make sure the dimensions of our images line up with matplotlib. So if we recall by default, pytorch is going to turn our image dimensions into what color channels first, however, matplotlib prefers color channels last. So let's go adjust, tensor dimensions for plotting. So let's go tag image. Let's call this tag image adjust equals tag image dot commute. And we're going to alter the order of the indexes. So this is going to go from color channels or the dimensions that is height width. And we're going to change this width, if I could spell, to height width color channels. Beautiful. That one will probably catch you off guard a few times. But we've seen it a couple of times now. So we're going to keep going with this plot adjusted samples. So now we can add a subplot to our matplotlib plot. And we want to create, we want one row of n images, this will make a lot more sense when we visualize it. And then for the index, we're going to keep track of i plus one. So let's keep going. So then we're going to go plot in show. And I'm going to go tug image adjust. So I'm going to plot this image here. And then let's turn off the axis. And we can go if the classes variable exists, which is up here, a list of classes, let's adjust the title of the plot to be the particular index in the class list. So title equals f class. And then we're going to put in here classes. And we're going to index on that with the target label index, which is going to come from here. Because that's going to be a new numerical format. And then if display shape, let's set the title equal to title plus f. We're going to go new line shape. This is going to be the shape of the image, tug image adjust dot shape. And then we'll set the title to PLT dot title. So you see how if we have display shape, we're just adjusting the title variable that we created here. And then we're putting the title onto the plot. So let's see how this goes. That is quite a beautiful function. Let's pass in one of our data sets and see what it looks like. Let's plot some random images. So which one should we start with first? So let's display random images from the image folder created data sets. So this is the inbuilt pytorch image folder. Let's go display random images, the function we just created above. We're going to pass in the train data. And then we can pass in the number of images. Let's have a look at five. And the classes is going to be the class names, which is just a list of our different class names. And then we can set the seed, we want it to be random. So we'll just set the seed to equal none. Oh, doesn't that look good? So this is from our original train data made with image folder. So option number one up here, option one, there we go. And we've passed in the class name. So this is sushi resize to 64, 64, three, same with all of the others, but from different classes. Let's set the seed to 42, see what happens. I get these images, we got a sushi, we got a pizza, we got pizza, sushi pizza. And then if we try a different one, we just go none. We get random images again, wonderful. Now let's write the same code, but this time using our train data custom data set. So display random images from the image folder custom data set. So this is the one that we created display random images. I'm going to pass in train data custom, our own data set. Oh, this is exciting. Let's set any equal to 10 and just see see how far we can go with with our plot. Or maybe we set it to 20 and just see if our code for adjusting the plot makes sense. Class names and seed equals, I'm going to put in 42 this time. There we go. For display purposes, and shouldn't be larger than 10 setting to 10 and removing shape display. So we have a stake image, a pizza image, pizza, steak pizza, pizza, pizza, pizza, steak, pizza. If we turn off the random seed, we should get another 10 random images here. Beautiful. Look at that. Steak, steak, sushi, pizza, steak, sushi class. I'm reading out the different things here. Pizza, pizza, pizza, pizza. Okay. So it looks like our custom data set is working from both a qualitative standpoint, looking at the different images and a quantitative. How about we change it to five and see what it looks like? Do we have a different shape? Yes, we do the same shape as above. Wonderful. Okay. So we've got train data custom. And we've got train data, which is made from image folder. But the premises remain, we've built up a lot of different ideas. And we're looking at things from different points of view. We are getting our data from the folder structure here into tensor format. So there's still one more step that we have to do. And that's go from data set to data loader. So in the next video, let's see how we can turn our custom loaded images, train data custom, and test data custom into data loaders. So you might want to go ahead and give that a try yourself. We've done it before up here. Turn loaded images into data loaders. We're going to replicate the same thing as we did in here for our option number two, except this time we'll be using our custom data set. I'll see you in the next video. I'll take some good looking images and even better that they're from our own custom data set. Now we've got one more step. We're going to turn our data set into a data loader. In other words, we're going to batchify all of our images so they can be used with the model. And I gave you the challenge of trying this out yourself in the last video. So I hope you gave that a go. But let's see what that might look like in here. So I'm going to go 5.4. Let's go. What should we call this? So turn custom loaded images into data loaders. So this is just goes to show that we can write our own custom data set class. And we can still use it with PyTorch's data loader. So let's go from utils torch dot utils that is utils dot data import data loader. We'll get that in here. We don't need to do that again, but I'm just doing it for completeness. So we're going to set this to train data loader custom. And I'm going to create an instance of data loader here. And then inside I'm going to pass the data set, which is going to be train data custom. I'm just going to set a universal parameter here in capitals for batch size equals 32. Because we can come down here, we can set the batch size, we're going to set this equal to 32. Or in other words, the batch size parameter we set up there, we can set the number of workers here as well. If you set to zero, let's go see what the default is actually torch utils data loader. What's the default for number of workers? Zero. Okay, beautiful. And recall that number of workers is going to set how many cores load your data with a data loader. And generally higher is better. But you can also experiment with this value and see what value suits your model and your hardware the best. So just keep in mind that number of workers is going to alter how much compute your hardware that you're running your code on uses to load your data. So by default, it's set to zero. And then we're going to shuffle the training data. Wonderful. And let's do the same for the test data loader. We'll create test data loader custom. And I'm going to create a new instance. So let me make a few code cells here of data loader, and create a data set or pass in the data set parameter as the test data custom. So again, these data sets are what we've created using our own custom data set class. I'm going to set the batch size equal to batch size. And let's set the number workers equal to zero. In a previous video, we've also set it to CPU count. You can also set it to one. You can hard code it to four all depends on what hardware you're using. I like to use OPA OS dot CPU count. And then we're not going to shuffle the test data. False. Beautiful. And let's have a look at what we get here. Train data loader custom and test data loader custom. And actually, I'm just going to reset this instead of being OOS CPU count. I'm going to put it back to zero, just so we've got it in line with the one above. And of course, numb workers, we could also set this numb workers equals zero or OS dot CPU count. And then we could come down here and set this as numb workers and numb workers. And let's have a look to see if it works. Beautiful. So we've got two instances of utils.data.data loader. Now, let's just get a single sample from the train data loader here, just to make sure the image shape and batch size is correct. Get image and label from custom data loader. We want image custom. And I'm going to go label custom equals next. And I'm going to iter over the train data loader custom. And then let's go print out the shapes. We want image custom dot shape and label custom. Do we get a shape here? Beautiful. There we go. So we have shape here of 32, because that is our batch size. Then we have three color channels, 64, 64, which is in line with what? Which is in line with our transform that we set all the way up here. Transform. We transform our image. You may want to change that to something different depending on the model you're using, depending on how much data you want to be comprised within your image. Recall, generally a larger image size encodes more information. And this is all coming from our original image folder custom data set class. So look at us go. And I mean, this is a lot of code here or a fair bit of code, right? But you could think of this as like you write it once. And then if your data set continues to be in this format, well, you can use this over and over again. So you might put this, this image folder custom into a helper function file over here, such as data set dot pie or something like that. And then you could call it in future code instead of rewriting it all the time. And so that's just exactly what pytorch is done with taught vision dot data sets dot image folder. So we've got some shapes here. And if we wanted to change the batch size, what do we do? We just change it like that 64. Remember, a good batch size is also a multiple of eight, because that's going to help out computing. And batch size equals one. We get a batch size equal of one. We've been through a fair bit. But we've covered a very important thing. And that is loading your own data with a custom data set. So generally, you will be able to load your own data with an existing data loading function or data set function from one of the torch domain libraries, such as torch audio, torch text, torch vision, torch rack. And later on, when it's out of beta, torch data. But if you need to create your own custom one, while you can subclass torch dot utils dot data, dot data set, and then add your own functionality to it. So let's keep pushing forward. Previously, we touched a little bit on transforming data. And you may have heard me say that torch vision transforms can be used for data augmentation. And if you haven't, that is what the documentation says here. But data augmentation is manipulating our images in some way, shape or form, so that we can artificially increase the diversity of our training data set. So let's have a look at that more in the next video. I'll see you there. Over the last few videos, we've created functions and classes to load in our own custom data set. And we learned that one of the biggest steps in loading a custom data set is transforming your data, particularly turning your target data into tenses. And we also had a brief look at the torch vision transforms module. And we saw that there's a fair few different ways that we can transform our data. And that one of the ways that we can transform our image data is through augmentation. And so if we went into the illustration of transforms, let's have a look at all the different ways we can do it. We've got resize going to change the size of the original image. We've got center crop, which will crop. We've got five crop. We've got grayscale. We've got random transforms. We've got Gaussian blur. We've got random rotation, random caffeine, random crop. We could keep going. And in fact, I'd encourage you to check out all of the different options here. But oh, there's auto augment. Wonderful. There's random augment. This is what I was hinting at. Data augmentation. Do you notice how the original image gets augmented in different ways here? So it gets artificially changed. So it gets rotated a little here. It gets dark and a little here or maybe brightened, depending how you look at it, it gets shifted up here. And then the colors kind of change here. And so this process is known as data augmentation, as we've hinted at. And we're going to create another section here, which is number six, other forms of transforms. And this is data augmentation. So how could you find out about what data augmentation is? Well, you could go here. What is data augmentation? And I'm sure there's going to be plenty of resources here. Wikipedia. There we go. Data augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. So I'm going to write down here, data augmentation is the process of artificially adding diversity to your training data. Now, in the case of image data, this may mean applying various image transformations to the training images. And we saw a whole bunch of those in the torch vision transformed package. But now let's have a look at one type of data augmentation in particular. And that is trivial augment. But just to illustrate this, I've got a slide here ready to go. We've got what is data augmentation. And it's looking at the same image, but from different perspectives. And we do this, as I said, to artificially increase the diversity of a data set. So if we imagine our original images over here on the left, and then if we wanted to rotate it, we could apply a rotation transform. And then if we wanted to shift it on the vertical and the horizontal axis, we could apply a shift transform. And if we wanted to zoom in on the image, we could apply a zoom transform. And there are many different types of transforms. As I've got a note here, there are many different kinds of data augmentation, such as cropping, replacing, shearing. And this slide only demonstrates a few. But I'd like to highlight another type of data augmentation. And that is one used to recently train pytorch torch vision image models to state of the art levels. So let's take a look at one particular type of data augmentation, used to train pytorch vision models to state of the art levels. Now, just in case you're not sure why we might do this, we would like to increase the diversity of our training data so that our images become harder for our model to learn. Or it gets a chance to view the same image from different perspectives so that when you use your image classification model in practice, it's seen the same sort of images, but from many different angles. So hopefully it learns patterns that are generalizable to those different angles. So this practice, hopefully, results in a model that's more generalizable to unseen data. And so if we go to torch vision, state of the art, here we go. So this is a recent blog post by the pytorch team, how to train state of the art models, which is what we want to do, state of the art means best in business, otherwise known as soda. You might see this acronym quite often using torch visions latest primitives. So torch vision is the package that we've been using to work with vision data. And torch vision has a bunch of primitives, which are, in other words, functions that help us train really good performing models. So blog post here. And if we jump into this blog post and if we scroll down, we've got some improvements here. So there's an original ResNet 50 model. ResNet 50 is a common computer vision architecture. So accuracy at one. So what do we have? Well, let's just say they get a boost in what the previous results were. So if we scroll down, there is a type of data augmentation here. So if we add up all of the improvements that they used, so there's a whole bunch here. Now, as your extra curriculum, I'd encourage you to look at what the improvements are. You're not going to get them all the first go, but that's all right. Blog posts like this come out all the time and the recipes are continually changing. So even though I'm showing you this now, this may change in the future. So I just scroll down to see if this table showed us what the previous results were. Doesn't look like it does. Oh, no, there's the baseline. So 76 and with all these little additions, it got right up to nearly 81. So nearly a boost of 5% accuracy. And that's pretty good. So what we're going to have a look at is trivial augment. So there's a bunch of different things such as learning rate optimization, training for longer. So these are ways you can improve your model. Random erasing of image data, label smoothing, you can add that as a parameter to your loss functions, such as cross entropy loss, mix up and cut mix, weight decay tuning, fixed res mitigations, exponential moving average, which is EMA, inference resize tuning. So there's a whole bunch of different recipe items here, but we're going to focus on what we're going to break it down. Let's have a look at trivial augment. So we'll come in here. Let's look at trivial augment. So if we wanted to look at trivial augment, can we find it in here? Oh, yes, we can. It's right here. Trivial augment. So as you'll see, if you pass an image into trivial augment, it's going to change it in a few different ways. So if we go into here, let's write that down. So let's see this in action on some of our own data. So we'll import from torch vision, import transforms. And we're going to create a train transform, which is equal to transforms dot compose. We'll pass it in there. And this is going to be very similar to what we've done before in terms of composing a transform. What do we want to do? Well, let's say we wanted to resize one of our images or an image going through this transform. Let's change its size to 224224, which is a common size in image classification. And then it's going to go through transforms. We're going to pass in trivial augment wide. And there's a parameter here, which is number of magnitude bins, which is basically a number from 0 to 31, 31 being the max of how intense you want the augmentation to happen. So say we, we only put this as 5, our augmentation would be of intensity from 0 to 5. And so in that case, the maximum wouldn't be too intense. So if we put it to 31, it's going to be the max intensity. And what I mean by intensity is say this rotation, if we go on a scale of 0 to 31, this may be a 10, whereas 31 would be completely rotating. And same with all these others, right? So the lower this number, the less the maximum up a bound of the applied transform will be. Then if we go transforms dot to tensor, wonderful. So there we've just implemented trivial augment. How beautiful is that? That is from the PyTorch torch vision transforms library. We've got trivial augment wide. And it was used trivial augment to train the latest state of the art vision models in the PyTorch torch vision models library or models repository. And if you wanted to look up trivial augment, how could you find that? You could search it. Here is the paper if you'd like to read it. Oh, it's implemented. It's actually a very, very, I would say, let's just say trivial augment. I didn't want to say simple because I don't want to downplay it. Trivial augment leverages the power of randomness quite beautifully. So I'll let you read more on there. I would rather try it out on our data and visualize it first. Test transform. Let's go transforms compose. And you might have the question of which transforms should I use with my data? Well, that's the million dollar question, right? That's the same thing as asking, which model should I use for my data? There's a fair few different answers there. And my best answer will be try out a few, see what work for other people like we've done here by finding that trivial augment worked well for the PyTorch team. Try that on your own problems. If it works well, excellent. If it doesn't work well, well, you can always excuse me. We've got a spelling mistake. If it doesn't work well, well, you can always set up an experiment to try something else. So let's test out our augmentation pipeline. So we'll get all the image paths. We've already done this, but we're going to do it anyway. Again, just to reiterate, we've covered a fair bit here. So I might just rehash on a few things. We're going to get list, image path, which is our, let me just show you our image path. We just want to get all of the images within this file. So we'll go image path dot glob, glob together all the files and folders that match this pattern. And then if we check, what do we get? We'll check the first 10. Beautiful. And then we can leverage our function from the four to plot some random images, plot random images. We'll pass in or plot transformed random transformed images. That's what we want. Let's see what it looks like when it goes through our trivial augment. So image paths, equals image part list. This is a function that we've created before, by the way, transform equals train transform, which is the transform we just created above that contains trivial augment. And then we're going to put n equals three for five images. And we'll do seed equals none to plot. Oh, sorry, n equals three for three images, not five. Beautiful. And we'll set the seed equals none, by the way. So look at this. We've got class pizza. Now trivial augment, it resized this. Now, I'm not quite sure what it did to transform it per se. Maybe it got a little bit darker. This one looks like it's been the colors have been manipulated in some way, shape, or form. And this one looks like it's been resized and not too much has happened to that one from my perspective. So if we go again, let's have a look at another three images. So trivial augment works. And what I said before, it harnesses the power of randomness. It kind of selects randomly from all of these other augmentation types, and applies them at some level of intensity. So all of these ones here, trivial augment is just going to select summit random, and then apply them some random intensity from zero to 31, because that's what we've set on our data. And of course, you can read a little bit more in the documentation, or sorry, in the paper here. But I like to see it happening. So this one looks like it's been cut off over here a little bit. This one again, the colors have been changed in some way, shape, or form. This one's been darkened. And so do you see how we're artificially adding diversity to our training data set? So instead of all of our images being this one perspective like this, we're adding a bunch of different angles and telling our model, hey, you got to try and still learn these patterns, even if they've been manipulated. So we'll try one more of these. So look at that one. That's pretty manipulated there, isn't it? But it's still an image of stake. So that's what we're trying to get our model to do is still recognize this image as an image of stake, even though it's been manipulated a bit. Now, will this work or not? Hey, it might, it might not, but that's all the nature of experimentation is. So play around. I would encourage you to go in the transforms documentation like we've just done, illustrations, change this one out, trivial augment wine, for another type of augmentation that you can find in here, and see what it does to some of our images randomly. I've just highlighted trivial augment because it's what the PyTorch team have used in their most recent blog post for their training recipe to train state-of-the-art vision models. So speaking of training models, let's move forward and we've got to build our first model for this section. I'll see you in the next video. Welcome back. In the last video, we covered how the PyTorch team used trivial augment wide, which is the latest state-of-the-art in data augmentation at the time of recording this video to train their latest state-of-the-art computer vision models that are within torch vision. And we saw how easily we could apply trivial augment thanks to torch vision dot transforms. And we'll just see one more of those in action, just to highlight what's going on. So it doesn't look like much happened to that image when we augmented, but we see this one has been moved over. We've got some black space there. This one has been rotated a little, and now we've got some black space there. But now's time for us to build our first computer vision model on our own custom data set. So let's get started. We're going to go model zero. We're going to reuse the tiny VGG architecture, which we covered in the computer vision section. And the first experiment that we're going to do, we're going to build a baseline, which is what we do with model zero. We're going to build it without data augmentation. So rather than use trivial augment, which we've got up here, which is what the PyTorch team used to train their state-of-the-art computer vision models, we're going to start by training our computer vision model without data augmentation. And then so later on, we can try one to see with data augmentation to see if it helps or doesn't. So let me just put a link in here, CNN explainer. This is the model architecture that we covered in depth in the last section. So we're not going to go spend too much time here. All you have to know is that we're going to have an input of 64, 64, 3 into multiple different layers, such as convolutional layers, relio layers, max pool layers. And then we're going to have some output layer that suits the number of classes that we have. In this case, there's 10 different classes, but in our case, we have three different classes, one for pizza, steak, and sushi. So let's replicate the tiny VGG architecture from the CNN explainer website. And this is going to be good practice, right? We're not going to spend too much time referencing their architecture. We're going to spend more time coding here. But of course, before we can train a model, what do we have to do? Well, let's go 7.1. We're going to create some transforms and loading data. We're going to load data for model zero. Now, we could of course use some of the variables that we already have loaded. But we're going to recreate them just to practice. So let's create a simple transform. And what is our whole premise of loading data for model zero? We want to get our data from the data folder, from pizza, steak sushi, from the training and test folders, from their respective folders, we want to load these images and turn them into tenses. Now we've done this a few times now. And one of the ways that we can do that is by creating a transform equals transforms dot compose. And we're going to pass in, let's resize it. So transforms dot resize, we're going to resize our images to be the same size as the tiny VGG architecture on the CNN explainer website. 64 64 three. And then we're also going to pass in another transform to tensor. So that our images get resized to 64 64. And then they get converted into tenses. And particularly, these values within that tensor are going to be between zero and one. So there's our transform. Now we're going to load some data. If you want to pause the video here and try to load it yourself, I'd encourage you to try out option one, loading image data using the image folder class, and then turn that data set, that image folder data set into a data loader. So batchify it so that we can use it with a pytorch model. So give that a shot. Otherwise, let's go ahead and do that together. So one, we're going to load and transform data. We've done this before, but let's just rehash on it what we're doing. So from torch vision import data sets, then we're going to create the train data simple. And I call this simple because we're going to use at first a simple transform, one with no data augmentation. And then later on for another modeling experiment, we're going to create another transform one with data augmentation. So let's put this here data sets image folder. And let's go the route equals the training directory. And then the transform is going to be what? It's going to be our simple transform that we've got above. And then we can put in test data simple here. And we're going to create data sets dot image folder. And then we're going to pass in the route as the test directory. And we'll pass in the transform is going to be the simple transform again above. So we're performing the same transformation here on our training data, and on our testing data. Then what's the next step we can do here? Well, we can to turn the data sets into data loaders. So let's try it out. First, we're going to import OS, then from torch dot utils dot data, we're going to import data loader. And then we're going to set up batch size and number of workers. So let's go batch size. We're going to use a batch size of 32 for our first model. Numb workers, which will be the number of excuse me, got a typo up here classic number of workers, which will be the what the number of CPU cores that we dedicate towards loading our data. So let's now create the data loaders. We're going to create train data loader simple, which will be equal to data loader. And the data set that goes in here will be train data simple. Then we can set the batch size equal to the batch size parameter that we just created, or hyper parameter that is, recall a hyper parameter is something that you can set yourself. We would like to shuffle the training data. And we're going to set numb workers equal to numb workers. So in our case, how many calls does Google Colab have? Let's just run this. Find out how many numb workers there are. I think there's going to be two CPUs. Wonderful. And then we're going to do the same thing for the test data loader. Test data loader simple. We're going to go data loader. We'll pass in the data set here, which is going to be the test data simple. And then we're going to go batch size equals batch size. We're not going to shuffle the test data set. And then the numb workers will just set it to the same thing as we've got above. Beautiful. So I hope you gave that a shot, but now do you see how quickly we can get our data loaded if it's in the right format? I know we spent a lot of time going through all of these steps over multiple videos and writing lots of code, but this is how quickly we can get set up to load our data. We create a simple transform, and then we load in and transform our data at the same time. And then we turn the data sets into data loaders just like this. Now we're ready to use these data loaders with a model. So speaking of models, how about we build the tiny VGG architecture in the next video? And in fact, we've already done this in notebook number three. So if you want to refer back to the model that we built there, right down here, which was model number two, if you want to refer back to this section and give it a go yourself, I'd encourage you to do so. Otherwise, we'll build tiny VGG architecture in the next video. Welcome back. In the last video, we got set up starting to get ready to model our first custom data set. And I issued you the challenge to try and replicate the tiny VGG architecture from the CNN explainer website, which we covered in notebook number three. But now let's see how fast we can do that together. Hey, I'm going to write down here section seven point two. And I know we've already coded this up before, but it's good practice to see what it's like to build pytorch models from scratch, create tiny VGG model class. So the model is going to come from here. Previously, we created our model, there would have been one big change from the model that we created in section number three, which is that our model in section number three used black and white images. But now the images that we have are going to be color images. So there's going to be three color channels rather than one. And there might be a little bit of a trick that we have to do to find out the shape later on in the classifier layer. But let's get started. We've got class tiny VGG, we're going to inherit from nn.module. This is going to be the model architecture copying tiny VGG from CNN explainer. And remember that it's a it's quite a common practice in machine learning to find a model that works for a problem similar to yours and then copy it and try it on your own problem. So I only want two underscores there. We're going to initialize our class. We're going to give it an input shape, which will be an int. We're going to say how many hidden units do we want, which will also be an int. And we're going to have an output shape, which will be an int as well. And it's going to return something none of type none. And if we go down here, we can initialize it with super dot underscore init. Beautiful. And now let's create the first COM block. So COM block one, which we'll recall will be this section of layers here. So COM block one, let's do an nn.sequential to do so. Now we need com relu com relu max pool. So let's try this out. And then com to D. The in channels is going to be the input shape of our model. The input shape parameter. The out channels is going to be the number of hidden units we have, which is from Oh, I'm gonna just put enter down here input shape hidden units. We're just getting those to there. Let's set the kernel size to three, which will be how big the convolving window will be over our image data. There's a stride of one and the padding equals one as well. So these are the similar parameters to what the CNN explainer website uses. And we're going to go and then relu. And then we're going to go and then com to D. And I want to stress that even if someone else uses like certain values for these, you don't have to copy them exactly. So just keep that in mind. You can try out various values of these. These are all hyper parameters that you can set yourself. Hidden units, out channels, equals hidden units as well. Then we're going to go kernel size equals three stride equals one. And we're going to put padding equals one as well. Then we're going to have another relu layer. And I believe I forgot my comma up here. Another relu layer here. And we're going to finish off with an N dot max pool 2D. And we're going to put in the kernel size. These equals two and the stride here equals two. Wonderful. So oh, by the way, for max pool 2D, the default stride value is same as the kernel size. So let's have a go here. What can we do now? Well, we could just replicate this block as block two. So how about we copy this down here? We've already had enough practice writing this sort of code. So we're going to go comp block two, but we need to change the input shape here. The input shape of this block two is going to receive the output shape here. So we need to line those up. This is going to be hidden units. Hidden units. And I believe that's all we need to change there. Beautiful. So let's create the classifier layer. And the classifier layer recall is going to be this output layer here. So we need at some point to add a linear layer. That's going to have a number of outputs equal to the number of classes that we're working with. And in this case, the number of classes is 10. But in our case, our custom data set, we have three classes, pizza, steak, sushi. So let's create a classifier layer, which will be an end sequential. And then we're going to pass in an end dot flatten to turn the outputs of our convolutional blocks into feature vector into a feature vector site. And then we're going to have an end dot linear. And the end features, do you remember my trick for calculating the shape in features? I'm going to put hidden units here for the time being. Out features is going to be output shape. So I put hidden units here for the time being because we don't quite yet know what the output shape of all of these operations is going to be. Of course, we could calculate them by hand by looking up the formula for input and output shapes of convolutional layers. So the input and output shapes are here. But I prefer to just do it programmatically and let the errors tell me where I'm wrong. So we can do that by doing a forward pass. And speaking of a forward pass, let's create a forward method, because every time we have to subclass an end dot module, we have to override the forward method. We've done this a few times. But as you can see, I'm picking up the pace a little bit because you've got this. So let's pass in the conv block one, we're going to go X, then we're going to print out x dot shape. And then we're going to reassign X to be self.com block two. So we're passing it through our second block of convolutional layers, print X dot shape to check the shape here. Now this is where our model will probably error is because the input shape here isn't going to line up in features, hidden units, because we've passed all of the output of what's going through comp block one, comp block two to a flatten layer, because we want a feature vector to go into our nn.linear layer, our output layer, which has an out features size of output shape. And then we're going to return X. So I'm going to print x dot shape here. And I just want to let you in on one little secret as well. We haven't covered this before, but we could rewrite this entire forward method, this entire stack of code, by going return self dot classifier, and then going from the outside in. So we could pass in comp block two here, comp block two, and then self comp block one, and then X on the inside. So that is essentially the exact same thing as what we've done here, except this is going to benefits from operator fusion. Now this topic is beyond the scope of this course, essentially, all you need to know is that operator fusion behind the scenes speeds up how your GPU performs computations. So all of these are going to happen in one step, rather than here, we are reassigning X every time we make a computation through these layers. So we're spending time going from computation back to memory, computation back to memory, whereas this kind of just chunks it all together in one hit. If you'd like to read more about this, I'd encourage you to look up the blog post, how to make your GPUs go bur from first principles, and bur means fast. That's why I love this post, right? Because it's half satire, half legitimately, like GPU computer science. So if you go in here, yeah, here's what we want to avoid. We want to avoid all of this transportation between memory and compute. And then if we look in here, we might have operator fusion. There we go. This is operator fusion, the most important optimization in deep learning compilers. So I will link this, making deep learning go bur from first principles by Horace Hare, a great blog post that I really like, right here. So if you'd like to read more on that, it's also going to be in the extracurricular section of the course. So don't worry, it'll be there. Now, we've got a model. Oh, where do we, where do we forget a comma? Right here, of course we did. And we've got another, we forgot another comma up here. Did you notice these? Beautiful. Okay. So now we can create our model by going torch or an instance of the tiny VGG to see if our model holds up. Let's create model zero equals tiny VGG. And I'm going to pass in the input shape. What is the input shape? It's going to be the number of color channels of our image. So number of color channels in our image data, which is three, because we have color images. And then we're going to put in hidden units, equals 10, which will be the same number of hidden units as the tiny VGG architecture. One, two, three, four, five, six, seven, eight, nine, 10. Again, we could put in 10, we could put in 100, we could put in 64, which is a good multiple of eight. So let's just leave it at 10 for now. And then the output shape is going to be what? It's going to be the length of our class names, because we want one hidden unit or one output unit per class. And then we're going to send it to the target device, which is of course CUDA. And then we can check out our model zero here. Beautiful. So that took a few seconds, as you saw there, to move to the GPU memory. So that's just something to keep in mind for when you build large neural networks and you want to speed up their computation, is to use operator fusion where you can, because as you saw, it took a few seconds for our model to just move from the CPU, which is the default to the GPU. So we've got our architecture here. But of course, we know that this potentially is wrong. And how would we find that out? Well, we could find the right hidden unit shape or we could find that it's wrong by passing some dummy data through our model. So that's one of my favorite ways to troubleshoot a model. Let's in the next video pass some dummy data through our model and see if we've implemented the forward pass correctly. And also check the input and output shapes of each of our layers. I'll see you there. In the last video, we replicated the tiny VGG architecture from the CNN explainer website, very similar to the model that we built in section 03. But this time, we're using color images instead of grayscale images. And we did it quite a bit faster than what we previously did, because we've already covered it, right? And you've had some experience now building pilotage models from scratch. So we're going to pick up the pace when we build our models. But let's now go and try a dummy forward pass to check that our forward method is working correctly and that our input and output shapes are correct. So let's create a new heading. Try a forward pass on a single image. And this is one of my favorite ways to test the model. So let's first get a single image. Get a single image. We want an image batch. Maybe we get an image batch, get a single image batch, because we've got images that are batches already image batch. And then we'll get a label batch. And we'll go next, it a train data loader. Simple. That's the data loader that we're working with for now. And then we'll check image batch dot shape and label batch dot shape. Wonderful. And now let's see what happens. Try a forward pass. Oh, I spelled single wrong up here. Try a forward pass. We could try this on a single image trying it on a same batch will result in similar results. So let's go model zero. And we're just going to pass it in the image batch and see what happens. Oh, no. Of course, we get that input type, torch float tensor and wait type torch CUDA float tensor should be the same or input should be. So we've got tensors on a different device, right? So this is on the CPU, the image batch, whereas our model is, of course, on the target device. So we've seen this error a number of times. Let's see if this fixes it. Oh, we get an other error. And we kind of expected this type of error. We've got runtime error amount one and mat two shapes cannot be multiplied. 32. So that looks like the batch size 2560 and 10. Hmm, what is 10? Well, recall that 10 is the number of hidden units that we have. So this is the size here. That's 10 there. So it's trying to multiply a matrix of this size by this size. So 10 has got something going on with it. We need to get these two numbers, the middle numbers, to satisfy the rules of matrix multiplication, because that's what happens in our linear layer. We need to get these two numbers the same. And so our hint and my trick is to look at the previous layer. So if that's our batch size, where does this value come from? Well, could it be the fact that a tensor of this size goes through the flatten layer? Recall that we have this layer up here. So we've printed out the shape here of the conv block, the output of conv block one. Now this shape here is the output of conv block two. So we've got this number, the output of conv block one, and then the output of conv block two. So that must be the input to our classifier layer. So if we go 10 times 16 times 16, what do we get? 2560. Beautiful. So we can multiply our hitting units 10 by 16 by 16, which is the shape here. And we get 2560. Let's see if that works. We'll go up here, times 16 times 16. And let's see what happens. We'll rerun the model, we'll rerun the image batch, and then we'll pass it. Oh, look at that. Our model works. Or the shapes at least line up. We don't know if it works yet. We haven't started training yet. But this is the output size. We've got the output. It's on the CUDA device, of course. But we've got 32 samples with three numbers in each. Now these are going to be as good as random, because we haven't trained our model yet. We've only initialized it here with random weights. So we've got 32 or a batch worth of random predictions on 32 images. So you see how the output shape here three corresponds to the output shape we set up here. Output shape equals length class names, which is exactly the number of classes that we're dealing with. But I think our number is a little bit different to what's in the CNN explainer 1616. How did they end up with 1313? You know what? I think we got one of these numbers wrong, kernel size, stride, padding. Let's have a look. Jump into here. If we wanted to truly replicate it, is there any padding here? I actually don't think there's any padding here. So what if we go back here and see if we can change this to zero and change this to zero? Zero. I'm not sure if this will work, by the way. If it doesn't, it's not too bad, but we're just trying to line up the shapes with the CNN explainer to truly replicate it. So the output of the COM Block 1 should be 30-30-10. What are we working with at the moment? We've got 32-32-10. So let's see if removing the padding from our convolutional layers lines our shape up with the CNN explainer. So I'm going to rerun this, rerun our model. I've set the padding to zero on all of our padding hyper parameters. Oh, and we get another error. We get another shape error. Of course we do, because we've now got different shapes. Wow, do you see how often that these errors come up? Trust me, I spend a lot of time troubleshooting these shape errors. So we now have to line up these shapes. So we've got 13-13-10. Now does that equal 16-90? Let's try it out. 13-13-10. 16-90. Beautiful. And do our shapes line up with the CNN explainer? So we've got 30-30-10. Remember, these are in PyTorch. So color channels first, whereas this is color channels last. So yeah, we've got the output of our first COM Block is lining up here. That's correct. And then same with the second block. How good is that? We've officially replicated the CNN explainer model. So we can take this value 13-13-10 and bring it back up here. 13-13-10. Remember, hidden units is 10. So we're just going to multiply it by 13-13. You could calculate these shapes by hand, but my trick is I like to let the error codes give me a hint of where to go. And boom, there we go. We get it working again. Some shape troubleshooting on the fly. So now we've done a single forward pass on the model. We can kind of verify that our data at least flows through it. What's next? Well, I'd like to show you another little package that I like to use to also have a look at the input and output shapes of my model. And that is called Torch Info. So you might want to give this a shot before we go into the next video. But in the next video, we're going to see how we can use Torch Info to print out a summary of our model. So we're going to get something like this. So this is how beautifully easy Torch Info is to use. So give that a shot, install it into Google CoLab and run it in a cell here. See if you can get something similar to this output for our model zero. And I'll see you in the next video. We'll try that together. In the last video, we checked our model by doing a forward pass on a single batch. And we learned that our forward method so far looks like it's intact and that we don't get any shape errors as our data moves through the model. But I'd like to introduce to you one of my favorite packages for finding out information from a PyTorch model. And that is Torch Info. So let's use Torch Info to get an idea of the shapes going through our model. So you know how much I love doing things in a programmatic way? Well, that's what Torch Info does. Before, we used print statements to find out the different shapes going through our model. And I'm just going to comment these out in our forward method so that when we run this later on during training, we don't get excessive printouts of all the shapes. So let's see what Torch Info does. And in the last video, I issued a challenge to give it a go. It's quite straightforward of how to use it. But let's see it together. This is the type of output we're looking for from our tiny VGG model. And of course, you could get this type of output from almost any PyTorch model. But we have to install it first. And as far as I know, Google CoLab doesn't come with Torch Info by default. Now, you might as well try this in the future and see if it works. But yeah, I don't get this module because my Google CoLab instance doesn't have an install. No problem with that. Let's install Torch Info here. Install Torch Info and then we'll import it if it's available. So we're going to try and import Torch Info. If it's already installed, we'll import it. And then if it doesn't work, if that try block fails, we're going to run pip install Torch Info. And then we will import Torch Info. And then we're going to run down here from Torch Info, import summary. And then if this all works, we're going to get a summary of our model. We're going to pass it in model zero. And we have to put in an input size here. Now that is an example of the size of data that will flow through our model. So in our case, let's put in an input size of 1, 3, 64, 64. So this is an example of putting in a batch of one image. You could potentially put in 32 here if you wanted, but let's just put in a batch of a singular image. And of course, we could change these values here if we wanted to, 24 to 24. But what you might notice is that if it doesn't get the right input size, it produces an error. There we go. So just like we got before when we printed out our input sizes manually, we get an error here. Because what Torch Info behind the scenes is going to do is it's going to do a forward pass on whichever model you pass it with an input size of whichever input size you give it. So let's put in the input size that our model was built for. Wonderful. So what Torch Info gives us is, oh, excuse me, we didn't comment out the printouts before. So just make sure we've commented out these printouts in the forward method of our 20 VGG class. So I'm just going to run this, then we run that, run that, just to make sure everything still works. We'll run Torch Info. There we go. So no printouts from our model, but this is, look how beautiful this is. I love how this prints out. So we have our tiny VGG class, and then we can see it's comprised of three sequential blocks. And then inside those sequential blocks, we have different combinations of layers. We have some conv layers, some relu layers, some max pool layers. And then the final layer is our classification layer with a flatten and a linear layer. And we can see the shapes changing throughout our model. As our data goes in and gets manipulated by the various layers. So are these in line with the CNN explainer? So if we check this last one, we've already verified this before. And we also get some other helpful information down here, which is total params. So you can see that each of these layers has a different amount of parameters to learn. Now, recall that a parameter is a value such as a weight or a bias term within each of our layers, which starts off as a random number. And the whole goal of deep learning is to adjust those random numbers to better represent our data. So in our case, we have just over 8000 total parameters. Now this is actually quite small. In the future, you'll probably play around with models that have a million parameters or more. And models now are starting to have many billions of parameters. And we also get some information here, such as how much the model size would be. Now this would be very helpful, depending on where we had to put our model. So what you'll notice is that as a model gets larger, as more layers, it will have more parameters, more weights and bias terms that can be adjusted to learn patterns and data. But its input size and its estimated total size would definitely get bigger as well. So that's just something to keep in mind if you have size constraints in terms of storage in your future applications. So ours is under a megabyte, which is quite small. But you might find that some models in the future get up to 500 megabytes, maybe even over a gigabyte. So just keep that in mind for going forward. And that's the crux of torch info, one of my favorite packages, just gives you an idea of the input and output shapes of each of your layers. So you can use torch info wherever you need. It should work with most of your PyTorch models. Just be sure to pass it in the right input size. You can also use it to verify like we did before, if the input and output shapes are correct. So check that out, big shout out to Tyler Yup, and everyone who's created the torch info package. Now in the next video, let's move towards training our tiny VGG model. We're going to have to create some training and test functions. If you want to jump ahead, we've already done this. So I encourage you to go back to section 6.2 in the functionalizing training and test loops. And we're going to build functions very similar to this, but for our custom data set. So if you want to replicate these functions in this notebook, give that a go. Otherwise, I'll see you in the next video and we'll do it together. How'd you go? Did you give it a shot? Did you try replicating the train step and the test step function? I hope you did. Otherwise, let's do that in this video, but this time we're going to do it for our custom data sets. And what you'll find is not much, if anything, changes, because we've created our train and test loop functions in such a way that they're generic. So we want to create a train step function. And by generic, I mean they can be used with almost any model and data loader. So train step is takes in a model and data loader and trains the model on the data loader. And we also want to create another function called test step, which takes in a model and a data loader and other things and evaluates the model on the data loader. And of course, for the train step and for the test step, each of them respectively are going to take a training data loader. I just might make this a third heading so that our outline looks nice, beautiful. Section seven is turning out to be quite a big section. Of course, we want them to be respectively taken their own data loader. So train takes in the train data loader, test takes in the test data loader. Without any further ado, let's create the train step function. Now we've seen this one in the computer vision section. So let's see what we can make here. So we need a train step, which is going to take in a model, which will be a torch and then dot module. And we want it also to take in a data loader, which will be a torch dot utils dot data dot data loader. And then it's going to take in a loss function, which is going to be a torch and then dot module as well. And then it's going to take in an optimizer, which is going to be torch opt in dot optimizer. Wonderful. And then what do we do? What's the first thing that we do in a training step? Well, we put the model in train mode. So let's go model dot train. Then what shall we do next? Well, let's set up some evaluation metrics, one of them being loss and one of them being accuracy. So set up train loss and train accuracy values. And we're going to accumulate these per batch because we're working with batches. So we've got train loss and train act equals zero, zero. Now we can loop through our data loader. So let's write loop through data loader. And we'll loop through each of the batches in this because we've batchified our data loader. So for batch x, y, in enumerate data loader, we want to send the data to the target device. So we could even put that device parameter up here. Device equals device. We'll set that to device by default. And then we can go x, y equals x dot two device. And y dot two device. Beautiful. And now what do we do? Well, remember the pie torch, the unofficial pie torch optimization song, we do the forward pass. So y pred equals model om x. And then number two is we calculate the last. So calculate the loss. Let's go loss equals loss function. And we're going to pass it in y pred y. We've done this a few times now. So that's why we're doing it a little bit faster. So I hope you noticed that the things that we've covered before, I'm stepping up the pace a bit. So it might be a bit of a challenge, but that's all right, you can handle it. And then, so that's accumulating the loss. So we're starting from zero up here. And then each batch, we're doing a forward pass, calculating the loss, and then adding it to the overall train loss. And so we're going to optimize a zero grad. So zero, the gradients of the optimizer for each new batch. And then we're going to perform back propagation. So loss backwards. And then five, what do we do? Optimize a step, step, step. Wonderful. Look at that. Look at us coding a train loop in a minute or so. Now, let's calculate the accuracy and accumulate it. Calculate the, you notice that we don't have an accuracy function here. That's because accuracy is quite a straightforward metric to calculate. So we'll first get the, the y pred class, because this is going to output model logits. As we've seen before, the raw output of a model is logits. So to get the class, we're going to take the arg max torch dot softmax. So we'll get the prediction probabilities of y pred, which is the raw logits, what we've got up here, across dimension one, and then also across dimension one here. Beautiful. So that should give us the labels. And then we can find out if this is wrong by checking it later on. And then we're going to create the accuracy by taking the y pred class, checking for a quality with the right labels. So this is going to give us how many of these values equal true. And we want to take the sum of that, take the item of that, which is just a single integer. And then we want to divide it by the length of y pred. So we're just getting the total number that are right, and dividing it by the length of samples. So that's the formula for accuracy. Now we can come down here outside of the batch loop, we know that because we've got this helpful line drawn here. And we can go adjust metrics to get the average loss and accuracy per batch. So we're going to set train loss is equal to train loss, divided by the length of the data loader. So the number of batches in total. And the train accuracy is the train act, divided by the length of the data loader as well. So that's going to give us the average loss and average accuracy per epoch across all batches. So train act. Now that's a pretty good looking function to me for a train step. Do you want to take on the test step? So pause the video, give it a shot, and you'll get great inspiration from this notebook here. Otherwise, we're going to do it together in three, two, one, let's do the test step. So create a test step function. So we want to be able to call these functions in an epoch loop. And that way, instead of writing out training and test code for multiple different models, we just write it out once, and we can call those functions. So let's create def test step, we're going to do model, which is going to be if I could type torch and then module. And then we're going to do data loader, which is torch utils dot data, that data loader, capital L there. And then we're going to just pass in a loss function here, because we don't need an optimizer for the test function. We're not trying to optimize anything, we're just trying to evaluate how our model did on the training dataset. And let's put in the device here, why not? That way we can change the device if we need to. So put model in a val mode, because we're going to be evaluating or we're going to be testing. Then we can set up test loss and test accuracy values. So test loss and test act. We're going to make these zero, we're going to accumulate them per batch. But before we go through the batch, let's turn on inference mode. So this is behind the scenes going to take care of a lot of pie torch functionality that we don't need. That's very helpful during training, such as tracking gradients. But during testing, we don't need that. So loop through data loader or data batches. And we're going to go for batch x, y in enumerate data loader. You'll notice that above, we didn't actually use this batch term here. And we probably won't use it here either. But I just like to go through and have that there in case we wanted to use it anyway. So send data to the target device. So we're going to go x, y equals x dot two device. And same with y dot two device. Beautiful. And then what do we do for an evaluation step or a test step? Well, of course, we do the forward pass, forward pass. And we're going to, let's call these test pred logits and get the raw outputs of our model. And then we can calculate the loss on those raw outputs, calculate the loss. We get the loss is equal to loss function on test pred logits versus y. And then we're going to accumulate the loss. So test loss plus equals loss dot item. Remember, item just gets a single integer from whatever term you call it on. And then we're going to calculate the accuracy. Now we can do this exactly how we've done for the training data set or the training step. So test pred labels, we're going to, you don't, I just want to highlight the fact that you actually don't need to take the softmax here, you could just take the argmax directly from this. The reason why we take the softmax. So you could do the same here, you could just directly take the argmax of the logits. The reason why we get the softmax is just for completeness. So if you wanted the prediction probabilities, you could use torch dot softmax on the prediction logits. But it's not 100% necessary to get the same values. And you can test this out yourself. So try this with and without the softmax and see if you get the same results. So we're going to go test accuracy. Plus equals, now we'll just create our accuracy calculation on the fly test pred labels. We'll check for equality on the y, then we'll get the sum of that, we'll get the item of that, and then we'll divide that by the length of the test pred labels. Beautiful. So it's going to give us accuracy per batch. And so now we want to adjust the metrics to get average loss and accuracy per batch. So test loss equals test loss divided by length of the data loader. And then we're going to go test, ac equals test, act divided by length of the data loader. And then finally, we're going to return the test loss, not lost, and test accuracy. Look at us go. Now, in previous videos, that took us, or in previous sections, that took us a fairly long time. But now we've done it in about 10 minutes or so. So give yourself a pat in the back for all the progress you've been making. But now let's in the next video, we did this in the computer vision section as well. We created, do we create a train function? Oh, no, we didn't. But we could. So let's create a function to functionize this. We want to train our model. I think we did actually. Deaf train, we've done so much. I'm not sure what we've done. Oh, okay. So looks like we might not have. But in the next video, give yourself this challenge, create a function called train that combines these two functions and loops through them both with an epoch range. So just like we've done here in the previous notebook, can you functionize this? So just this step here. So you'll need to take in a number of epochs, you'll need to take in a train data loader and a test data loader, a model, a loss function, an optimizer, and maybe a device. And I think you should be pretty on your way to all the steps we need for train. So give that a shot. But in the next video, we're going to create a function that combines train step and test step to train a model. I'll see you there. How'd you go? In the last video, I issued you the challenge to combine our train step function, as well as our test step function together in their own function so that we could just call one function that calls both of these and train a model and evaluate it, of course. So let's now do that together. I hope you gave it a shot. That's what it's all about. So we're going to create a train function. Now the role of this function is going to, as I said, combine train step and test step. Now we're doing all of this on purpose, right, because we want to not have to rewrite all of our code all the time. So we want to be functionalizing as many things as possible, so that we can just import these later on, if we wanted to train more models and just leverage the code that we've written before, as long as it works. So let's see if it does, we're going to create a train function. I'm going to first import TQDM, TQDM.auto, because I'd like to get a progress bar while our model is training. There's nothing quite like watching a neural network train. So step number one is we need to create a train function that takes in various model parameters, plus optimizer, plus data loaders, plus a loss function. A whole bunch of different things. So let's create def train. And I'm going to pass in a model here, which is going to be torch and then dot module. You'll notice that the inputs of this are going to be quite similar to our train step and test step. I don't actually need that there. So we also want a train data loader for the training data, torch dot utils dot data dot data loader. And we also want a test data loader, which is going to be torch dot utils dot data dot data loader. And then we want an optimizer. So the optimizer will only be used with our training data set, but that's okay. We can take it as an input of the miser. And then we want a loss function. This will generally be used for both our training and testing step. Because that's what we're combining here. Now, since we're working with multi class classification, I'm going to set our loss function to be a default of an n dot cross entropy loss. Then I'm going to get epochs. I'm going to set five, we'll train for five epochs by default. And then finally, I'm going to set the device equal to the device. So what do we get wrong here? That's all right. We'll just keep coding. We'll ignore these little red lines. If they stay around, we'll come back to them. So step number two, I'm going to create. This is a step you might not have seen, but I'm going to create an empty results dictionary. Now, this is going to help us track our results. Do you recall in a previous notebook, we outputted a model dictionary for how a model went. So if we look at model one results, yeah, we got a dictionary like this. So I'd like to create one of these on the fly, but keep track of the result every epoch. So what was the loss on epoch number zero? What was the accuracy on epoch number three? So we'll show you how I'll do that. We can use a dictionary and just update that while our model trains. So results, I want to keep track of the train loss. So we're going to set that equal to an empty list and just append to it. I also want to keep track of the train accuracy. We'll set that as an empty list as well. I also want to keep track of the test loss. And I also want to keep track of the test accuracy. Now, you'll notice over time that these, what you can track is actually very flexible. And what your functions can do is also very flexible. So this is not the gold standard of doing anything by any means. It's just one way that works. And you'll probably find in the future that you need different functionality. And of course, you can code that out. So let's now loop through our epochs. So for epoch in TQDM, let's create a range of our epochs above. And then we can set the train loss. Have I missed a comma up here somewhere? Type annotation not supported for that type of expression. Okay, that's all right. We'll just leave that there. So we're going to go train loss and train act, recall that our train step function that we created in the previous video, train step returns our train loss and train act. So as I said, I want to keep track of these throughout our training. So I'm going to get them from train step. Then for each epoch in our range of epochs, we're going to pass in our model and perform a training step. So the data loader here is of course going to be the train data loader. The loss function is just going to be the loss function that we pass into the train function. And then the optimizer is going to be the optimizer. And then the device is going to be device. Beautiful. Look at that. We just performed a training step in five lines of code. So let's keep pushing forward. It's telling us we've got a whole bunch of different things here. Epox is not defined. Maybe we just have to get rid of this. We can't have the type annotation here. And that'll that'll stop. That'll stop Google Colab getting angry at us. If it does anymore, I'm just going to ignore it for now. Epox. Anyway, we'll leave it at that. We'll find out if there's an error later on. Test loss. You might be able to find it before I do. So test step. We're going to pass in the model. We're going to pass in a data loader. Now this is going to be the test data loader. Look at us go. Grading training and test step functions, loss function. And then we don't need an optimizer. We're just going to pass in the device. And then behind the scenes, both of these functions are going to train and test our model. How cool is that? So still within the loop. This is important. Within the loop, we're going to have number four is we're going to print out. Let's print out what's happening. Print out what's happening. We can go print. And we'll do a fancy little print statement here. We'll get the epoch. And then we will get the train loss, which will be equal to the train loss. We'll get that to, let's go four decimal places. How about that? And then we'll get the train accuracy, which is going to be the train act. We'll get that to four, maybe three decimal of four, just for just so it looks nice. It looks aesthetic. And then we'll go test loss. We'll get that coming out here. And we'll pass in the test loss. We'll get that to four decimal places as well. And then finally, we'll get the test accuracy. So a fairly long print statement here. But that's all right. We'd like to see how our model is doing while it's training. Beautiful. And so again, still within the epoch, we want to update our results dictionary so that we can keep track of how our model performed over time. So let's pass in results. We want to update the train loss. And so this is going to be this. And then we can append our train loss value. So this is just going to expend the list in here with the train loss value, every epoch. And then we'll do the same thing on the train accuracy, append train act. And then we'll do the same thing again with test loss dot append test loss. And then we will finally do the same thing with the test accuracy test accuracy. Now, this is a pretty big function. But this is why we write the code now so that we can use it multiple times later on. So return the field results at the end of the epoch. So outside the epochs loop. So our loop, we're outside it now. Let's return results. Now, I've probably got an error somewhere here and you might be able to spot it. Okay, train data loader. Where do we get that invalid syntax? Maybe up here, we don't have a comma here. Was that the issue the whole time? Wonderful. You might have seen that I'm completely missed that. But we now have a train function to train our model. And the train function, of course, is going to call out our train step function and our test step function. So what's left to do? Well, nothing less than train and evaluate model zero. So our model is way back up here. How about in the next video, we leverage our functions, namely just the train function, because it's going to call our train step function and our test step function and train our model. So I'm going to encourage you to give that a go. You're going to have to go back to the workflow. Maybe you'll maybe already know this. So what have we done? We've got our data ready and we turned it into tenses using a combination of these functions. We've built and picked a model while we've built a model, which is the tiny VGG architecture. Have we created a loss function yet? I don't think we have or an optimizer. I don't think we've done that yet. We've definitely built a training loop though. We aren't using torch metrics. We're just using accuracy, but we could use this if we want. We haven't improved through experimentation yet, but we're going to try this later on and then save and reload the model. We've seen this before. So I think we're up to picking a loss function and an optimizer. So give that a shot. In the next video, we're going to create a loss function and an optimizer and then leverage the functions we've spent in the last two videos creating to train our first model model zero on our own custom data set. This is super exciting. I'll see you in the next video. Who's ready to train and evaluate model zero? Put your hand up. I definitely am. So let's do it together. We're going to start off section 7.7 and we're going to put in train and evaluate model zero, our baseline model on our custom data set. Now, if we refer back to the PyTorch workflow, I issued you the challenge in the last video to try and create a loss function and an optimizer. I hope you gave that a go, but we've already built a training loop. So we're going to leverage our training loop functions, namely train, train step and test step. All we need to do now is instantiate a model, choose a loss function and an optimizer and pass those values to our training function. So let's do that. All right, this is so exciting. Let's set the random seeds. I'm going to set torch manual seed 42 and torch cuda manual seed 42. Now remember, I just want to highlight something. I read an article the other day about not using random seeds. The reason why we are using random seeds is for educational purposes. So to try and get our numbers on my screen and your screen as close as possible, but in practice, you quite often don't use random seeds all the time. The reason why is because you want your models performance to be similar regardless of the random seed that you use. So just keep that in mind going forward. We're using random seeds to just exemplify how we can get similar numbers on our page. But ideally, no matter what the random seed was, our models would go in the same direction. That's where we want our models to eventually go. But we're going to train for five epochs. And now let's create a recreate an instance of tiny VGG. We can do so because we've created the tiny VGG class. So tiny VGG, which is our model zero. We don't have to do this, but we're going to do it any later. So we've got all the code in one place, tiny VGG. What is our input shape going to be? That is the number of color channels of our target images. And because we're dealing with color images, we have an input shape of three. Previously, we used an input shape of one to deal with grayscale images. I'm going to set hidden units to 10 in line with the CNN explainer website. And the output shape is going to be the number of classes in our training data set. And then, of course, we're going to send the target model to the target device. So what do we do now? Well, we set up a loss function and an optimizer, loss function, and optimizer. So our loss function is going to be because we're dealing with multiclass classification, and then cross entropy, if I could spell cross entropy loss. And then we're going to have an optimizer. This time, how about we mix things up? How about we try the atom optimizer? Now, of course, the optimizer is one of the hyper parameters that you can set for your model, and a hyper parameter being a value that you can set yourself. So the parameters that we want to optimize are our model zero parameters. And we're going to set a learning rate of 0.001. Now, recall that you can tweet this learning rate, if you like, but I believe, did I just see that the default learning rate of atom is 0.001? Yeah, there we go. So Adam's default learning rate is one to the power of 10 to the negative three. And so that is a default learning rate for Adam. And as I said, oftentimes, different variables in the pytorch library, such as optimizers, have good default values that work across a wide range of problems. So we're just going to stick with the default. If you want to, you can experiment with different values of this. But now let's start the timer, because we want to time our models. We're going to import from time it. We want to get the default timer class. And I'm going to import that as timer, just so we don't have to type out default timer. So the start time is going to be timer. This is going to just put a line in the sand of what the start time is at this particular line of code. It's going to measure that. And then we're going to train model zero. Now this is using, of course, our train function. So let's write model zero results, and then they wrote model one, but we're not up to there yet. So let's go train model equals model zero. And this is just the training function that we wrote in a previous video. And the train data is going to be our train data loader. And we've got train data loader simple, because we're not using data augmentation for model one. And then our test data loader is going to be our test data loader simple. And then we're going to set our optimizer, which is equal to the optimizer we just created. Friendly atom optimizer. And the loss function is going to be the loss function that we just created, which is an n cross entropy loss. Finally, we can send in epochs is going to be num epochs, which is what we set at the start of this video to five. And of course, we could train our model for longer if we wanted to. But the whole idea of when you first start training a model is to keep your experiments quick. So that's why we're only training for five, maybe later on you train for 10, 20, tweak the learning rate, do a whole bunch of different things. But let's go down here, let's end the timer, see how long our models took to train, and the timer and print out how long it took. So in a previous section, we created a helper function for this. We're just going to simplify it in this section. And we're just going to print out how long the training time was. Total training time. Let's go n time minus start time. And then we're going to go point, we'll take it to three decimal places, hey, seconds, you ready to train our first model, our first convolutional neural network on our own custom data set on pizza, stake and sushi images. Let's do it. You're ready? Three, two, one, no errors. Oh, there we go. Okay, should this be trained data loader? Did you notice that? What is our trained data taker's input? Oh, we're not getting a doc string. Oh, there we go. We want trained data loader, data loader, and same with this, I believe. Let's try again. Beautiful. Oh, look at that lovely progress bar. Okay, how's our model is training quite fast? Okay. All right, what do we get? So we get an accuracy on the training data set of about 40%. And we get an accuracy on the test data set of about 50%. Now, what's that telling us? It's telling us that about 50% of the time our model is getting the prediction correct. But we've only got three classes. So even if our model was guessing, it would get things right 33% of the time. So even if you just guessed pizza every single time, because we only have three classes, if you guessed pizza every single time, you get a baseline accuracy of 33%. So our model isn't doing too much better than our baseline accuracy. Of course, we'd like this number to go higher, and maybe it would if it trained for longer. So I'll let you experiment with that. But if you'd like to see some different methods of improving a model, recall back in section number O two, we had an improving a model section, improving a model. Here we go. So here's some things you might want to try. We can improve a model by adding more layers. So if we come back to our tiny VGG architecture, right up here, we're only using two convolutional blocks. Perhaps you wanted to add in a convolutional block three. You can also add more hidden units. Right now we're using 10 hidden units. You might want to double that and see what happens. Fitting for longer. This is what we just spoke about. So right now we're only fitting for five epochs. So if you maybe wanted to try double that again, and then even double that again, changing the activation functions. So maybe relu is not the ideal activation function for our specific use case. Change the learning rate. We've spoken about that before. So right now our learning rate is 0.001 for Adam, which is the default. But perhaps there's a better learning rate out there. Change the loss function. This is probably not in our case, not going to help too much because cross entropy loss is a pretty good loss for multi class classification. But these are some things that you could try these first three, especially. You could try quite quickly. You could try doubling the layers. You could try adding more hidden units. And you could try fitting for longer. So I'd give that a shot. But in the next video, we're going to take our model zero results, which is a dictionary or at least it should be. And we're going to plot some loss curves. So this is a good way to inspect how our model is training. Yes, we've got some values here. Let's plot these in the next video. I'll see you there. In the last video, we trained our first convolutional neural network on custom data. So you should be very proud of that. That is no small feat to take our own data set of whatever we want and train apply to its model on it. However, we did find that it didn't perform as well as we'd like it to. We also highlighted a few different things that we could try to do to improve it. But now let's plot our models results using a loss curve. So I'm going to write another heading down here. We'll go, I believe we're up to 7.8. So plot the loss curves of model zero. So what is a loss curve? So I'm going to write down here, a loss curve is a way of tracking your models progress over time. So if we just looked up Google and we looked up loss curves, oh, there's a great guide by the way. I'm going to link this. But I'd rather if and doubt code it out than just look at guides. Yeah, loss curves. So yeah, loss over time. So there's our loss value on the left. And there's say steps, which is epochs or batches or something like that. Then we've got a whole bunch of different loss curves over here. Essentially, what we want it to do is go down over time. So that's the idea loss curve. Let's go back down here. And a good guide for different loss curves can be seen here. We're not going to go through that just yet. Let's focus on plotting our own models, loss curves, and we can inspect those. Let's get the model keys. Get the model zero results keys. I'm going to type in model zero results dot keys because it's a dictionary. Let's see if we can write some code to plot these values here. So yeah, over time. So we have one value for train loss, train, act, test loss, and test act for every epoch. And of course, these lists would be longer if we train for more epochs. But let's just how about we create a function called def plot loss curves, which will take in a results dictionary, which is of string and a list of floats. So this just means that our results parameter here is taking in a dictionary that has a string as a key. And it contains a list of floats. That's what this means here. So let's write a doc string plots training curves of a results dictionary. Beautiful. And so we're in this section of our workflow, which is kind of like a, we're kind of doing something similar to TensorBoard, what it does. I'll let you look into that if you want to. Otherwise, we're going to see it later on. But we're really evaluating our model here. Let's write some plotting code. We're going to use map plot lib. So we want to get the lost values of the results dictionary. So this is training and test. Let's set loss equal to results train loss. So this is going to be the loss on the training data set. And then we'll create the test loss, which is going to be, well, index on the results dictionary and get the test loss. Beautiful. Now we'll do the same and we'll get the accuracy. Get the accuracy values of the results dictionary. So training and test. Then we're going to go accuracy equals results. This will be the training accuracy train act and accuracy. Oh, we'll call this test accuracy actually test accuracy equals results test act. Now let's create a number of epochs. So we want to figure out how many epochs we did. We can do that by just counting the length of this value here. So figure out how many epochs there were. So we'll set epochs equal to a range because we want to plot it over time. Our models results over time. That's that's the whole idea of a loss curve. So we'll just get the the length of our results here. And we'll get the range. So now we can set up a plot. Let's go PLT dot figure. And we'll set the fig size equal to something nice and big because we're going to do four plots. We want one for maybe two plots, one for the loss, one for the accuracy. And then we'll go plot the loss. PLT dot subplot. We're going to create one row, two columns, and index number one. We want to put PLT dot plot. And here's where we're going to plot the training loss. So we get that a label of train loss. And then we'll add another plot with epochs and test loss. The label here is going to be test loss. And then we'll add a title, which will be loss PLT. Let's put a label on the X, which will be epochs. So we know how many steps we've done. This plot over here, loss curves, it uses steps. I'm going to use epochs. They mean almost the same thing. It depends on what scale you'd like to see your loss curves. We'll get a legend as well so that we are the labels appear. Now we're going to plot the accuracy. So PLT dot subplot. Let's go one, two, and then index number two that this plot's going to be on PLT dot plot. We're going to go epochs accuracy. And the label here is going to be train accuracy. And then we'll get on the next plot, which is actually going to be on the same plot. We'll put the test accuracy. That way we have the test accuracy and the training accuracy side by side, test accuracy same with the train loss and train, sorry, test loss. And then we'll give our plot a title. This plot is going to be accuracy. And then we're going to give it an X label, which is going to be epochs as well. And then finally, we'll get the plot, but legend, a lot of plotting code here. But let's see what this looks like. Hey, if we've done it all right, we should be able to pass it in a dictionary just like this and see some nice plots like this. Let's give it a go. And I'm going to call plot loss curves. And I'm going to pass in model 0 results. All righty then. Okay. So that's not too bad. Now, why do I say that? Well, because we're looking here for mainly trends, we haven't trained our model for too long. Quantitatively, we know that our model hasn't performed at the way we'd like it to do. So we'd like the accuracy on both the train and test data sets to be higher. And then of course, if the accuracy is going higher, then the loss is going to come down. So the ideal trend for a loss curve is to go down from the top left to the bottom right. In other words, the loss is going down over time. So that's, the trend is all right here. So potentially, if we train for more epochs, which I'd encourage you to give it a go, our model's loss might get lower. And the accuracy is also trending in the right way. Our accuracy, we want it to go up over time. So if we train for more epochs, these curves may continue to go on. Now, they may not, they, you never really know, right? You can guess these things. But until you try it, you don't really know. So in the next video, we're going to have a look at some different forms of loss curves. But before we do that, I'd encourage you to go through this guide here, interpreting loss curves. So I feel like if you just search out loss curves, you're going to find Google's guide, or you could just search interpreting loss curves. Because as you'll see, there's many different ways that loss curves can be interpreted. But the ideal trend is for the loss to go down over time, and metrics like accuracy to go up over time. So in the next video, let's cover a few different forms of loss curves, such as the ideal loss curve, what it looks like when your model's underfitting, and what it looks like when your model's overfitting. And if you'd like to have a primer on those things, I'd read through this guide here. Don't worry too much if you're not sure what's happening. We're going to cover a bit more about loss curves in the next video. I'll see you there. In the last video, we looked at our model's loss curves, and also the accuracy curves. And a loss curve is a way to evaluate a model's performance over time, such as how long it was training for. And as you'll see, if you Google some images of loss curves, you'll see many different types of loss curves. They come in all different shapes and sizes. And there's many different ways to interpret loss curves. So this is Google's testing and debugging and machine learning guide. So I'm going to set this as actually curriculum for this section. So we're up to number eight. Let's have a look at what should an ideal loss curve look like. So we'll just link that in there. Now, loss curve, I'll just rewrite here, is a loss curve is, I'll just make some space. A loss curve is one of the most helpful ways to troubleshoot a model. So the trend of a loss curve, you want it to go down over time, and the trend typically of an evaluation metric, like accuracy, you want it to go up over time. So let's go into the keynote, loss curves. So a way to evaluate your model's performance over time. These are three of the main different forms of loss curve that you'll face. But again, there's many different types as mentioned in here, interpreting loss curves. Sometimes you get it going all over the place. Sometimes your loss will explode. Sometimes your metrics will be contradictory. Sometimes your testing loss will be higher than your training loss. We'll have a look at what that is. Sometimes your model gets stuck. In other words, the loss doesn't reduce. Let's have a look at some loss curves here in the case of underfitting, overfitting, and just right. So this is the Goldilocks zone. Underfitting is when your model's loss on the training and test data sets could be lower. So in our case, if we go back to our loss curves, of course, we want this to be lower, and we want our accuracy to be higher. So from our perspective, it looks like our model is underfitting. And we would probably want to train it for longer, say, 10, 20 epochs to see if this train continues. If it keeps going down, it may stop underfitting. So underfitting is when your loss could be lower. Now, the inverse of underfitting is called overfitting. And so two of the biggest problems in machine learning is trying to underfitting. So in other words, make your loss lower and also reduce overfitting. These are both active areas of research because you always want your model to perform better, but you also want it to perform pretty much the same on the training set as it does the test set. And so overfitting would be when your training loss is lower than your testing loss. And why would this be overfitting? So it means overfitting because your model is essentially learning the training data too well. And that means the loss goes down on the training data set, which is typically a good thing. However, this learning is not reflected in the testing data set. So your model is essentially memorizing patterns in the training data set that don't generalize well to the test data set. So this is where we come to the just right curve is that we want, ideally, our training loss to reduce as much as our test loss. And quite often, you'll find that the loss is slightly lower on the training set than it is on the test set. And that's just because the model is exposed to the training data, and it's never seen the test data before. So it might be a little bit lower on the training data set than on the test data set. So underfitting, the model's loss could be lower. Overfitting, the model is learning the training data too well. Now, this would be equivalent to say you were studying for a final exam, and you just memorize the course materials, the training set. And when it came time to the final exam, because you don't even memorize the course materials, you couldn't adapt those skills to questions you hadn't seen before. So the final exam would be the test set. So that's overfitting. The train loss is lower than the test loss. And just right, ideally, you probably won't see loss curves this exact smooth. I mean, they might be a little bit jumpy. Ideally, your training loss and test loss go down at a similar rate. And of course, there's more combinations of these. If you'd like to see them, check out the Google's loss curve guide that you can check that out there. That's some extra curriculum. Now, you probably want to know how do you deal with underfitting and overfitting? Let's look at a few ways. We'll start with overfitting. So we want to reduce overfitting. In other words, we want our model to perform just as well on the training data set as it does on the test data set. So one of the best ways to reduce overfitting is to get more data. So this means that our training data set will be larger. Our model will be exposed to more examples. And with us, in theory, it doesn't always work. These all come with a caveat, right? They don't always work as with many things in machine learning. So get more data, give your model more chance to learn patterns, generalizable patterns in a data set. You can use data augmentation. So make your models training data set harder to learn. So we've seen a few examples of data augmentation. You can get better data. So not only more data, perhaps the data that you're using isn't that the quality isn't that good. So if you enhance the quality of your data set, your model may be able to learn better, more generalizable patterns and in turn reduce overfitting. Use transfer learning. So we're going to cover this in a later section of the course. But transfer learning is taking one model that works, taking its patterns that it's learned and applying it to your own data set. So for example, I'll just go into the Torch Vision models library. Many of these models in here in Torch Vision, the models module, have already been trained on a certain data set and such as ImageNet. And you can take the weights or the patterns that these models have learned. And if they work well on an ImageNet data set, which is millions of different images, you can adjust those patterns to your own problem. And oftentimes that will help with overfitting. If you're still overfitting, you can try to simplify your model. Usually this means taking away things like extra layers, taking away more hidden units. So say you had 10 layers, you might reduce it to five layers. Why does this? What's the theory behind this? Well, if you simplify your model and take away complexity from your model, you're kind of telling your model, hey, use what you've got. And you're going to have to, because you've only got five layers now, you're going to have to make sure that those five layers work really well, because you've no longer got 10. And the same for hidden units. Say you started with 100 hidden units per layer, you might reduce that to 50 and say, hey, you had 100 before. Now use those 50 and make your patterns generalizable. Use learning rate decay. So the learning rate is how much your optimizer updates your model's weight every step. So learning rate decay is to decay the learning rate over time. So you might look this up, you can look this up, go high torch, learning rate, scheduling. So what this means is you want to decrease your learning rate over time. Now, I know I'm giving you a lot of different things here, but you've got this keynote as a reference. So you can come across these over time. So learning rate scheduling. So we might look into here, do we have schedule, scheduler, beautiful. So this is going to adjust the learning rate over time. So for example, at the start of when a model is training, you might want a higher learning rate. And then as the model starts to learn patterns more and more and more, you might want to reduce that learning rate over time so that your model doesn't update its patterns too much in later epochs. So that's the concept of learning rate scheduling. At the closer you get to convergence, the lower you might want to set your learning rate, think of it like this. If you're reaching for a coin at the back of a couch, can we get an image of that coin at back of couch? Images. So if you're trying to reach a coin in the cushions here, so the closer you get to that coin, at the beginning, you might take big steps. But then the closer you get to that coin, the smaller the step you might take to pick that coin out. Because if you take a big step when you're really close to the coin here, the coin might fall down the couch. The same thing with learning rate decay. At the start of your model training, you might take bigger steps as your model works its way down the loss curve. But then you get closer and closer to the ideal position on the loss curve. You might start to lower and lower that learning rate until you get right very close to the end and you can pick up the coin. Or in other words, your model can converge. And then finally, use early stopping. So if we go into an image, is there early stopping here? Early stopping. Loss curves early stopping. So what this means is that you stop. Yeah, there we go. So there's heaps of different guides early stopping with PyTorch. Beautiful. So what this means is before your testing error starts to go up, you keep track of your model's testing error. And then you stop your model from training or you save the weight or you save the patterns where your model's loss was the lowest. So then you could just set your model to train for an infinite amount of training steps. And as soon as the testing error starts to increase for say 10 steps in a row, you go back to this point here and go, I think that was where our model was the best. And the testing error started to increase after that. So we're going to save that model there instead of the model here. So that's the concept of early stopping. So that's dealing with overfitting. There are other methods to deal with underfitting. So recall underfitting is when we have a loss that isn't as low as we'd like it to be. Our model is not fitting the data very well. So it's underfitting. So to reduce underfitting, you can add more layers slash units to your model. You're trying to increase your model's ability to learn by adding more layers or units. You can again tweak the learning rate. Perhaps your learning rate is too high to begin with and your model doesn't learn very well. So you can adjust the learning rate again, just like we discussed with reaching for that coin at the back of a couch. If your model is still underfitting, you can train for longer. So that means giving your model more opportunities to look at the data. So more epochs, that just means it's got looking at the training set over and over and over and over again and trying to learn those patterns. However, you might find again, if you try to train for too long, your testing error will start to go up. Your model might start overfitting if you train too long. So machine learning is all about a balance between underfitting and overfitting. You want your model to fit quite well. And so this is a great one. So you want your model to start fitting quite well. But then if you try to reduce underfitting too much, you might start to overfit and then vice versa, right? If you try to reduce overfitting too much, your model might underfit. So this is one of the most fun dances in machine learning, the balance between overfitting and underfitting. Finally, you might use transfer learning. So transfer learning helps with overfitting and underfitting. Recall transfer learning is using a model's learned patterns from Ron problem and adjusting them to your own. We're going to see this later on in the course. And then finally, use less regularization. So regularization is holding your model back. So it's trying to prevent overfitting. So if you do too much preventing of overfitting, in other words, regularizing your model, you might end up underfitting. So if we go back, we have a look at the ideal curves, underfitting. If you try to prevent underfitting too much, so increasing your model's capability to learn, you might end up overfitting. And if you try to prevent overfitting too much, you might end up underfitting. We are going for the just right section. And this is going to be a balance between these two throughout your entire machine learning career. In fact, it's probably the most prevalent area of research is trying to get models not to underfit, but also not to overfit. So keep that in mind. A loss curve is a great way to evaluate your model's performance over time. And a lot of what we do with the loss curves is try to work out whether our model is underfitting or overfitting, and we're trying to get to this just right curve. We might not get exactly there, but we want to keep trying getting as close as we can. So with that being said, let's now build another model in the next video. And we're going to try a method to try and see if we can use data augmentation to prevent our model from overfitting. Although that experiment doesn't sound like the most ideal one we could do right now, because it looks like our model is underfitting. So with your knowledge of what you've just learned in the previous video, how to prevent underfitting, what would you do to increase this model's capability of learning patterns in the training data set? Would you train it for longer? Would you add more layers? Would you add more hidden units? Have a think and we'll start building another model in the next video. Welcome back. In the last video, we covered the important concept of a loss curve and how it can give us information about whether our model is underfitting. In other words, our model's loss could be lower or whether it's overfitting. In other words, the training loss is lower than the test loss or far lower than the validation loss. That's another thing to note here is that I put training and test sets here. You could also do this with a validation data set and that the just right, the Goldilocks zone, is when our training and test loss are quite similar over time. Now, there was a fair bit of information in that last video, so I just wanted to highlight that you can get this all in section 04, which is the notebook that we're working on. And then if you come down over here, if we come to section 8, watch an ideal loss curve look like we've got underfitting, overfitting, just right, how to deal with overfitting. We've got a few options here. We've got how to deal with underfitting and then we've got a few options there. And then if we wanted to look for more, how to deal with overfitting. You could find a bunch of resources here and then how to deal with underfitting. You could find a bunch of resources here as well. So that is a very fine line, very fine balance that you're going to experience throughout all of your machine learning career. But it's time now to move on. We're going to move on to creating another model, which is tiny VGG, with data augmentation this time. So if we go back to the slide, data augmentation is one way of dealing with overfitting. Now, it's probably not the most ideal experiment that we could take because our model zero, our baseline model, looks like it's underfitting. But data augmentation, as we've seen before, is a way of manipulating images to artificially increase the diversity of your training data set without collecting more data. So we could take our photos of pizza, sushi, and steak and randomly rotate them 30 degrees and increase diversity forces a model to learn or hopefully learn. Again, all of these come with a caveat of not always being the silver bullet to learn more generalizable patterns. Now, I should have spelled generalizable here rather than generalization, but similar thing. Let's go here. Let's create to start off with, we'll just write down. Now let's try another modeling experiment. So this is in line with our PyTorch workflow, trying a model and trying another one and trying another one, so and so over again. This time, using the same model as before, but with some slight data augmentation. Oh, maybe we're not slight. That's probably not the best word. We'll just say with some data augmentation. And if we come down here, we're going to write section 9.1. We need to first create a transform with data augmentation. So we've seen what this looks like before. We're going to use the trivial augment data augmentation, create training transform, which is, as we saw in a previous video, what PyTorch the PyTorch team have recently used to train their state-of-the-art computer vision models. So train transform trivial. This is what I'm going to call my transform. And I'm just going to from Torch Vision import transforms. We've done this before. We don't have to re-import it, but I'm going to do it anyway, just to show you that we're re-importing or we're using transforms. And we're going to compose a transform here. Recall that transforms help us manipulate our data. So we're going to transform our images into size 64 by 64. Then we're going to set up a trivial augment transforms, just like we did before, trivial augment wide. And we're going to set the number of magnitude bins here to be 31, which is the default here, which means we'll randomly use some data augmentation on each one of our images. And it will be applied at a magnitude of 0 to 31, also randomly selected. So if we lower this to five, the upper bound of intensity of how much that data augmentation is applied to a certain image will be less than if we set it to say 31. Now, our final transform here is going to be too tensor because we want our images in tensor format for our model. And then I'm going to create a test transform. I'm going to call this simple, which is just going to be transforms dot compose. And all that it's going to have, oh, I should put a list here, all that it's going to have, we'll just make some space over here, is going to be transforms. All we want to do is resize the image size equals 64 64. Now we don't apply data augmentation to the test data set, because we only just want to evaluate our models on the test data set. Our models aren't going to be learning any generalizable patterns on the test data set, which is why we focus our data augmentations on the training data set. And I've just readjusted that. I don't want to do that. Beautiful. So we've got a transform ready. Now let's load some data using those transforms. So we'll create train and test data sets and data loaders with data augmentation. So we've done this before. You might want to try it out on your own. So pause the video if you'd like to test it out. Create a data set and a data loader using these transforms here. And recall that our data set is going to be creating a data set from pizza, steak and sushi for the train and test folders. And that our data loader is going to be batchifying our data set. So let's turn our image folders into data sets. Data sets, beautiful. And I'm going to write here train data augmented just so we know that it's it's been augmented. We've got a few of similar variable names throughout this notebook. So I just want to be as clear as possible. And I'm going to use, I'll just re import torch vision data sets. We've seen this before, the image folder. So rather than our use our own custom class, we're going to use the existing image folder class that's within torch vision data sets. And we have to pass in here a root. So I'll just get the doc string there, root, which is going to be equal to our trainer, which recall is the path to our training directory. Got that saved. And then I'm going to pass in here, the transform is going to be train transform trivial. So our training data is going to be augmented. Thanks to this transform here, and transforms trivial augment wide. You know where you can find more about trivial augment wide, of course, in the pie torch documentation, or just searching transforms trivial augment wide. And did I spell this wrong? trivial. Oh, train train transform. I spelled that wrong. Of course I did. So test data, let's create this as test data simple, equals data sets dot image folder. And the root D is going to be here the test directory. And the transform is just going to be what the test transform simple. Beautiful. So now let's turn these data sets into data loaders. So turn our data sets into data loaders. We're going to import os, I'm going to set the batch size here to equal to 32. The number of workers that are going to load our data loaders, I'm going to set this to os dot CPU count. So there'll be one worker per CPU on our machine. I'm going to set here the torch manual seed to 42, because we're going to shuffle our training data. Train data loader, I'm going to call this augmented equals data loader. Now I just want to I don't need to re import this, but I just want to show you again from torch dot utils. You can never have enough practice right dot data. Let's import data loader. So that's where we got the data loader class from. Now let's go train data augmented. We'll pass in that as the data set. And I'll just put in here the parameter name for completeness. That's our data set. And then we want to set the batch size, which is equal to batch size. I'm going to set shuffle equal to true. And I'm going to set num workers equal to num workers. Beautiful. And now let's do that again with the test data loader that this time test data loader. I'm going to call this test data loader simple. We're not using any data augmentation on the test data set, just turning our images, our test images into tenses. The data set here is going to be test data simple. Going to pass in the batch size equal to batch size. So both our data loaders will have a batch size of 32. Going to keep shuffle on false. And num workers, I'm going to set to num workers. Look at us go. We've already got a data set and a data loader. This time, our data loader is going to be augmented for the training data set. And it's going to be nice and simple for the test data set. So this is really similar, this data loader to the previous one we made. The only difference in this modeling experiment is that we're going to be adding data augmentation, namely trivial augment wide. So with that being said, we've got a data set, we've got a data loader. In the next video, let's construct and train model one. In fact, you might want to give that a go. So you can use our tiny VGG class to make model one. And then you can use our train function to train a new tiny VGG instance with our training data loader augmented and our test data loader simple. So give that a go and we'll do it together in the next video. I'll see you there. Now that we've got our data sets and data loaders with data augmentation ready, let's now create another model. So 9.3, we're going to construct and train model one. And this time, I'm just going to write what we're going to doing, going to be doing sorry. This time, we'll be using the same model architecture, but we're changing the data here. Except this time, we've augmented the training data. So we'd like to see how this performs compared to a model with no data augmentation. So that was our baseline up here. And that's what you'll generally do with your experiments. You'll start as simple as possible and introduce complexity when required. So create model one and send it to the target device, that is, to the target device. And because of our helpful selves previously, we can create a manual seed here, torch.manualseed. And we can create model one, leveraging the class that we created before. So although we built tiny VGG from scratch in this video, in this section, sorry, in subsequent coding sessions, because we've built it from scratch once and we know that it works, we can just recreate it by calling the class and passing in different variables here. So let's get the number of classes that we have in our train data augmented classes. And we're going to send it to device. And then if we inspect model one, let's have a look. Wonderful. Now let's keep going. We can also leverage our training function that we did. You might have tried this before. So let's now train our model. She's going to put here. Wonderful. Now we've got a model and data loaders. Let's create what do we have to do? We have to create a loss function and an optimizer and call upon our train function that we created earlier to train and evaluate our model. Beautiful. So I'm going to set the random seeds, torch dot manual seeds, and torch dot CUDA, because we're going to be using CUDA. Let's set the manual seed here 42. I'm going to set the number of epochs. We're going to keep many of the parameters the same. Set the number of epochs, num epochs equals five. We could of course train this model for longer if we really wanted to by increasing the number of epochs. But now let's set up the loss function. So loss FN equals NN cross entropy loss. Don't forget this just came into mind. Loss function often as well in PyTorch is called criterion. So the criterion you're trying to reduce. But I just like to call it loss function. And then we're going to have optimizer. Let's use the same optimizer we use before torch dot opt in dot atom. Recall SGD and atom are two of the most popular optimizers. So model one dot parameters. Then the parameters we're going to optimize. We're going to set the learning rate to zero zero one, which is the default for the atom optimizer in PyTorch. Then we're going to start the timer. So from time it, let's import the default timer as timer. And we'll go start time equals timer. And then let's go train model one. How can we do this? Well, we're going to get a results dictionary as model one results. We're going to call upon our train function. Inside our train function, we'll pass the model parameter as model one. For the train data loader parameter, we're going to pass in train data loader augmented. So our augmented training data loader. And for the test data loader, we can pass in here test data loader. Simple. Then we can write our optimizer, which will be the atom optimizer. Our loss function is going to be an n cross entropy loss, what we've created above. And then we can set the number of epochs is going to be equal to num epochs. And then if we really wanted to, we could set the device equal to device, which will be our target device. And now let's end the timer and print out how long it took. Took n time equals timer. And we'll go print total training time for model one is going to be n time minus start time. And oh, it would help if I could spell, we'll get that to three decimal places. And that'll be seconds. So you're ready? We look how quickly we built a training pipeline for model one. And look how big easily we created it. So go ask for coding all of that stuff up before. Let's train our second model, our first model using data augmentation. You're ready? Three, two, one, let's go. No errors. Beautiful. We're going nice and quick here. So oh, about just over seven seconds. So what what GPU do I have currently? Just keep this in mind that I'm using Google Colab Pro. So I get preference in terms of allocating a faster GPU. Your model training time may be longer than what I've got, depending on the GPU. It also may be faster, again, depending on the GPU. But we get about seven seconds, but it looks like our model with data augmentation didn't perform as well as our model without data augmentation. Hmm. So how long did our model before without data augmentation take the train? Oh, just over seven seconds as well. But we got better results in terms of accuracy on the training and test data sets for model zero. So maybe data augmentation doesn't help in our case. And we kind of hinted at that because the loss here was already going down. We weren't really overfitting yet. So recall that data augmentation is a way to help with overfitting generally. So maybe that wasn't the best step to try and improve our model. But let's nonetheless keep evaluating our model. In the next video, we're going to plot the loss curves of model one. So in fact, you might want to give that a go. So we've got a function plot loss curves, and we've got some results in a dictionary format. So try that out, plot the loss curves, and see what you see. Let's do it together in the next video. I'll see you there. In the last video, we did the really exciting thing of training our first model with data augmentation. But we also saw that quantitatively, it looks like that it didn't give us much improvement. So let's keep evaluating our model here. I'm going to make a section. Recall that one of my favorite ways or one of the best ways, not just my favorite, to evaluate the performance of a model over time is to plot the loss curves. So a loss curve helps you evaluate your model's performance over time. And it will also give you a great visual representation or a visual way to see if your model is underfitting or overfitting. So let's plot the loss curves of model one results and see what happens. We're using this function we created before. And oh my goodness, is that going in the right direction? It looks like our test loss is going up here. Now, is that where we want it to go? Remember the ideal direction for a loss curve is to go down over time because loss is measuring what? It's measuring how wrong our model is. And the accuracy curve looks like it's all over the place as well. I mean, it's going up kind of, but maybe we don't have enough time to measure these things. So an experiment that you could do is train both of our models model zero and model one for more epochs and see if these loss curves flatten out. So I'll pose you the question, is our model underfitting or overfitting right now or both? So if we want to have a look at the loss curves, our just right is for the loss that is, this is not for accuracy, this is for loss over time, we want it to go down. So for me, our model is underfitting because our loss could be lower, but it also looks like it's overfitting as well. So it's not doing a very good job because our test loss is far higher than our training loss. So if we go back to section four of the LearnPyTorch.io book, what should an ideal loss curve look like? I'd like you to start thinking of some ways that we could deal with overfitting of our model. So could we get more data? Could we simplify it? Could we use transfer learning? We're going to see that later on, but you might want to jump ahead and have a look. And if we're dealing with underfitting, what are some other things that we could try with our model? Could we add some more layers, potentially another convolutional block? Could we increase the number of hidden units per layer? So if we've got currently 10 hidden units per layer, maybe you want to increase that to 64 or something like that? Could we train it for longer? That's probably one of the easiest things to try with our current training functions. We could train for 20 epochs. So have a go at this, reference this, try out some experiments with, see if you can get these loss curves more towards the ideal shape. And in the next video, we're going to keep pushing forward. We're going to compare our model results. So we've done two experiments. Let's now see them side by side. We've looked at our model results individually, and we know that they could be improved. But a good way to compare all of your experiments is to compare your model's results side by side. So that's what we're going to do in the next video. I'll see you there. Now that we've compared our models loss curves on their own individually, how about we compare our model results to each other? So let's have a look at comparing our model results. And so I'm going to write a little note here that after evaluating our modeling experiments on their own, it's important to compare them to each other. And there's a few different ways to do this. There's a few different ways to do this. Number one is hard coding. So like we've done, we've written functions, we've written helper functions and whatnot, and manually plotted things. So I'm just going to write in here, this is what we're doing. Then, of course, there are tools to do this, such as PyTorch plus TensorBoard. So I'll link to this, PyTorch TensorBoard. We're going to see this in a later section of the course. TensorBoard is a great resource for tracking your experiments. If you'd like to jump forward and have a look at what that is in the PyTorch documentation, I'd encourage you to do so. Then another one of my favorite tools is weights and biases. So these are all going to involve some code as well, but they help out with automatically tracking different experiments. So weights and biases is one of my favorite, and you've got platform for experiments. That's what you'll be looking at. So if you run multiple experiments, you can set up weights and biases pretty easy to track your different model hub parameters. So PyTorch, there we go. Import weights and biases, start a new run on weights and biases. You can save the learning rate value and whatnot, go through your data and just log everything there. So this is not a course about different tools. We're going to focus on just pure PyTorch, but I thought I'd leave these here anyway, because you're going to come across them eventually, and MLflow is another one of my favorites as well. We have ML tracking, projects, models, registry, all that sort of stuff. If you'd like in to look into more ways to track your experiments, there are some extensions. But for now, we're going to stick with hard coding. We're just going to do it as simple as possible to begin with. And if we wanted to add other tools later on, we can sure do that. So let's create a data frame for each of our model results. We can do this because our model results recall are in the form of dictionaries. So model zero results. But you can see what we're doing now by hard coding this, it's quite cumbersome. Can you imagine if we had say 10 models or even just five models, we'd have to really write a fair bit of code here for all of our dictionaries and whatnot, whereas these tools here help you to track everything automatically. So we've got a data frame here. Model zero results over time. These are our number of epochs. We can notice that the training loss starts to go down. The testing loss also starts to go down. And the accuracy on the training and test data set starts to go up. Now, those are the trends that we're looking for. So an experiment you could try would be to train this model zero for longer to see if it improved. But we're currently just interested in comparing results. So let's set up a plot. I want to plot model zero results and model one results on the same plot. So we'll need a plot for training loss. We'll need a plot for training accuracy, test loss and test accuracy. And then we want two separate lines on each of them. One for model zero and one for model one. And this particular pattern would be similar regardless if we had 10 different experiments, or if we had 10 different metrics we wanted to compare, you generally want to plot them all against each other to make them visual. And that's what tools such as weights and biases, what TensorBoard, and what ML flow can help you to do. I'm just going to get out of that, clean up our browser. So let's set up a plot here. I'm going to use matplotlib. I'm going to put in a figure. I'm going to make it quite large because we want four subplots, one for each of the metrics we want to compare across our different models. Now, let's get number of epochs. So epochs is going to be length, or we'll turn it into a range, actually, range of Len model zero DF. So that's going to give us five. Beautiful range between zero and five. Now, let's create a plot for the train loss. We want to compare the train loss across model zero and the train loss across model one. So we can go PLT dot subplot. Let's create a plot with two rows and two columns. And this is going to be index number one will be the training loss. We'll go PLT dot plot. I'm going to put in here epochs and then model zero DF. Inside here, I'm going to put train loss for our first metric. And then I'm going to label it with model zero. So we're comparing the train loss on each of our modeling experiments. Recall that model zero was our baseline model. And that was tiny VGG without data augmentation. And then we tried out model one, which was the same model. But all we did was we added a data augmentation transform to our training data. So PLT will go x label. They both used the same test data set and PLT dot legend. Let's see what this looks like. Wonderful. So there's our training loss across two different models. So we notice that model zero is trending in the right way. Model one kind of exploded on epoch number that would be zero, one, two, or one, depending how you're counting. Let's just say epoch number two, because that's easier. The loss went up. But then it started to go back down. So again, if we continued training these models, we might notice that the overall trend of the loss is going down on the training data set, which is exactly what we'd like. So let's now plot, we'll go the test loss. So I'm going to go test loss here. And then I'm going to change this. I believe if I hold control, or command, maybe, nope, or option on my Mac keyboard, yeah, so it might be a different key on Windows. But for me, I can press option and I can get a multi cursor here. So I'm just going to come back in here. And that way I can backspace there and just turn this into test loss. Wonderful. So I'm going to put this as test loss as the title. And I need to change the index. So this will be index one, index two, index three, index four. Let's see what this looks like. Do we get the test loss? Beautiful. That's what we get. However, we noticed that model one is probably overfitting at this stage. So maybe the data augmentation wasn't the best change to make to our model. Recall that even if you make a change to your model, such as preventing overfitting or underfitting, it won't always guarantee that the change takes your model's evaluation metrics in the right direction. Ideally, loss is going from top left to bottom right over time. So looks like model zero is winning out here at the moment on the loss front. So now let's plot the accuracy for both training and test. So I'm going to change this to train. I'm going to put this as accuracy. And this is going to be index number three on the plot. And do we save it as, yeah, just act? Wonderful. So I'm going to option click here on my Mac. This is going to be train. And this is going to be accuracy here. And then I'll change this one to accuracy. And then I'm going to change this to accuracy. And this is going to be plot number four, two rows, two columns, index number four. And I'm going to option click here to have two cursors, test, act. And then I'll change this to test, act. And I'm going to get rid of the legend here. It takes a little bit to plot because we're doing four graphs in one hit. Wonderful. So that's comparing our models. But do you see how we could potentially functionalize this to plot, however, many model results that we have? But if we had say another five models, we did another five experiments, which is actually not too many experiments on a problem, you might find that sometimes you do over a dozen experiments for a single modeling problem, maybe even more. These graphs can get pretty outlandish with all the little lines going through. So that's again what tools like TensorBoard, weights and biases and MLflow will help with. But if we have a look at the accuracy, it seems that both of our models are heading in the right direction. We want to go from the bottom left up in the case of accuracy. But the test accuracy that's training, oh, excuse me, is this not training accuracy? I messed up that. Did you catch that one? So training accuracy, we're heading in the right direction, but it looks like model one is yeah, still overfitting. So the results we're getting on the training data set aren't coming over to the testing data set. And that's what we really want our models to shine is on the test data set. So metrics on the training data set are good. But ideally, we want our models to perform well on the test data set data it hasn't seen before. So that's just something to keep in mind. Whenever you do a series of modeling experiments, it's always good to not only evaluate them individually, evaluate them against each other. So that way you can go back through your experiments, see what worked and what didn't. If you were to ask me what I would do for both of these models, I would probably train them for longer and maybe add some more hidden units to each of the layers and see where the results go from there. So give that a shot. In the next video, let's see how we can use our trained models to make a prediction on our own custom image of food. So yes, we used a custom data set of pizza steak and sushi images. But what if we had our own, what if we finished this model training and we decided, you know what, this is a good enough model. And then we deployed it to an app like neutrify dot app, which is a food recognition app that I'm personally working on. Then we wanted to upload an image and have it be classified by our pytorch model. So let's give that a shot, see how we can use our trained model to predict on an image that's not in our training data and not in our testing data. I'll see you in the next video. Welcome back. In the last video, we compared our modeling experiments. Now we're going to move on to one of the most exciting parts of deep learning. And that is making a prediction on a custom image. So although we've trained a model on custom data, how do you make a prediction on a sample slash image in our case? That's not in either the training or testing data set. So let's say you were building a food recognition app, such as neutrify, take a photo of food and learn about it. You wanted to use computer vision to essentially turn foods into QR codes. So I'll just show you the workflow here. If we were to upload this image of my dad giving two thumbs up for a delicious pizza. And what does neutrify predicted as pizza? Beautiful. So macaronutrients that you get some nutrition information and then the time taken. So we could replicate a similar process to this using our trained PyTorch model, or be it. It's not going to be too great of results or performance because we've seen that we could improve our models, but based on the accuracy here and based on the loss and whatnot. But let's just see what it's like, the workflow. So the first thing we're going to do is get a custom image. Now we could upload one here, such as clicking the upload button in Google Colab, choosing an image and then importing it like that. But I'm going to do so programmatically, as you've seen before. So let's write some code in this video to download a custom image. I'm going to do so using requests and like all good cooking shows, I've prepared a custom image for us. So custom image path. But again, you could use this process that we're going to go through with any of your own images of pizza, steak or sushi. And if you wanted to train your own model on another set of custom data, the workflow will be quite similar. So I'm going to download a photo called pizza dad, which is my dad, two big thumbs up. And so I'm going to download it from github. So this image is on the course github. And let's write some code to download the image. If it doesn't already exist in our Colab instance. So if you wanted to upload a single image, you could click with this button. Just be aware that like all of our other data, it's going to disappear if Colab disconnects. So that's why I like to write code. So we don't have to re upload it every time. So if not custom image path is file, let's open a request here or open a file going to open up the custom image path with right binary permissions as F short for file. And then when downloading, this is because our image is stored on github. When downloading an image or when downloading from github in general, you typically want the raw link need to use the raw file link. So let's write a request here equals request dot get. So if we go to the pytorch deep learning repo, then if we go into, I believe it might be extras, not in extras, it's going to be in images, that would make a lot more sense. Wouldn't it Daniel? Let's get O for pizza dad. So if we have a look, this is pytorch deep learning images, O for pizza dad. There's a big version of the image there. And then if we click download, just going to give us the raw link. Yeah, there we go. So that's the image. Hey dad, how you doing? Is that pizza delicious? It looks like it. Let's see if our model can get this right. What do you think? Will it? So of course, we want our model to predict pizza for this image because it's got a pizza in it. So custom image path, we're going to download that. I've just put in the raw URL above. So notice the raw github user content. That's from the course github. Then I'm going to go f dot right. So file, write the request content. So the content from the request, in other words, the raw file from github here. Similar workflow for if you were getting another image from somewhere else on the internet and else if it is already downloaded, let's just not download it. So print f custom image path already exists skipping download. And let's see if this works or run the code. So downloading data o four pizza dad dot jpeg. And if we go into here, we refresh. There we go. Beautiful. So our data or our custom image, sorry, is now in our data folder. So if we click on this, this is inside Google CoLab now. Beautiful. We got a big nice big image there. And there's a nice big pizza there. So we're going to be writing some code over the next few videos to do the exact same process as what we've been doing to import our custom data set for our custom image. What do we still have to do? We still have to turn it into tenses. And then we have to pass it through our model. So let's see what that looks like over the next few videos. We are up to one of the most exciting parts of building dev learning models. And that is predicting on custom data in our case, a custom image of a photo of my dad eating pizza. So of course, we're training a computer vision model on here on pizza steak and sushi. So hopefully the ideal result for our model to predict on this image will be pizza. So let's keep going. Let's figure out how we can get our image, our custom image, our singular image into Tensor form, loading in a custom image with pytorch, creating another section here. So I'm just going to write down here, we have to make sure our custom image is in the same format as the data our model was trained on. So namely, that was in Tensor form with data type torch float 32. And then of shape 64 by 64 by three. So we might need to change the shape of our image. And then we need to make sure that it's on the right device. Command MM, beautiful. So let's see what this looks like. Hey, so if I'm going to import torch vision. Now the package you use to load your data will depend on the domain you're in. So let's open up the torch vision documentation. We can go to models. That's okay. So if we're working with text, you might want to look in here for some input and output functions, so some loading functions, torch audio, same thing. Torch vision is what we're working with. Let's click into torch vision. Now we want to look into reading and writing images and videos because we want to read in an image, right? We've got a custom image. We want to read it in. So this is part of your extracurricular, by the way, to go through these for at least 10 minutes each. So spend an hour if you're going through torch vision. You could do the same across these other ones. It will just really help you familiarize yourself with all the functions of PyTorch domain libraries. So we want to look here's some options for video. We're not working with video. Here's some options for images. Now what do we want to do? We want to read in an image. So we've got a few things here. Decode image. Oh, I've skipped over one. We can write a JPEG if we wanted to. We can encode a PNG. Let's jump into this one. Read image. What does it do? Read the JPEG or PNG into a three-dimensional RGB or grayscale tensor. That is what we want. And then optionally converts the image to the desired format. The values of the output tensor are you int eight. Okay. Beautiful. So let's see what this looks like. Okay. Mode. The read mode used optionally for converting the image. Let's see what we can do with this. I'm going to copy this in. So I'll write this down. We can read an image into PyTorch using and go with that. So let's see what this looks like in practice. Read in custom image. I can't explain to you how much I love using deep learning models to predict on custom data. So custom image. We're going to call it you int eight because as we read from the documentation here, it reads it in you int eight format. So let's have a look at what that looks like rather than just talking about it. Torch vision.io. Read image. What's our target image path? Well, we've got custom image path up here. This is why I like to do things programmatically. So if our collab notebook reset, we could just run this cell again, get our custom image and then we've got it here. So custom image you int eight. Let's see what this looks like. Oh, what did we get wrong? Unable to cast Python instance. Oh, does it need to be a string expected a value type of string or what found POSIX path? So this the path needs to be a string. Okay. If we have a look at our custom image path, what did we get wrong? Oh, we've got a POSIX path. So let's convert this custom image path into a string and see what happens. Look at that. That's how image in integer form. I wonder if this is plotable. Let's go PLT dot M show custom image you int eight. Maybe we get a dimensionality problem here in valid shape. Okay. Let's some permute it, permute, and we'll go one, two, zero. Is this going to plot? It's a fairly big image. There we go. Two thumbs up. Look at us. So that is the power of torch vision.io. I owe stands for input output. We were just able to read in our custom image. Now, how about we get some metadata about this? Let's go. We'll print it up here, actually. I'll keep that there because that's fun to plot it. Let's find the shape of our data, the data type. And yeah, we've got it in Tensor format, but it's you int eight right now. So we might have to convert that to float 32. We want to find out its shape. And we need to make sure that if we're predicting on a custom image, the data that we're predicting on the custom image needs to be on the same device as our model. So let's print out some info. Print. Let's go custom image Tensor. And this is going to be a new line. And then we will go custom image you int eight. Wonderful. And then let's go custom image shape. We will get the shape parameter custom image shape or attribute. Sorry. And then we also want to know the data type custom image data type. But we have a kind of an inkling because the documentation said it would be you int eight, you int eight, and we'll go D type. Let's have a look. What do we have? So there's our image Tensor. And it's quite a big image. So custom image shape. So what was our model trained on? Our model was trained on images of 64 by 64. So this image encodes a lot more information than what our model was trained on. So we're going to have to change that shape to pass it through our model. And then we've got an image data type here or Tensor data type of torch you int eight. So maybe that's going to be some errors for us later on. So if you want to go ahead and see if you can resize this Tensor to 64 64 using a torch transform or torch vision transform, I'd encourage you to try that out. And if you know how to change a torch tensor from you int eight to torch float 32, give that a shot as well. So let's try make a prediction on our image in the next video. I'll see you there. In the last video, we loaded in our own custom image and got two big thumbs up from my dad, and we turned it into a tensor. So we've got a custom image tensor here. It's quite big though, and we looked at a few things of what we have to do before we pass it through our model. So we need to make sure it's in the data type torch float 32, shape 64, 64, 3, and on the right device. So let's make another section here. We'll go 11.2 and we'll call it making a prediction on a custom image with a pie torch model with a trained pie torch model. And albeit, our models aren't quite the level we would like them at yet. I think it's important just to see what it's like to make a prediction end to end on some custom data, because that's the fun part, right? So try to make a prediction on an image. Now, I want to just highlight something about the importance of different data types and shapes and whatnot and devices, three of the biggest errors in deep learning. In let's see what happens if we try to predict on you int eight format. So we'll go model one dot eval and with torch dot inference mode. Let's make a prediction. We'll pass it through our model one. We could use model zero if we wanted to here. They're both performing pretty poorly anyway. Let's send it to the device and see what happens. Oh, no. What did we get wrong here? Runtime error input type. Ah, so we've got you int eight. So this is one of our first errors that we talked about. We need to make sure that our custom data is of the same data type that our model was originally trained on. So we've got torch CUDA float tensor. So we've got an issue here. We've got a you into eight image data or image tensor trying to be predicted on by a model with its data type of torch CUDA float tensor. So let's try fix this by loading the custom image and convert to torch dot float 32. So one of the ways we can do this is we'll just recreate the custom image tensor. And I'm going to use torch vision dot IO dot read image. We don't have to fully reload our image, but I'm going to do it anyway for completeness and a little bit of practice. And then I'm going to set the type here with the type method to torch float 32. And then let's just see what happens. We'll go custom image. Let's see what this looks like. I wonder if our model will work on this. Let's just try again, we'll bring this up, copy this down to make a prediction and custom image dot two device. Our image is in torch float 32 now. Let's see what happens. Oh, we get an issue. Oh my goodness, that's a big matrix. Now I have a feeling that that might be because our image, our custom image is of a shape that's far too large. Custom image dot shape. What do we get? Oh my gosh, 4000 and 3,024. And do you notice as well that our values here are between zero and one, whereas our previous images, do we have an image? There we go. That our model was trained on what between zero and one. So how could we get these values to be between zero and one? Well, one of the ways to do so is by dividing by 255. Now, why would we divide by 255? Well, because that's a standard image format is to store the image tensor values in values from zero to 255 for red, green and blue color channels. So if we want to scale them, so this is what I meant by zero to 255, if we wanted to scale these values to be between zero and one, we can divide them by 255. Because that is the maximum value that they can be. So let's see what happens if we do that. Okay, we get our image values between zero and one. Can we plot this image? So plt dot m show, let's plot our custom image. We got a permute it. So it works nicely with mapplotlib. What do we get here? Beautiful. We get the same image, right? But it's still quite big. Look at that. We've got a pixel height of or image height of almost 4000 pixels and a width of over 3000 pixels. So we need to do some adjustments further on. So let's keep going. We've got custom image to device. We've got an error here. So this is a shape error. So what can we do to transform our image shape? And you might have already tried this. Well, let's create a transform pipeline to transform our image shape. So create transform pipeline or composition to resize the image. Because remember, what are we trying to do? We're trying to get our model to predict on the same type of data it was trained on. So let's go custom image transform is transforms dot compose. And we're just going to, since our image is already of a tensor, let's do transforms dot resize, and we'll set the size to the same shape that our model was trained on, or the same size that is. So let's go from torch vision. We don't have to rewrite this. It's already imported. But I just want to highlight that we're using the transforms package. We'll run that. There we go. We've got a transform pipeline. Now let's see what happens when we transform our target image, transform target image. What happens? Custom image transformed. I love printing the inputs and outputs of our different pipelines here. So let's pass our custom image that we've just imported. So custom image transform, our custom image is recall of shape. Quite large. We're going to pass it through our transformation pipeline. And let's print out the shapes. Let's go original shape. And then we'll go custom image dot shape. And then we'll go print transformed shape is going to be custom image underscore transformed dot shape. Let's see the transformation. Oh, would you look at that? How good we've gone from quite a large image to a transformed image here. So it's going to be squished and squashed a little. So that's what happens. Let's see what happens when we plot our transformed image. We've gone from 4000 pixels on the height to 64. And we've gone from 3000 pixels on the height to 64. So this is what our model is going to see. Let's go custom image transformed. And we're going to permute it to be 120. Okay, so quite pixelated. Do you see how this might affect the accuracy of our model? Because we've gone from custom image, is this going to, oh, yeah, we need to plot dot image. So we've gone from this high definition image to an image that's of far lower quality here. And I can kind of see myself that this is still a pizza, but I know that it's a pizza. So just keep this in mind going forward is that another way that we could potentially improve our model's performance if we increased the size of the training image data. So instead of 64 64, we might want to upgrade our models capability to deal with images that are of 224 224. So if we have a look at what this looks like 224 224. Wow, that looks a lot better than 64 64. So that's something that you might want to try out later on. But we're going to stick in line with the CNN explainer model. How about we try to make another prediction? So since we transformed our image to be the same size as the data our model was trained on. So with torch inference mode, let's go custom image pred equals model one on custom image underscore transformed. Does it work now? Oh my goodness, still not working expected all tensors on the same device. Of course, that's what we forgot here. Let's go to device. Or actually, let's leave that error there. And we'll just copy this code down here. And let's put this custom image transform back on the right device and see if we finally get a prediction to happen with our model. Oh, we still get an error. Oh my goodness, what's going on here? Oh, we need to add a batch size to it. So I'm just gonna write up here. This will error. No batch size. And this will error. Image not on right device. And then let's try again, we need to add a batch size to our image. So if we look at custom image transformed dot shape, recall that our images that passed through our model had a batch dimension. So this is another place where we get shape mismatch issues is if our model, because what's going on in neural network is a lot of tensor manipulation. If the dimensions don't line up, we want to perform matrix multiplication and the rules. If we don't play to the rules, the matrix multiplication will fail. So let's fix this by adding a batch dimension. So we can do this by going a custom image transformed. Let's unsqueeze it on the first dimension and then check the shape. There we go. We add a single batch. So that's what we want to do when we make a prediction on a single custom image. We want to pass it to our model as an image or a batch of one sample. So let's finally see if this will work. Let's just not comment what we'll do. This, or maybe we'll try anyway, this should work. Added a batch size. So do you see the steps we've been through so far? And we're just going to unsqueeze this. Unsqueeze on the zero dimension to add a batch size. Oh, it didn't error. Oh my goodness. It didn't error. Have a look at that. Yes, that's what we want. We get a prediction load it because the raw outputs of our model, we get a load it value for each of our custom classes. So this could be pizza. This could be steak. And this could be sushi, depending on the order of our classes. Let's just have a look. Class to IDX. Did we not get that? Class names. Beautiful. So pizza steak sushi. We've still got a ways to go to convert this into that. But I just want to highlight what we've done. So note, to make a prediction on a custom image, we had to. And this is something you'll have to keep in mind for almost all of your custom data. It needs to be formatted in the same way that your model was trained on. So we had to load the image and turn it into a tensor. We had to make sure the image was the same data type as the model. So that was torch float 32. And then we had to make sure the image was the same shape as the data the model was trained on, which was 64, 64, three with a batch size. So that was one, three, 64, 64. And excuse me, this should actually be the other way around. This should be color channels first, because we're dealing with pie torch here. 64. And then finally, we had to make sure the image was on the same device as our model. So they are three of the big ones that we've talked about so much the same data type or data type mismatch will result in a bunch of issues. Shape mismatch will result in a bunch of issues. And device mismatch will also result in a bunch of issues. If you want these to be highlighted, they are in the learn pie torch.io resource. We have putting things together. Where do we have it? Oh, yeah, no, it's in the main takeaway section, sorry, predicting on your own custom data with a trained model as possible, as long as you format the data into a similar format to what the model was trained on. So make sure you take care of the three big pie torch and deep learning errors. Wrong data types, wrong data shapes, and wrong devices, regardless of whether that's images or audio or text, these three will follow you around. So just keep them in mind. But now we've got some code to predict on custom images, but it's kind of all over the place. We've got about 10 coding cells here just to make a prediction on a custom image. How about we functionize this and see if it works on our pizza dad image. I'll see you in the next video. Welcome back. We're now well on our way to making custom predictions on our own custom image data. Let's keep pushing forward. In the last video, we finished off getting some raw model logits. So the raw outputs from our model. Now, let's see how we can convert these logits into prediction labels. Let's write some code. So convert logits to prediction labels. Or let's go convert logits. Let's first convert them to prediction probabilities. Probabilities. So how do we do that? Let's go custom image pred probes equals torch dot softmax to convert our custom image pred across the first dimension. So the first dimension of this tensor will be the inner brackets, of course. So just this little section here. Let's see what these look like. This will be prediction probabilities. Wonderful. So you'll notice that these are quite spread out. Now, this is not ideal. Ideally, we'd like our model to assign a fairly large prediction probability to the target class, the right target class that is. However, since our model when we trained it isn't actually performing that all that well. The prediction probabilities are quite spread out across all of the classes. But nonetheless, we're just highlighting what it's like to predict on custom data. So now let's convert the prediction probabilities to prediction labels. Now, you'll notice that we used softmax because why we are working with multi class classification data. And so we can get the custom image pred labels, the integers, by taking the argmax of the prediction probabilities, custom image pred probes across the first dimension as well. So let's go custom image pred labels. Let's see what they look like. Zero. So the index here with the highest value is index number zero. And you'll notice that it's still on the coded device. So what would happen if we try to index on our class names with the custom image pred labels? Or maybe that doesn't need to be a plural. Oh, there we go. We get pizza. But you might also have to change this to the CPU later on. Otherwise, you might run into some errors. So just be aware of that. So you notice how we just put it to the CPU. So we get pizza. We got a correct prediction. But this is as good as guessing in my opinion, because these are kind of spread out. Ideally, this value would be higher, maybe something like 0.8 or above for our pizza dad image. But nonetheless, our model is getting two thumbs up even on this 64 by 64 image. But that's a lot of code that we've written. Let's functionize it. So we can just pass in a file path and get a custom prediction from it. So putting custom image prediction together. Let's go building a function. So we want the ideal outcome is, let's plot our image as well. Ideal outcome is a function where we plot or where we pass an image path to and have our model predict on that image and plot the image plus the prediction. So this is our ideal outcome. And I think I'm going to issue this as a challenge. So give that a go, put all of our code above together. And you'll just have to import the image, you'll have to process it and whatnot. I know I said we were going to build a function in this video, but we're going to say that to the next video. I'd like you to give that a go. So start from way back up here, import the image via torture vision.io read image, format it using what we've done, change the data type, change the shape, change the device, and then plot the image with its prediction as the title. So give that a go and we'll do it together in the next video. How'd you go? I just realized I had a typo in the previous cell, but that's all right. Did you give it a shot? Did you put together the custom image prediction in a function format? I'd love it if you did. But if not, that's okay. Let's keep going. Let's see what that might look like. And there are many different ways that you could do this. But here's one of the ways that I've thought of. So we want to function that's going to pred and plot a target image. We wanted to take in a torch model. And so that's going to be ideally a trained model. We wanted to also take in an image path, which will be of a string. It can take in a class names list so that we can index it and get the prediction label in string format. So let's put this as a list of strings. And by default, this can equal none. Just in case we just wanted the prediction, it wants to take in a transform so that we can pass it in some form of transform to transform the image. And then it's going to take in a device, which will be by default the target device. So let's write a little doc string here, makes a prediction on a target image with a trained model and plots the image and prediction. Beautiful. Now what do we have to do first? Let's load in the image. Load in the image just like we did before with torch vision. So target image equals torch vision.io dot read image. And we'll go string on the image path, which will be the image path here. And we convert it to a string just in case it doesn't get passed in as a string. And then let's change it into type torch float 32. Because we want to make sure that our custom image or our custom data is in the same type as what we trained our model on. So now let's divide the image pixel values by 255 to get them between zero or to get them between zero one as a range. So we can just do this by target image equals target image divided by 255. And we could also just do this in one step up here 255. But I've just put it out there just to let you know that, hey, read image imports image data as between zero and 255. So our model prefers numbers between zero and one. So let's just scale it there. Now we want to transform our data if necessary. In our case, it is, but it won't always be. So we want this function to be pretty generic predomplot image. So if the transform exists, let's set the target image to the transform, or we'll pass it through the transform that is wonderful. And the transform we're going to get from here. Now what's left to do? Well, let's make sure the model is on the target device. It might be by default, but if we're passing in a device parameter, we may as well make sure the model is there too. And now we can make a prediction. So let's turn on a vowel slash inference mode and make a prediction with our model. So model, we call a vowel mode, and then with torch dot inference mode, because we're making a prediction, we want to turn our model into inference mode, or put it in inference mode context. Let's add an extra dimension to the image. Let's go target image. We could do this step above, actually, but we're just going to do it here. From kind of remembering things on the fly here of what we need to do, we're adding a, this is, let's write this down, this is the batch dimension. e g our model will predict on batches of one x image. So we're just unsqueezing it to add an extra dimension at the zero dimension space, just like we did in a previous video. Now let's make a prediction on the image with an extra dimension. Otherwise, if we don't have that extra dimension, we saw that we get a shape issue. So right down here, target image pred. And remember, this is going to be the raw model outputs, raw logit outputs. We're going to target image pred. And yeah, I believe that's all we need for the prediction. Oh wait, there was one more thing, two device. Me too. Also make sure the target image is on the right device. Beautiful. So fair few steps here, but nothing we can't handle. All we're really doing is replicating what we've done for batches of images. But we want to make sure that if someone passed any image to our pred and plot image function, that we've got functionality in here to handle that image. And do we get this? Oh, we want just target image to device. Did you catch that error? So let's keep going. Now let's convert the logits. Our models raw logits. Let's convert those to prediction probabilities. This is so exciting. We're getting so close to making a function to predict on custom data. So we'll set this to target image pred probes, which is going to be torch dot softmax. And we will pass in the target image pred here. We want to get the softmax of the first dimension. Now let's convert our prediction probabilities, which is what we get in the line above. We want to convert those to prediction labels. So let's get the target image pred labels labels equals torch dot argmax. We want to get the argmax of, or in other words, the index, which is the maximum value from the pred probes of the first dimension as well. Now what should we return here? Well, we don't really need to return anything. We want to create a plot. So let's plot the image alongside the prediction and prediction probability. Beautiful. So plot dot in show, what are we going to pass in here? We're going to pass in here our target image. Now we have to squeeze this, I believe, because we've added an extra dimension up here. So we'll squeeze it to remove that batch size. And then we still have to permute it because map plot lib likes images in the format color channels last one, two, zero. So remove batch dimension. And rearrange shape to be hc hwc. That is color channels last. Now if the class names parameter exists, so we've passed in a list of class names, this function is really just replicating everything we've done in the past 10 cells, by the way. So right back up here, we're replicating all of this stuff in one function. So pretty large function, but once we've written it, we can pass in our images as much as we like. So if class names exist, let's set the title to our showcase that class name. So the pred is going to be class names. Let's index on that pred image, or target image pred label. And this is where we'll have to put it to the CPU, because if we're using a title with map plot lib, map plot lib cannot handle things that are on the GPU. This is why we have to put it to the CPU. And then I believe that should be enough for that. Let's add a little line in here, so that we can have it. Oh, I've missed something. An outside bracket there. Wonderful. Let's add the prediction probability, because that's always fun to see. So we want target image pred probs. And we want to get the maximum pred problem from that. And we'll also put that on the CPU. And I think we might get this three decimal places. Now this is saying, oh, pred labels, we don't need that. We need just non plural, beautiful. Now, if the class names doesn't exist, let's just set the title equal to f f string, we'll go pred, target image pred label. Is Google Colab still telling me this is wrong? Target image pred label. Oh, no, we've still got the same thing. It just hasn't caught up with me, and I'm coding a bit fast here. And then we'll pass in the prob, which will be just the same as above. I could even copy this in. Beautiful. And let's now set the title to the title. And we and we will turn the axes off. PLT axes false. Fair bit of code there. But this is going to be a super exciting moment. Let's see what this looks like. When we pass it in a target image and a target model, some class names, and a transform. Are you ready? We've got our transform ready, by the way, it's back up here. Custom image transform. It's just going to resize our image. So let's see. Oh, this file was updated remotely or in another tab. Sometimes this happens, and usually Google Colab sorts itself out, but that's all right. It doesn't affect our code for now. Pred on our custom image. Are you ready? Save failed. Would you like to override? Yes, I would. So you might see that in Google Colab. Usually it fixes itself. There we go. Save successfully. Pred and plot image. I was going to say, Google Colab, don't fail me now. We're about to predict on our own custom data. Using a model trained on our own custom data. Image part. Let's pass in custom image path, which is going to be the path to our pizza dad image. Let's go class names, equals class names, which is pizza, steak, and sushi. We'll pass in our transform to convert our image to the right shape and size custom image transform. And then finally, the target device is going to be device. Are you ready? Let's make a prediction on custom data. One of my favorite things. One of the most fun things to do when building deep learning models. Three, two, one. How did it go? Oh, no. What did we get wrong? CPU. Okay. Such a so close, but yet so far. Has no attribute CPU. Oh, maybe we need to put this to CPU. That's where I got the square bracket wrong. So that's what we needed to change. We needed to because this is going to be potentially on the GPU. Tag image pred label. We need to put it on the CPU. We need to do that. Why? Because this is going to be the title of our map plot lib plot. And map plot lib doesn't interface too well with data on a GPU. Let's try it again. Three, two, one, running. Oh, look at that. Prediction on a custom image. And it gets it right. Two thumbs up. I didn't plan this. Our model is performing actually quite poorly. So this is as good as a guess to me. You might want to try this on your own image. And in fact, if you do, please share it with me. I would love to see it. But you could potentially try this with another model. See what happens? Steak. Okay, there we go. So even though model one performs worse quantitatively, it performs better qualitatively. So that's the power of a visualize, visualize, visualize. And if we use model zero, also, which isn't performing too well, it gets it wrong with a prediction probability of 0.368, which isn't too high either. So we've talked about a couple of different ways to improve our models. Now we've even got a way to make predictions on our own custom images. So give that a shot. I'd love to see your custom predictions, upload an image here if you want, or download it into Google Colab using code that we've used before. But we've come a fairly long way. I feel like we've covered enough for custom data sets. Let's summarize what we've covered in the next video. And I've got a bunch of exercises and extra curriculum for you. So this is exciting stuff. I'll see you in the next video. In the last video, we did the very exciting thing of making a prediction on our own custom image, although it's quite pixelated. And although our models performance quantitatively didn't turn out to be too good qualitatively, it happened to work out. But of course, there are a fair few ways that we could improve our models performance. But the main takeaway here is that we had to do a bunch of pre processing to make sure our custom image was in the same format as what our model expected. And this is quite a lot of what I do behind the scenes for Nutrify. If you upload an image here, it gets pre processed in a similar way to go through our image classification model to output a label like this. So let's get out of this. To summarize, I've got a colorful slide here, but we've already covered this predicting on custom data. These are three things to make sure of, regardless of whether you're using images, text or audio, make sure your data is in the right data type. In our case, it was torch float 32. Make sure your data is on the same device as the model. So we had to put our custom image to the GPU, which was where our model also lived. And then we had to make sure our data was in the correct shape. So the original shape was 64, 64, 3. Actually, this should be reversed, because it was color channels first. But the same principle remains here. We had to add a batch dimension and rearrange if we needed. So in our case, we used images of this shape batches first color channels first height width. But depending on your problem will depend on your shape, depending on the device you're using will depend on where your data and your model lives. And depending on the data type you're using will depend on what you're using for torch float 32 or something else. So let's summarize. If we go here main takeaways, you can read through these, but some of the big ones are pie torch has many built in functions to deal with all kinds of data from vision to text to audio to recommendation systems. So if we look at the pie torch docs, you're going to become very familiar with these over time. We've got torch audio data, torch text, torch vision is what we practiced with. And we've got a whole bunch of things here for transforming and augmenting images, data sets, utilities, operators, and torch data is currently in beta. But this is just something to be aware of later on. So it's a prototype library right now, but by the time you watch this, it might be available. But it's another way of loading data. So just be aware of this for later on. And if we come back to up here, if applied to watch built in data loading functions, don't suit your requirements, you can write your own custom data set classes by subclassing torch dot utils dot data dot data set. And we saw that way back up here in option number two. Option two, here we go, loading image data with a custom data set, wrote plenty of code to do that. And then a lot of machine learning is dealing with the balance between overfitting and underfitting. We've got a whole section in the book here to check out what an ideal loss curve should look like and how to deal with overfitting, how to deal with underfitting. It's it is a fine line. So much of the research and machine learning is actually dedicated towards this balance. And then three big things for being aware of when you're predicting on your own custom data, wrong data types, wrong data shapes, and wrong devices. This will follow you around, as I said, and we saw that in practice to get our own custom image ready for a trained model. Now, we have some exercises here. If you'd like the link to it, you can go to loan pytorch.io section number four exercises, and of course, extra curriculum. A lot of the things I've mentioned throughout the course that would be a good resource to check out contained in here. But the exercises, this is this is your time to shine, your time to practice. Let's go back to this notebook, scroll right down to the bottom. Look how much code we've written. Goodness me, exercises for all exercises and extra curriculum. See here, turn that into markdown. Wonderful. And so if we go in here, you've got a couple of resources. There's an exercise template notebook for number four, and example solutions for notebook number four, which is what we're working on now. So of course, I'd encourage you to go through the pytorch custom data sets exercises template first. Try to fill out all of the code here on your own. So we've got some questions here. We've got some dummy code. We've got some comments. So give that a go. Go through this. Use this book resource to reference. Use all the code we've written. Use the documentation, whatever you want. But try to go through this on your own. And then if you get stuck somewhere, you can look at an example solution that I created, which is here, pytorch custom data sets exercise solutions. And just be aware that this is just one way of doing things. It's not necessarily the best. It's just a way to reference what you're writing to what I would do. And there's actually now live walkthroughs of the solutions, errors and all on YouTube. So if you go to this video, which is going to mute. So this is me live streaming the whole thing, writing a bunch of pytorch code. If you just keep going through all of that, you'll see me writing all of the solutions, running into errors, trying different things, et cetera, et cetera. But that's on YouTube. You can check that out on your own time. But I feel like we've covered enough exercises. Oh, by the way, this is in the extras exercises tab of the pytorch deep learning repo. So extras exercises and solutions that are contained in there. Far out. We've covered a lot. Look at all that. So that has been pytorch custom data sets. I will see you in the next section. Holy smokes. That was a lot of pytorch code. But if you're still hungry for more, there is five more chapters available at learnpytorch.io, which cover transfer learning, my favorite topic, pytorch model experiment tracking, pytorch paper replicating, and pytorch model deployment. How do you get your model into the hands of others? And if you'd like to learn in this video style, the videos for those chapters are available at zero to mastery.io. But otherwise, happy machine learning. And I'll see you next time."
    },
    {
        "id": "cedd6f06-ae37-4fc7-b487-d2ec5b85a1e3",
        "type": "video",
        "domaine": "technology",
        "titre": "Machine Learning in 2024 – Beginner's Course",
        "url": "https://www.youtube.com/watch?v=bmmQA8A-yUA",
        "description": "This ",
        "chaine": "freeCodeCamp.org",
        "durée": "4:19:33",
        "keywords": [
            "machine learning model",
            "machine learning",
            "linear regression model",
            "linear regression",
            "independent variables",
            "dependent variable",
            "data",
            "regression model",
            "learning model",
            "model"
        ],
        "transcription": "this machine learning course is created for beginners who are learning in 2024 the course begins with a machine learning road map for 2024 emphasizing career paths and beginner-friendly Theory then the course moves on to Hands-On practical applications and a comprehensive end to-end project using python Todd have created this course she is an experienced data science professional her aim is to demystify machine learning Concepts making them accessible and actionable for newcomers and to bridge the gap in existing educational resources setting you on a path to success in the evolving field of machine learning looking to step into machine learning or data science it's about starting somewhere practical yet powerful in this introductory course machine learning for beginners we are going to cover the basics of machine learning and we're going to put that into practice by implementing it in a real world case study I'm d founder of Lun Tech where we are making data science and AI more accessible for individuals and businesses if you're looking for machine learning deep learning data science or AI resources then check out the free resources section in lunch. or our YouTube channel where you can find more content and you can dive into machine learning and in AI we're going to start with machine learning road map we in this detailed section we are going to discuss the exact skill set that you need to get into machine learning we're also going to cover the definition of machine learning what is a common career path and lot of resources that you can use in order to get into machine learning then we are going to start with the actual Theory we are going to touch base the basics we're going to learn what are those different fundamentals in machine learning once we have learned the theory and we have also looked into the machine learning road map we're going to put our Theory into practice we are going to conduct an endtoend a basic yet powerful case study where we're are going to implement the linear aggression model we're going to use it both for caal analysis and for Predictive Analytics for Californian house prices we're are going to find out the features that drive the Californian house values and we are going to discuss the stepbystep approach for conducting a real world data science project at the end of this course you are going to to know the exact machine learning road map for 2024 what are the exact skill set and the action plan that you can use to get into machine learning and in data science you are going to learn the basics when it comes to machine learning you're going to implement it into actual machine learning project end to end including implementing pandas numai psychic learn touch models medal tap and curn in Python for a real world data science project dive into machine learning with us start Simple Start strong let's get started hi there in this video we are going to talk about how you can get into machine learning in 2024 first we are going to start with all the skills that you need in order to get into machine learning step by step what are the topics that you need to cover and what are the topics that you need to study in order to to get into machine learning we are going to talk about what is machine learning then we are going to cover step by step what are the exact topics and the skills that you need in order to become a machine learning researcher or just get into machine learning then we're going to cover the type of exact projects you can complete so examples of portfolio projects in order to put it on your resume and to start to apply for machine learning related jobs and then we are going to also talk about the type of industries that you can get into once you have all the skills and you want to get into machine learning so the exact career path and what kind of business titles are usually related to machine learning we are also going to talk about the average salary that you can expect for each of those different machine learning related positions at the end of this video you are going to know what exactly machine learning is where is it used what kind of skills are there that you need in order to get into to machine learning in 2024 and what kind of career path with what kind of compensation you can expect with the corresponding business titles when you want to start your career in machine learning so we will first start with the definition of machine learning what machine learning is and what are the different sorts of applications of machine learning that you most likely have heard of but you didn't know that it was based on machine learning so what is machine learning machine learning is a brand of artificial intelligence of AI that helps to uh build models based on the data and then learn from this data in order to make different decisions and it's being used across different Industries uh starting from healthare till entertainment in order to improve uh the customer uh experience custom identify customer behavior um improve the sales for the businesses uh and it also helps um governments to make decisions so it's really has a wide range of applications so let's start with the healthcare for instance machine learning is being used in the healthcare to help with the uh diagnosis of diseases it can help to uh diagnose cancer uh during the co it helped many hospitals to identify whether people are getting more uh severe side effects or they are getting p uh pneumonia um based on those pictures and that was all based on machine learning and specifically comp computer vision uh in the healthcare is also being used for drug Discovery it's being used for personalized medicine for personalizing treatment plans to improve the operations of the hospitals to understand what is the amount of uh people and uh patients that hospital can expect in each of those uh uh days per week and also to estimate the amount of doctors that need to be available the amount of uh people uh that the hospital can expect in the emergency room based on the day or the time of the day and this is basically not a machine learning application then we have uh machine learning in finance machine learning is being largely used in finance for different applications starting from fraud detection in credit cards or in other sorts of banking operations um it's also being used in trading uh with specifically in combination with quantitative Finance to help traders to make decisions with they need to go short or long into different stocks or bonds or different assets just in general to estimate the price that those talks will happen Assets in the real time in the most accurate way uh it's also being used in uh retail uh it helps you understand an estimated demand for certain products in certain warehouses it also helps you understand what is the most appropriate or closest uh uh warehouses that the items for that corresponding customer should be shipped so it's uh optimizing the operations it's also being used to build different direct Commander systems and search engines like the famous Amazon is doing so every time when you go to Amazon and you are searching for project or product you will most likely see many article recommenders and that's based on machine learning because Amazon is uh Gathering the data and comparing your behavior So based on what you have bought based on what you are searching uh to other customers and those items to other items in order to understand what are the items that you will most likely will be interested in and eventually will buy it and that's exactly based on machine learning and specifically different sorts of recommended system algorithm and then we have uh marketing where machine learning is being heavily used because this can help to understand uh what are these different tactics and specific targeting uh groups that that you belong and how retailers can Target you uh in order to reduce their marketing cost and to result in high conversion rates so to ensure that you buy their product then we have machine learning in autonomous vehicles that's based on machine learning and specifically uh deep learning applications uh and then we have also um uh natural language Pro processing which is highly related to the famous Chad GPT I'm sure you are using it and that's that's based on the machine learning and specifically the large language models so the Transformers large language models where you are going and providing your text and then question and the chat GPT will provide answer to you or in fact any other uh virtual assistant or chat boats those are all based on machine learning and then we have also uh smart home devices so Alexa is based on machine learning also in agriculture uh machine learning is being used heavily these days to estimate what the weather conditions will be uh to understand what will be the uh production of different plants uh what will be the um outcome of this uh to understand and to make decisions uh also how they can optimize those uh crop uh yields to monitor uh soil health and for different sorts of applications that can just in general uh improve the uh revenue for the farmer then we have of course in the entertainment so the Vivid example is Netflix that uses the uh data uh that you are providing uh related to the movies and also based on what kind of movies you are watching Netflix is uh building this super smart recommender system to recommend you movies that you most likely will be interested in and you will also like it so in all this machine learning is being used and it's actually super powerful topic and super powerful uh field to get into and in the upcoming 10 years this is only going to grow so if you have made that decision or you are about to make that decision to get into machine learning continue watching this video because I'm going to tell you exactly what kind of skills you need and what kind of uh practice projects you can complete in order to get into machine learning in 2024 so you first need to start with mathematics you Al also need to know python you also need to know statistics you will need to know machine learning and you will need to know some NLP to get into machine learning so let's now unpack each of those skill sets so independent the type of machine learning you are going to do you need to know mathematics and specifically you need to know linear algebra so you need to know what is matrix multiplication what are the vectors matrices dot product you need to know how you can uh multiply those different matrices Matrix with vectors what are these different rules the dimensions also what does it mean to transform a matrix the inverse of the Matrix identity Matrix diagonal matrix uh those are all Concepts as part of linear algebra that you need to know as part of your mathematical skill set in order to understand those different machine learning algorithms then as part of your mathematics you also need to to know calculus and specifically differential Theory so you need to know these different theorems such as chain rule the rule of uh differentiating when you have sum of instances when you have constant multiply with an instance when you have um uh sum but also subtraction division multiplication of two items and then you need to take the uh derivative of that what is this idea of derivative what is the idea of partial derivative what is the idea of Haitian so first order derivative second order derivative and it would be also great to know a basic integration Theory so we have differentiation and the opposite of it is integration Theory so this is kind of basic you don't need to know uh too much when it comes to calculus but those are basic things that you need to know uh in order to succeed in machine learning uh then the next Concepts uh such as discrete mathematics so you need to know uh what is this idea of uh graph Theory uh what are this uh combinations combinators uh what is uh this idea of complexity which is important when you want to become a machine learning engineer because you need to understand what is this Big O notation so you need to understand what is this complexity of uh n s complexity of n complexity of n log n um and about that you need to know uh some basic um mathematics when it comes which comes from usually high school so you need to know multiplication division you need to understand uh multiplying uh uh amounts which are within the parentheses you need to understand um different symbols that represent mathematical um values you need to know this idea of using X's y's uh and then what is X2 what is y^ 2 What is X to ^ 3 so different exponents of the different VAR variables then you need to know what is logarithm what is logarithm at the base of two what is logarithm at the base of e and then at the base of 10 uh what is the idea of e so what is the idea of Pi uh what is this idea of uh exponent logarithm and how does those uh transform when it comes to taking derivative of the logarithm taking the derivative of the uh exponent those are all values and all uh topics that are actually quite basic they might sound complicated but they are actually not so if someone explains you uh clearly then you will definitely understand it from the first goal and uh for this uh to understand all those different mathematical Concepts so linear algebra calculus differential Theory and then discrete mathematics and those different symbols you need to uh go for instance uh and look for courses or um YouTube tutorials that are about uh basic mathematics uh for machine learning and AI uh don't go and look further you can check for instance Can Academy which is uh quite favorite when it comes to learning math uh both for uni students and also for just people who want to learn mathematics and this will be your guide um or you can check our resources at Lear tech. cuz we are going also to uh provide this resources for you uh in case you want to learn mathematics for your machine Learning Journey the next skill set that you need to gain in order to break into machine learning is the statistics so you need to know this is a must statistics if you want to get into machine learning and in AI in general so there are few topics that you must um study when it comes to statistics and uh those are descriptive statistics multivariate statistics inferential statistics probability distribution and some bial thinking so let's start with descriptive statistics when it comes to descriptive statistics you need to know what is side of mean uh median standard deviation variance and uh just in general how you can uh analyze the data with using this descriptive measures so distance measures but also variational measures then the next topic area that you need to know as part of your statistical Journey is the inferential statistics so you need to know those INF famous theories such as Central limit theorem the law of a large numbers uh and how you can um relate to this idea of population sample unbiased sample and also uh a hypothesis testing confidence interval statistical significance uh and uh how you can test different theories by using uh this idea of statistical significance uh what what is the power of the test what is type one error what is type two error so uh this is super important for understanding different SES of machine learning applications if you want to get into machine learning then you have probability distributions and this idea of probabilities so to understand those different machine learning Concepts you need to know what are probabilities so what is this idea of probability what is this idea of Sample versus population uh what is what does it mean to estimate probability what are those different rules of probability so conditional probability uh and um those uh probability uh values and rules that usually you can uh apply when you have uh probability of um multipliers probability of two sums um and then uh you need to understand some uh popular and you need to know some popular probability distribution function and those are perno distribution binomial distribution uh normal distribution uniform distribution exponential distribution so those are all super important distributions that you need to know in order to understand uh this idea of normality normalization uh also uh this idea of bare noly trials and uh relating uh different probability distributions to different uh uh higher level statistical concept steps so rolling a dice the probability of it how it is related to bero distribution or to binomial distribution and those are super important when it comes to hypothesis testing but also for uh many other machine learning applications so then we have the ban thinking this is super important when it comes to more advanced machine learning but also some basic machine learning you need to know what is the Bas theorem which arguably is one of the most popular statistical theorems out there comparable also to the central limit theorem you need to know what is conditional probability what is this bias theorem and how does it relate to conditional probability uh what is this uh bation uh statistics Ide at very high level you don't need to know everything in uh super detailed but you need to know um the these Concepts at least at high level in order to understand machine learning so to learn statistics and fundamental concepts of Statistics you can check out the fundamentals to statistics course at lunch. here you can learn all this required Concepts and topics and you can practice it in order to get into machine learning and to gain the statistical skills the next skill set that you must know is the fundamentals to machine learning so this covers not only the basics of machine learning but also the most popular machine learning algorithms so you need to know this uh different um mathematical side of these algorithms step by step how they work what are the benefits of them what are the demores and and which one to use for what type of applications so you need to know this uh categorization of supervised versus unsupervised versus semi-supervised then you need to know what is this idea of classification regression or uh clustering then you need to know uh also time series analysis uh you also need to know uh these different popular algorithms including linear regression also logistic regression LDA so linear discriminant analysis you need to know KNN you uh need to know uh decision treats both classification and regression case you need to know uh random Forest begging but also boosting so popular boosting algorithms like uh light GBM GBM uh so gradient boosting models and you need to know uh HG boost uh you uh also need to know um some supervised learning algorithm such as K means uh usually Ed for class string you need to know DB scan which becomes more and more popular in uh class string algorithms you also need to know hierarchal class string um and um for all this type of uh models you need to understand the idea behind them what are the advantages and disadvantages whether they can be applied for unsupervised versus supervised versus semi-supervised you need to know whether they are for regression classification or for uh class stre beside of this popular algorithms and models you also need to know the basics of uh training a machine learning model so you need to know uh this process behind training validating and testing your machine learning algorithms so you need to know uh what does it mean to uh perform hyperparameter tuning what are those different optimization algorithms that can be used to optimize your parameters such as uh GD SGD SGD with momentum Adam and Adam V you also need to know the testing process this idea of splitting the data into train validation and then test you need to know resampling techniques why are they used including the um bootstrapping and uh cross viation and there's different sorts of cross viation techniques such as one out cross validation kful cross validation validation set approach uh you also need to know um this uh idea of uh Matrix and how you can use different Matrix to evaluate your machine learning models such as uh classification type of metrics like F1 score FB Precision recall um cross entropy um and also you need to know some Matrix that can be used to evaluate regression type of problems like the uh me squared error so MC root me squared error R MC uh MAA so the absolute uh version of those different sorts of Errors um and um or the residual sum of squares for all these cases you not only need to know higher level what the those algorithms or those uh topics or concepts are doing but you actually need to know the uh mathematics behind it their benefits the uh disadvantage ages because during the interviews you can definitely expect questions that will test uh not only your high level understanding but also this uh background knowledge if you want to learn machine learning and you want to gain those skills then uh feel free to check out my uh fundamentals to machine learning course at lunch. or you can also check out and download for free the fundamentals to machine learning handbook that I published with free cord Camp then the next skill set that you definitely need to gain is a knowledge in python python is actually one of the most popular programming languages out there and it's being used across software Engineers uh AI Engineers machine learning Engineers data scientists so this this is the universal language I would say when it comes to programming so if you're considering getting into machine learning in 2024 then python will be your friend so knowing the theory is one thing then uh implementing it uh in in the actual job is another and that's exactly where python comes in handy so you need to know python in order to perform uh descriptive statistics in order to trade machine learning model or more advanced machine learning models so deep learning models you can use for training validation and uh for testing of your models and uh also for building different sorts of applications so python is super powerful therefore it's also gaining such a high uh popularity across the globe because it has so many uh libraries it has uh taner flow pie torch both that uh are must if you want to not only get into machine learning but also the advanced uh levels of machine learning so if you are considering the AI engineering jobs or machine learning engineering jobs and uh you want to train for instance deep learning models uh or you want to build large l W models or generative AI models then you definitely need to learn uh pytorch and tens flow which are Frameworks that I use in order to uh Implement different deep learning uh which are Advanced machine learning models here are few libraries that you need to know in order to uh get into machine learning so you definitely need to know pandas napai you need to know psyit learn scipi you also need to know uh nltk for the TX data you also need to know tensor flow and Pythor for bit more advanced machine learning and um beside this there are also data visualization libraries that I would definitely suggest you to practice with which are the Met plot lip and specifically the PIP plot and also the curn when it comes to python beside knowing how to use libraries you also need to know some basic data structures so you need to know what are these variables how you can create variables what what are the matrices arrays how the indexing works and also uh what are the lists what are the sets so unique lists uh What uh are the ways that you can what are the different operations you can perform uh how does the Sorting for instance work I would definitely suggest you know um some basic data structures and algorithms such as binary sort so in optimal way to sort your arrays you also need to know uh the data processing in Python so you need to understand how to identify missing data how to uh identify uh duplicating your data how to clean this how to perform feature engineering so how to combine uh multiple variables or to perform operations to create new variables um you also need to know uh how you can aggregate your data how you can filter your data how you can sort your data and of course you also need to know how you can form AB testing in your Python and how you can train machine learning models how you can test it and how you can evaluate them and also visualize the performance of it if you want to Learn Python then the easiest thing you can do is just to Google for uh python for data science or python for machine learning tutorials or blogs or you can even try out the python for data science course at Learner tech. in order to learn all these Basics and usage of these libraries and some practical examples when it comes to python for machine learning the next skill set that you need to gain in order to get into machine learning is the basic introduction to NLP natural language processing so you need to know how to work with text Data given that these days the text data is the Cornerstone of all these different Advanced algorithms such as uh gpts Transformers the attention mechanisms so those uh applications that you see as part of building chat boat or this uh p I uh applications based on Tex data they are all based on NLP so therefore you need to know this basics of NLP to just get started with machine learning so you need to know uh this idea of text Data what are those strings uh how you can clean Text data so how you can clean uh those um dirty data that you get and what are the steps involved such as lower casing uh removing punctuation tokenization uh also what is this idea of stemming lemmatization stop wordss how you can use the nltk in Pyon in order to perform this cleaning you also need to know uh this idea of embeddings and uh you can also learn this idea of uh the uh tfidf which is a basic uh NLP algorithm uh you also uh can learn this idea of word and Bings uh the sub word embeddings uh and the character embeddings if you want to learn the basics of NLP you can check out those Concepts and learn them as part of the blogs there are many tutorials on YouTube you can also try the introduction to uh NLP course at lunch. in order to learn this uh different Basics that form the NLP if you want to go beyond this uh intro till medium level machine learning and you also want to learn more advanced machine learning and this is something that you need to know after you have gained all these preview skills that I mentioned then you can gain uh this uh knowledge and the skill set by learning deep learning and also uh you can consider uh getting into generative AI topics so you can for instance learn what are the rnns what are the Ann what are the CNN you can learn what is this uh out encoder concept what are the variational outen coders what what are the uh generative adversarial networks so gens uh you can understand what is this idea of reconstruction error uh you can understand this um these different sorts of neural networks what is this idea of back propagation the optimization of these algorithms by using the different optimization algorithms such as GD HGD um HGD momentum Adam adamw RMS prop uh you uh can also go One Step Beyond and you can uh get into gener AI topics such as um uh the uh variational Auto encoders like I just mentioned but also the large language models so if you want to move towards the NLP side of generative Ai and you want to know how the ched GPT has been invented how the gpts work or the birth model uh then you will definitely need to uh get into this topic of language model so what are the end grams what is the attention mechanism what is the difference between the self attention and attention what is uh one head self attention mechanism what is multi-ad self attention mechanism you also need to know at high level this uh encoder decoder architecture of Transformers so you need to know the architecture of Transformers and how they solve different problems of uh reur neuron networks or RNN and lstms uh you can also look into uh this uh uh encoder based or decoder based algorithm such as uh gpts or Birch model and those all will help you to not only get into machine learning but also stand out from all the other candidates by having this Advanced knowledge let's now talk about different sorts of projects that you can complete in order to train your machine learning skill set that you just learned uh so there are few projects that I suggest you to complete and you can put it this on your resume to start to apply for machine learning roles the first application the project that I would suggest you to do is building a basic recommender system whether it's a job recommender system or a movie recommender system in this way you can showcase how you can use for instance text Data from those job advertisement how you can use numeric data such as the ratings of the movies in order to build a topend recommender system this will showcase your understanding of the distance measures such as cosign similarity this Cann algorithm idea and this will help you to uh uh tackle this specific uh area of data science and machine learning the next project I would suggest you to do will be to build a regression based model so in this way you will showcase that you understand this idea of regression how to work with a Predictive Analytics and predictive model that has a dependent variable response variable that is in the numeric format so here for instance you can uh estimate the salaries of the jobs based on the uh characteristics of the uh job based on this data which you can get for instance from uh open source uh web pages such as keegle and you can then uh use different sorts of regression algorithms to perform your predictions of the salaries evaluate the model and then compare the uh performance of the different machine learning regression based algorithms for instance you can use the uh linear regression you can use the decision trees regression version you can use the um uh random Forest you can use uh GBM xgo in order to Showcase and then in one uh graph to compare this uh performance of these different algorithms by using single regression uh ml modal metrics so for instance the rmsc this project will showcase that you understand how you can train a regression model how you can test it and validate it and it will showcase your understanding of optimization of this regression algorithm you understand this concept of hyperparameter unit the next project that I would suggest you to do in order to Showcase your classification knowledge so when it comes to uh predicting a class for an observation given uh the feature space would be uh to uh build a classification model that would classify emails being a Spam or not a Spam so you can use a publicly available data that will be uh describing a specific email and then you will have multiple emails and the idea is to uh build a machine learning model that would classify the email to the class zero and class one where class zero for instance can be your uh not being a Spam and one being a Spam so with this binary classification you will showcase that you know how to train a machine learning model for classification purposes and you can here use for instance logistic regression you can use also the decision Trea for classification case you can also use random Forest the uh EG she Bo for classification GBM for classification and uh with all these models you can then obtain the performance metrics such as uh F1 score or you can put the rck curve uh or the uh area under the Curve metrics and you can also compare those different classification models so in this way you will also tackle another area of expertise when it comes to the machine learning then a final project that I would suggest you to do would be uh from the unsupervised learning to Showcase another area of expertise and here you can for instance use data to your customers into good better and best customers based on their transaction history the amount of uh money that they are spending in the store so uh in this case you can for instance use K means uh DB scan hierarchy clustering and then you can evaluate your uh clustering algorithms and then select the one that performs the best so you will then in this case cover yet another area of machine learning which would be super important to show case that you can not only handle recommended systems or supervised learning but also unsupervised learning and the reason why I suggest you to uh cover all these different areas and complete this four different projects is because in this way you will be covering different expertise and areas of machine learning so you will be also putting projects on your uh resume that are covering different sorts of algorithms different sorts of uh Matrix and approaches and it will show case that you actually know a lot from machine learning now if you want to go beyond the basic or medium level and you want to be considered for medium or Advanced machine learning uh levels and positions you also need to know bit more advanced which means that you need to complete bit more advanced projects for instance if you want to apply for generative AI related or large language models related positions I would suggest you to complete a project where you are building a very basic uh large language model and specifically the pre-training process which is the most difficult one so in this case uh for instance you can build a baby GPT and I'll put a here link that you can follow where I'm building a baby GPT a basic pre-trained GPT algorithm where uh I am using a text Data uh publicly available data in order to uh uh process data in the same way like GPT is doing and the encoded part of the Transformer in this way you will showcase to your um hiring managers that you understand this architecture behind Transformers architecture behind the um uh large language models and the gpts and you understand how you can use pytorch in Python in order to do this Advanced NLP and generative AI task and finally let's now talk about the common career path and the business titles that you can expect from a career in machine learning so assuming that you have gained all the skills uh that are must for breaking into machine learning there are different sorts of business titles that you can apply in order to get into machine learning so when it comes to machine learning uh you can uh get into machine learning uh and there are different fields that are covered as part of this so uh first we have the general machine learning researcher machine learning researcher is basically doing a research so training testing evaluating different machine learning algorithms they are usually people who come from academic background but it doesn't mean that you cannot get into machine learning research without getting a degree in statistics mathematics or in um um machine learning specifically not at all so uh if you have this um desire and this passion for reading doing research uh and you don't mind reading uh research papers then machine learning res researcher job would be a good fit for you so machine learning combined with research then sets you uh for the machine learning researcher role then we have the machine learning engineer so machine learning engineer is the engineering version of the machine learning uh expertise which means that we are combining machine learning skills with the engineering skills such as productionizing pipelines or end to end robust pipeline scalability of the m model considering all these different aspects of the model not only from the performance side when it comes to the quality of the algorithm but also the uh scalability of it and when putting it in front of many users so when it comes to combining engineering with machine learning then you get machine learning engineering so if you are someone who is a software engineer and you want to get into machine learning then machine learning engineering would be the best fit for you so so for machine learning engineering you not only need to have all these different skills that I already mentioned but you also need to have this good grasp of uh uh scalability of algorithms the uh uh data structures and algorithms type of um skill set uh the uh complexity of the moral uh also system design so this one uh converges more towards and similar to the software engineering position combined with machine learning red than your pure machine learning or AI role then we have the AI research versus AI engineering position so uh the uh AI research position is similar to The Machine learning uh research position and the AI engineer position is similar to The Machine learning engineer position with only single difference when it comes to machine learning we are specifically talking about the traditional machine learning so linear regression logistic regression and also uh random Forest exy boost begging and when it comes to AI research and AI engineer position here we are tackling more the advanced machine learning so here we are talking about deep learning models such as RNN lstms grus CNN or computer vision applications and we are also talking about uh generative AI models large language models so uh we are talking about um the Transformers implementation of Transformers the gbts T5 all these different algorithms that are from uh more advanced uh AI topics rather than traditional machine learning uh for those you will then be applying for AI research and AI engineering positions and finally you have these different sorts of obervations niches from AI for instance NLP research NLP engineer or even data science positions for which you will need to know machine learning and knowing machine learning will set you apart for the source of positions so also the business titles such as data science or technical data science positions NLP researcher NLP engineer for this all uh you will need to know machine learning and knowing machine learning will help you to break into those positions and those career paths if you want to prepare for your deep learning interviews for instance and you want to get into AI engineering or AI research then I have recently published for free a full course with 100 interview questions with answers for a span of 7.5 hours that will help you to prepare for your deep learning interviews and for your machine learning interviews you can check out my uh fundamentals to machine learning course at lunch. or uh you can download the machine learning fundamentals handbook from free Cod camp and check out my blogs and also free resources at lunch. AI in order to prepare for your interviews and in order to get into machine learning let's not talk talk about the list of resources that you can use in order to get into machine learning in 2024 so to learn statistics and the fundamental concepts of Statistics you can check out the fundamental statistics course at lunch. here you can learn all this required Concepts and topics and you can practice it in order to get into machine learning and to gain this statistical skills then when you want to learn machine learning you can check the fundamentals to a learning course at lunch. to get all these basic concepts the fundamentals to machine learning and the list of comprehensive and the most comprehensive list of machine learning algorithms out there as part of this course then you can also check out the introduction to NLP course at the lunch. a in order to learn the basic concepts behind natural language preprocessing and finally if you want to Learn Python and specifically python for Ral learning you can check out the python for data science course at lunch. and if you want to get access to this different projects that you can practice your machine learning skills that you just learned you can either check out the ultimate data science boot camp that covers a specific course the uh data science uh project portfolio course covering multiple of these projects that you can train your machine learning skills and put on your resume or you can also check my GitHub account or my LinkedIn account where I cover many case studies including the baby GPT and I will also put the link to this course and to this uh case study in the link below and once you have gained all the skills you are ready to get into machine learning in 2024 in this lecture we will go through the basic concepts in machine learning that is needed to understand and follow conversations and solve main problems using machine learning strong understanding of machine learning Basics is an important step for anyone looking to learn more about or work with machine learning we'll be looking at the three concepts in this tutorial we will Define and look into the difference between supervised and unsupervised machine learning models then we will look into the difference between the regression and classification type of machine learning models after this we will look into the process of training machine learning models from scratch and how to evaluate them by introducing performance metrics what you can use depending on the type of machine learning model or problem you are dealing with so whether it's a supervised or unsupervised whether it's regression versus classification type of problem machine learning methods are categorized into two types depending on the existence of the label data in the training data set which is especially important in the training process so we are talking about the So-Cal dependent variable that we so in the section of fundamental Su statistics supervised and unsupervised machine learning models are two main type of machine learning algorithms one key difference between the two is the level of supervision during the training phase supervised machine learning algorithms are Guided by the labeled examples while as supervised algorithms are not as learning model is more reliable but it also requires a larger amount of labeled data which can be timec consuming and quite expensive to obtain examples of supervised machine learning models include regression and classification type of models on the other hand unsupervised machine learning algorithms are trained on unlabeled data the model must find patterns and relationships in the data without the guidance of correct outputs so we no longer have a dependent variable so unsupervised ml models require training data that consists only of independent variables or the features and there is no dependent variable or label data that can supervise the algorithm when learning from the data examples of unsupervised models are clust string models and outlier detection techniques supervised machine learning methods are categorized into two types depending on the type of dependent variable they are predicting so we have regression type and we have classification type some key differences between regression and classification include output type so the regression algorithms predict continuous values while the classification algorithms predict categorized values some key difference between regression and classification include the output type the evaluation metrics and their applications so with regards to the output type regression algorithms predict continuous values while classification algorithms predict categorical values with regard to the evaluation metric different evaluation metrics are being used for regression and classification tasks for example mean square is commonly used to evaluate regression models while accuracy is commonly used to evaluate classification models when it comes to Applications regression and classification models are used in entirely different types of applications regression models are often used for prediction tests while classifications are used for decision making tasks progression algorithms are used to predict the continuous value such as price or probability for example a regression model might be used to predict the price of a house based on its size location or other features examples of regression type of machine learning models are linear regression fixed effect regression exus regression Etc classification algorithms on the other hand are used to predict the categorical value these algorithms take an input and classify it to one of the several predetermined categories for example a classification model might be used to classify emails as a Spam or as not a Spam or to identify the type of animal in an image examples of classification type of machine learning models are logistic regression exus classification random Forest classification let us now look into different typee of performance metrics we can use in order to evaluate different type of machine learning models for aggression models common evaluation Matrix includes residual sum of squared which is the RSS mean squared error which is the msse the root mean squared error or rmsc and the mean absolute error which is the m AE this metrix measure the difference between the predicted values and the True Values with a lower value indicating a better feed for the model so let's go through this metrics one by one the first one is the RSS or the residual sum of squares this is a matrix commonly used in the setting of linear regression when we are evaluating the performance of the model in estimating the different coefficients and here the beta is a coefficient and the Yi is our dependent variable value and the Y head is the predicted value as you can see the RSS or the residual sum of square or the beta is equal to sum of all the squ of Y IUS y hat across all I is equal to 1 n where I is the index of the each r or the individual or the observation included in the data the second Matrix is the m or the mean squared error which is the average of the squared differences between the predicted values and the True Values so as you can see m is equal to 1 / to n and then sum across all i y i minus y head squ as you can see the RSS and the msse are quite similar in terms of their uh formulas the only difference is that we are adding a 1 / to n and then this makes it the average across all the square differences between the predicted value and the actual true valum a lower value of msse indicates a better fit the rmsc which is the root mean squared error is the square root of the msse so as you can see it has the same formula as msse only with the difference that we are adding a square roof on the top of that formula a lower value of rmsc indicates a better fit and finally the Mae or the mean absolute error is the average absolute difference between the predicted values so the Y hat and the True Values or y i a lower value of this indicates a better fit the choice of a regression metrics depends on the specific problem you are trying to solve and the nature of your data for instance the MSE is commonly used when you want to penalize large errors more than the small ones MSE is sensitive to outliers which means that it may not be the best choice when your data contains many outliers or extreme values rmsc on the other hand which is the square root of the MSC makes it easier to interpret so it's easier interpretable because it's in the same units as Target variable it is commonly used when you want to compare the performance of different models or when you want to report the error in a way that it's easier to understand and to explain the Mia is commonly used when you want to penalize all errors equally regardless of their magnitude and Mia is less sensitive to outliers compared to msse for classification models common evaluation metrics include accuracy precision recall and F1 score this metrics measure the ability of the machine learning model to correctly classify instances into the correct categories let's briefly look into this metrix individually so the accuracy is a proportion of correct predictions made by the model it's calculated by taking the correct predictions so the correct number of predictions and divide two all number of predictions which means correct predictions plus incorrect predictions next we will look into the Precision so Precision is the proportion of true positive predictions among all positive predictions made by the model and it's equal to True positive divided to True positive plus false positive so all number of positives true positives are cases where the model correctly predict a positive outcome while false positives are the cases where the model incorrectly predict a positive outcome next Matrix is recall recall is a proportion of true positive predictions among all actual positive instances it's calculated as the number of true positive predictions divided by the total number of actual positive instances which means dividing the true positive to True positive plus false negative so for example let's say we are looking into medical test a true positive would be a case where it has correctly identifies a patient as having a disease while a false positive would be a case where the test incorrectly identifies a healthy patient as having the disease and the final score is the F1 score the F1 score is the harmonic mean or the usual mean of the Precision and recall with a higher value indicating a better balance between precision and recall and it's calculated as the two times recall times Precision divided to recall plus Precision for unsupervised models such as class string models whose performance is typically evaluated using metrics that measure the similarity of the data points within a cluster and the dis similarity of the data points between different clusters we have three type of metrics that we can use homogeneity is a measure of the degree to which all of the data points within a single cluster belong to the same class A Higher value indicates a more homogeneous cluster so as you can see homogeneity of age where age is the simply the short way of describing homogeneity is equal to one minus conditional entropy given cluster assignments divided to the entropy or predicted class if you wondering what this entropy is then stay tuned as we are going to discuss this entropy whenever we will discuss the clustering as well as decision trees X Matrix is the silid score silid score is a measure of the similarity of the data point to its own cluster compared to the other clusters a higher silid score indicates that the data point is well matched to its own cluster this is usually used for DB scan or k me so here the silhouette score can be represented by this formula so the S so or the silhouette score is equal to B minus AO divided to the maximum of AO and B where s o is The Silo coefficient of the data point characterized by o AO is the average distance between o and all the other data points in the cluster to which o belongs and the B is the minimum average distance from o to all the Clusters to which o does not belong the final metrix we look to is the completeness completeness is another measure of the degree to which all of the data points that belongs to a particular class are assigned to the same cluster a higher value indicates a more compete cluster let's conclude this lecture by going through the step-by-step process of evaluating a machine learning model at a very simplified version since there are many additional considerations and techniques that may be needed depending on a specific task and the characteristics of the data knowing how to properly train machine learning model is really important since this defines the accuracy of the results and conclusions you will make the training Pro process starts with the preparing of the data this includes splitting the data into training and test sets or if you are using more advanced resampling techniques that we will talk about later than splitting your data into multiple sets the training set of your data is used to feed the model if you have also a validation set then this validation set is used to optimize your hyperparameters and to pick the best model while the test set is to use to evaluate the model performance when when we will approach more lectures in this section we will talk in detail about these different techniques as well as what the training means what the test means what validation means as well as what the hyperparameter tuning means secondly we need to choose an algorithm or set of algorithms and train the model on the training data and save the fitted model there are many different algorithms to choose from and the appropriate algorithm will depend on the specific test task and the characteristics of the data as a third step we need to adjust the model parameters to minimize the error on the training set by performing hyperparameter tuning for this we need to use validation data and then we can select the best model that results in the least possible validation error rate in this step we want to look for the optimal set of parameters that are included as part of our model to end up with a model that has the least possible error so it performs in the best possible way in the final two steps we need to evaluate the model we are always interested in a test a rate and not the training or the validation error rates because we have not used a test set but we have used the training and validation sets so this test error rate will give you an idea of how well the model will generalize to the new unseen data we need to use the optimal set of parameters from hyperparameter tuning stage and the training data to train the model again with this hyper parameters and with the best model so we can use the best fitted model to get the predictions on the test data and this will help us to calculate our test error rate once we have calculated the test error rate and we have also obtained our best model we are ready to save the predictions so once we are satisfied with the model performance and we have tuned the parameters we can use it to make predictions on a new unseen data on the test data and compute the performance metrics for the model us the predictions and the real values of the target variable from the test data and this complete this lecture so in this lecture we have spoken about the basics of machine learning we have discussed the difference between the the unsupervised and supervised learning models as well as regression versus classification we have discussed in details the different type of performance metrics we can use to evaluate different type of machine learning models as well as we have looked into the simplified version of the step-by-step process to train the machine machine learning model in this lecture lecture number two we will discuss a very important Concepts which you need to know before considering and applying any statistical or machine learning model here I'm talking about the bias of the model and the variance of the model and the trade of between the two which we call bias various trade of whenever you are using a statistical econometrical or a machine learning model no matter how simple the model is you should always evaluate your model and check its error rate in all this cases it comes down to the trade-off you make between the variance of the model and the bias of your model because there is always a catch when it comes to the model choice and the performance let us firstly Define what bias and the variant of the machine learning model are the inability of the model to capture the true relationship in the data is called bias hence the machine learning models that are able to detect the true relationship in the data have low bias usually complex models or more flexible models tend to have a lower bias than simpler models so mathematically the bias of the model can be expressed as the expectation of the difference between the estimate and the True Value let us also Define the variance of the model the variance of the model is the inconsistency level or the variability of the model performance when applying the model to different data sets when the same model that is trained using training data performs entirely differently than on the test data this means that there is a large variation or variance in the model complex models or more flexible models tend to have a higher variance than simpler models in order to evaluate the performance of the model we need to look at the amount of error that the model is making for Simplicity let's assume we have the following simple regression model which aims to use a single independent variable X to model the numeric y dependent variable that is we fit our model on our training observations where we have a pair of independent and dependent variables X1 y1 X2 Y2 up to xn YN and we obtain an estimate for our training observations fhe we can then compute this let's say fhe X1 fhe X2 up to fhe xn which are the estimat for our dependent variable y1 Y2 up to YN and if these are approximately equal to this actual values so one head is approximately equal to y1 Y2 head is approximately equal to Y2 head Etc then the training error rate would be small however if we are really interested in whether our model is predicting the dependent variable appropriately we want to instead of looking at the training error rate we want to look at our test error rate so so the error rate of the model is the expected Square difference between the real test values and their prediction where the predictions are made using the machine learning model we can rewrite this aor rate as a sum of two quantities where as you can see the left part is the amount of FX minus F hat x^ squared and the second entity is the variance of the error term so the accuracy of Y head as a prediction for y depends on the two quantities which we can call the reducible error and the irreducible error so this is the reducible error equal to FX minus f x s and then we have our irreducible error or the variance of Epsilon so the accuracy of Y head as a prediction for y depends on the two quantities which we can call the reducible error and the irreducible error in general The Fad will not be a perfect estimate for f and this inaccuracy will introduce some errors this error is reducible since we can potentially improve the accuracy of fad by using the most appropriate machine learning model and the best version of it to estimate the F however even if it was possible to find a model that would estimate F perfectly so that the estimated response took the form of Y head is equal to FX our prediction would still have some error in it this happens because Y is also a function of the error rate Epsilon which by definition cannot be predicted by using our feature X so there will always be some error that is not predictable so variability associated with the error Epsilon also affects the accuracy of the predictions and this is known as the irreducible error because no matter how well we will estimate F we cannot reduce the error introduced by the Epsilon this error contains all the features that are not included in our model so all the unknown factors that have an influence on our dependent variable but are not included as part of our data but we can't reduce the reducible error rate which is based on two values the variance of the estimate and the bias of the model if we were to simplify the mathematical expression describing the error rate that we got then it's equal to the variance of our model plus squared bias of our model plus the irreducible error so even if we cannot reduce the irreducible error we can reduce the reducible error rate which is based on the two values the variance and the squared bias so though the mathematical derivation is out of the scope of this course just keep in mind that the reducible error of the model can be described as the sum of the variance of the model and a squared bias of the model so mathematically the error in the supervised machine learning model is equal to the squared bias in the model the variance of the model and the irreducible error therefore in order to minimize the expected test error rate so on the Unseen data we need to select the machine learning meod that simultaneously achieves low variance and low bias and that's exactly what we call called bias variance tradeoff the problem is is that there is a negative correlation between the variance and the bias of the model another thing that is highly related to the bias and the variance of the model is the flexibility of the machine learning model so flexibility of the machine learning model has a direct impact on its variance and on its bias let's look at this relationships one by one so complex models or more flexible models tend to have a lower bias but at the same time complex models or flexible models tend to have higher variance than simpler models so as the flexibility of the model increases the model finds the true patterns in the data easier which reduces the bias of the model at the same time the variance of such models increases so as the flexibility of the model decreases model finds it more difficult to find the true parents in the data which then increases the bias of the morel but also decreases the variance of the model keep this topic in mind and we will continue this topic in the next next lecture when we will be discussing the topic of overfitting and how to solve the overfitting problem by using regularization in this lecture lecture number three we will talk about very important concept called overfitting and how we can solve overfitting by using different techniques including regularization this topic is related to the previous lecture and to the topics of error of the model train error rate test error rate bias and a variance of the machine learning model overfitting is important to know and also how to solve it with regularization because this topic can lead to inaccurate predictions and the lack of generalization of the model to new data knowing how to detect and prevent overfitting is crucial in building effective machine learning models questions about this topic are almost guaranteed to appear during every single data science interview in the previous lecture we discuss the relationship between model flexibility and the variance as well as the bias of the model we saw that as the flexibility of the model increases model finds the true pattern in the data easier which reduces the bias of the model but at the same time the variance of such models increases so as the flexibility of the model decreases model finds it more difficult to find the true patterns in the data which then increases the bias of the model and decreases the variance of the model let's first formally Define what the overfitting problem is as well as what the underfitting is so overfitting occurs when the model performs well in the training while the model performs worse on the test data so you end up having a low training error rate but a high test error rate and in the ideal world we want our test error rate to be low or at least that the training a rate is equal to the test error rate overfitting is a common problem in machine learning where a model learns the detail and noise in training data to the point where it negatively impacts the performance of the model on this new data so the model follows the data too closely closer than it should this means that the noise or random fluctuations of the training data is picked up and learned as concepts by the model which it should actually ignore the problem is that the noise or random component of the training data will be very different from the noise in the new data the model will therefore be less effective in making predictions on new data overfitting is caused by having too many features too complex of a model or too little of the data when the model is overfitting then also the model has high variance and low bias usually the higher is the model flexibility the higher is the risk of overfitting because then we have higher risk of having a model following the data too closely and following the noise so underfitting is the other way around underfitting occurs when our test error rate is much lower than our training error rate given that overfitting is much bigger of a problem and we want ideally to fix the case when our test theate is large we will only focus on the overfitting and this also the topic that you can expect during your data science interviews as well as something that you need to be aware of whenever you are training a machine learning model all right so now we we know what overfitting is we should now talk about how we can fix this problem there are several ways of fixing or preventing overfitting first you can reduce the complexity of the model we saw that higher the complexity of the model higher is the chance of the following the data including the noise too closely resulting in overfitting therefore reducing the flexibility of the model will reduce the overfitting as well this can be done by using a simpler model with fewer parameters or by applying a regularization techniques such as L1 or L2 regularization that we will talk in a bit kind solution is to collect more data the more data you have the less likely your model will overfit third and another solution is using resampling techniques one of which is cross validation this is a technique that allows you to train and test your model on different subsets of your data which can help you to identify if your model is overfitting we will discuss cross validation as well as other re sampling techniques later in the section another solution is to apply early stopping early stopping is a technique where you monitor the performance of the model on a validation set during the training process and stop the training when the performance starts to decrease another solution is to use assemble methods by combining multiple models such as decision trees overfitting can be reduced we will be covering many popular emble techniques in this course as well finally you can is what we call dropout dropout is a regularization technique for reducing overfitting in narrow networks by dropping out or setting to zero some of the neurons during the training process because from time to time Dropout related questions do appear during the data science interviews for people with no experience so if someone asks you about Dropout then at least you will remember that it's a technique used to solve overfitting in the setting of deep learning it's worth noting that there is no one solution that works for all types of overfitting and often a group of these techniques that we just talk about should be used to address the problem we saw that when the model is overfitting then the model has high variance and low bias by definition regularization or what we also call shrinkage is a method that shrinks some of the estimated coefficients toward zero to penalize unimportant variables for increasing the variance of the model this is a technique used to solve the overfitting problem by introducing the lethal bias in the model was significantly decreasing its variance there are three types of regularization techniques that are widely known in the industry the first one is to reach regression or L2 regularization the second one is the ler regression or the L1 regularization and finally the third one is the Dropout which is a regularization technique used in deep learning we will cover the first two types in this lecture let's now talk about re regression or L2 regularization so re regression or L2 regularization is a shrinkage technique that aims to solve overfitting by shrinking some of the modor coefficients towards zero retrogression introduces latal bias into the model while significantly reducing the model variance R regression is a variation of linear regression but instead of trying to minimize the sum of squared residuales that linear regression does it aims to minimize the sum of squared residuales added on the top of the squared coefficients what we call L2 regularization term let's look at a multiple linear regression example with P independent variables or predictors that are used to model the dependent variable y if you have followed the statistical section of this course you might also recall that the most popular estimation technique to estimate the parameter of the linear regression assuming its assumptions are satisfied is the ordinary Le squares or the OLS which finds the optimal coefficients by minimizing the sum of squared residuales or the RSS so re regression is pretty similar to the OS except that the coefficients are estimated by minimizing a slightly different cost or loss function this is the loss function of the re regession where beta J is the coefficient of the model for variable J beta0 is the intercept and x i j is the input value for the variable J and observation I Yi is a target variable or the dependent variable for observation Y and N is the number of samples and Lambda is what we call regularization parameter of the r regression so this is the loss function of OLS that you can see here and added a penalization term so it's combined the what we call RSS so if you check out the very initial lecture in this section where we spoke about different metrics that can be used to evaluate regression type of models you can see RSS and the definition of RSS well if you compare this expression then you can easily find that this is the exact formula for the RSS added with an intercept and this right term is what we called a penalty amount which basically represents the Lambda times the sum of the squar of the coefficients included in our model here Lambda which is always positive so it's always larger than equal zero is the tuning parameter or the penalty parameter this expression of the sum squared coefficients is called L2 Norm which is why we call this L2 penalty based regression or L2 regularization in this way regression assigns a penalty by shrinking their coefficients towards zero reduces the overall model variance but this coefficient will never become exactly zero so the model parameters are never said to exactly zero which means that all P predictors of the model are still intact this one is a key property of retrogression to keep in mind that it shrinks the parameters towards zero but never exactly sets them equal to zero L2 Norm is a mathematical term coming from linear algebra and it's standing for alian Norm we spoke about the penalty parameter lum LDA what we also call the tuning parameter Lambda which serves to control the relative impact of the penalty on the regression coefficient estimates when the Lambda is equal to zero the penalty term has no effect and the re regression will introduce the ordinary Le squares estimates but as the Lambda increases the impact of the shrinkage penalty grows and the r regression coefficient estimates approach to zero what is important to keep in mind which you can also see from this graph is that in r agression large Lambda will assign a penalty to some variables by shrinking their coefficients towards zero but they will never become exactly zero which becomes a problem when you are dealing with a model that has a large number of features and your model has a low interpretability retrogressions advantage over ordinarily squares is coming from the earlier introduced bias Varian trade of phenomenon so as in Lambda the penalty parameter increases the flexibility of the retrogression F decreases leading to decreased variance but increased bias the main advantages of retrogression are solving overfitting which regression can shrink the regression coefficient of less important predictors towards zero it can improve the prediction accuracy as well by reducing the variance and increasing the bias of the model Rich repression is less sensitive to outliers in the data compared to linear regression Rich regression is computationally less expensive compared to class or regression the main disadvantage of R aggression is the low modal interpretability as the P so the number of features your model is large let's now look into another regularization technique called l or regression or L1 regularization by definition l or regression or L1 regularization is a shrinkage technique that aims to solve overfitting by shrinking some of the modal coefficients towards zero and setting some to exactly zero l or regression like retrogression introduces later bias into the model while significantly reducing model variance there is however small difference between the two regression techniques that makes a huge difference in their results we saw that one of the biggest disadvantages of R regression is that it will always include all the predictors or all the p predictors in the final model whereas in case of lasso it overcomes this disadvantage so large Lambda or penalty parameter will assign a penalty to some variables by shrinking their coefficients towards zero in case of Rich aggression they will never become exactly zero which becomes a problem when your model has a large number of features and it has a low interpretability and L or regression overcomes this disadvantage of retrogression let's have a look at the loss function of L regularization so this is the loss function of OLS which is a left part of the formula called RSS combined with a penalty amount which is the right hand side of the expression the Lambda times some of the absolute values of the coefficients beta J as you can see this is the RSS that we just saw which is exactly the same as the loss function of the OLS and then we are adding the second term which basically is the Lambda the penalization parameter multiplied by the sum of the absolute value of the coefficient beta J where J goes from one till p and the p is number of predictors included in now model here once again the Lambda which is always positive larger than equal Z is a tuning parameter or the penalty parameter this expression of the sum of squared coefficients is called L1 Norm which is why we call this L1 penalty based regression or L1 regularization in this way L of regression assigns a penalty to some of the variables by shrinking their coefficients towards zero and setting some of these parameters to exactly zero so this means that some of the coefficients will end up being exactly equal to zero which is a key difference between the L regression versus the reg regression the L1 Norm is a mathematical term coming from the linear alra and it's standing for man had Norm or distance you might see here a key difference when comparing the visual representation of the L regression compared to the visual representation of the reg agression so if you look at this point you can see that there will be cases where our coefficients will be set to exactly zero this is where we have this intersection whereas in case of R regression you can recall that there was not a single intersection so the numbers where the circle was closed to the intersection points but there was not a single point when there was an intersection and the coefficients were put to zero and that's the key difference between two regression type of models between the two regularization Tech techniques the main advantages of loss or regression are solving overfitting so loss or regression can shrink the regression coefficient of less important predictors toward zero and some to exactly zero as the model filters some variables out L indirectly performs also what we call feature selection such that the resulted model is highly interpretable and with less features and much more interpretable compared to the reg aggression laso can also improve the predi accuracy of the model by reducing the variance and increasing the bias of the model but not as much as the retrogression earlier when speaking about correlation we also briefly discussed the concept of causation we discuss that correlation is not a causation and we also briefly spoke the method used to determine whether there is a causation or not that model is the infamous linear aggression and even if this model is recognized as a simple approach it's one one of the few methods that allows identifying features that have an impact or statistically significant impact on a variable that we are interested in and we want to explain and it also helps you identify how and how much there is a change in the Target variable when changing the independent variable values to understand the concept of linear aggression you should also know and understand the concepts of dependent variable independent variable linearity and statistical significant effect dependent variables are often referred to as response variables or explained variables by definition dependent variable is a variable that is being measured or tested it's called the dependent variable because it's thought to depend on the independent variables so you can have one or multiple independent variables but you can have only one dependent variable that you are interested in that is your target variable let's now look into the independent variable definition so independent variables are often referred as regressors or explanatory variables and by definition independent variable is the variable that is being manipulated or controlled in the experiment and is believed to have an effect on the dependent variable put it differently the value of the dependent variable is s to depend on the value of the independent variable for example in an experiment to test the effect of having a degree on the wage the degree variable would be your independent variable and the wage would be your dependent variable finally let's look into the very important concept of statistical significance we call the effect statistically significant if it's unlikely to have occurred by random chance in other words a statistically significant effect is one that is likely to be real and not due to a random chance let's now Define the linear regression model formally and then we will dive deep into the theoretical and practical details by definition V regression is a statistical or machine learning method that can help to model the impact of a unit change in the variable the independent variable on the values of another Target variable or the dependent variable when the relationship between the two variables is assumed to be linear when the linear regression model is based on a single independent variable then we call this model simple linear regression when the model is based on multiple independent variables we call it multiple linear regression let's look at the mathematical expression describing linear regression you can recall that when the linear regression model is based on a single independent variable we just call it a simple linear regression this expression that you see here is the most common mathematical expression describing simple linear regression so you can see that we are saying that the Yi is equal to Beta 0 plus beta 1 x i plus UI in this expression the Yi is the dependent variable and the I that you see here is the index corresponding to the E row so whenever you are getting the data and you want to analyze this data you will have multiple rows and if your multiple rows describe the observations that you have in your data so it can be people it can be observation describing uh your data then the each characterizes the specific roow the each roow that you have in your data and the Yi is then variables value corresponding to that each show then the same holds for the XI so the XI is then the independent variable or the explanatory variable or the regressor that you have in your model which is the variable that we are testing so we want to manipulate it to see whether this variable has a statistically significant impact on the dependent variable y so we want to see whether the unit change in the X will result in a specific change in the Y and what kind of change is that so beta Z that you see here is not a variable and it's called intercept or constant something that is unknown so we don't have that in our data and it's one of the parameters of linear regression it's an unknown number which the linear regression model should estimate so we want to use the linear regression model to find out this uh unknown value as well as the second unknown value which is a beta one as well as we can estimate the error terms which are represented by the UR so beta one next to the XI so next to the independent variable is also not a variable so like beta zero is an unknown parameter in linear regression model an unknown number which the linear regression model should estimate beta one is often referred as a slope coefficient of variable X which is the number that quantifies how much dependent variable y will change if the independent variable X will change by one unit so that's EX exactly what we are most interested in the beta one because this is the coefficient and this is the unknown number that will help us to understand and answer the question whether our independent variable X has a statistically significant impact on our dependent variable y finally the U that you see here or the UI in the expression is the error term or the amount of mistake that the model makes when explaining the target variable we add this value since we know that we can never exactly and accurately estimate the Target variable so we will always make some amount of estimation error and we can never estimate the exact value of y hence we need to account for this mistake that we are going to make and we know in advance that we are going to have this mistake by adding an error term to our model let's also have a brief look at how multiple linear regression is usually expressed in mathematical terms so you might recall that difference between the simple linear regression and multiple linear regression is that the first one has a a single independent variable in it whereas the letter or the multiple linear regression like the name suggest has multiple independent variables in it so more than one knowing this type of Expressions is critical since they not only appear a lot in the interviews but also in general you will see them in the data science blogs in presentations in books and also in papers so being able to quickly identify and say ah I remember saying this at once then it will help you to easier understand and follow the process and the story line so uh what you see here you can read as Yi is equal to Beta 0 plus beta 1 * X1 I plus beta 2 * X2 I plus beta 3 * X3 I plus UI so this is the most common mathematical expression describing multiple linear regression in this case with three independent variables so if you were to have more independent variables you should add them with their corresponding indices and coefficients so in this case the method will aim to estimate the model parameters which are beta 0 beta 1 beta 2 and beta Tre so like before Yi is our dependent variable which is always a single one so we only have one dependent variable then we have beta 0 which is our intercept or the constant then we have our first slope coefficient which is beta 1 corresponding to our first independent variable X1 then we have X1 I which stands for the independent variable the first independent variable with an index one and the I stands for the index corresponding to the row so whenever we have multiple linear regression we always need to specify two indices and not only one like we had in our uh single linear regression the index cor that characterizes which independent variable we are referring to so whether it's independent variable one two or three and then we need to specify which row we are referring to which is the index I so you might notice that that in this case all the indices are the same because we are uh looking into one specific role and we are representing this role by using the independent variables the error term and dependent variable so then we are adding our third term which is beta 2 * x2i so the beta 2 is our third unknown parameter in the model and the second slope coefficient corresponding to our second independent variable and then we have our third independent variable with the corresponding slope coefficient beta 3 as well as we also add like always an error term to account for the error that we know that we are going to make so now when we know what the linear regression is and how to express it in the mathematical terms you might be asking the next logical question well we know that when we know what the linear regression is and how to express it in the mathematical terms you might be asking the next logical question how do we find those unknown parameters in the model in order to find out how the independent variables in impacted the dependent variable finding this unknown parameters is called estimating in data science and in general so we are interested in finding out the possible values or the values that the best approximate the unknown values in our model and we call this process estimation and one technique used to estimate linear regression parameters is called oils or ordinary Le squares so domain idea behind this approach the OLS is to find the best fitting straight line so the regression line through a set of paired X and y's so our independent variables and dependent variables values by minimizing the sum of squared errors so to minimize the sum of squares of the differences between the observed dependent variable and its values which are the predicted values that we are predicted by our model that's exactly what we want to do by by using this linear function of the independent variables the residuals so this is too much information let's go it step by step so in linear regression we just so when we are expressing our simple linear regression we have this error term and we can never know what is the actual error term but what we can do is to estimate the value of the error term which we call residual so we want to minimize the sum of squ residuales because we don't know the errors so we want to find a line that will best fit our data in such way that the error that we are making or the sum of squared errors is as small as possible and since we don't know the errors we can estimate the Errors By each time looking at the predicted value that is predicted by our model and the True Value and then we can subtract them from each other and we can see how good our model is estimating the values that we have so how good is our model estimating the unknown parameters so to minimize the sum of squar of the differences between the observed dependent variable and its values predicted by the linear function of the independent variables so the minimizing the sum of squared residuales so uh we Define the estimate of a parameters and variables by adding a hge on the top of the variables or parameters so in this case you can see that y I had is equal to Beta Z head plus beta 1 head XI so you can see that we no longer have a error term this and we say that Yi head is the estimated value of Yi and beta zero head is the estimated value of beta 0 beta 1 head is the estimated value of our beta 1 and the XI is still our data so the values that we have in our data and therefore we don't have a hat since that does not need to be estimated so what we want to do is to estimate our dependent variable and we want to compare our estimated value that we got using our OLS with the actual with the real value such that we can calculate our errors or the estimate of the error which is represented by the UI head so the UI head is equal to Yi minus Yi head where UI head is simply the estimate of the error term or the residual so this predicted error is always referred as residual so make sure that you do not confuse the error with the residual so error can never be observed error you can never calculate and you will never know but what you can do is to predict the error and you can when you predict the error then you get a recal and what oil is trying to do is to minimize the amount of airor that it's making therefore it looks at the sum of squared residuales across all the observation and it tries to find the line that will minimize this value therefore we are saying that the O tries to find the best fitting straight line such that it minimizes the sum of squared residuals we have discussed this model when we were talking about this model mainly from the perspective of causal analysis in order to identify features that have a statistically significant impact on the response variable but linear regression can also be used as a prediction model for modeling linear relationship so let's refresh our memory with the definition of linear regression model by definition linear regression is a statistical or a machine learning method that can help to modrow the impact of a unit change in a variable the independent variable on the values of another Target variable the dependent variable when the relationship between two variables is linear we also discussed how mathematically we can express what we call Simple linear regression and a multiple linear regression so this how the uh simple linear regression can be represented so uh in case of simple linear regression you might recorde that we are dealing with just a single independent variable and we always have just one dependent variable both in the single linear regression and in the multiple linear regression so here you can see that Yi is equal to Beta 0 plus beta 1 * XI plus UI where Y is the dependent variable and I is basically the index of each observation or the row and then the beta 0 is The Intercept which is also known as constant and then the beta 1 is the slope coefficient or a parameter corresponding to the independent variable X which is unnown and a constant which want to estimate along to the beta zero and then the XI is the independent variable corresponding to the observation I and then finally the UI is the error term corresponding to the observation I do keep in mind that this error term we are adding because we do know that we always are going to make a mistake and we can never perfectly estimate the dependent variable therefore to account for this mistake we are adding this UI so let's also recall the estimation technique that we use to estimate the parameter of the linear regression model so the beta 0 and beta 1 and to predict the response variable so we call this estimation technique ORS or the ordinary Le squares NS is an estimation technique for estimating the unknown parameters in the linear regression model to predict the response or the dependent variable so we need to estimate the beta Z so we need to get the beta zero head and we need to estimate the beta one or the beta 1 head in order to obtain the Y I head so Yi head is equal to Beta Z head plus beta 1 head time x i where the um difference between the Yi head and the Yi so the true value of the dependent variable and the predicted value they are different will then produce our estimate of the error or what we also call residual the main idea behind this approach is to find the best fitting straight line so the regression line through a set of paired X and Y values by minimizing the sum of squared residuales so we want to minimize our errors as much as possible therefore we are taking their squared version and we are trying to sum them up and we want to minimize this entire error so to minimize the sum of squar residual so the difference between the observed dependent variable and its values predicted by the linear function of the independent variables we need to use the OLS one of the most common questions related to linear regression that comes time and time again in the uh data science related interviews is a topic of the Assumption of the linear regression model so you need to know each of these five fundamental assumptions of the linear regression and the OLS and also you need to know how to test whether each of these assumptions are satisfied so the first assumption is the linearity Assumption which states that the relationship between the independent variables and the dependent variable is linear we also say that the model is linear in parameters you can also check whether the linearity assumption is Satisfied by plotting the residuals to the fitted values if the pattern is not linear then the estimat will be biased in this case we say that the linearity assumption is violated and we need to use more flexible models such as tree based models that we will discuss in a bit that are able to model these nonlinear relationships the second assumption in the linear regression is the Assumption about randomness of the sample which means that the data is randomly sampled and which basically means that the errors or the residuales of the different observations in the data are independent of each other you can also check whether the second assumption so this assumption about random sample is Satisfied by plotting the residuals you can then check whether the mean of this residuales is around zero and if not then the OLS estimate will be biased and the second assumption is violated this means that you are systematically over or under predicting the dependent variable the third assumption is the exogeneity Assumption which is a really important assumption often as during the data science interviews exogeneity means that each independent variable is uncorrelated with the error terms exogeneity refers to the assumption that the independent variables are not affected by the error term in the model in other words the independent variables are assumed to be determined independently of the erors in the model exogeneity is a key Assumption of the new regression model as it allows us to interpret the estimated coefficient as representing the true causal effect of the independent variables on the dependent variable if the independent variables are not exogeneous then the estimated coefficients may be biased and the interpretation of the results may be invalid in this case we call this problem an endogeneity problem and we say that the independent variable is not exogeneous but it's endogeneous it's important to carefully consider the exogeneity Assumption when building a linear regression model as violation of this assumption can lead to invalid or misleading results if this assumption is satisfied for an independent variable in the linear model we call this independent variable exogeneous so otherwise we call it endogeneous and we say that we have a problem of endogenity endogenity refers to the situation in which the independent variables in the linear regression model are correlated with the error terms in the model in other words the errors are not independent of the independent variables endogeneity is a violation of one of the key assumptions of the linear regression model which is that the independent variables are EX geners or not affected by the errors in the model endogenity can arise in a number of ways for example it can be caused by omitted variable bias in which an important predictor of the dependent variable is not included in the model it can also be caused by the reverse causality in which the dependent variable affects the independent variable so those two are a very popular examples of the case when we can get an endogenity problem and those are things that you should know whenever you are interest in for data science roles especially when it's related to machine learning because those questions are uh being asked to you in order to test whether you understand the concept of exogeneity versus endogenity and also in which cases you can get endogenity and also how you can solve it so uh in case of omitted variable bias let's say you are estimating a person's salary and you are using as independent variable their education their number of years of experience and uh some other factors but you are not including for instance in your model a feature that would describe the uh intelligence of a person or uh for instance IQ of the person well given that those are a very important indicator for a person in order to perform in their uh field and this can definitely have um indirect impact on their salary not including these variables will result in omitted variable bias because this will then be uh Incorporated in your um error term and uh this can also relate to the other independent variables because then your uh IQ is also related to the um to the education that you have higher is your IQ usually higher is your education so in this way you will have an error term that includes an important variable so this is the omitted variable which is then uh correlated with your uh one of your or multiple of your independent variables include in your model so the other example other cause of the endogenity problem is the reverse causality and um what reverse causality means is basically that not only the independent variable has an impact on the dependent variable but also the dependent variable has an impact on the independent variable so there is a reverse relationship which is something that we want to avoid we want to have our features that include in our model that have only an impact on dependent variable so they are explaining the dependent variable but not the other way around because if you have the um the other way so you have the dependent variable impacting your independent variable then you will have the error term being related to this independent variable because there are some components that also Define your dependent variable so knowing the uh few examples such as those that can cause uh endogenity so they can violate the exogeneity assumption is really important then uh you can also check for the exogeneity Assumption by conducting a formal statistical test this is called house one test so this is an econometrical test that helps to understand whether you have an exogeneity uh violation or not but this is out of the scope of this course I will however include uh many resources related the exogeneity endogenity the omitted variable bias as well as the reverse cality and also how the house one test can be conducted so for that check out the interation guide where you can also find the corresponding free your resources the fourth assumption linear regression is the Assumption about homos skes homos refers to the assumption that the variance of the errors is constant across all predicted values this assumption is also known as the homogeneity of the variance homosa is an important Assumption of linear regression model as it allows us to use certain statistical techniques and make inferences about parameters of the model if the errors are not homoskedastic then the result of these techniques may be invalid or misleading if this assumption is violated then we say that we have heteroscedasticity hecticity refers to the situation in which the variance of the error terms in the linear regression model is not constant across all the predicted values so we have a variating variant in other words the Assumption of homos skas testing in that case is violated and we say we have a problem of heos heteros can be a real problem in V regression nurses because it can lead to invalid or misleading results for example the standard estimates and the confidence intervals for the parameters may be incorrect which means that also the statistical test may have incorrect type one error rates so you might recall when we were discussing the linear regression as part of the fundamental statis section of this course is that we uh looked into the output that comes from a python and we saw that we are getting uh estimates as part of the output as well as standard errors then the T Test so the student T test and then the corresponding P values and the 95% confidence intervals so whenever there is a heos problem the um coefficient might still be accurate but then the corresponding standard error the U student T Test which is based on the standard error and then the P value as well as the uh confidence intervals may not be accurate so you might get the uh good and reasonable coefficient but then you don't know how to correctly evaluate them you might end up discovering that um you might end up stating that certain uh independent variables are statistically significant because their coefficients are statistically significant since their P values are small but in the reality those P values are misleading because they are based on the wrong statistical uh test and they are based on the wrong standard errors you can check for this assumption by plotting the residual and see whether there is a funnel like graph if there's Fel like gra then you have a a constant variance but if there is not then you won't see this fenel like this shape that indicates that your variances are constant and if not then we say we have a problem of heos skos if you have a heteros system you can no longer use the OS and the linear regression and instead you need to look for other more advanced econometrical regression techniques that do not make such a strong assumption regarding the variance of your um residuals so you can for instance use the GLS the fgs the GMM and this type of solutions will um help to solve the hoscar problem and they will not make a strong assumptions regarding the variance in your model the fifth and the final assumption in linear regression is the Assumption about no perfect multicolinearity this assumption states that there are no exactly new relationships between the independent variables multicolinearity refers to the case when two or more independent variables in your linear regression model are highly correlated with each other this can be a problem because it can lead to unstable and unreliable estimate of the parameters in the model perfect multicolinearity happens when the independent variables are perfectly correlated with each other meaning that one variable can be perfectly predicted from the other ones and this can cause the estimated coefficient your linear regression model to be infinite or undefined and can lead your errors to be uh entirely misleading when making a predictions using this model if perfect multicolinearity is detected it may be necessary to remove one if not more problematic variables such that you will avoid having correlated variables in your model and even if the perfect multicolinearity is not present multicolinearity at a high level can still be a problem if the correlations between the independent variables are high in this case the estimate of the parameters may be imprecise and the model may be uh entirely misleading and will results in less reliable uh predictions so uh to test for the multicolinearity Assumption you have different solutions you have different options the first way uh you can do that is by using the uh di test De test is a formal statistical and econometrical test that will help you to identify which variables cause a problem and whether you have a perfect multicolinearity in your linear regression model you can PL heat map which will be based on the uh correlation metrix corresponding to your features then you will have your uh correlations per pair of independent variables plotted as a part of your heat map and then you can identify all the um pair of features that are highly correlated with each other and those are problematic features one of which should be removed from your model and in this way by uh showing the heat map you can also showcase your stakeholders why you have remove certain variables from your model whereas explaining a Diller test is much more complex because it involves more advanced econometrics and linear uh regression um explanation so if you're wondering how you can perform this de FL test and you want to prepare the uh questions related to perfect multicolinearity as well as how you can solve the perfect multicolinearity problem in your linear regression model then head towards the interview preparation guide included in this part of of the course in order to answer such questions and also to see the 30 most popular interview questions you can expect from this section in the interview preparation guide now let's look into an example coming from the linear regression in order to see how all those pieces of the puzzle come together so let's say we have collected a data on a class size and a test course for of students and we want to model the linear relationship between the class size and the test course using the linear regression model so as we have just one independent variable we are dealing with a simple linear regession and the model equation would be as follows so you can see that the test course is equal to beta0 plus beta 1 multip by class size plus Epsilon so here the class size is the single independent variable that we got in our model the test score is the dependent variable the beta0 is is The Intercept or the constant the beta one is the coefficient of Interest as this the coefficient corresponding to our independent variable and this will help us to understand what is the uh impact of a unit change in the class size on the test score and then finally we are including in our model our error term to account for the mistakes that we are definitely going to make when estimating the uh dependent variable that has course the goal is to estimate the coefficient 0 and beta 1 from the data and use the estimated model to predict the test course based on the class size so once we have the estimates we can then interpret them as follows the Y intercept the beta zero represents the expected test course when the class size is zero it represents the base score that the student would have obtained if the class size would have been zero then the coefficient for the class size the beta one represents the change in the test course associated with the one unit change in the class size the positive coefficient would imply that one unit change in the class size would increase the test course whereas the negative coefficient would uh imply that the one unit change in the class size will decrease the test course uh correspondingly we can then use this model with OLS estimate in order to predict the test course for any given class size so let's go ahead and Implement that in Python if you're wondering how this can be done then head towards the resources section as as well as the part of the Python for data science where you can learn more about how to work with pendant data frames how to import the data as well as how to fit a linear regression model so the problem is as follows we have collected data on the class size and we have this independent variable so as you can see here we have the students uncore data and then we have the class size and this our feature and then we want to estimate the Y which is the test SC so uh here is the code a sample code that will fit a linear regression model we are keeping here everything very simple we are not splitting our data into training test and then fitting the model on the training data and making the predictions with the test score but we just want to see how we can interpret the uh coefficients so keeping everything very simple so you can see here that we are getting an intercept equal to 63.7 and the coefficient corresponding to our single independent variable class size is equal to minus 0.40 what this means is that so each increase of the uh class size by one unit will result in the decrease of the test scores with 0.4 so there is a negative relationship between the two now the next question is whether there is a statistical significance whether the uh coefficient is actually significant and where the class size has actually statistically significant imp impact on the dependent variable but all those are things that we have discussed as part of the fundamental statistic section of this course as well as we are going to look into a linear regression example when we are going to discuss the hypothesis testing so I would highly suggest you to uh stop in here to revisit the fundamentals to statistic section of this course to refresh your memory in terms of linear regression and then um check also the hypothesis test uh section of the course in order to look into a specific example of linear regression when we are discussing the standard errors how you can evaluate your OLS estimation results how you can use the student T Test the P value and the confidence intervals and how you can estimate them in this way you will learn for now only the theory related to the coefficients and then you can um add on the top of this Theory once you have learned all the other sections and the other topics in this course let's finally discuss the advantages and the disadvantages of the linear regression model so some of the advantages of the linear regression model are the following the linear regression is relatively simple and easy to understand and to implement linear regression models are well suited for understanding the relationship between a single independent variable and a dependent variable also linear regression can help to handle multiple independent variables and can estimate the unique relationship between each independent variable and the corresponding dependent variable thear regression model can also be extended to handle more complex models such as pooms interaction terms allowing for more flexibility in the modeling the data also linear aggression model can be easily regularized to prevent overfitting which is a common problem in modeling as we saw uh in the beginning of this section so you can use for instance retrogression which is an extension of Vue regression you can use ler regression which is also an extension of Vue regression model and then finally linear regression models are widely supported by software packages and libraries making it easy to implement and to analyze and some of the disadvantages of the linear aggression are the following so the linear aggression models make a lot of strong assumptions regarding for instance the linearity between independent variables and independent variables while the true relationship can actually be also nonlinear so the model will not then be able to capture the complexity of the data so nonlinearity and the predictions will be inaccurate therefore it's really important to have a data that has a linear relationship for linear regression to work linear regression also assumes that the error terms are normally distributed and also homoskedastic error terms are independent across observations violations of the strong assumption will lead to bias and inefficient estimates linear regression is also sensitive to outliers which can have a disproportionate effect on the estimate of the regression coefficients linear regression does not easily handle categorical independent variables which often require additional data preparation or the use of indicator variables or using encodings finally linear regression also assumes that the independent variables are exogeneous and not affected by the error terms if this assumption is violated then the result of the model may be misleading in this lecture lecture number five we will discuss another simple machine learning technique called logistic regression which is simple but very important classification model useful when dealing with a problem where the output should be a probability so the name regression in logistic regression might be confusing since this is actually a classification model logistic regression is widely used in a variety of fields such as social sciences medicine and Engineering so let us firstly Define the logistic regression model the logistic regression is a supervised classification technique that models the conditional probability of an event occurring or observation belonging to a certain class given a data set of independent variables and those are our features the class can have two categories or more but later on we will learn that logistic regression Works ideally when we have just two classes this is is another very important and very popular machine learning technique which though named regression is actually a supervised classification technique so when the relationship between two variables is linear the dependent variable is a categorical variable and you want to predict a variable in the form of a probability so a number between zero and one then logistic regression comes in very handy this is because during the prediction process in logistic regression the classifier predicts the probability ility a value between Z and one of each observation belonging to a certain class for instance if you want to predict the probability or the likelihood of a candidate being elected or Not Elected during the election process given the set of characteristics that you got about your candidate let's say the popularity score the past successes and other descriptive variables about this candidate then logistic regression comes in very handy to model this probability so rather than predicting the response variable logistic regression models the probability that y belongs to a particular category similar to the linear regression with a difference that instead of Y it predicts the log odds so we will come about this definition of log odds and odds in a bit in statistical terminology what we are trying to do is to model the conditional distribution of the response y given the predictors X therefore logistic regression helps to predict the probability of Y belonging to a certain class given the feature space what we call probability of Y given X if you're wondering what is the concept of probability what is this conditional probability then make sure to head towards the section of fundamentals to statistics as we are going to in detail about this Concepts as well as we are looking into different examples these definitions and this Concepts will help you to better follow this lecture so here we see the probability X which is what we are interested in modeling and it's equal to e to the power beta 0 + beta 1 * x / to 1 + e^ beta 0 + beta 1 * X let's now look into the formulas for the odds and log ODS both these formulas are really important because you can expect them during your data science interviews so sometimes you will be asked to explicitly write down the odds and log ODS formulas and those are highly related to the log likelihood and likelihood functions which are the base for the estimation technique mle or the maximum likelihood estimation used to estimate the unknown parameters in the logistic agression so the log odds and the odds are highly related to each other and in logistic regression we use the odds and log ODS to describe the probability of an event occurring the odds is a ratio of the probability of an event occurring to the probability of the event not occurring so as you can see the odd is equal to PX / to 1 - PX where PX is the probability of event occurring and 1 - PX is the probability of the event not occurring so this formula is equal to E power beta 0 + beta 1 * X in our formula where we only have one independent variable and the E simply is the ERS number or the 2.72 which is a constant so we won't derive this formula by ourselves because that's out of the scope of this course but feel free to head out to the PX formula that we just saw in the previous slide and take this formula divide it to one minus 2 exactly the same expression and you can verify that you will end up with this expression that you see here for example if the probability of a person having a heart attack is 0.2 then the ads of having a heart attack will be 0.2 / to 1 - 0.2 which is equal to 0.25 the low OD also known as the logit function is a natural logarithm of the OD so as you can see here the log of px/ to 1 minus PX and this is equal to Beta 0 plus beta 1 * X so you can see that we are getting rid of this e and this is simply because of a mathematical expression that says if we take the log of the e to the power something then we end up with only the exponent part in it though this is out of the scope of this course to look into the mathematical derivation of this formula I will include many resources regarding this logarithm the Transformations and the mathematics behind it just in case you want to look into those details and do some uh extra learning so logistic regression uses the log ODS as the dependent variable and the independent variables are used to predict this log ODS the coefficient of the independent varibles represent then the change in the log OD for a one unit change in the independent variable so you might that in the linear regression we were modeling the actual dependent variable in case of logistic regression the difference is that we are modeling the logas another important Concept in logistic regression is the likelihood function the likelihood function is used to estimate the parameters of the model given the observed data sometimes during the interviews you might also be asked to write down the exact likelihood formula or the log likelihood function so I would definitely suggest you to memorize this one and to understand all the components included in this formula the likelihood function describes the probability of The observed data given the parameters of the model and if you follow the lecture of the probability density functions in the section of fundamentals to statistics you might here even recognize the bar noly PDF since the likelihood function here is based on the probability Mass function of a Baro distribution which is a distribution of a binary outcome So This is highly applicable to the case where we have only two categories in our dependent variable and we are trying to estimate the probability of observation to belonging to one of those two classes so this is the L likelihood function and this is the likelihood function we start with the likelihood function and the L the capital letter L stands for the likelihood function the L is equal the likelihood function L is equal to product across all pair of these multipliers so we have Peak side to the power Yi multiplied by 1 - pxi to^ 1 - y i where pxi is the PX that we just so only for observation I and the Yi is simply the class so Yi will either be equal to zero or one so Yi is equal to 1 then 1 minus Yi is equal to zero so we every time we are looking into the probability of observation belonging to the first class multiply by the probability of observation not belonging to that plus and we take this cross multiplications and we do that for all the observations that are included in our data and this also comes from mathematics so this stands for the product so uh given that it's harder to work with products compared to the sums we then apply the Lo likelihood uh transformation in order to obtain the Lo likelihood function instead of likelihood function so when we apply this log transformation so we take the L logarithm of this expression we end up with this log likelihood expression and here again one more time we are making use of a mathematical property which says that if we take the logarithm of the products we end up with the sum of the logarithms so we go from the products to the sums I will also include resources regarding that such that you can also learn the mathematics Behind These Transformations so the L likelihood with a lowercase L is equal to logarithm of the products p i^ y i * 1 - PX i^ 1 - Yi and when we apply that mathematical transformation then the L is equal to sum across all observation I is equal to 1 till M and then y i so the power the exponent comes to the front Yi * logarithm of the pxi plus 1 - Yi * logarithm of 1 - pxi while for linear regression we use OLS as estimation technique for logis regression in other estimation technique should be used the reason why we cannot use OLS in logistic regression to find the best fitting line is because the errors can become very large or very small and sometimes even negative in case of logistic aggression while for logistic regression we aim for predicted value between zero and one therefore for logistic regression we need to use estimation technique called maximum likelihood estimation or in short mle where the likelihood function calculates the probability of observing the data outcome given the input data in the model we just saw the likel function in the previous slide this function is then optimized to find the set of parameters that result in the largest sum likelihood so the maximum likelihood over the training data set logistic function will always produce this s-shaped curve regardless of the value of independent variable able X resulting in sensible estimation most of the time so value between 0 and one so as you can see this s-shaped cure is what characterizes the maximum likelihood estimation corresponding to the logistic regression and it will always provide not come between zero and one then the idea behind the maximum likelihood estimation is to find a set of estimates that would maximize the likelihood function so let's go through the maximum likelihood estimation step by step what we need to do first is to define a likelihood function the first step is to always Define this function for the model secondly we need to write the log likelihood function so the next step is to take the natural logarithm of the likelihood function to obtain the log likelihood function so I'm talking about this one the L likel function is a more convenient and computationally efficient function to work with and what we need to do next is to find the maximum of this L like function so this step consists of finding the values of the parameters beta 0 and beta 1 that maximize the L lik function there are many optimization algorithms that can be used to find the maximum but these are out of the scope of this course and you don't need to know them as part of becoming a data scientist and entering data science field in the fourth step we need to estimate the parameters so we are talking about the beta 0 and beta 1 once the maximum of the log likel function is found the values of the parameters that correspond to the maximum are considered the maximum likelihood estimate of the parameters and then in the next step we need to check the model Feit so once the maximum likelihood estimates are obtained we can check the goodness of fit of the model by calculating information criteria such as AIC B Bic or R squ where AIC stands for akas information criteria Bic stands for bi information criteria and r s refers to the same evaluation value that we use for evaluating linear regression in the final step we need to make predictions and evaluate the model using the maximum likelihood estimates the model can be used to make predictions on a new unseen data and the performance of the model can be then evaluated using various evaluation metrics such as accuracy precision and recall those are metrics that we have Revisited as part of the very initial lecture in the section and those are metrics that you need to know so unlike the AIC Bic that we just spoke about that evaluates the goodness of feed of the very initial estimates that come from the maximum likelihood the accuracy and precision and the recall evaluate the final model so the values that we get for the nuan in data when we make the predictions and we get the classes and those are metrics that you need to know if you're wondering what this accuracy is what this Precision recall is as well as the F1 score make sure to head towards the very initial lecture in this section where we talked about the exact definition of this metrix let's finally discuss the advantages and the disadvantages of the logistic regression so some of the advantages of logistic regressions are that it's a simple model it has a low variance it has a low bias and it provides probabilities some of the disadvantages of logistic regressions are logistic regression is unable to model nonlinear relationship so one of the key assumptions that logistic regression is making is that there is a linear relationship between your independent variable and your dependent variable logistic regression is also unstable when your classes are well separable as well logistic agression becomes very unstable when you have more than two classes so this means whenever you have more than two categories in your dependent variable or whenever your classes are well separable using logistic regression for classification purposes will not be very smart so instead you should look for other models that you can use for this task and one of such models is linear discriminate analysis so the LDA that we will introduce in the next lecture so this is all for this lecture where we have looked into the logistic regression and the maximum likelihood estimation in the next lecture we will look into the LDA so stay tuned and I will see you in the next lecture looking to step into machine learning or data science it's about starting somewhere practical yet powerful and as the simple yet most popular machine learning algorithm linear regression linear aggression isn't just a jargon it's a tool that is used both for a finding out what are the most important features in your data as well as being used to forecast the future that's your starting point in the Journey of data science and Hands-On machine learning uh work embark on a handson data science and machine learning project where we are going to find what are the drivers of Californian house prices you will clean the data visualize the key trends you will learn how to process your data and how to use different python libraries to understand what are those drivers of Californian house values you're are going to learn how to implement linear regression in Python and learn all these fundamental steps that you need in order to conduct a proper handson data science project at the end of this project you will not only learn those different python libraries when it comes to data science and machine learning such as pandas psyit learn tou models medf Le curn but you will also be able to put this project on your person website and on your resume a point size stepbystep case study and approach to build your confidence and expertise in machine learning and in data science in this part we are going to talk about a case study in the field of Predictive Analytics and causal analysis so we are going to use this simple yet powerful regression technique called your regression in order to perform causal analysis and Predictive Analytics so by causal analysis I mean that we are going to look into this correlations clation and we're trying to figure out what are the features that have an impact on the housing price on the house value so what are these features that are describing the house that Define and cause the variation in the uh house prices the goal of this case study is to uh practice linear regression model and to get this first feeling of how uh you can use a machine learning model a simple machine learning model in order to perform uh model training model evaluation and also use it for causal analysis where you are trying to identify features that have a statistically significant impact on your response variable so on your dependent variable so here is the step-by-step process that we are going to follow in order to find out what are the features that Define the Californian house values so first we are going to understand what are the set of independent variables that we have we're also going to understand what is the response variable that we have so for our multiple linear regression model we are going to understand what are this uh techniques that we uh need and what are the libraries in Python that we need to load in order to be able to conduct this case study so first we are going to load all these libraries and we are going to understand why we need them then we are going to conduct data loading and data preprocessing this is a very important step and I deliberately didn't want you to skip this and didn't want you to give you the clean data cuz uh usually in normal real Hands-On data science job you won't get a clean data you will get a dirty data which will contain missing values which will contain outliers and those are things that you need to handle before you proceed to the actual and F part which is the modeling and the uh analysis so therefore we are going to do missing data analysis we are going to remove the missing data from our Californian house price data we are going to conduct outlier detection so we are going to identify outliers we are going to learn different techniques that you can use visualization uh techniques uh in Python that you can use in order to identify outliers and then remove them from your data then we are going to perform data visualization so we are going to explore the data and we are going to do different plots to learn more about the data to learn more about this outliers and different statistical techniques uh combined with python so then we are going to do correlation analysis to identify some problematic features which is something that I would suggest you to do independent the nature of your case study to understand understand what kind of variables you have what is the relationship between them and whether you are dealing with some potentially problematic variables so then we will be uh moving towards the fun part which is performing the uh multiple theine regression in order to perform the caal NES which means identifying the features in the Californian house blocks that Define the value of the Californian houses so uh finally we will do very quickly another uh implementation of the same multiple uh multiple linear regression in order to uh give you not only one but two different ways of conducting linear regression because linear regression can be used not only for caal analysis but also as a standalone a common machine learning regression type of model therefore I will also tell you how you can use psych learn as a second way of training and then predicting the C for house values so without further Ado let's get started once you become a DAT a scientist or machine learning researcher or machine learning engineer there will be some cases some Hands-On uh data science projects where the business will come to you and we'll tell you well here we have this data and we want to understand what are these features that have the biggest influence on this Auto factor in this specific case in our case study um let's assume we have a client that uh is interested in identifying what are the features that uh Define the house price so maybe it's someone who wants to um uh invest in uh houses so it's someone who is interested in buying houses and maybe even renovating them and then reselling them and making a profit in that way or maybe in the long-term uh investment Market when uh people are buying real estate in a way of uh in inting in it and then longing for uh holding it for a long time and then uh selling it later or for some other purposes the end goal in this specific case uh for a person is to identify what are this features of the house that makes this house um to be priced at a certain level so what are the features of the house that are causing the price and the value of the house so we are going to make use of this very popular data set that is available on kagal and it's originally coming from psyit learn and is called California housing prices I'll also make sure to put the link uh of this uh specific um data set uh both in my GitHub account uh under this repository that will be dedicated for this specific case study as well as um I will also point out the additional links that you can use to learn more about this data set so uh this data set is derived from 1990 um US Census so United uh States census using one row Paris sensus block so a Blog group or block is the smallest uh geographical unit for which the US cus Bureau publishes sample data so a Blog group typically has a population of 600 to 3,000 people who are living there so a household is a group of people residing with within a single home uh since the average number of rooms and bedrooms in this data set are provided per household this conss may be um May take surprisingly large values for blog groups with few households and many empty houses such as Vacation Resorts so um let's now look into uh the variables that are available in this specific data set so uh what we have here is the med Inc which is the median income in blog group so uh this um touches the uh financial side and uh Financial level of the uh block uh block of households then we have House age so this is the median house age in the block group uh then we have average rooms which is the average number of rooms uh per household and then we have average bedroom which is the average number of bedrooms per household then we have population which is the uh blog group population so that's basically like we just saw that's the number of people who live in that block then we have a uh o OU uh which is basically the average number of household members uh then we have latitude and longitude which are the latitude and longitude of this uh block group that we are looking into so as you can see here we are dealing with aggregate data so we don't have the uh the data per household but rather the data is calculated and average aggregated based on a block so this very common in data science uh when we uh want to reduce the dimension of the data and when we want to have some sensible numbers and create this crosssection data and uh cross-section data means that we have multiple observations for which we have data on a single time period period in this case we are using as an aggregation unit the block and uh we have already learned as part of the uh Theory lectures this idea of median so we have seen that there are different descriptive measures that we can use in order to aggregate our data one of them is the mean but the other one is the median and often times especially if we are dealing with skute distribution so if we have a distribution that is not symmetric but it's rather right cuute or left skewed then we need to use this idea of median because median is then better representation of this um uh scale of the data um compared to the mean and um in this case we will soon see when representing and visualizing this data that we are indeed dealing with a skewed data so um this basically a very simple a very basic data set with not too many features so great um way to uh get your hands uh uh on with actual machine learning use case uh we will be keeping it simple but yet we will be learning the basics and the fundamentals uh in a very good way such that uh learning more um difficult and more advanced machine learning models will be much more easier for you so let's now get into the actual coding part so uh here I will be using the Google clap so I will be sharing the link to this notebook uh combined with the data in my python for data science repository and you can make use of it in order to uh follow this uh tutorial uh with me so uh we always start with importing uh libraries we can run a l regression uh manually without using libraries by using matrix multiplication uh but I would suggest you not to do that you can do it for fun or to understand this metrix multiplication the linear algebra behind the linear regression but uh if you want to um get handson and uh understand how you can use the new regression like you expect to do it on your day-to-day job then you expect to use um instead libraries such as psychic learn or you can also use the statsmodels.api libraries in order to understand uh this topic and also to get handson I decided to uh showcase this example not only in one library in Cy thir but also the starts models and uh the reason for this is because many people use linear regression uh just for Predictive Analytics and for that using psyit learn this is the go-to option but um if you want to use linear regression for causal analysis so to identify and interpret this uh features the independent variables that have a statistically significant impact on your response variable and then you will need to uh use another Library a very handy one for linear regression which is called uh stats models. API and from there you need to import the SM uh functionality and this will help you to do exactly that so later on we will see how nicely this Library will provide you the outcome exactly like you will learn on your uh traditional econometrics or introduction to linear regression uh class so I'm going to give you all this background information like no one before and we're going to interpret and learn everything such that um you start your machine Learning Journey in a very proper and uh in a very um uh high quality way so uh in this case uh first thing we are going to import is the pendence library so we are importing pendis Library as PD and then non pile Library as NP we are going to need pendes uh just to uh create a pendis data frame to read the data and then to perform data wrangling to identify the missing data outliers so common data wrangling and data prosessing steps and then we are going to use npy and npy is a common way to uh use whenever you are visualizing data or whenever you are dealing with metrices or with arrays so pandas and nonp are being used interchangeably so then we are going to use meth plot lip and specifically the PIP plat from it uh and this library is very important um when you want to visualize a data uh then we have cburn um which uh is another handy data visualization library in Python so whenever you want to visualize data in Python then methot leip and Cy uh cburn there are two uh very handy data visualization techniques that you must know if you like this um cooler undertone of colors the Seaburn will be your go-to option because then the visualizations that you are creating are much more appealing compared to the med plot Le but the underlying way of working so plotting scatter plot or lines or um heat map they are the same so then we have the STS mods. API uh which is the library from which we will be importing the uh as uh that is the temple uh linear regression model that we will be using uh for our caal analysis uh here I'm also importing the uh from Psychic learn um linear model and specifically the linear regression model and um this one uh is basically similar to this one you can uh use both of them but um it is a common um way of working with machine learning model so whenever you are dealing with Predictive Analytics so we you are using the data not for uh identifying features that have a statistically significant impact on the response variable so features that have an influence and are causing the dependent variable but rather you are just interested to use the data to train the model on this data and then um test it on an unseen data then uh you can use pyit learn so psyit learn will uh will be something that you will be using not only for linear regression but also for a machine learning model I think of uh Canon um logistic regression um random Forest decision trees um boosting techniques such as light GBM GBM um also clustering techniques like K means DB scan anything that you can think of uh that fits in in this category of traditional machine learning model you will be able to find Ayler therefore I didn't want you to limit this tutorial only to the S models which we could do uh if we wanted to use um if we wanted to have this case study for uh specifically for linear regression which we are doing but instead I wanted to Showcase also this usage of psychic learn because pyic learn is something that you can use Beyond linear regression so for all these added type of machine learning models and given that this course is designed to introduce you to the world of machine learning I thought that we will combine this uh also with psychic learning something that you are going to see time and time again when you are uh using python combined with machine learning so then I'm also uh importing the uh training test plate uh from the psychic learn model selection such that we can uh split our data into train and test now uh before we move into uh the uh actual training and testing we need to first load our data so so therefore uh what I did was to uh here uh in this sample data so in a folder in Google collab I uh put it this housing. CSV data that's the data that you can download uh when you go to this specific uh page so uh when you go here um then uh you can also uh download here that data so download 49 kab of this uh housing data and that's exactly what I'm uh downloading and then uploading here in Google clap so this housing. CSV in this folder so I'm copying the path and I'm putting it here and I'm creating a variable that holds this um name so the path of the data so the file uncore path is the variable string variable that holds the path of the data and then what I need to do is that I need to uh take this file uncore path and and I need to put it in the pd. read CSV uh which is a function that we can use in order to uh load data so PD stands for pandas the short way of uh naming pandas uh PD do and then read uncore CSV is the function that we are taking from Panda's library and then within the parentheses we are putting the file uncore path if you want to learn more about this Basics or variable different data structures some basic python for data science then um to ensure that we are keeping this specific tutorial structured I will not be talking about that but feel free to check the python for data science course and I will put the link um in the comments below such that you can uh learn that if you don't know yet and then you can come back to this tutorial to learn how you can use python in combination with linear regression so uh the first thing that I tend to do before moving on to the the actual execution stage is to um look into the data to perform data exploration so what I tend to do is to look at the data field so the name of the variables that are available in the data and that you can do by doing data. columns so you will then look into the columns in your data this will be the name of your uh uh data fields so let's go ahead and do command enter so we see that we have longitude like attitude housing unor median age we have total rooms we have total bedrooms population so basically the the um amount of people who are living in the in those households and in those houses then we have households then we have median income we have median housecore value and we have ocean proximity now you might notice that the name of these variables are a bit different than in the actual um documentation of the California house so you see here the naming is different but the underlying uh explanation is the same so here they are just trying to make it uh nicer and uh represent it in a better uh naming but uh it is a common um thing to see in Python when we are dealing with uh data that uh we have this underscores in the name approvation so we have housing uncore median AG which in this case you can see that it says house um age so bit different but their meaning is the same this is still the median house age in the block group so uh one thing uh that you can also uh notice here is that the um in the official uh documentation we don't have this um one extra variable that we have here which is the ocean proximity and this basically uh describes the uh Clos cless of the house from the ocean which of course uh for some people can definitely mean a increase or decrease in the house price so I basically um we have all these variables and next thing that I tend to do is to look into the actual data and one thing that we can do is just to look at the um top 10 rows of the data instead of printing the entire uh data frame so when we go and uh execute this specific part of the code and the command you can see that here we have the top 10 rows uh of our data so we have the longitude the latitude we have the housing median age you can see we are see some 41 year 21 year 52 year basically the number of years that a house the median age of the house is 41 21 52 and this is per block then we have the number of total bedrooms so we see that uh we have um in this blog uh the total number of rooms that this houses have is 7,99 so we are already seeing a data that consists of these large numbers which is something to take into account when uh you are dealing with machine learning models and especially with line regression then we have total bedrooms um and we have then population households median income median house value and the ocean proximity one thing that you can see right of the bed is that uh we have longitude and latitude uh which have some uh unique uh characteristics um and longitude is with minuses latitude is with pluses uh but that's fine for the linear regression because what it is basically looking is uh whether a variation in certain independent variables in this case longitude and latitude but that will cause a change in the dependent variable so just to refresh our memory what this linear regression will do in this case um so we are dealing with multiple inine regression because we have more than one independent variables so we have as independent variables those different features that describe the house except of the house price because median house value is the dependent variable so that's basically what we are trying to figure out we want to see what are the features of the house that cause so Define the house price we want to identify what are um the features that cause a change in our dependent variable and specifically uh what is the uh change in our median house price uh volue if we apply a one unit change in our independent feature so if we have a multiple linear regession we have learned during the theory lecture that what linear regression tries to use during causal analysis is that it tries to keep all the independent variables constant and then investigate for a specific independent variable what is this one unit uh change uh increase uh in the specific independent variable will result in what kind of change in our dependent variable so if we for instance change by one unit our uh housing median age um then what will be the correspond in change in our median household value keeping everything else concent so that's basically the idea behind multi multiple linear regression and using that for this specific use case and in here um what we also want to do is to find out what are the uh data types and whether we can learn bit more about our data before proceeding to the next step and for that I tend to use this uh info uh function in panel so given that the data is a penis data frame I will just do data. info and then parentheses and then this will uh show us what is the data type and what is the number of new values per variable so um as we have already noticed from this header which we can also see here being confirmed that ocean proximity is a variable that is not a numeric value so here you can see nearby um also a value for that variable which unlike all the other values is represented by a string so this is something that we need to take into account because later on when we uh will be doing the data prop processing and we will actually uh actually run this model we will need to do something with this specific variable we need to process it so um for the rest we are dealing with numeric variables so you can see here that longitude latitude or all the other variables including our dependent variable is a numeric variable so float 64 the only variable that needs to be taken care of is this ocean uncore proximity uh which um we can actually later on also see that is um categorical string variable and what this basically means is that it has these different categories so um for instance uh let us actually do that in here very quickly so let's see what are all the unique values for this variable so if we take the name of this variable so we copied from this overview in here and we do unique then this should give us the unique values for this categorical variable so here we go so we have actually five different unique values for this categorical string variable so this means that this ocean proximity can take uh five different values and it can be either near Bay it can be less than 1 hour from the ocean it can be Inland it can be near Ocean and it can be uh in the Iceland what this means is that we are dealing with a feature that describes the distance uh of the block from the ocean and here the underlying idea is that maybe this specific feature has a statistically significant impact on the house value meaning that it might be possible that for some people um in certain areas or in certain countries living in the uh nearby the ocean uh will be increasing the value of the house so if there is a huge demand for houses which are near the ocean so people prefer to uh leave near the ocean then most likely there will be a positive relationship if there is a uh negative relationship then it means that uh people uh if uh in that area in California for instance people do not prefer to live near the ocean then uh we will see this negative relationship so we can see that um if we increase uh the uh if if people uh if the house is in the uh um area that is uh not close to Ocean so further from the ocean then the house value will be higher so this is something that we want to figure out with this line regression we want to understand what are the features that uh Define the value of the house and we can say that um if the house has those characteristics then most likely the house price will be higher or the house price will be lower and uh linear aggression helps us to not only understand what are those features but also to understand how much higher or how much lower will be the value of the house if we have the certain characteristics and if we increase the certain characteristics by one unit so next we are going to look into uh the missing data in our data so in order to have a proper machine learning model we need to do some uh data processing so for that what we need to do is we need to check for the uh missing values in our data and we need to understand what is this amount of new values per data field and this will help us to understand whether uh we can uh remove some of those missing values or we need to do imputation so depending on the amount of missing data that we got in our data we can then understand which all those Solutions we need to take so here we can see that uh we don't have any n values when it comes to longitude latitude housing median age and all the other variables except of one variable one independent variable and that's the total bedrooms so we can see that um out of all the observations that we got the total uh underscore bedrooms variable has 207 cases when we do not have the corresponding uh information so when it comes to representing this numbers in percentages which is something that you should do as your next step we can see that um out of uh the entire data set uh for total underscore bedrooms variable um only 1. n n uh 3% is missing now this is really important because by simply looking at the number of times the uh number of missing uh observations perir data field this won't be helpful for you because you will not be able to understand relatively how much of the data is missing now if you have for a certain variable 50% missing or 80% missing then it means that for majority of your house blocks you don't have that information and including that will not be beneficial for your Morel nor will be it accurate to include it and it will result in biased uh Morel because if you have for the majority of observations uh no information and for certain observations you do that inform you have that information then you will automatically skew your results and you will have biased results therefore if you have uh for the majority of your um data set that specific uh variable missing then I would suggest you choose just to drop that independent variable in this case we have just one uh% uh of the uh house blocks missing that information which means that this gives me confidence that uh I would rather keep this independent variable and just to drop those observations that do not have a total uh underscore bedrooms uh information now another solution could also be is uh to instead of dropping that entire independent variable is just to uh use some sort of imputation technique so uh what this means is that uh we will uh try to find a way to systematically find a replacement for that missing value so we can use mean imputation median imput ation or more model based more advanced statistical or econometrical approaches to perform imputation so for now this out of the scope of this problem but I would say look at the uh percentage of uh observations that for which this uh independent variable has missing uh values if this is uh low like less than 10% and you have a large data set then uh you should uh be comfortable dropping those observations but if you have a small data set so you got only 100 observations and for them like 20% or 40% is missing then consider from imputation so try to find the values that can be um used in order to replace those missing values now uh once we have this information and we have identified the missing values the next thing is to uh clean the data so here what I'm doing is that I'm using the data that we got and I'm using the function drop na which means drop the um uh observations where the uh value is missing so I'm dropping all the observations for which the total underscore bedrooms has a null value so I'm getting rid of my missing observations so after doing that I'm checking whether I got rid of my missing observations and you can see here that when I'm printing data do is n do sum so I'm summing up the number of uh Missing observations no values per uh variable then uh now I no longer have any missing observations so I successfully deleted all the missing observations now the next state is to describe the data uh through some descriptive statistics and through data visualization so before moving on towards the caal analysis or predictive analysis in any sort of machine learning traditional machine learning approach try to First Look Into the data try to understand the data and see uh whether you are seeing some patterns uh what is the mean uh of different um numeric data fields uh do you have certain uh categorical values that cause an un unbalanced data those are things that you can discover uh early on uh before moving on to uh the model training and testing and blindly believing to the numbers so data visualization techniques and data exploration are great way to understand uh this uh data that you got before using that uh in order to train in t machine learning model so here I'm using the uh traditional describe function of pendas so data. describe parentheses and then this will give me the descriptive statistics of my data so here what we can see is that in total we got uh 20 , 640 observations uh and then uh we also have a mean of uh all the variables so you can see that per variable I have the same count which basically means that for all variables I have the same number of rows and then uh here I have the mean which means that um here we have the mean of the uh variables so per variable we have their mean and then we have their standard deviation so the square root of the variance we have the minimum we have the maximum but we also have the 25th percentile the 15 percentile and the 75th percentile so the uh percentile uh and quantiles those are uh statistical terms that we oftenly use and the 25th percentile is the first quantile the 15 percentile is the second quantile or the uh median and the 75th percentile is the third quantile so uh what this basically means is that uh this percentiles help us to understand what is this threshold when it comes to looking at the um observations uh that fall under the 25% uh and then above the 25% so when we look at this uh standard deviation standard deviation helps us to interpret the variation in the data at the unit so scale of that variable so in this case the variable is median house value and we have that the mean is equal to 206 ,000 approximately so more or less that uh range 206 K and then the standard deviation is 115k what this means is that uh in the data set we will find blocks that will have the median house value that will be uh 200 uh 6K 206k plus 115k which is around 321k so there will be blocks where the median house value is around 321k and there will also be blocks where the um median house value will be around uh 91k so 206,000 minus 115k so this the idea behind standard deviation this variation your data so next we can interpret the idea of this uh minimum and the maximum of your data in your data fields the minimum will help you to understand what is this minimum value that you have per data field numeric data field and what is the maximum value so what is the range of values that you are looking into in case of the median house value this means what um are the uh what is this minimum median house value per uh block and uh in case of Maximum what is this um highest value per block when it comes to Medan house value so this can uh help you to understand um when we look at this aggregated data so the median house value what are the blocks that have the uh cheapest uh houses when it comes to their valuation and what are the most expensive uh blocks of houses so we can see that uh the cheapest um block uh where in that block the median house value is uh 15K so 14,999 and the house block with the um highest valuation when it comes to the median house value so uh the median um valuation of the houses is equal to $500,000 And1 which means that when we look at our blocks of houses um that uh the median house value in this most expensive blocks will be a maximum 500k so uh next thing that I tend to do is to visualize the data I tend to start with the dependent variable so this is the variable of interest the target variable or the response variable which is in our case the median house value so this will serve us as our dependent variable and what I want you to do is to upload this histogram uh in order to understand what is the distribution of median house values so I want to see that when when looking at the data what are the um most frequently appearing median house values and uh what are this uh type of blocks that have um unique less frequently um appearing uh meded house values by plotting this type of plots you can see some outliers some um frequently appearing values but also some values that uh go uh and uh are lying outside of the range and this will help you to identify and learn more about your data and toid identify outliers in your data so in here I'm using the uh curn uh Library so given that earlier I already imported this libraries there is no need to import here what I'm doing is that I'm setting the the GD so which basically means that I'm saying the background should be white and I also want discrete so this means those discrete behind then I'm initializing the size of the figure so PLT this comes from met plotly P plot and then I'm setting the figure the figure size should be 10x 6 so um this is the 10 and this is the six then we have the main plot so I'm um using the uh his plot function from curn and then I'm taking from the uh clean data so from which we have removed the missing data I'm picking the uh variable of interest which is the median house value and then I'm saying upload this um histogram using the fors green color and then uh I'm saying uh the title of this figure is distribution of p and house values then um I'm also mentioning what is the X label which basically means what is the name of this variable that I'm putting on the xaxis which is a median house value and what is the Y label so what is the name of the variable that I need to put on the Y AIS and then I'm saying pl. show which means show me the figure so that's basically how in Python the visualization works we uh first need to write down the the actual uh figure size uh and then we need to uh Set uh the function uh in the right variable so provide data to the visualization then we need to put the title we need to put the X label y label and then we need to say show me the visualization and uh if you want to learn more about this visualization techniques uh make sure to check the python for data science course cuz that one will help you to understand slowly uh and in detail how you can uh visualize your data so in here what we are visualizing is the frequency of these median house values in the entire data set what this means is that we are looking at the um number of times each of those median house values appear in the data set so uh we want to understand are there uh certain uh median house values that appear very often and are there certain house values that do not appear that often so those can be may be considered outliers uh because we want in our data only to keep those uh most relevant and representative data points we want to derive conclusions that hold for the majority of our uh uh observations and not for outliers we will be then using that uh representative data in order to run our linear regression and then make conclusions when looking at this graph what we can see is that uh we have a certain cluster of um median house values that appear quite often and those are the cases when this frequency is high so you can see that uh we have for instance houses in here in all this block that appear um very often so for instance the median house value U of A about 160 170k this appears very frequently so you can see that the frequency is above 1,000 those are the most frequently appearing Medan house values and um there are cases when the um so you can see in here and you can see in here houses that uh whose median house value is not appearing very often so you can see that their frequency is low so um roughly speaking those houses they are unusual houses they can be considered as outliers and the same holds also for these houses because you can see that for those the frequency is very low which means that in our population of houses so California house prices you'll most likely see houses uh blocks of houses whose medium value is between let's say um 17K up to to uh let's say uh 300 or 350k but anything below and above this is considered as unusual so you don't often see a houses that are um so house blocks that have a median house value less than uh 70 or 60k and then uh also uh houses that are above um 370 or 400k so do consider that uh we are dealing with 1990 um a year data and not the current uh prices because nowadays uh Californian houses are much more expensive but this is the data coming from 1990 so uh do take that into account when interpreting this type of data visualizations so uh what we can then do is to use this idea of inter quantile range to remove this outl what this basically means is that we are looking at the lowest 25th uh% percentile so uh we are looking at this first quantile so 0.25 which is a 25th percentile and we are looking at this upper 25th um percent which means the third quantile or the 75th percentile and then we want to basically remove those uh by using this idea of 25th percentile and 75th percentile so the first quantile and the third quantile we can then identify what are the um uh observations so the blocks that have a median house value that is below the uh 25th per H and above the 75% he so basically we want to uh get the middle part of our data so we want to get this data for which the median house uh value is above the 25th percentile so U above all the uh median house values that is above the uh lowest 25% uh percent and then we also want to remove this very large median house values so we want to uh keep in our data the so-called normal uh and representative blocks blocks where the Medan house uh value is above the lowest 25% and smaller than the largest 25% what we are using is this statistical uh term called inter Quan range you don't need to know the name but I think it would be just work to understand it because this is a very popular way of uh making a datadriven uh removal of the outliers so I'm selecting the um 25th percentile by using the quantile function from pandas uh so I'm saying find for me the um value that divides my entire uh block of observations so block observations to observations for which the Medan house value is below the um the um 25th percentile and above the 25th percentile so what are the largest 75% and what are the smallest 25% when it comes to the median house value and we will then be removing this 25% so that I will do by using this q1 and then uh we will be using the uh Q3 in order to remove the very large median house Valu so the uh upper 25th percentile and then uh in order to um calculate the inter quanti range we need to uh pick the Q3 and subtract from it the q1 so just to understand this idea of q1 and Q3 so the Quantas better let's actually print this uh q1 and this uh Q3 so let's actually remove this part for now and they run it so as you can see here what we are finding is that the uh q1 so the 25th percentile or first quantile is equal to 19,500 so it basically is a number in here what it means is that um we have uh 25% um of the um observations the smallest observations have a median house value that is below the uh $119,500 and the remaining 75 uh% of our observations have a meeting house value that is above the $190,500 and then the uh Q3 which is the third quantile or the 75th percentile it describes this threshold the volume where we make a distinction between the um uh lowest median house values the first 75th uh% of the lowest uh median house values versus the uh most expensive so the highest median house values so what is this upper uh 25% uh when it comes to the median house value so we see that that distinction is 264,000 save $700 so it is somewhere in here which basically means that when it comes to this uh to this blocks of uh houses the most expensive ones with the highest valuation so the 25% top rated median house values they are above 264,000 that's something that we want to remove so we want to remove the observations that have a smallest median house value and the largest median house values and and usually it's a common practice when it comes to the inter quantile uh range approach to multiply the inter quantile range by 1.5 in order to um obtain the lower bound and the upper bound so to understand what are the um thresholds that we need to use in order to remove the uh blocks uh so observation from our data where the med house value is very small or very large so for that we will be multiply the IQR so inter quanti range by 1.5 and when we uh subtract this value from q1 then we will be getting our lower bound when uh we will be adding this value to Q3 then we will be using and getting this threshold when it comes to the uh upper bound and we will be seeing that um after we uh clean this uh outliers from our data we end up uh getting um smaller data so this means that uh previously we had uh 20K so 20,43 3 observations and now we have 9,369 observations so we have roughly removed um like about 1,000 or bit over 1,000 observations from our data so uh next let's look into some other variables for instance the median uh income and um one other technique that we can use in order to identify outliers in the data is by using the box plots so I wanted to showcase the different approaches that we can use in order to visualize the data and to identify outliers such that you will be familiar with uh different techniques so let's go ahead and plot the uh box plot and box plot is a statistical um way to represent your data uh the central boook uh represents the inter Quant range so um that is is the IQR uh and with the uh with the bottom and the top edges they indicate the 25th percentile so the first quantile and the 75% H so the third quantile respectively the length of this box that you see here uh this dark part is basically the 50% of your data for the median income and uh this uh median uh line inside this box um this is the uh the one with uh contrast in color that represents the median of the data set so the median is the middle value when data is sorted in an ascending order then we have this whiskers in our box Flo and this line of whiskers extends from the top and the bottom of the box and indicate this range for the rest of the data set excluding the outliers they are typically this 1.5 IQR above and 1.5 times um IQR uh below the q1 something that we also saw uh just previously when we were removing the outliers from the median house volum so in order to um identify the outliers you can quickly see that we have all these points that um lie above the 1.5 time IQR above the um third quantile so the 75% H and um that's something that you can also see here and this means that those are uh blocks of houses that have unusually high median income that's something that we want to remove from our data and therefore we can use the uh exactly the same approach that we used previously for the median house value so we will then identify the uh 25th percentile or the first quantile so q1 and then Q3 so the third quantile or the 75th percentile then we will compute the IQR um and then we will be obtaining the lower bound and the upper upper bound using this 1.5 um as a scale and then we will be using that this lower bound and upper bound to then um use this filters in order to remove from the data all the observations where the medium income is above the lower bound and all the observations that have a median income below the upper bound so we are using lower bound and upper bound to perform double filtering we are using two filters in the same row as you can see and we are using this parenthesis and this end functionality to tell to python well first look that this condition is satisfied so the observations have a median income that is above this lower bound and at the same time it should hold that the observation so the block should have a median income that is below the upper bound and if this uh block this observation in the data satisfies to two of this criteria then we are dealing with a good point a normal point and we can keep this and we are saying that this is our new data so let's actually go ahead and execute this code in this case we can see too high as all our out layers lie in this part of the box putot and then we will end up with the clean data I'm taking this clean data and then I'm putting it under data just for Simplicity and uh this data now uh is much more clean and uh it's better representation of the population something that ideally we want because we want to find out what are the features that uh describe and Define the house value not based on this unique and rare houses which are too expensive or which are in the blogs that have uh very high income uh people but rather we want to see the uh the uh true representation so the most frequently appearing data what are the features that Define the house value of the prices uh for common uh houses and for common areas for people with average or with normal income that's what we want to uh find so uh the next thing that I tend to do uh when it comes to especially regression nases and caal nases is to plot the correlation heat map so this means that uh we are getting the um uh correlation Matrix pairwise correlation score uh for each of this pair of variables in our data when it comes to the linear regression one of the uh assumptions of the linear regression that we learned during the theory part is that we should not have a perfect multicolinearity what this means is that there should not be a high correlation between pair of independent variables so knowing one should not help us to automatically Define the value of the other independent variable and if the correlation between the two independent variables is very high it means that we might potentially be dealing with multicolinearity that's something that we do want to avoid so hit map is a great way to identify whether we have this type of problematic independent variables and whether we need to drop any of them or maybe multiple of them to ensure that we are dealing with proper linear regression model and the assumptions lession model is satisfied now when we look at this correlation heat map um and uh here we use the curn in order to plot this as you can see here the colors can be from very light so white from till very dark green where uh the light means um there is a negative strong negative correlation and very dark uh green means that there is a very strong positive correlation so uh we know that correlation a value Pearson correlation can take values between minus one and 1 minus one means uh very strong negative correlation one means very strong positive correlation and um usually when uh we are dealing with correlation of the variable with itself so a correlation between longitude and longitude then uh this correlation is equal to one so as you can see on the diagonal we have there for all the ones because those are the pairwise correlation of the variables with themselves and then um in here uh all the values under the diagonal are actually equal to the uh mirror of them in the upper diagonal because the variable between so the correlation between uh the same two variables independent of how we put it so which one we put first and which one the second is going to be the same so basically correlation between longitude and ltitude and correlation latitude and longitude is the same so um now we have refreshed our memory on this let's now look into the actual number and this heat map so as we can see here we have this section where we um have uh variables independent variables um that have a low uh positive correlation with the uh remaining independent variables so you can see here that we have this light green uh values which indicate a low positive relationship between pair of variables one thing that is very interesting here is the middle part of this heat map where we have this dark numbers so the numbers uh below the diagonals are something we can interpret and remember that below diagonal and above diagonal is basically the mirror we here already see a problem because we are dealing with variables which are going to be independent variables in our model that have a high correlation now why is this a problem because one of the assumptions of linear regression like we saw during the theory section is that we should not have a multiple uh colinearity so multicolinearity problem when we have perfect multicolinearity it means that we are dealing with independent variables that have a high correlation knowing a value one variable will help us to know automatically what is the value of the other one and when we have a correlation of 0.93 which is very high or 0.98 this means that those two variables those two independent variables they have a super high positive relationship this is a problem because this might cause our model to result in uh very large standard errors and also not accurate and not generalizable model that's something we want to avoid and and uh we want to ensure that the assumptions of our model are satisfied now um we are dealing with independent variable which is total underscore bedrooms and households which means that number of total bedrooms uh pair block and the uh households is highly correlated positively correlated and this a problem so ideally what we want to do is to drop one of those two independent variables and and uh the reason why we can't do that is because uh those two variables given that they are highly correlated they already uh explain similar type of information so they contain similar type of variation which means that including the two just it doesn't make sense on one hand it's uh violating the moral assumptions potentially and on the other hand it's not even adding too much volum because the other one already shows similar variation so um the total underscore bedrooms basically contains similar type of information as the households so we can as well um so we can better just drop one of those uh two independent variables now uh the question is which one and that's something that we can uh Define by also looking at other correlations in here because we uh have a total bedrooms uh having a high correlation with households but we can also see that the total underscore rooms has a very high correlation with our households so this means that there is yet another independent variable that has a high correlation with our households variable and then this total underscore rooms has also High uh correlation with the total underscore bedroom so this means that um we can decide which one is has um more frequently uh High correlation with the rest of independent variables and in this case it seems like that the largest two numbers in here are the um this one and this one so we see that the total bedroom has a 0.93 as correlation with the total underscore rooms and uh at the same time we also see that hotel bedrooms has also um very high correlation with the household so 0.98 which means that total underscore bedrooms has the highest correlation with the remaining independent variables so we might as well drop this independent variable but before you do that I would suggest to do one more quick visual check and it is to look into the total uncore bedroom correlation with the dependent variable to understand how strong of a relationship does this have on the response variable that we are looking into so we see that the uh total underscore bedroom uh has this one 0.05 correlation with the response variable so the median house value when it comes to the total rooms that one has much higher so I'm already seeing from here that uh we can feel comfortable uh excluding and dropping the total underscore bedroom from our data in order to ensure that we are not dealing with perfect multicolinearity so this exactly what I'm doing here so I'm dropping the um total bedrooms so after doing that we no longer have this uh total bedrooms as the column so before moving on to the actual CA analysis there is one more step that I wanted to uh show you uh which is super important when it comes to the POS analysis and some uh introductory econometrical stuff so uh when you have a string categorical variable there are a few ways that you can deal with them one easy way that you will see um on the web is to perform one H encoding which basically means transforming all this uh string values so um we have a near Bay less than 1 hour ocean uh Inland near Ocean Iceland to transform all these values to some numbers such that we we have for the ocean proximity variable values such as 1 2 3 4 5 one way of doing that can be uh something like this but better way when it comes to using this type of variables in linear regression is to transform this a string uh category type of variable to what we're calling dami variables so dami variable means that this variable takes two possible values and usually uh it is a binary Boolean variable which means that it can take two possible values zero and one where one means that the condition is satisfied and zero means condition is not satisfied so let me give you an example in this specific case we have that the ocean proximity has five different values and ocean proximity is just a single variable then uh what we will do is we will use the uh get underscore D function in Python from pandas in order to uh go from this one variable to a five different variable per each of this category which means that now we will have new variables that uh will uh basically be uh whether uh it is uh nearby or not whether it's less than 1 hour uh uh from the ocean uh variable whether it's Inland whether it's near Ocean or whether is an island this will be a separate binary variable a dummy variable that will take value 0 and one which means that we are going from one string categorical variable to five different dami variables and in this case um each of those dami variables that you can see here we are creating five dami variables each of each for uh each of those five categories and then uh we are combining them and uh from the original data we will then be dropping the ocean prox IM data so on one hand we are getting rid of this string variable which is a problematic variable for linear regression when combined with the pyler library because cyler cannot handle this type of um data when it comes to linear regression and B we are making our job easier when it comes to interpreting the results so uh interpreting linear regression for CER nazes uh is much more easy when we have dami variables then when we have a one string categorical variable so just to give you an example if we are creating from this string variable uh five different dami variables and those are those five different dami variables that you can see in here so this means that if we are looking at this one category so let's say uh ocean _ proximity under Inland it means that for all the rows where we have the value equal to zero it means this criteria is not satisfied which means that uh ocean proximity uh underscore Inland is equal to zero which means that the house blob we are dealing with is not from Inland so that criteria is not satisfied and otherwise if this value is equal to one so for all these rows when the ocean proximity Inland is equal to one It means that the criteria is satisfied and we are dealing with house blocks that are indeed in the Inland one thing thing to keep in mind uh when it comes to uh transforming a string categorical variable to um set of DS is that you always need to drop at least one of the categories and the reason for this is because we learned during the theory that uh we should have no perfect multicolinearity this means that um we cannot have five different variables that are perfectly correlated and if we include all these values and this variables it means that um when uh we know that the uh uh block of houses is not near the bay is not less than 1 hour ocean is not Inland is not near the ocean automatically we know that it should be the remaining category which is Inland so we know that for all those blocks the um uh ocean proximity underscore uh uh irand uh Iceland will be equal to one and that's something that we want to avoid because because that is the definition of perfect multicolinearity So to avoid one of the oils assumptions to be violated we need to drop one of those categories so uh we can see in here uh that's exactly uh what I'm doing I'm saying so let's go ahead and actually drop one of those variables so let's see first what is the set of all variables we got so we got less than one hour uh ocean Inland Iceland new bay and then uh new ocean let's actually drop one of them so let's drop the Iceland and uh that we can do very simply by let me see I is not allowing me to add a code in here so we are doing data is equal to uh and then data do drop and then the name of the variable we within the uh quotation marks and then uh X is = to 1 so in this way I'm basically dropping one of the uh daming variables that uh I created in order to avoid the perfect multicolinearity assumption to be violated and once I go ahead and print the columns now we should see uh this uh column uh disappearing here we go so we successfully deleted that variable let's go ahead and actually get the head so now you can see that we no longer have a string in our data but instead we got four additional binary variable out of a string categorical variable with five categories all right now we are ready to do the actual work uh when it comes to the training a machine learning model uh or statistical model we learn during the uh theory that we always need to split that data into train uh and test set that is the minimum in some cases we also need to do train validation and test such that we can train the model on the training data and then optimize the model on validation data and find out what is the optimal set of hyperparameters and then uh use this information to uh apply this fitted and optimized model on an unseen test data we are going to skip the validation set for Simplicity especially given that we are dealing with a very simple machine learning model as linear regression and we're going to split our data into train and test and here uh what I'm going to do is first I'm creating this list of the name or variables that we are going to use in order to um train our machine learning bottle so uh we have a set of independent variables and a set of dependent variable so in our multiple linear regression here is the set of uh independent variables that we will have so we have long itude latitude housing median Edge total rooms population households median income median house value and the four different categorical dami uh four different uh dami variables that we built from the categorical variable then um I am specifying that the uh Target variable is so the target so the response variable or the dependent variable is the um median house value this is the value that we want to uh uh Target because we want to see what are the features and what are the independent variables out of the set of all features that have a statistically significant impact on the uh dependent variable which is the median house value because we want to find out what are these features um describing the houses in the block that cause a change cause a variation in the um t Target variable such as the Medan house value so here we have X is equal to and then uh from the data we are taking all the features that have the following names and then we have the uh Target which is a midin house uh house value and that's uh the column that we are going to subtract and select from the data so we are doing data filtering so here we are then selecting and what I'm using here is the train test complete function from the psych learn so you might recall that in the beginning we spoke and imported this uh model selection um library and from the cyler model selection we imported the train _ testore Spate function now this is a function that you are going to need quite a lot in machine learning because this a very easy way to uh split your data so um in here uh the arguments of the this function is first the uh Matrix or the data frame that contains the independent variables in our case X so here you fill in X and then the second uh argument is the dependent variable so uh the Y and then we have test size which means um what is the uh proportion of um observations that you want to put in the test and what is the proportion of observation that you um don't want to put basically in the training if you are putting 0.2 it means that you want your test size to be uh 20% of your entire 100% of data and the remaining 80% will be your training data so if you provide your point two to this argument then the function automatically understands that you want this 80 20 division so 80% training and then 20% test size and then finally you can also uh add the random State because the split is going to be random so the data is going to be randomly selected from the entire data and to ensure that your results are reproducible and uh the next time you are running this um notebook you will get the same results and also to ensure that me and you get the same results we will be using a random State and a random state of 111 is just um random number there I liked and decided to use here so uh when we go in um use this and run this command you can see that we have a training set size 15K and then test size uh 38k so when you look at these numbers you will then get a verification that you are dealing with 20% versus 80% thresholds so then we go and we do the training one thing to keep in mind is that here we are using the SM Library uh NSM function that we imported from the uh stats model. API so this is one one uh function that we can use in order to conduct our uh Cal analysis and to train Le regression model so uh for that what we need to do so uh when we are using this Library uh this Library doesn't automatically add the uh first uh column of ones uh in your uh set of independent variables which means that it only goes and looks at what are the features that you have provided and those are all the independent variables but we learned from the theory that uh when it comes to linear regression we always are adding this intercept so the beta0 if you go back to the theory lectures you can see this beta0 to be added to both to the simple linear regression and to the multipar regression this ensures that we look at this intercept and we see what is this average uh in this case median house value if all the other features are um equal to zero so um therefore given that the this specific stats models. API is not adding this uh constant um column to the beginning for intercept it means that we need to add this manually therefore we are saying sm. addore constant to the exrain which means that U now our uh x uh table or X data frame uh add a column of ones uh to the features so let me actually show you uh before doing the uh training because I think this also something that you should be aware of so if we do here a pause so I'm going to do xcore train underscore uh constant and then I'm also going to print um the same um feature data frame before adding this constant such that you see what I mean so as you can see here this is just the same set of all columns that form the independent variables the features so then when we add the constant now after doing that you can see that now we have this initial column of ones this is th such that we can have uh uh beta Z at the end which is the intercept and we can then perform a valid multiple linear regression otherwise you don't have an intercept and this is just not what you're looking for now the psychic learn Library does this automatically therefore when you are using uh this tou models. API you should add this constant and then I use the pyit learn without adding the constant and if you're wondering why to use this specific model as uh we already discussed about this just to refresh your memory we are using the T models. API because this one has this nice property of visualizing the summary of your result results so your P values your test your standard errors something that you definitely are looking for when you are performing a proper causal analysis and you want to identify the features that have a statistically significant impact on your dependent variable if you are using a machine learning model including linear regression only for Predictive Analytics so in that case you can use the psychic learn without worrying about using STS models. API so this is about adding constant uh now we are ready to actually uh fit our model or train our model therefore what we need to do is to use sm. OLS so OS is the ordinar squares estimation technique that we also discussed as part of the theory and we need to provide first the dependent variable so Yore train and then the um feature set which is xcore train uncore constant so then what we need to do is to do that feed par paresis which means that take the OS model and use the Yore train as my dependent variable and xcore Trainor constant as my independent variable set and then fit the OLS algorithm and linear regression on this specific data if you're wondering why y train or X train and what is the differ between train and test and sure to go and revisit the training um Theory lectures because there I go in detail into this concept of training and testing and how we can divide the data into train and test and uh this Y and X as we have already discussed during this tutorial is simply this distinction between independent variables defined by X and the dependent variable defined by y so y train y test is the dependent variable data for the training data and test data and then EXT train ex uh test is simply the training data features so ex train and then test data features X test we need to use x train and Y train to fit our data to learn from the data and then once it comes down to evaluating the model we need to uh use the fitted model from which we have learned using both the dependent variable and the independent variable set so y train X train and then uh once we have this model uh that is fitted we can apply this to unseen data exore test we have can obtain the predictions and we can compare this to the true y so Yore test and to see how different the Y uh underscore test is from the Y predictions for this unseen data and to evaluate how moral uh is performing this prediction so how moral is uh managing to identify the median uh house values and predict median house uh values based on the uh um fitted model and on an unseen data so exore test so this is just a background info and some refreshment and now um in this case we are just uh fitting the data on the training uh dependent variable and then training uh independent variable edit a constant and then we are ready to print the summary now let's now interpret those results first thing that we can see is that uh all the coefficients and all the independent variables are statistically significant and how can I say this well um if we look in here we can see the column of P values this is the first thing that you need to look at when you are getting this results of a caal analysis in linear oppression so here we are seeing that the P value is very small and just to refresh our memory P value says what is this probability that you have obtained too high of a test statistics uh given that this is just by a random chance so you are seeing statistically significant results which is just by random chance and not because your uh n hypothesis is false and you need to reject it so that's one thing in here you can see you can see that we are getting much more so first thing that you can do is to verify that you have used the correct dependent variable so you can see here that the dependent variable is a median house value the model that is used to estimate those coefficients in your model is the OS the method is the Le squares so Le squares is simply uh the uh technique that is the underlying approach of minimizing the sum of uh uh squared residuals so the least squares the date that we are running this analysis is the 26th of January of 2024 uh so we have the number of observations which is the number of training observations so the 80% of our original data we have R squ which is the um Matrix that showcases what is the um goodness of fat of your model so r s is a matrix that is commonly used in linear regression specifically to identify how good your model is able to fit your data with this linear regression line and the r squ uh the maximum of R squ is one and the minimum is zero 0.58 uh in this case approximately 59 it means that uh all your data that you got and all your independent variables so those are all the independent variables that you have included they are able to explain 59% so 0.59 out of the entire set of variation so 59% of variation in your response variable which is the median house value you are able to explain with a set of independent variables that you have provided to the model now what does this mean on one hand it means that you have a reasonable enough information so anything above 0.5 is quite good which means that more than half of the uh entire variation in your median house value you are able to explain but on the other hand it means also that there is approximately 40% of variation so information about your house values that you don't have in your data this means that you might consider going and looking for extra additional information so additional independent variables to add on the top of the existing independent variables in order to increase this amount and to increase the amount of information and variation that you are able to explain with your model so the r squ this is like the best way to uh explain what is the quality of your regression model another thing that we have is the adjusted R squ adjusted R squ and R squ in this specific case as you can see they are the same so 0 um 59 this usually means that uh you're fine when it comes amount of features that you are using once you overwhelm your model with too many features you will notice that the adjusted R squ will be different than your R squ so adjusted R squ helps you to understand whether your Motel is performing well only because you are adding so many of you of those variables or because really they contain some useful information CU sometimes the r squ it will automatically increase just because you are adding too many independent variables but in some cases those independ variables they are not useful so they are just adding to the complexity of the model and possibly overfitting your model but not providing any edit information then we have the F statistics here which corresponds to the F test and uh F test um it comes from statistics uh you don't need to know it but I would say uh check out the fundamentals to statistics course if you do want to know it because it means that uh you are testing whether all these independent variables Al together whether they are helping to explain your uh dependent variable so the median house value and uh if the F statistics is very large or the P value of your F statistics is very small so 0.0 it means that all your independent variables jointly are statistically significant which means that all of them together helped you explain your uh uh median house value and have a statistically significant impact or your median house value which means that you have a good set of independent variables so then we have the log likelihood not super relevant in this case you have the AIC Bic which stand for AAS information criteria and bation information criteria those are also not necessary to know for now but once you advance in your career in machine learning it might be useful to know at higher level for now think of it like um value that helps to understand this uh information that you gain when you are adding this set of independent variables to your model but this is just optional ignore it if you don't know it for now okay let's now go into the fun part so in this Mata uh part of the summary uh table we got first the set of uh independent variables so we have our constant which is The Intercept we have the longitude latitude housing median age total roles population households median income and the four dami variables that we have created then we have the coefficients corresponding to those independent variables those are basically the beta0 beta 1 head beta 2 head Etc which are the um parameters of the linear regression model that our oils method has estimated based on the data that we have provided now before interpreting this independent variables the first thing you need to do as I mentioned in the beginning is to look at this P value column this showcases the set of all independent variables that are statistically significant and usually this table that you will get from a Sato API is at 5% significance level so the alpha the threshold of statistical significance is equal to 5% and any P value that is smaller than 0.05 it means you are dealing with a statistically significant independent variable now the next thing that you can see here in the left is the T statistics this P value is based on a t test so this T Test is simply stating as we have learned during the theory and you can also check the fundamental to statistics course from lunar tech for more detailed understanding of this test but for now this T Test um States a hypothesis whether um each of these independent variables individually has a statistically significant impact on the dependent variable and whenever this uh T Test has a p value that is smaller than the 0.05 it means you are dealing with statistically significant uh independent variable in this case we are super lucky all our independent variables are statistically significant then the question is whether we have a positive statistical significant or negative that's something that you can see by the signs of these numbers so you can see that longitude has a negative coefficient latitude negative coefficient housing median age positive coefficient Etc negative coefficient means that this independent variable causes a negative change in the dependent variable so more specifically when we look for instance the um let's say which one should we look uh let's say the uh total uh underscore rooms when we look at the total underscore rooms and it's minus 2.67 it means that when we look at this total number of rooms and we increase the number of rooms uh by uh one additional unit so one more room added to the total underscore rooms then the uh house value uh decreases by minus 2.67 now you might be wondering but how is this possible well first of all the value the coefficient is quite small so in one hand it's it's not super relevant as we can see the uh relationship between them is not super strong because the U margin of this um coefficient is quite small but on the other hand you can explain that at some point when you are adding more rooms it just doesn't add any value and in fact in some cases just decreases the value of the house this might be the case at least this is the case based on this data we can see that if there is a negative coefficient then one unit increase in that specific independent variables all else constant will result in um uh in this case for instance in case of the total rooms uh 2.67 decrease in the median house value everything else constant we are also referring to this ass set that is parus in econometric which means that everything else constant so one more time let's refresh our memory on this so ensure that we are clear on this if we add one more room to the total number of rooms then the median house value will decrease by $267 and this when the longitude latitude house median age population households median income and all the other criterias are the same so if we have uh for instance this negative value this means that we are getting a decrease in the median house value if we have an increase by one unit in our uh total number of roles now let's look at the op opposite uh case when the coefficient is actually positive and large which is the hous in median age this means is if we have two houses they have uh exactly the same characteristics so they have the same longitude latitude they have the same total number of rooms population housing households median income they are uh the same in terms of the distance from the ocean then um if one of these houses has one more additional year added on the uh median age so housing median age so it's one year older then the house value of this specific house is higher by $846 so this house which has one more additional median age has $ 846 higher median house value compared to the one that has all these characteris ICS except it has just the um uh house median age that uh is one year less so one more additional uh year in the median age will result in 846 uh increase in the mediate house value everything else constant so this is regarding this idea of negative and imp positive and then the margin of coefficient now let's look at one dami variable and um explain the idea behind it and how we can interpret it and uh it's it's a good way to understand how the dond variables can be interpreted in the context of linear regression so one of the independent variables is the ocean proximity Inland and the coefficient is equal to- 2108 e plus 0.5 this simply means - 210 K uh approximately and um what this means is that if we have two houses they have exactly the same characteristics so their longitude latitude is the same house median age is the same they have the same total number of rooms population households median income all these characteristics for this two blocks of houses is the same with a single difference that one block is located in the um Inland when it comes to Ocean proximity and the other block of houses is not located in the Inland so in this case the reference so the um category that we have removed from here was the Iceland you might recall uh so if the block of houses is in the Inland that their value is on average uh smaller and less by 210k when it comes to the median house value compared to the block of houses that has exactly the same characteristics but it's not in the Inland so for instance is in the uh Iceland so uh when it comes to this dumi variables where there is also an underlying reference variable which you have deleted as part of your string categorical variable then you need to reference your dami variable to that specific category this might sound complex it is actually not I would say uh it's just a matter of practicing and trying to understand what is this approach of D variable it means that you either have that criteria or not in this specific case it means that if you have two blocks of houses with exactly the same characteristics and one block of houses is in the Inland and the other one is not in the Inland for instance is in the Iceland then the block of houses in the Inland will have on average 210,000 less uh median house value compared to the block of houses that is the IND for instance in the Iceland uh when it comes to the ocean proximity which kind of uh makes sense because in California people might prefer living uh in the isoland location in the houses might have more demand when it comes to the Iceland location compared to the um Inland locations so the longitude uh has a statistically significant impact on the uh median house value latitude house median age has an impact and causes a a statistically significant difference in the Medan house value if there is a change in median age the total number of rooms have an impact on the median house volume and the population has an impact households median income as well as the uh proximity from the ocean and this is because all their P values is uh zero which means that they are smaller than 0.05 and this means that they all have a statistically significant impact on the median house value in the Californian house in market now when it comes to the uh interpretation of all of them uh we have interpreted just few uh for the sake of Simplicity and ensuring that this uh this entire case study doesn't take too long but what I would suggest you to do is to uh interpret all of the uh coefficients here because we have interpreted just the housing median age and the um the total number of rooms but you can also interpret the population uh as well as the median income and uh we have also interpreted one of those Dy variables but feel free also to interpret all the other ones so by doing this you can also uh Even build an entire case study paper in which you can explain in one or two pages the results that you have obtained and this will showcase that you have an understanding of how you can interpret the linear gressional results another thing that I would suggest you to do is to uh add a comment on the standard error so let's now look into the standard errors we can see a huge standard error that we are um making and this is the direct result of the fourth assumption that was violated now this case study is super important and useful in a way that it showcases what happens if some of your um assumptions are satisfied and if some of those assumptions are violated so in this specific specific case the Assumption related to the uh uh the errors having a constant variance is violated so we have a heos SK assist the issue and that's something that we are seeing back in our results and this is a very good example of the case that even without checking the assumptions you can already see that the standard error is very large and uh you can see here that given that the standard ER is large this already gives a hint that most most likely our heteroscedasticity uh is present and our homoscedasticity assumption is violated you keep in mind this um idea of um large standard errors that we just saw because we are going to see that this becomes a problem also for the um performance of the model and we will see that we are obtaining a large error due to this and uh one more comment when it comes to the total rooms and the housing median age in some cases the linear regression results might not seem logical but sometimes they actually is an underlying explanation that can be provided or maybe your model is just overfitting or biased that's also possible and uh that's something that uh you can do by checking your ois assumptions and uh before uh going to that stage I wanted to briefly showcase to you this um idea of predictions so we have now fitted our model on the uh uh training data and we are ready to perform the predictions so we can then use our fitted model and we can then uh use the test data so ex test in order to perform the predictions so to uh use a data to get new house mediate house values for the um blocks of houses for which we are not providing the uh corresponding Medan house price so on aning data we are uh re um applying our model that we have already fitted and we want to see what are these predicted median house values and then we can compare these predictions to the true median house values that we have but we are not yet exposing them and we want to see how good our model is doing a job of estimating and finding these unknown median house values for the test data so for all the blocks of houses for which we provided the characteristics in the X test but we are not providing the Y test so uh as usual like in case of training we are adding a constant with this library and then we are saying model. fitted model uncore fitted so the fitted model and then that predict and providing the test data and those are the test predictions now uh once we do this we can then get the test predictions and uh if we print those you can see that we are getting a least of house values those are the house values for the um um blocks of houses which were included as part of the testing data so the 20% of our entire data set uh like I mentioned just before in order to ensure that your model is performing well you need to check the OS assumptions so uh during the um Theory section we learned that there are a couple of assumptions that your model should satisfy and your data should satisfy for OLS to provide uh B unbiased and um efficient uh estimates which means that they are accurate their standard error is low something that um we are also seeing as part of the summary results and uh your estimates are accurate so the standard error is a measure that showcases how efficient your estimat are which means um do you have a high variation uh can the coefficients that you are showing in this table very a lot which means that you don't have accurate um coefficient and your coefficient can be all the way from one place to the other so the range is very L large which means that your standard error will be very large and this is a bad sign or you are dealing with an accurate estimation and uh it's more precise estimation and in that case the standard there will be low uh and unbias estimate means that your estimates are are a true representation of the pattern between each pair of independent variable and the response variable if you want to learn more about this IDE of bias unbias and then efficiency and sure to check the U fundamental statistics course at lunar Tech because it explains very clearly this Concepts in detail so here I'm assuming that you know or maybe you don't even need it but I would suggest you to know at higher level at least then uh let's quickly do the checking of oiless assumption so the first assumption is the linearity Assumption which means that your model is linear in parameters one way of checking that is by using your already fitted model and your uh predicted model so the Y uh uh test which are your true house median house values for your test data and then test predictions which are your uh predicted median house values for nonen data so you are using the uh True Values and the predicted values in order to um plot them and then to also plot the best fitted line in an ideal situation when you would make no error and your model would give you the exact True Values um and then see how well your um uh how linear is this relationship do we actually have a linear relationship now if the observed versus predicted values where the observed means the uh real uh test test wise and the predicted means the test predictions if this pattern is kind of linear and matching this perfect linear line then you have um assumption one that is satisfied your linearity assumption is satisfied and you can say that your uh data uh and your model is indeed linear in parameters then uh we have the second assumption which states that your uh sample should be random and this basically translates that the uh expectation of your error terms should be equal to zero and uh one way of checking this is by simply taking the residuales from your fitted model so model on score fitted and then that's residual so you take the residuales you obtain the average which is a good estimate of your expectation of errors and then this is the mean of residuales so the average uh residuales where the residual is the estimate of your true error terms and then uh here what I do is just I just round up uh to the two decimals behind uh the uh the point this means that uh we are getting uh this average amount of uh errors or the estimate of the errors which we are referring as residuales and if this number is equal to zero which is the case so the mean of the residuales in our model is zero it means that indeed the um uh expectation of the uh error terms at least the estimate of it expectation of the residuales is inde equal to zero another way of checking the um uh second assumption which is that the um moral uh has a is based on the random sample and the sample we are using is random which means that the expectation of the error terms is equal to zero is by plotting the residuales versus fitted values so uh we are taking the resid from the fitted model and we are comparing to the fitted values that comes from the model uh and we are looking at this um graph this scatter plot which you can see in here and we're looking where this um pattern is uh symmetric uh around the uh threshold of zero so you can see this line kind of comes right in the middle of this pattern which means that on average we have residuales that are across zero so the mean of the residuales is equal to zero and that's exactly what we were calculating also here therefore we can say that we are indeed dealing with a random sample this FL is also super useful when it comes to the fourth assumption that we will come a bit later so for now let's check the third assumption which is the Assumption of exogeneity so exogeneity means that uh each of our independent variables should be uncorrelated from the error terms so there is no omitted variable bias there is no um reverse causality which means that the uh independent variable has an impact on the dependent variable but not the other way around so dependent variable should not have an impact and should not cause the independent variable so for that there are few ways that we can deal with uh with this uh one way is just straightforward to compute the uh correlation coefficient between between each of these independent variables and the residuales that you have obtained from your fitted model the just simple uh technique that you can use in a very uh quick way to understand what is this uh correlation between each pair of independent variable and the residuals which are the best estimates of your error terms and in this way you can understand that there is a correlation between your independent variables and your error terms another way you can do that and this is more advanced and bit more um towards the econometrical side is by using this test which is called the Durban uh view housan test so this uh Durban view housan test is um a more professional more advanced way of uh using an econometrical test to find out whether you have um exogene so exogeneity sup is satisfied or you have endogenity which means that one or multiple of your your independent variables is potentially correlated with your error terms uh I won't go into detail of this test uh I'll put some explanation here and also feel free to uh check any uh introductory to econometrics course to understand more on this Duran Vu housan test for exogeneity assumption the fourth assumption that we will talk about is the homos skasis homosa assumption states that the error terms should have a variance that is constant which means that when we are looking at this variation that uh the model is making uh across uh different observations that uh when we look at them the variation is kind of constant so uh we have all these uh cases when the uh in observations for which the residuals are bit small in some cases bit large we have this miror when it comes to this figure with what we are calling heteros skos which means means that homos assumption is violated our error terms do not have a variation that is constant across all the observations and we have a high variation and different variations for different observations so we have the heteros issue we should consider a bit more um flexible approaches like uh GLS fgs GMM all bit more advanced econometrical algorithms so uh the final part of this case study will be to show you how you can do uh this all but for machine learning traditional machine learning site by using the psychic learn so uh in here um I'm using the um standard scaler function in order to uh scale my data because we saw uh in the summary of the table um that we got from the stats uh mos. API that our data is at a very high scale because the uh median house values are those large numbers the uh age uh the median age of the house is in this very large numbers that's something that you want to avoid when you are using the linear regression as a Predictive Analytics model when you are using it for interpreting purposes then you should keep the skilles because it's easier to interpret those values and to understand uh what is the difference in the median price uh of the house when you compare different characteristics of the box of houses but when it comes to using it for Predictive Analytics purposes which means that you really care about the accuracy of your predictions then you need to uh scale your data and ensure that your data is standardized one way of doing that is by using the standard scaler function uh in the pyit learn. preprocessing uh and uh the way I do it is that I initialize the scaler by using the standard scaler and then parenthesis which are just import from this psychic learn library and then uh I am uh taking this scaler I'm doing that fitore transform exrain which basically means take the independent variables and ensure that we scale and standardize the data and standardization simply means that uh we are standardizing the data that we have to ensure that um some large values do not wrongly influence the predictive power of the model so the the model is not confused by the large numbers and finds a wrong variation but instead it focuses on the a true variation in the data based on how much the change in one independent variable causes a change in the dependent variable here given that we are dealing with the supervised learning algorithm uh the exrain uh scaled will be then containing our standardized uh features so independent variables and then each test SC will contain our standardized test features so the Unseen data that the model will not see during the training but only during prediction and then what we will be doing is that we will also use the um y train and Y train uh is the dependent variable in now supervised model and why train corresponds to the training data so we will then first initialize the linear regression here so linear regression model from pyit learn and then uh we will initialize the model this is just the empty linear regression model and then we will take this initialized uh model and then we will fit them on the uh training data so exore trained uncore scale so this is the trained features and then the um uh dependent variable from training data so why train uh do you knowe that I'm not scaling the dependent variable this is a common practice cuz you don't want to uh standardize your dependent variable rather than you want to ensure that your features are standardized because what you care is about the variation in your features and to ensure that the model doesn't mess up when it's learning from those features less when it comes to looking into the impact of those features on your dependent variable so then uh I am fitting the uh model on this training data so uh features and independent variable and then I'm using this fitted uh model the LR which already has learned from this features and dependent variable during supervised training and then I'm using the X test scale so the test standardized uh data in order to uh perform the prediction so to predict the immediate house values for the test data unseen data and you can notice that here in no places I'm using white test white test I'm keeping to myself which is the dependent variable True Values such that I can then compare to this predicted values and see how well my motor was able to actually get the predictions now uh let's actually also do one more step I'm importing from the psyit learn the Matrix such as mean squared error uh and I'm using the mean squared error to find out how well my motel was able to predict those house prices so this means that uh we have on average we are making an error of 59,000 of dollars when it comes to the median house prices which uh dependent on what we consider as large or small this is something that we can look into so um like I mentioned in the beginning the uh idea behind linear regression using IND specific uh course is not to uh use it in terms of pure traditional machine learning but rather than to perform um causal analysis and to see how we can interpret it when it comes to the quality of the predictive power of the model then uh if you want to improve this model this can be considered as the next step you can understand whether your model is overfitting and then the next step could be to apply for instance the um lasso regularization so lasso regression which addresses the overfitting you can also consider going back and removing more outliers from the data Maybe the outliers that we have removed was not enough so you can also apply that factor then another thing that you can do is to consider bit more advanced machine learning algorithms because it can be that um although the um regression assumption is satisfied but still um using bit more flexible Motors like random Forest decision trees or boosting techniques will be bit more more appropriate and this will give you higher predictive power consider also uh uh working more with this uh scaled uh version or normalization of your data as the next step in your machine Learning Journey you can consider learning bit more advanced machine learning models so now when you know in detail what is linear regression and how you can use it how you can train and test a machine learning Model A simple one yet very popular one and you also know what is logistic progression and all these Basics you're ready to go on to the next step which is learning all the other popular traditional machine learning models think about learning decision trees for modeling nonlinear relationships think about learning bagging boosting random forest and different sours of optimization algorithms like gradi and descent HGD HGD with momentum Adam Adam V RMS prop and what is the difference between them and how you can Implement them and also consider a learning clustering approaches like K means uh DB skin hierarchial clust string doing this will help you uh to get more hands on and go to this next step when it comes to the machine learning once you have covered all these fundamentals you are ready to go one step further which is getting into deep Le thank you for watching this video If you like this content make sure to check all the other videos available on this channel and don't forget to subscribe like and comment to help the algorithm to make this content more accessible to everyone across the world and if you want to get free resources make sure to check the free resources section at lunch. and if you want to become a job ready data scientist and you are looking for this accessible boot camp that will help you to make your job ready data scientist consider enrolling to the data science boot camp the ultimate data science boot camp at l. you will learn all the theory the fundamentals to become a jbre data scientist you will also implement the learn theory into real world multiple data science projects beside this after learning the theory and practicing it with a real world case studies you will also prepare for your data science interviews and if you want to stay up to date with do recent developments in Tech what are the headlines that you have missed in the last week what are the open positions currently in the market across the globe and what are the tech startups that are making waves in the tech and sure to subscribe to the data science Nai newsletter from [Music] lunarch"
    },
    {
        "id": "faadc444-58bc-4702-927d-3e79574a0250",
        "type": "video",
        "domaine": "technology",
        "titre": "11. Introduction to Machine Learning",
        "url": "https://www.youtube.com/watch?v=h0e2HAPTGF4",
        "description": "In this lecture, Prof. Grimson introduces ",
        "chaine": "MIT OpenCourseWare",
        "durée": "51:31",
        "keywords": [
            "machine learning",
            "data",
            "machine learning algorithm",
            "learning",
            "features",
            "line",
            "things",
            "distance",
            "learning algorithm",
            "machine"
        ],
        "transcription": "The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free. To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu. ERIC GRIMSON: OK. Welcome back. You know, it's that\ntime a term when we're all kind of doing this. So let me see if I can get a few\nsmiles by simply noting to you that two weeks from\ntoday is the last class. Should be worth at least a\nlittle bit of a smile, right? Professor Guttag is smiling. He likes that idea. You're almost there. What are we doing for the\nlast couple of lectures? We're talking about\nlinear regression. And I just want to\nremind you, this was the idea of I have\nsome experimental data. Case of a spring where I put\ndifferent weights on measure displacements. And regression was giving\nus a way of deducing a model to fit that data. And In some cases it was easy. We knew, for example, it was\ngoing to be a linear model. We found the best line\nthat would fit that data. In some cases, we said\nwe could use validation to actually let us explore\nto find the best model that would fit it, whether a\nlinear, a quadratic, a cubic, some higher order thing. So we'll be using that to\ndeduce something about a model. That's a nice segue into\nthe topic for the next three lectures, the last big\ntopic of the class, which is machine learning. And I'm going to argue, you can\ndebate whether that's actually an example of learning. But it has many of\nthe elements that we want to talk about when we\ntalk about machine learning. So as always, there's\na reading assignment. Chapter 22 of the book gives\nyou a good start on this, and it will follow\nup with other pieces. And I want to start\nby basically outlining what we're going to do. And I'm going to\nbegin by saying, as I'm sure you're aware,\nthis is a huge topic. I've listed just five\nsubjects in course six that all focus on\nmachine learning. And that doesn't\ninclude other subjects where learning is\na central part. So natural language processing,\ncomputational biology, computer vision\nrobotics all rely today, heavily on machine learning. And you'll see those in\nthose subjects as well. So we're not going to\ncompress five subjects into three lectures. But what we are going to do\nis give you the introduction. We're going to start by talking\nabout the basic concepts of machine learning. The idea of having examples, and\nhow do you talk about features representing those\nexamples, how do you measure distances\nbetween them, and use the notion\nof distance to try and group similar\nthings together as a way of doing machine learning. And we're going to\nlook, as a consequence, of two different standard\nways of doing learning. One, we call\nclassification methods. Example we're\ngoing to see, there is something called\n\"k nearest neighbor\" and the second class,\ncalled clustering methods. Classification works\nwell when I have what we would call labeled data. I know labels on my\nexamples, and I'm going to use that to\ntry and define classes that I can learn, and\nclustering working well, when I don't have labeled data. And we'll see what that\nmeans in a couple of minutes. But we're going to give\nyou an early view of this. Unless Professor Guttag\nchanges his mind, we're probably not going to\nshow you the current really sophisticated machine\nlearning methods like convolutional neural\nnets or deep learning, things you'll read\nabout in the news. But you're going to\nget a sense of what's behind those, by looking\nat what we do when we talk about learning algorithms. Before I do it, I want\nto point out to you just how prevalent this is. And I'm going to admit\nwith my gray hair, I started working in AI in\n1975 when machine learning was a pretty simple thing to do. And it's been\nfascinating to watch over 40 years, the change. And if you think about it, just\nthink about where you see it. AlphaGo, machine learning based\nsystem from Google that beat a world-class level Go player. Chess has already been conquered\nby computers for a while. Go now belongs to computers. Best Go players in the\nworld are computers. I'm sure many of\nyou use Netflix. Any recommendation\nsystem, Netflix, Amazon, pick your favorite, uses\na machine learning algorithm to suggest things for you. And in fact, you've probably\nseen it on Google, right? The ads that pop\nup on Google are coming from a machine\nlearning algorithm that's looking at your preferences. Scary thought. Drug discovery, character\nrecognition-- the post office does character recognition of\nhandwritten characters using a machine learning algorithm\nand a computer vision system behind it. You probably don't\nknow this company. It's actually an MIT\nspin-off called Two Sigma, it's a hedge fund in New York. They heavily use AI and\nmachine learning techniques. And two years ago, their\nfund returned a 56% return. I wish I'd invested in the fund. I don't have the kinds\nof millions you need, but that's an impressive return. 56% return on your\nmoney in one year. Last year they didn't\ndo quite as well, but they do extremely well using\nmachine learning techniques. Siri. Another great MIT\ncompany called Mobileye that does computer vision\nsystems with a heavy machine learning component that is\nused in assistive driving and will be used in\ncompletely autonomous driving. It will do things like\nkick in your brakes if you're closing too fast\non the car in front of you, which is going to\nbe really bad for me because I drive\nlike a Bostonian. And it would be\nkicking in constantly. Face recognition. Facebook uses this,\nmany other systems do to both detect\nand recognize faces. IBM Watson-- cancer diagnosis. These are all just\nexamples of machine learning being used everywhere. And it really is. I've only picked nine. So what is it? I'm going to make an\nobnoxious statement. You're now used to that. I'm going to claim\nthat you could argue that almost every computer\nprogram learns something. But the level of learning\nreally varies a lot. So if you think back to\nthe first lecture in 60001, we showed you Newton's method\nfor computing square roots. And you could argue,\nyou'd have to stretch it, but you could argue\nthat that method learns something about how to\ncompute square roots. In fact, you could generalize\nit to roots of any order power. But it really didn't learn. I really had to program it. All right. Think about last week when we\ntalked about linear regression. Now it starts to feel\na little bit more like a learning algorithm. Because what did we do? We gave you a set\nof data points, mass displacement data points. And then we showed you how\nthe computer could essentially fit a curve to that data point. And it was, in some sense,\nlearning a model for that data that it could then use\nto predict behavior. In other situations. And that's getting\ncloser to what we would like when we\nthink about a machine learning algorithm. We'd like to have program that\ncan learn from experience, something that it can then\nuse to deduce new facts. Now it's been a problem in\nAI for a very long time. And I love this quote. It's from a gentleman\nnamed Art Samuel. 1959 is the quote\nin which he says, his definition of\nmachine learning is the field of study\nthat gives computers the ability to learn without\nbeing explicitly programmed. And I think many\npeople would argue, he wrote the first such program. It learned from experience. In his case, it played checkers. Kind of shows you how\nthe field has progressed. But we started with checkers,\nwe got to chess, we now do Go. But it played checkers. It beat national level\nplayers, most importantly, it learned to\nimprove its methods by watching how it did in games\nand then inferring something to change what it thought\nabout as it did that. Samuel did a bunch\nof other things. I just highlighted one. You may see in a\nfollow on course, he invented what's called\nAlpha-Beta Pruning, which is a really useful\ntechnique for doing search. But the idea is, how can\nwe have the computer learn without being\nexplicitly programmed? And one way to\nthink about this is to think about the difference\nbetween how we would normally program and what we would\nlike from a machine learning algorithm. Normal programming, I\nknow you're not convinced there's such a thing\nas normal programming, but if you think of\ntraditional programming, what's the process? I write a program that\nI input to the computer so that it can then\ntake data and produce some appropriate output. And the square root finder\nreally sits there, right? I wrote code for using Newton\nmethod to find a square root, and then it gave me the\nprocess of given any number, I'll give you the square root. But if you think about\nwhat we did last time, it was a little different. And in fact, in a machine\nlearning approach, the idea is that I'm going\nto give the computer output. I'm going to give it examples of\nwhat I want the program to do, labels on data,\ncharacterizations of different classes of things. And what I want\nthe computer to do is, given that characterization\nof output and data, I wanted that machine\nlearning algorithm to actually produce\nfor me a program, a program that I can\nthen use to infer new information about things. And that creates, if you\nlike, a really nice loop where I can have the\nmachine learning algorithm learn the program\nwhich I can then use to solve some other problem. That would be really\ngreat if we could do it. And as I suggested, that\ncurve-fitting algorithm is a simple version of that. It learned a model for the\ndata, which I could then use to label any other\ninstances of the data or predict what I would see in\nterms of spring displacement as I changed the masses. So that's the kind of idea\nwe're going to explore. If we want to learn\nthings, we could also ask, so how do you learn? And how should a computer learn? Well, for you as a human, there\nare a couple of possibilities. This is the boring one. This is the old style\nway of doing it, right? Memorize facts. Memorize as many facts as you\ncan and hope that we ask you on the final exam\ninstances of those facts, as opposed to some other\nfacts you haven't memorized. This is, if you think way\nback to the first lecture, an example of declarative\nknowledge, statements of truth. Memorize as many as you can. Have Wikipedia in\nyour back pocket. Better way to learn is to\nbe able to infer, to deduce new information from old. And if you think\nabout this, this gets closer to what we\ncalled imperative knowledge-- ways to deduce new things. Now, in the first\ncases, we built that in when we wrote that\nprogram to do square roots. But what we'd like in\na learning algorithm is to have much more like\nthat generalization idea. We're interested in\nextending our capabilities to write programs that can\ninfer useful information from implicit\npatterns in the data. So not something\nexplicitly built like that comparison of\nweights and displacements, but actually implicit\npatterns in the data, and have the algorithm figure\nout what those patterns are, and use those to\ngenerate a program you can use to infer new\ndata about objects, about string\ndisplacements, whatever it is you're trying to do. OK. So the idea then,\nthe basic paradigm that we're going\nto see, is we're going to give the\nsystem some training data, some observations. We did that last time with\njust the spring displacements. We're going to then\ntry and have a way to figure out, how do\nwe write code, how do we write a program, a system\nthat will infer something about the process that\ngenerated the data? And then from\nthat, we want to be able to use that to make\npredictions about things we haven't seen before. So again, I want to\ndrive home this point. If you think about it, the\nspring example fit that model. I gave you a set of\ndata, spatial deviations relative to mass displacements. For different masses, how\nfar did the spring move? I then inferred something\nabout the underlying process. In the first case, I\nsaid I know it's linear, but let me figure out what\nthe actual linear equation is. What's the spring constant\nassociated with it? And based on that result,\nI got a piece of code I could use to predict\nnew displacements. So it's got all of those\nelements, training data, an inference engine,\nand then the ability to use that to make\nnew predictions. But that's a very simple\nkind of learning setting. So the more common\none is one I'm going to use as\nan example, which is, when I give you\na set of examples, those examples have some\ndata associated with them, some features and some labels. For each example,\nI might say this is a particular kind of thing. This other one is\nanother kind of thing. And what I want to\ndo is figure out how to do inference on\nlabeling new things. So it's not just, what's the\ndisplacement of the mass, it's actually a label. And I'm going to use one\nof my favorite examples. I'm a big New\nEngland Patriots fan, if you're not, my apologies. But I'm going to use\nfootball players. So I'm going to show\nyou in a second, I'm going to give you a set of\nexamples of football players. The label is the\nposition they play. And the data, well, it\ncould be lots of things. We're going to use\nheight and weight. But what we want\nto do is then see how would we come up with\na way of characterizing the implicit pattern of how\ndoes weight and height predict the kind of position\nthis player could play. And then come up\nwith an algorithm that will predict the\nposition of new players. We'll do the draft\nfor next year. Where do we want them to play? That's the paradigm. Set of observations, potentially\nlabeled, potentially not. Think about how do we do\ninference to find a model. And then how do we use that\nmodel to make predictions. What we're going\nto see, and we're going to see multiple\nexamples today, is that that\nlearning can be done in one of two very broad ways. The first one is called\nsupervised learning. And in that case,\nfor every new example I give you as part\nof the training data, I have a label on it. I know the kind of thing it is. And what I'm going\nto do is look for how do I find a rule that would\npredict the label associated with unseen input based\non those examples. It's supervised because I\nknow what the labeling is. Second kind, if\nthis is supervised, the obvious other one\nis called unsupervised. In that case, I'm just going to\ngive you a bunch of examples. But I don't know the labels\nassociated with them. I'm going to just\ntry and find what are the natural ways\nto group those examples together into different models. And in some cases, I may know\nhow many models are there. In some cases, I may\nwant to just say what's the best grouping I can find. OK. What I'm going to do today\nis not a lot of code. I was expecting cheers for that,\nJohn, but I didn't get them. Not a lot of code. What I'm going to do\nis show you basically, the intuitions behind\ndoing this learning. And I\"m going to start with my\nNew England Patriots example. So here are some data points\nabout current Patriots players. And I've got two\nkinds of positions. I've got receivers,\nand I have linemen. And each one is just labeled by\nthe name, the height in inches, and the weight in pounds. OK? Five of each. If I plot those on a\ntwo dimensional plot, this is what I get. OK? No big deal. What am I trying to do? I'm trying to learn, are\ntheir characteristics that distinguish the two\nclasses from one another? And in the unlabeled\ncase, all I have are just a set of examples. So what I want to\ndo is decide what makes two players similar\nwith the goal of seeing, can I separate this\ndistribution into two or more natural groups. Similar is a distance measure. It says how do I take\ntwo examples with values or features\nassociated, and we're going to decide how\nfar apart are they? And in the unlabeled case, the\nsimple way to do it is to say, if I know that there are\nat least k groups there-- in this case, I'm going\nto tell you there are two different groups there-- how could I decide how\nbest to cluster things together so that all the\nexamples in one group are close to each other, all\nthe examples in the other group are close to each other, and\nthey're reasonably far apart. There are many ways to do it. I'm going to show you one. It's a very standard way, and\nit works, basically, as follows. If all I know is that\nthere are two groups there, I'm going to start\nby just picking two examples as my exemplars. Pick them at random. Actually at random is not great. I don't want to pick too\nclosely to each other. I'm going to try and\npick them far apart. But I pick two examples\nas my exemplars. And for all the other\nexamples in the training data, I say which one\nis it closest to. What I'm going to try\nand do is create clusters with the property\nthat the distances between all of the examples\nof that cluster are small. The average distance is small. And see if I can\nfind clusters that gets the average distance\nfor both clusters as small as possible. This algorithm works by\npicking two examples, clustering all the other\nexamples by simply saying put it in the group to which\nit's closest to that example. Once I've got\nthose clusters, I'm going to find the median\nelement of that group. Not mean, but median, what's\nthe one closest to the center? And treat those as exemplars\nand repeat the process. And I'll just do it either\nsome number of times or until I don't get any\nchange in the process. So it's clustering\nbased on distance. And we'll come back to\ndistance in a second. So here's what would\nhave my football players. If I just did this\nbased on weight, there's the natural\ndividing line. And it kind of makes sense. All right? These three are\nobviously clustered, and again, it's\njust on this axis. They're all down here. These seven are at\na different place. There's a natural\ndividing line there. If I were to do it based\non height, not as clean. This is what my\nalgorithm came up with as the best\ndividing line here, meaning that these four,\nagain, just based on this axis are close together. These six are close together. But it's not nearly as clean. And that's part of the\nissue we'll look at is how do I find\nthe best clusters. If I use both\nheight and weight, I get that, which was actually\nkind of nice, right? Those three cluster together.\nthey're near each other, in terms of just\ndistance in the plane. Those seven are near each other. There's a nice, natural\ndividing line through here. And in fact, that\ngives me a classifier. This line is the\nequidistant line between the centers\nof those two clusters. Meaning, any point\nalong this line is the same distance to\nthe center of that group as it is to that group. And so any new example,\nif it's above the line, I would say gets that label,\nif it's below the line, gets that label. In a second, we'll\ncome back to look at how do we measure\nthe distances, but the idea here\nis pretty simple. I want to find groupings\nnear each other and far apart from\nthe other group. Now suppose I actually knew\nthe labels on these players. These are the receivers. Those are the linemen. And for those of you\nwho are football fans, you can figure it out, right? Those are the two tight ends. They are much bigger. I think that's Bennett and\nthat's Gronk if you're really a big Patriots fan. But those are tight ends,\nthose are wide receivers, and it's going to\ncome back in a second, but there are the labels. Now what I want to do is say,\nif I could take advantage of knowing the labels, how\nwould I divide these groups up? And that's kind of easy to see. Basic idea, in this\ncase, is if I've got labeled groups\nin that feature space, what I want to do is\nfind a subsurface that naturally divides that space. Now subsurface is a fancy word. It says, in the\ntwo-dimensional case, I want to know\nwhat's the best line, if I can find a single line,\nthat separates all the examples with one label from all the\nexamples of the second label. We'll see that, if the\nexamples are well separated, this is easy to\ndo, and it's great. But in some cases,\nit's going to be more complicated because\nsome of the examples may be very close\nto one another. And that's going\nto raise a problem that you saw last lecture. I want to avoid overfitting. I don't want to create a\nreally complicated surface to separate things. And so we may have to\ntolerate a few incorrectly labeled things, if\nwe can't pull it out. And as you already\nfigured out, in this case, with the labeled data,\nthere's the best fitting line right there. Anybody over 280 pounds is\ngoing to be a great lineman. Anybody under 280 pounds is\nmore likely to be a receiver. OK. So I've got two different\nways of trying to think about doing this labeling. I'm going to come back to\nboth of them in a second. Now suppose I add\nin some new data. I want to label new instances. Now these are actually players\nof a different position. These are running backs. But I say, all I know about\nis receivers and linemen. I get these two new data points. I'd like to know, are\nthey more likely to be a receiver or a linemen? And there's the data\nfor these two gentlemen. So if I go back to\nnow plotting them, oh you notice one of the issues. So there are my linemen, the\nred ones are my receivers, the two black dots are\nthe two running backs. And notice right here. It's going to be really\nhard to separate those two examples from one another. They are so close to each other. And that's going to\nbe one of the things we have to trade off. But if I think about using\nwhat I learned as a classifier with unlabeled data, there\nwere my two clusters. Now you see, oh, I've got\nan interesting example. This new example I would\nsay is clearly more like a receiver than a lineman. But that one there, unclear. Almost exactly lies\nalong that dividing line between those two clusters. And I would either say, I\nwant to rethink the clustering or I want to say, you know what? As I know, maybe there\naren't two clusters here. Maybe there are three. And I want to classify\nthem a little differently. So I'll come back to that. On the other hand, if I\nhad used the labeled data, there was my dividing line. This is really easy. Both of those new\nexamples are clearly below the dividing line. They are clearly\nexamples that I would categorize as being\nmore like receivers than they are like linemen. And I know it's a\nfootball example. If you don't like football,\npick another example. But you get the\nsense of why I can use the data in a labeled\ncase and the unlabeled case to come up with different\nways of building the clusters. So what we're going\nto do over the next 2 and 1/2 lectures is\nlook at how can we write code to learn that way\nof separating things out? We're going to learn models\nbased on unlabeled data. That's the case where I don't\nknow what the labels are, by simply trying to find ways\nto cluster things together nearby, and then use the\nclusters to assign labels to new data. And we're going to learn models\nby looking at labeled data and seeing how do we best come\nup with a way of separating with a line or a plane or a\ncollection of lines, examples from one group, from\nexamples of the other group. With the acknowledgment that\nwe want to avoid overfitting, we don't want to create a\nreally complicated system. And as a consequence,\nwe're going to have to make some\ntrade-offs between what we call false positives\nand false negatives. But the resulting classifier\ncan then label any new data by just deciding where\nyou are with respect to that separating line. So here's what you're going\nto see over the next 2 and 1/2 lectures. Every machine learning method\nhas five essential components. We need to decide what's\nthe training data, and how are we going to evaluate\nthe success of that system. We've already seen\nsome examples of that. We need to decide\nhow are we going to represent each instance\nthat we're giving it. I happened to choose height and\nweight for football players. But I might have been better\noff to pick average speed or, I don't know, arm\nlength, something else. How do I figure out what\nare the right features. And associated with that,\nhow do I measure distances between those features? How do I decide what's\nclose and what's not close? Maybe it should be different, in\nterms of weight versus height, for example. I need to make that decision. And those are the\ntwo things we're going to show you examples of\ntoday, how to go through that. Starting next week,\nProfessor Guttag is going to show you how you\ntake those and actually start building more detailed versions\nof measuring clustering, measuring similarities to find\nan objective function that you want to minimize to decide what\nis the best cluster to use. And then what is the best\noptimization method you want to use to learn that model. So let's start talking\nabout features. I've got a set of\nexamples, labeled or not. I need to decide what is it\nabout those examples that's useful to use when I\nwant to decide what's close to another thing or not. And one of the problems\nis, if it was really easy, it would be really easy. Features don't always\ncapture what you want. I'm going to belabor\nthat football analogy, but why did I pick\nheight and weight. Because it was easy to find. You know, if you work for the\nNew England Patriots, what is the thing that you really\nlook for when you're asking, what's the right feature? It's probably some other\ncombination of things. So you, as a designer,\nhave to say what are the features I want to use. That quote, by the\nway, is from one of the great statisticians\nof the 20th century, which I think captures it well. So feature engineering,\nas you, as a programmer, comes down to deciding\nboth what are the features I want to measure in that vector\nthat I'm going to put together, and how do I decide\nrelative ways to weight it? So John, and Ana, and I\ncould have made our job this term really easy\nif we had sat down at the beginning of the\nterm and said, you know, we've taught this\ncourse many times. We've got data\nfrom, I don't know, John, thousands of students,\nprobably over this time. Let's just build a\nlittle learning algorithm that takes a set of data and\npredicts your final grade. You don't have to\ncome to class, don't have to go through\nall the problems, because we'll just\npredict your final grade. Wouldn't that be nice? Make our job a little easier,\nand you may or may not like that idea. But I could think about\npredicting that grade? Now why am I telling\nthis example. I was trying to see if I\ncould get a few smiles. I saw a couple of them there. But think about the features. What I measure? Actually, I'll put this on\nJohn because it's his idea. What would he measure? Well, GPA is probably not a\nbad predictor of performance. You do well in other\nclasses, you're likely to do well in this class. I'm going to use this\none very carefully. Prior programming experience\nis at least a predictor, but it is not a\nperfect predictor. Those of you who haven't\nprogrammed before, in this class, you can still\ndo really well in this class. But it's an indication that\nyou've seen other programming languages. On the other hand, I don't\nbelieve in astrology. So I don't think the month\nin which you're born, the astrological sign\nunder which you were born has probably anything to do\nwith how well you'd program. I doubt that eye color\nhas anything to do with how well you'd program. You get the idea. Some features\nmatter, others don't. Now I could just throw all\nthe features in and hope that the machine learning algorithm\nsorts out those it wants to keep from those it doesn't. But I remind you of that\nidea of overfitting. If I do that,\nthere is the danger that it will find some\ncorrelation between birth month, eye color, and GPA. And that's going to\nlead to a conclusion that we really don't like. By the way, in case\nyou're worried, I can assure you\nthat Stu Schmill in the dean of\nadmissions department does not use machine\nlearning to pick you. He actually looks at a\nwhole bunch of things because it's not easy to\nreplace him with a machine-- yet. All right. So what this says is\nwe need to think about how do we pick the features. And mostly, what\nwe're trying to do is to maximize something called\nthe signal to noise ratio. Maximize those features that\ncarry the most information, and remove the ones that don't. So I want to show\nyou an example of how you might think about this. I want to label reptiles. I want to come up with a\nway of labeling animals as, are they a reptile or not. And I give you a single example. With a single example,\nyou can't really do much. But from this example, I know\nthat a cobra, it lays eggs, it has scales, it's\npoisonous, it's cold blooded, it has no legs,\nand it's a reptile. So I could say my model\nof a reptile is well, I'm not certain. I don't have enough data yet. But if I give you\na second example, and it also happens\nto be egg-laying, have scales, poisonous,\ncold blooded, no legs. There is my model, right? Perfectly reasonable\nmodel, whether I design it or a machine learning\nalgorithm would do it says, if all of these are\ntrue, label it as a reptile. OK? And now I give you\na boa constrictor. Ah. It's a reptile. But it doesn't fit the model. And in particular,\nit's not egg-laying, and it's not poisonous. So I've got to refine the model. Or the algorithm has\ngot to refine the model. And this, I want to remind you,\nis looking at the features. So I started out\nwith five features. This doesn't fit. So probably what I\nshould do is reduce it. I'm going to look at scales. I'm going to look\nat cold blooded. I'm going to look at legs. That captures all\nthree examples. Again, if you think about\nthis in terms of clustering, all three of them\nwould fit with that. OK. Now I give you another example-- chicken. I don't think it's a reptile. In fact, I'm pretty\nsure it's not a reptile. And it nicely still\nfits this model, right? Because, while it has scales,\nwhich you may or not realize, it's not cold blooded,\nand it has legs. So it is a negative example\nthat reinforces the model. Sounds good. And now I'll give\nyou an alligator. It's a reptile. And oh fudge, right? It doesn't satisfy the model. Because while it does have\nscales and it is cold blooded, it has legs. I'm almost done\nwith the example. But you see the point. Again, I've got to think\nabout how do I refine this. And I could by\nsaying, all right. Let's make it a little more\ncomplicated-- has scales, cold blooded, 0 or four legs-- I'm going to say it's a reptile. I'll give you the dart frog. Not a reptile,\nit's an amphibian. And that's nice because\nit still satisfies this. So it's an example outside\nof the cluster that says no scales,\nnot cold blooded, but happens to have four legs. It's not a reptile. That's good. And then I give you-- I have to give you\na python, right? I mean, there has to\nbe a python in here. Oh come on. At least grown at\nme when I say that. There has to be a python here. And I give you\nthat and a salmon. And now I am in trouble. Because look at scales, look\nat cold blooded, look at legs. I can't separate them. On those features,\nthere's no way to come up with a way\nthat will correctly say that the python is a\nreptile and the salmon is not. And so there's no easy\nway to add in that rule. And probably my best\nthing is to simply go back to just two features,\nscales and cold blooded. And basically say,\nif something has scales and it's cold blooded,\nI'm going to call it a reptile. If it doesn't have\nboth of those, I'm going to say\nit's not a reptile. It won't be perfect. It's going to incorrectly\nlabel the salmon. But I've made a design\nchoice here that's important. And the design choice is that\nI will have no false negatives. What that means is\nthere's not going to be any instance of something\nthat's not a reptile that I'm going to call a reptile. I may have some false positives. So I did that the wrong way. A false negative\nsays, everything that's not a reptile I'm going\nto categorize that direction. I may have some false\npositives, in that, I may have a few things\nthat I will incorrectly label as a reptile. And in particular,\nsalmon is going to be an instance of that. This trade off of false\npositives and false negatives is something that we worry\nabout, as we think about it. Because there's no perfect\nway, in many cases, to separate out the data. And if you think back to my\nexample of the New England Patriots, that running back\nand that wide receiver were so close together in\nheight and weight, there was no way I'm going to\nbe able to separate them apart. And I just have to\nbe willing to decide how many false positives\nor false negatives do I want to tolerate. Once I've figured out what\nfeatures to use, which is good, then I have to decide\nabout distance. How do I compare\ntwo feature vectors? I'm going to say vector\nbecause there could be multiple dimensions to it. How do I decide how\nto compare them? Because I want to use the\ndistances to figure out either how to group things together\nor how to find a dividing line that separates things apart. So one of the things I have\nto decide is which features. I also have to\ndecide the distance. And finally, I\nmay want to decide how to weigh relative importance\nof different dimensions in the feature vector. Some may be more valuable than\nothers in making that decision. And I want to show you\nan example of that. So let's go back to my animals. I started off with a\nfeature vector that actually had five dimensions to it. It was egg-laying, cold\nblooded, has scales, I forget what the other one\nwas, and number of legs. So one of the ways I\ncould think about this is saying I've got four binary\nfeatures and one integer feature associated\nwith each animal. And one way to learn to separate\nout reptiles from non reptiles is to measure the distance\nbetween pairs of examples and use that distance to\ndecide what's near each other and what's not. And as we've said\nbefore, it will either be used to cluster things or to\nfind a classifier surface that separates them. So here's a simple way to do it. For each of these examples,\nI'm going to just let true be 1, false be 0. So the first four\nare either 0s or 1s. And the last one is\nthe number of legs. And now I could say, all right. How do I measure\ndistances between animals or anything else, but these\nkinds of feature vectors? Here, we're going\nto use something called the Minkowski Metric\nor the Minkowski difference. Given two vectors\nand a power, p, we basically take\nthe absolute value of the difference between\neach of the components of the vector, raise it to\nthe p-th power, take the sum, and take the p-th route of that. So let's do the two\nobvious examples. If p is equal to 1, I just\nmeasure the absolute distance between each component, add\nthem up, and that's my distance. It's called the\nManhattan metric. The one you've seen more,\nthe one we saw last time, if p is equal to 2, this is\nEuclidean distance, right? It's the sum of the\nsquares of the differences of the components. Take the square root. Take the square root\nbecause it makes it have certain\nproperties of a distance. That's the Euclidean distance. So now if I want to measure\ndifference between these two, here's the question. Is this circle closer to the\nstar or closer to the cross? Unfortunately, I put\nthe answer up here. But it differs, depending\non the metric I use. Right? Euclidean distance, well,\nthat's square root of 2 times 2, so it's about 2.8. And that's three. So in terms of just standard\ndistance in the plane, we would say that these two\nare closer than those two are. Manhattan distance,\nwhy is it called that? Because you can only walk along\nthe avenues and the streets. Manhattan distance\nwould basically say this is one, two,\nthree, four units away. This is one, two,\nthree units away. And under Manhattan\ndistance, this is closer, this pairing is closer\nthan that pairing is. Now you're used to\nthinking Euclidean. We're going to use that. But this is going\nto be important when we think about how\nare we comparing distances between these different pieces. So typically, we'll\nuse Euclidean. We're going to see Manhattan\nactually has some value. So if I go back to my three\nexamples-- boy, that's a gross slide, isn't it? But there we go-- rattlesnake, boa\nconstrictor, and dart frog. There is the representation. I can ask, what's the\ndistance between them? In the handout for today,\nwe've given you a little piece of code that would do that. And if I actually run\nthrough it, I get, actually, a nice\nlittle result. Here are the distances between those\nvectors using Euclidean metric. I'm going to come back to them. But you can see the\ntwo snakes, nicely, are reasonably close to each other. Whereas, the dart frog is a\nfair distance away from that. Nice, right? That's a nice separation\nthat says there's a difference between these two. OK. Now I throw in the alligator. Sounds like a Dungeons\n& Dragons game. I throw in the alligator, and I\nwant to do the same comparison. And I don't get nearly as nice\na result. Because now it says, as before, the two snakes\nare close to each other. But it says that the dart\nfrog and the alligator are much closer, under\nthis measurement, than either of them\nis to the other. And to remind you, right,\nthe alligator and the two snakes I would like to be close\nto one another and a distance away from the frog. Because I'm trying to\nclassify reptiles versus not. So what happened here? Well, this is a place where\nthe feature engineering is going to be important. Because in fact, the alligator\ndiffers from the frog in three features. And only in two features from,\nsay, the boa constrictor. But one of those features\nis the number of legs. And there, while\non the binary axes, the difference is\nbetween a 0 and 1, here it can be between 0 and 4. So that is weighing the distance\na lot more than we would like. The legs dimension is\ntoo large, if you like. How would I fix this? This is actually, I would\nargue, a natural place to use Manhattan distance. Why should I think\nthat the difference in the number of legs or the\nnumber of legs difference is more important than\nwhether it has scales or not? Why should I think that\nmeasuring that distance Euclidean-wise makes sense? They are really completely\ndifferent measurements. And in fact, I'm\nnot going to do it, but if I ran Manhattan\nmetric on this, it would get the alligator\nmuch closer to the snakes, exactly because it differs only\nin two features, not three. The other way I\ncould fix it would be to say I'm letting too\nmuch weight be associated with the difference\nin the number of legs. So let's just make\nit a binary feature. Either it doesn't have\nlegs or it does have legs. Run the same classification. And now you see the\nsnakes and the alligator are all close to each other. Whereas the dart frog, not\nas far away as it was before, but there's a pretty natural\nseparation, especially using that number between them. What's my point? Choice of features matters. Throwing too many\nfeatures in may, in fact, give us some overfitting. And in particular,\ndeciding the weights that I want on those\nfeatures has a real impact. And you, as a designer\nor a programmer, have a lot of influence in how\nyou think about using those. So feature engineering\nreally matters. How you pick the\nfeatures, what you use is going to be important. OK. The last piece of\nthis then is we're going to look at some examples\nwhere we give you data, got features associated with them. We're going to, in some\ncases have them labeled, in other cases not. And we know how now to\nthink about how do we measure distances between them. John. JOHN GUTTAG: You\nprobably didn't intend to say weights of features. You intended to say\nhow they're scaled. ERIC GRIMSON: Sorry. The scales and not\nthe-- thank you, John. No, I did. I take that back. I did not mean to say\nweights of features. I meant to say the\nscale of the dimension is going to be important here. Thank you, for the\namplification and correction. You're absolutely right. JOHN GUTTAG: Weights, we\nuse in a different way, as we'll see next time. ERIC GRIMSON: And\nwe're going to see next time why we're going to\nuse weights in different ways. So rephrase it. Block that out of your mind. We're going to talk about\nscales and the scale on the axes as being important here. And we already said\nwe're going to look at two different\nkinds of learning, labeled and unlabeled,\nclustering and classifying. And I want to just\nfinish up by showing you two examples of that. How we would think about\nthem algorithmically, and we'll look at them\nin more detail next time. As we look at it,\nI want to remind you the things that are\ngoing to be important to you. How do I measure distance\nbetween examples? What's the right\nway to design that? What is the right set of\nfeatures to use in that vector? And then, what constraints do\nI want to put on the model? In the case of\nunlabelled data, how do I decide how many\nclusters I want to have? Because I can give you a really\neasy way to do clustering. If I give you 100 examples,\nI say build 100 clusters. Every example is\nits own cluster. Distance is really good. It's really close to itself,\nbut it does a lousy job of labeling things on it. So I have to think\nabout, how do I decide how many clusters,\nwhat's the complexity of that separating service? How do I basically avoid\nthe overfitting problem, which I don't want to have? So just to remind\nyou, we've already seen a little version of\nthis, the clustering method. This is a standard way to\ndo it, simply repeating what we had on an earlier slide. If I want to cluster\nit into groups, I start by saying how many\nclusters am I looking for? Pick an example I take as\nmy early representation. For every other example\nin the training data, put it to the closest cluster. Once I've got those, find the\nmedian, repeat the process. And that led to that separation. Now once I've got it,\nI like to validate it. And in fact, I should\nhave said this better. Those two clusters came without\nlooking at the two black dots. Once I put the\nblack dots in, I'd like to validate, how well\ndoes this really work? And that example there is\nreally not very encouraging. It's too close. So that's a natural place to\nsay, OK, what if I did this with three clusters? That's what I get. I like the that. All right? That has a really\nnice cluster up here. The fact that the algorithm\ndidn't know the labeling is irrelevant. There's a nice grouping of five. There's a nice grouping of four. And there's a nice grouping\nof three in between. And in fact, if I looked\nat the average distance between examples in\neach of these clusters, it is much tighter\nthan in that example. And so that leads to, then,\nthe question of should I look for four clusters? Question, please. AUDIENCE: Is that overlap\nbetween the two clusters not an issue? ERIC GRIMSON: Yes. The question is, is the overlap\nbetween the two clusters a problem? No. I just drew it\nhere so I could let you see where those pieces are. But in fact, if you like,\nthe center is there. Those three points are\nall closer to that center than they are to that center. So the fact that they\noverlap is a good question. It's just the way I\nhappened to draw them. I should really\ndraw these, not as circles, but as some little\nbit more convoluted surface. OK? Having done three, I could\nsay should I look for four? Well, those points down\nthere, as I've already said, are an example where\nit's going to be hard to separate them out. And I don't want to overfit. Because the only way\nto separate those out is going to be to come up with\na really convoluted cluster, which I don't like. All right? Let me finish with showing\nyou one other example from the other direction. Which is, suppose I give\nyou labeled examples. So again, the goal\nis I've got features associated with each example. They're going to have\nmultiple dimensions on it. But I also know the label\nassociated with them. And I want to learn\nwhat is the best way to come up with a rule that\nwill let me take new examples and assign them to\nthe right group. A number of ways to do this. You can simply say I'm looking\nfor the simplest surface that will separate those examples. In my football case that\nwere in the plane, what's the best line that\nseparates them, which turns out to be easy. I might look for a more\ncomplicated surface. And we're going to see\nan example in a second where maybe it's a\nsequence of line segments that separates them out. Because there's not just one\nline that does the separation. As before, I want to be careful. If I make it too\ncomplicated, I may get a really good separator,\nbut I overfit to the data. And you're going\nto see next time. I'm going to just\nhighlight it here. There's a third\nway, which will lead to almost the same\nkind of result called k nearest neighbors. And the idea here is I've\ngot a set of labeled data. And what I'm going to do\nis, for every new example, say find the k, say the five\nclosest labeled examples. And take a vote. If 3 out of 5 or 4 out of 5\nor 5 out of 5 of those labels are the same, I'm going to\nsay it's part of that group. And if I have less\nthan that, I'm going to leave it\nas unclassified. And that's a nice way\nof actually thinking about how to learn them. And let me just finish by\nshowing you an example. Now I won't use football\nplayers on this one. I'll use a different example. I'm going to give\nyou some voting data. I think this is\nactually simulated data. But these are a set of\nvoters in the United States with their preference. They tend to vote Republican. They tend to vote Democrat. And the two categories are\ntheir age and how far away they live from Boston. Whether those are relevant\nor not, I don't know, but they are just two things I'm\ngoing to use to classify them. And I'd like to say,\nhow would I fit a curve to separate those two classes? I'm going to keep\nhalf the data to test. I'm going to use half\nthe data to train. So if this is my\ntraining data, I can say what's the best\nline that separates these? I don't know about best,\nbut here are two examples. This solid line has the\nproperty that all the Democrats are on one side. Everything on the other\nside is a Republican, but there are some Republicans\non this side of the line. I can't find a line that\ncompletely separates these, as I did with the\nfootball players. But there is a decent\nline to separate them. Here's another candidate. That dash line has the\nproperty that on the right side you've got-- boy, I don't\nthink this is deliberate, John, right-- but\non the right side, you've got almost\nall Republicans. It seems perfectly appropriate. One Democrat, but there's a\npretty good separation there. And on the left side,\nyou've got a mix of things. But most of the Democrats are\non the left side of that line. All right? The fact that left\nand right correlates with distance from Boston is\ncompletely irrelevant here. But it has a nice punch to it. JOHN GUTTAG: Relevant,\nbut not accidental. ERIC GRIMSON: But\nnot accidental. Thank you. All right. So now the question is,\nhow would I evaluate these? How do I decide\nwhich one is better? And I'm simply\ngoing to show you, very quickly, some examples. First one is to look at what's\ncalled the confusion matrix. What does that mean? It says for this, one of\nthese classifiers for example, the solid line. Here are the predictions,\nbased on the solid line of whether they would\nbe more likely to be Democrat or Republican. And here is the actual label. Same thing for the dashed line. And that diagonal is\nimportant because those are the correctly labeled results. Right? It correctly, in\nthe solid line case, gets all of the correct\nlabelings of the Democrats. It gets half of the\nRepublicans right. But it has some where\nit's actually Republican, but it labels it as a Democrat. That, we'd like to\nbe really large. And in fact, it leads\nto a natural measure called the accuracy. Which is, just to\ngo back to that, we say that these\nare true positives. Meaning, I labeled it as being\nan instance, and it really is. These are true negatives. I label it as not being an\ninstance, and it really isn't. And then these are\nthe false positives. I labeled it as being an\ninstance and it's not, and these are the\nfalse negatives. I labeled it as not being\nan instance, and it is. And an easy way to measure it\nis to look at the correct labels over all of the labels. The true positives and\nthe true negatives, the ones I got right. And in that case, both models\ncome up with a value of 0.7. So which one is better? Well, I should validate that. And I'm going to\ndo that in a second by looking at other data. We could also ask,\ncould we find something with less training error? This is only getting 70% right. Not great. Well, here is a more\ncomplicated model. And this is where\nyou start getting worried about overfitting. Now what I've done,\nis I've come up with a sequence of lines\nthat separate them. So everything above this\nline, I'm going to say is a Republican. Everything below this line,\nI'm going to say is a Democrat. So I'm avoiding that one. I'm avoiding that one. I'm still capturing\nmany of the same things. And in this case, I get 12 true\npositives, 13 true negatives, and only 5 false positives. And that's kind of nice. You can see the 5. It's those five red\nones down there. It's accuracy is 0.833. And now, if I apply that to the\ntest data, I get an OK result. It has an accuracy of about 0.6. I could use this idea to try\nand generalize to say could I come up with a better model. And you're going to\nsee that next time. There could be other ways\nin which I measure this. And I want to use this\nas the last example. Another good measure we use is\ncalled PPV, Positive Predictive Value which is how many true\npositives do I come up with out of all the things I\nlabeled positively. And in this solid model,\nin the dashed line, I can get values about 0.57. The complex model on the\ntraining data is better. And then the testing\ndata is even stronger. And finally, two other\nexamples are called sensitivity and specificity. Sensitivity basically\ntells you what percentage did I correctly find. And specificity\nsaid what percentage did I correctly reject. And I show you this\nbecause this is where the trade-off comes in. If sensitivity is how\nmany did I correctly label out of those\nthat I both correctly labeled and incorrectly\nlabeled as being negative, how many them did\nI correctly label as being the kind that I want? I can make sensitivity 1. Label everything is the\nthing I'm looking for. Great. Everything is correct. But the specificity will be 0. Because I'll have a bunch of\nthings incorrectly labeled. I could make the specificity\n1, reject everything. Say nothing as an instance. True negatives goes to 1, and\nI'm in a great place there, but my sensitivity goes to 0. I've got a trade-off. As I think about the machine\nlearning algorithm I'm using and my choice of\nthat classifier, I'm going to see\na trade off where I can increase specificity at\nthe cost of sensitivity or vice versa. And you'll see a nice technique\ncalled ROC or Receiver Operator Curve that gives you a sense of\nhow you want to deal with that. And with that, we'll\nsee you next time. We'll take your\nquestion off line if you don't mind, because\nI've run over time. But we'll see you next\ntime where Professor Guttag will show you examples of this."
    },
    {
        "id": "65a3b605-1a95-49a9-9b70-5d39d9494e53",
        "type": "video",
        "domaine": "technology",
        "titre": "All Machine Learning algorithms explained in 17 min",
        "url": "https://www.youtube.com/watch?v=E0Hmnixke2g",
        "description": "All ",
        "chaine": "Infinite Codes",
        "durée": "16:30",
        "keywords": [
            "machine learning algorithms",
            "supervised learning algorithms",
            "training data set",
            "large data sets",
            "learning algorithms linear",
            "decision tree algorithm",
            "learning supervised learning",
            "algorithms linear regression",
            "called Deep learning",
            "learning algorithms including"
        ],
        "transcription": "in the next 17 minutes I will give you an overview of the most important machine learning algorithms to help you decide which one is right for your problem my name is Tim and I have been a data scientist for over 10 years and taught all of these algorithms to hundreds of students in real life machine learning boot camps there is a simple strategy for picking the right algorithm for your problem in 17 minutes you will know how to pick the right one for any problem and get a basic intuition of each algorithm and how they relate to each other my goal is to give as many of you as possible an intuitive understanding of the major machine learning algorithms to make you stop feeling overwhelmed according to Wikipedia machine learning is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data and thus perform tasks without explicit instructions much of the recent advancements in AI are driven by neural networks which I hope to give you an intuitive understanding of by the end of this video Let's divide machine learning into its subfields generally machine learning is divided into two areas supervised learning and unsupervised learning supervised learning is when we have a data set with any number of independent variables also called features or input variables and a dependent variable also called Target or output variable that is supposed to be predicted we have a so-called training data set where we know the True Values for the output variable also called labels that we can train our algorithm on to later predict the output variable for new unknown data examples could be predicting the price of a house the output variable based on features of the house say square footage location year of construction Etc categorizing an object as a cat or a dog the output variable or label based on features of the object say height weight size of the ears color of the eyes Etc unsupervised learning is basically any learning problem that is not supervised so where no truth about the data is known so where a supervised algorithm would be like showing a little kid what a typical cat looks like and what a typical dog looks like and then giving it a new picture and asking it what animal it sees an unsupervised algorithm would be giving a kid with no idea of what cats and dogs are a pile of pictures of animals and asking it to group by similarity without any further instructions examples of unsupervised problems might be to sort all of your emails into three unspecified categories which you can then later inspect and name as you wish the algorithm will decide on its own how it will create those categories also called clusters let's start with supervised learning arguably the bigger and more important branch of machine learning there are broadly two subcategories in regression we want to predict a continuous numeric Target variable for a given input variable using the example from before it could be predicting the price of a house given any number features of a house and determining their relationship to the final price of the house we might for example find out that square footage is directly proportional to the price linear dependence but that the age of the house has no influence on the price of the house in classification we try to assign a discrete categorical label also called a class to a data point for example we may want to assign the label spam or no spam to an email based on its content sender and so on but we could also have more than two classes for example junk primary social promotions and updates as Gmail does by default now let's dive into the actual algorithms starting with the mother of all machine learning algorithms linear regression in general supervised learning algorithms try to determine the relationship between two variables we try to find the function that Maps one to the other linear regression in its simplest form is trying to determine a linear relationship between two variables namely the input and the output we want to fit a linear equation to the data by minimizing the sum of squares of the distances between data points and the regression Line This simply minimizes the average distance of the real data to our predictive model in this case the regression line and should therefore minimize prediction errors for new data points a simple example of a linear relationship might be the height and shoe size of a person where the regression fit might tell us that for every one unit of shoe size increase the person will be on average 2 Ines taller you can make your model more complex and fit multi-dimensional data to an output variable in the example of the shoe size you might for example want to include the gender age and ethnicity of the person to get an even better model many of the very fancy machine learning algorithms including neural networks are just extensions of this very simple idea as I will show you later in the video logistic regression is a variant of linear regression and probably the most basic classification algorithm instead of fitting a line to two numerical variables with a presumably linear relationship you now try to predict a categorical output variable using categorical or numerical input variables let's look at an example we now want to predict one of two classes for example the gender of a person based on height and weight so a linear regression wouldn't make much sense anymore instead of fitting a line to the data we now fit a so-called sigmoid function to the data which looks like this the equation will now not tell us about a linear relationship between two variables but will now conveniently tell us the probability of a data point falling into a certain class given the value of the input variable so for example the likelihood of an adult person with a height of 180 cm being a man would be 80% this is completely made up of course the K nearest neighbors algorithm or KNN is a very simple and intuitive algorithm that can be used for both regression and class ification it is a so-called non-parametric algorithm the name means that we don't try to fit any equations and thus find any parameters of a model so no true model fitting is necessary the idea of KNN is simply that for any given new data point we will predict the target to be the average of its K nearest neighbors while this might seem very simple this is actually a very powerful predictive algorithm especially when relationships are more complicated than a simple linear relationship in a classification example we might say that the gender of a person will be the same as the majority of the five people closest in weight and height to the person in question in a regression example we might say that the weight of a person is the average weight of the three people closest in height and of chest circumference this makes a ton of intuitive sense you might realize that the number three seems a bit arbitrary and it is K is called a hyperparameter of the algorithm and choosing the right K is an art choosing a very small number of K say one or two will lead to your model predicting your training data set very well but not generalizing well to unseen data this is called overfitting choosing a very large number say 1,000 will lead to a worst fit over overall this is called underfitting the best number is somewhere in between and Depends a lot on the problem at hand methods for finding the right hyperparameters include cross validation but are beyond the scope of this video support Vector machine is a supervised machine learning algorithm originally designed for classification tasks but it can also be used for regression tasks the core concept of the algorithm is to draw a decision boundary between data points that separates data points of the training set as well as possible as the name suggests a new unseen data point will be classified according to where it falls with respect to the decision boundary let's take this arbitrary example of trying to classify animals by their weight and the length of their nose in this simple case of trying to classify cats and elephants the decision boundary is a straight line the svm algorithm tries to find the line that separates the classes with the largest margin possible that is maximizing the space between the different classes this makes the decision boundary generalize well and less sensitive to noise and outliers in the training data the so-called support vectors are the data points that sit on the edge of the margin knowing the support vectors is enough to classify new data points which often makes the algorithm very memory efficient one of the benefits of SPM is that it is very powerful in high Dimensions that is if the number of features is large compared to the size of the data in those higher dimensional cases the decision boundary is called a hyperplane another feature that makes svms extremely powerful is the use of so-called kernel functions which allow for the identification of Highly complex nonlinear decision boundaries kernel functions are an implicit way to turn your original features into new more complex features using the so-called kernel trick which is beyond the scope of this video this allows for efficient creation of nonlinear decision boundaries by creating complex new features such as weight divided by height squared also called the BMI this is called implicit feature engineering neural networks take the idea of implicit feature engineering to the next level as I will explain later possible kernel functions for svms are the linear the polinomial the RBF and the sigmoid kernel another fairly simple classifier is the naive Bas classifier that gets its name from B theorem which looks like this I believe it's easiest to understand naive Bay with an example use case that it is often used for spam filters we can train our algorithm with a number of spam and non-spam emails and count the occurrences of different words in each class and thereby calculate the probability of certain words appearing in spam emails and non-spam emails we can then quickly classify a new email based on the words it contains by by using base theorem we simply multiply the different probabilities of all words in the email together this algorithm makes the false assumption that the probabilities of the different words appearing are independent of each other which is why we call this classifier naive this makes it very computation Ally efficient while still being a good approximation for many use cases such as spam classification and other text-based classification tasks decision trees are the basis of a number of more complex supervised learning algorithms in its simplest form a decision tree looks somewhat like this the decision tree is basically a series of yes no questions that allow us to partition a data set in several Dimensions here is an example decision tree for classifying people into high and lowrisk patients for heart attacks the goal of the decision tree algorithm is to create so-called Leaf nodes at the bottom of the tree that are as pure as possible meaning instead of randomly splitting the data we try to find splits that lead to the resulting groups or leaves to be as pure as possible which is to say that as few data points as possible are misclassified while this might seem like a very basic and simple algorithm which it is we can turn it into a very powerful algorithm by combining many decision trees together combining many simple models to a more powerful complex model is called an ensemble algorithm one form of ensembling is bagging where we train multiple models on different subsets of the training data using a method called bootstrap a famous version of this idea is called a random Forest where many decision trees vote on the classification of your data by majority vote of the different trees in the random Forest random forests are very powerful estimators that can be used both for classification and regression the randomness comes from randomly excluding features for different trees in the forest which prevents overfitting and makes it much more robust because it removes correlation between the trees another type of Ensemble method is called boosting where instead of running many decision trees in parallel like for random forests we train models in sequence where each model focuses on fixing the errors made by the previous model we combine a series of weak models in sequence thus becoming a strong model because each sequential model tries to fix the errors of the previous model boosted trees often get to higher accuracies than random forests but are also more prone to overfitting its sequential nature makes it slower to train than random forests famous examples of boosted trees are Ada boost gradient boosting and XG boost the details of which are beyond the scope of this video now let's get to the reigning king of AI neural networks to to understand neural networks let's look at logistic regression again say we have a number of features and are trying to predict a target class the features might be pixel intensities of a digital image and the target might be classifying the image as one of the digits from 0 to 9 now for this particular case you might see why this might be difficult to do with logistic regression because say the number one doesn't look the same when different people write it and even if the same person writes it several times it will look slightly different each time and it won't be the exact same pixels illuminated for every instance of the number one all of the instances of the number one have commonality however like they all have a dominating vertical line and usually no Crossing Lines as other digits might have and usually there are no circular shapes in the number one as there would be in the number eight or or nine however the computer doesn't initially know about these more complex features but only the pixel intensities we could manually engineer these features by measuring some of these things and explicitly adding them as new features but artificial neural networks similarly to using a kernel function with a support Vector machine are designed to implicitly and automatically design these features for us without any guidance from humans we do this by adding additional layers of unknown variables between the input and output variables in its simplest form this is called a single layer percep chop which is basically just a multi-feature regression task now if we add a hidden layer the hidden variables in the middle layer represent some hidden unknown features and instead of predicting the target variable directly we try to predict these hidden features with our input features and then try to predict the target variables with our new hidden features in our specific example we might be able to say that every time several pixels are illuminated next to each other they represent a horizontal line which can be a new feature to try and predict the digit in question even though we never explicitly defined a feature called horizontal line This is a much simplified view of what is actually going on but hopefully this gets the point across we don't usually know what the hidden features represent we just train the neural network to predict the final Target as well as possible the hidden features we can Design This Way are limited in the case of the single hidden layer but what if we add a layer and have the hidden layer predict another hidden layer what if we now had even more layers this is called Deep learning and can result in very complex hidden features so that might represent all kinds of complex information in the pictures like the fact that there is a face in the picture however we will usually not know what the hidden features mean we just know that they result in good predictions all we have talked about so far is supervised learning where we wanted to predict a specific Target variable using some input variables however sometimes we don't have anything specific to predict and just want to find some underlying structure in our data that's where unsupervised learning comes in a very common unsupervised problem is clustering it's easy to confuse clustering with classification but they are conceptually very different classification is when we know the classes we want to predict and have training data with true labels available shown as colors here like pictures of cats and dogs clustering is when we don't have any labels and want to find unknown clusters just by looking at the overall structure of the data and trying to find potential clusters in the data for example we might look at a two-dimensional data set that looks like this any human will probably easily see three clusters here but it's not always as straightforward as your data might might also look like this we don't know how many clusters there are because the problem is unsupervised the most famous clustering algorithm is called K means clustering just like for KNN K is a hyperparameter and stands for the number of clusters you are looking for finding the right number of clusters again is an art and has a lot to do with your specific problem and some trial and error in domain knowledge might be required this is beyond the scope of this video K means is very simple you start by randomly selecting centers for your K clusters and assigning all data points to the cluster center closest to them the Clusters here are shown in blue and green you then recalculate the cluster centers based on the data points now assigned to them you can see the centers moving closer to the actual clusters you then assign the data points again to the new cluster centers followed by recalculating the cluster centers you repeat this process until the centers of the Clusters have stabilized while K means is the most famous and most common clustering algorithm other algorithms exist including some where you don't need to specify the number of clusters like hierarchical clustering and DB scan which can find clusters of arbitrary shape but I won't discuss them here the last type of algorithm I will leave you with is dimensionality reduction the idea of dimensionality reduction is to reduce the number of features or dimensions of your data set keeping as much information as possible usually this group of algorithms does this by finding correlations between existing features and removing potentially redundant Dimensions without losing much information for example do you really need a picture in high resolution to recognize the airplane in the picture or can you reduce the number of pixels in the image as such dimensionality reduction will give you information about the relationships within your existing features and it can also be used as a pre-processing step in your supervised learning algorithm to reduce the number of features in your data set and make the algorithm more efficient and robust an example algorithm is principal component analysis or PCA let's say we are trying to predict types of fish based on several features like length height color and number of teeth when looking at the correlations of the different features we might find that height and length are strongly correlated and including both both won't help the algorithm much and might in fact hurt it by introducing noise we can simply include a shape feature that is a combination of the two this is actually extremely common in large data sets and allows us to reduce the number of features dramatically and still get good results PCA does this by finding the directions in which most variance in the data set is retained in this example the direction of most variant is a diagonal this is called the first principal component or PC and can become our new shape feature the second principal component is orthogonal to the first and only explains a small fr C of the variant of the data set and can thus be excluded from our data set in this case in large data sets we can do this for all features and rank them by explain variants and exclude any principal components that don't contribute much to the variant and thus wouldn't help much in our ml model this was all common machine learning algorithms explained if you are overwhelmed and don't know which algorithm you need here is a great cheat sheet by syit learn that will help you decide which algorithm is right for which type of problem if you want a road map on how to learn machine learning check out my video on that"
    },
    {
        "id": "72e2be33-ab49-4ce3-b9a5-bad0cbb6e64b",
        "type": "video",
        "domaine": "technology",
        "titre": "Web Development Technologies - A Practical Guide",
        "url": "https://www.youtube.com/watch?v=8sXRyHI3bLw",
        "description": "My annual guide to every ",
        "chaine": "Traversy Media",
        "durée": "2:43:32",
        "keywords": [
            "HTML CSS JavaScript",
            "HTML CSS SQL",
            "web web framework",
            "great PHP framework",
            "building web applications",
            "SSR Frameworks",
            "Create react app",
            "popular web framework",
            "SSR SSG State",
            "opinionated web framework"
        ],
        "transcription": "[Music] hey guys welcome to my practical web development guide for 2024 so believe it or not this is the eth or ninth year that I've done this I think the first one was back in 2016 or 2017 so it's crazy how fast time goes by and I'm sure that many of you or or most of you know what this is but for those that don't every year I do this guide and I go through just about every web development technology that I can think of from tools to languages to Frameworks as well as some of the different routes that you can take and and just offer some of my own personal advice to succeed in web development and I do this because it's extremely overwhelming just to learn what you need to learn because there's so many different things so I try to put it all in one place and put some things into perspective and you can kind of pick your path from there and I also have a page on my website that has all the content that I've created including YouTube videos and playlists as well as premium courses on a lot of the stuff that we talk about in this guide and I put it in the same order as well so it's easy to follow and I'll have a link to that in the description all right so a couple of notes some things to keep in mind as you're watching or listening to this video uh it is long so you may want to kind of put it on in the background while you're cleaning or exercising or whatever it is you do and I'll have time stamps in the description so you can just jump around if you want to so first off you do not have to learn everything we talk about in fact I'd say it's impossible to learn everything that I mentioned in this guide even if your life was extended 100 more years so look at it like a restaurant menu you can see what's available and then you pick and choose what looks good to you so next this is not a latest trends video I know there's a lot of those types of videos out around this time of year I will outline some of the new technologies but that's not what this video is about it's about absolutely everything that I can think of that you may have to learn as a web developer and I don't care if it's 20 years old or 20 days old if it's relevant then I'll talk about it also if you've watched past years you'll notice that I don't really remove anything I just add to it so most of the stuff that was in last year's video will still be in this year's video I just elaborate it on a bit differently I don't even go back to previous years for reference lastly I always try to keep these pretty objective however I do share my opinion on some things I'll try to make it clear when I'm giving my opinion uh keep that in mind that neither myself or anyone else has experience with every single piece of technology in this guide so some of it is based on research and just what I've heard from others all right so before we talk about specific Technologies I want to talk about some of the common roles and paths that web developers choose and I think it's important because it will help you decide what you want or what you need to learn so the first one is one that I feel like is overlooked a lot especially when it comes to like YouTube videos and so on typically they just talk about front end backend full stack but a web designer is pretty typical uh pretty typical path to take which is sort of like a mix of development and design and these are people that are more focused on the front end but don't really build complex uis and applications they stick to you know static websites small business websites things like that they may use a CMS like WordPress um they're usually pretty good at design as well as HTML and CSS because a lot of times they go solo in their Freelancers so they have to build their projects from the ground up and uh they typically have some knowledge of programming you know basic JavaScript Etc but usually not enough to build uh a complex full stack application without using some kind of third-party software so the they get into kind of the business side of things SEO maybe some marketing things like that so if that sounds interesting to you then you might take this route next we have what is I guess the most common role that people start with and that's a front-end developer so this is someone that works on the client side of the web so they work on the user interface they create the interactions that a user has with a website or web app now I will say that the lines between front end and backend are are getting more blurred every day especially with Technologies like nextjs where some of the page is rendered on the server and some of it's rendered on the client but for the most part front-end developers work on the client side of the web um with the most important Technologies being HTML CSS and JavaScript in general um most of the time they'll also move on to front-end Frameworks like react view angular and I'll talk more about those later next we have a backend developer this is someone that works on the server side so they work with databases database ORS um they're not focused on the user us interface at all they're usually the ones building the apis that the front-end developers will consume and get data from the server now with the front end your programming language is is typically going to be JavaScript but on the back end you have you know dozens of languages to choose from you can use JavaScript of course with something like node.js but you can also use Python PHP C and and many many more languages which we'll talk about later then you have a fullstack developer who works on both the front and back back end so you'll need to know HTML CSS JavaScript but also need to know a server side language or server side technology you'll work with databases and ORS just like a backend developer now in my experience it seems that most fullstack positions are more focused on either the front end or the back end but you still do need to know both and again that line is is getting more and more blurred and it seems that full stack is the most popular end goal for people it seems at at least from what I I see you know running a channel and and seeing a lot of developers and people that are coming up it seems like front end is where they want to start but ultimately they want to be full stack developers now I'm going to throw a fifth role in there and that's devops and this is someone that's responsible for deployment and maintenance of your application maintenance of the servers um there you know security scalability they do write code but it's not the same as front end or backend development you're not building the application you're building the infrastructure that the application runs on and you'll typically need to know Technologies like Docker and kubernetes you'll need to know about certain hosting platforms like AWS um you might write bash scripts Python scripts need to know how to manage a Linux server this isn't really my wheelhouse but it may be something that you're interested in and it's usually a separate role than uh a software developer now for the rest of this video when we talk about certain Technologies or concepts I'm going to have the typ types of developers that it pertains to up in the leftand corner here so you'll see something like this with WD for web designer front end backend full stack and devops and this will help you keep track for whatever your your goals are all right so now we've talked about the different roles let's talk about some goals and paths that you can take as a web developer and one thing I want to mention that's really important is that your goals can change over time so what you choose now doesn't mean you won't change it later I've been doing for about 15 years and I've been a freelancer a full-time employee a consultant an instructor um and I've done side projects so you you most likely won't do the same thing for your entire career so don't feel like you're stuck with whatever you choose now so the most common is to learn to code to become a full-time developer for a company and this is where you know you work for a company you get salary uh benefits your pay can vary greatly depending on where you live and and what company you work for but it's a very stable job and you don't have to worry about finding clients or anything like that you just show up you do your job hopefully you really like coding and you get to you know do your passion for work so it doesn't really feel like work you get paid quite a bit um there's positions for all types including the ones that we talked about many developers strive to work at at like a Fang company which is you know Facebook Amazon Apple Netflix Google these are some of the biggest Tech compan IES in the world and they pay very well however there are there's a lot of companies out there that pay just as well if not better so don't feel like you have to work for one of these huge corporations there's there's so many companies out there so freelancing is another option and this is for developers that are somewhat business savvy it definitely isn't for everyone there's a lot of added stress in running your own business but it can be incredibly rewarding in many ways you know you'll probably struggle from financially at first depending on where you're starting out but if you gain the experience and you put your all into it you can possibly make much more than you could at a 9 to5 UM as a software developer and and freelancing is essentially investing in yourself and you do need to know quite a bit you kind of have to be a jack of all trades master of none because typically you're starting out solo so you'll need to do everything from the the design to the HTML CS to whatever you're using for a backend if you do have a backend or if you're using Wordpress typically you're going to go for technologies that allow you to create things fast um and you can also Niche down and work with certain industries so for instance you might do medical websites or something like that um there's so many different routes to take within the route of freelancer so another option you have is to work for a startup which is a little different than working for a large company it's pretty risky because most startups do fail that's just a fact but if you're one of the first employees it can be very very rewarding and you can be very successful and make a ton of money um and then you could also think about starting your your own startup later on down the line I wouldn't say that should be your first goal once you learn how to code um and that kind of leads us to the next one which is to create a product or a SAS which is a software as a service so you could build some kind of app that you could charge monthly for so you have recurring income and I would say this is great for a secondary goal so maybe start off either as a full-time employee or a freelancer and work on a product that you think will be successful in your spare time and then you know if that starts to grow you could always switch over and do that full-time and then internships uh they do offer Real World Experience there's paid internships and even if it's not paid you do get a lot of experience and it looks great on your resume for when it is you know when it comes time to find a job and typically internships that aren't paid they will lead to a paid position so it's a great option if you know just to get you going in the industry so these are just some of the things you can do these are I would say the most common especially the first two full-time employe freelancer um there's a lot of things that I would say you can do but I wouldn't s just starting out with like Consulting like teaching things like that again like I said earlier you don't have to stick with one thing once you choose that path all right so let's get into some of the basic essential tools that you need to start coding so first obviously you need a computer with an operating system people ask me all the time what's the best laptop for coding the truth is you can use just about anything from the last 5 to 10 years for web development if you were doing something like 3D modeling then you need a a bit more of a powerful computer but for web development you don't need much I'd say just make sure you have at least 8 GB of RAM and an SSD I think the bigger decision is what operating system you want to use but even that really just comes down to preference people ask me what I prefer I I like Mac OS just because it things seem to work a bit more smoothly especially when it comes to things like the terminal I think that Windows has gotten a lot better though and I do use Windows I'd say probably 30% of the time I just prefer Mac OS for my serious projects and then obviously you have Linux which is a great option because you can kind of mimic your production environments and it's very beneficial to learn Linux server Administration if you're going to be doing any kind of devops all right so so again it just comes down to preference so a text editor this is where you'll write your code and there's a lot of options out there personally I prefer Visual Studio code it's free it's open source it's very powerful it's very customizable I'd say about 80 to 90% of the web developers that I talk to use vs code um some other options are Sublime Text which technically isn't free but it has a trial That Never Ends if you do use it for a long time I would suggest paying for it um there's adom which is free and open source Vim is also pretty popular it's a bit more advanced than the others it has a uh quite a learning curve but it's very powerful and the people that use it swear by it and you don't really have to use your mouse at all so you can be very very efficient and fast writing your code so there's also idees which are integrated development environments they have a a little bit more features than a standard text editor you don't really need an IDE for most types of web development but there are some that are geared towards specific languages for instance you have pycharm for python developers you have PHP storm for PHP developers so that may be something you want to look into But ultimately I would definitely recommend vs code to to most people as far as far as web browsers go that's really preference I'm sure that all of you already have a preference I like Chrome there's not really a specific reason it just does everything I need to I I like the dev tools I think Chrome and Firefox would be the the the two most popular Firefox also has great Dev tools maybe a little better than Chrome um you could even use Microsoft Edge I I came up in the the Internet Explorer days and Microsoft browsers were just horrible I remember i6 and it it was just a nightmare but now Edge actually uses chromium under the hood so you could just as well use that um Safari I'm not too crazy about Brave is really cool for uh for privacy features Brave and Vivaldi and then there's a a newer browser called polyan which is directed toward web development but it's not free and personally I'm not going to pay for a browser Chrome does everything I need um so it's just preference and then for terminals it used to be that that front-end developers didn't really need to use a terminal for much but now with all the the framework clis and npm and git you do need to know at least the basics so as far as terminal programs go I think the default in Mac OS or most Linux dros are great uh for Windows Windows used to really suck with terminals with the you know the CMD command prompt I never really could get into Powershell uh but now the windows terminal isn't bad it has SSH you used to have to use tools like putty um I prefer get bash on Windows which is a third-party bash terminal um but you could also use the windows subsystem for Linux it is a bit more advanced though so I wouldn't suggest that for beginners um and then for Linux obviously you have tons of of thirdparty terminals you have Terminator alitt for Mac OS I'll either use the default or iterm 2 which just has a a little more features and I think it looks a little better all right so now we've come to the first big part of learning to be a web developer and that is HTML and CSS so these two technologies are essentially the building blocks of the visual part of the web HTML is a markup language that's used to structure the content of a web page and then CSS cascading stylesheets is the styling language that's used to style the content so you can think of HTML as the skeleton and CSS as the skin you can't have one without the other HTML itself is actually very very simple it's just a bunch of tags that you use to structure your content so as far as what you want to learn about HTML you want to learn how to create semantic markup this means using the correct tags for the correct content you also want to learn about accessibility this is making sure that your content is accessible to everyone including people with disabilities you want to learn all the common tags and attributes so things like heading paragraphs lists there's a lot of older deprecated tags that you don't even have to bother with uh I would say semantic tags excuse me like header and footer are very very important so spend some time learning how to structure your pages semantically and then CSS is a a much different more complex technology it's a styling language that's used to style the content of a web page it's very powerful and it's constantly evolving um there's a lot to learn about CSS you want to learn about all the core properties for things like colors fonts the Box model which is how elements are laid out and spaced on the page and how to use margin padding borders um spec specificity is important because sometimes you'll have multiple styles that apply to the same element and you need to know which one will be applied and the different units of measurements like pixels M's Rems and percentages you'll want to learn about different types of selectors like classes IDs there's also what we call pseudo selectors um you want to learn about the different layout methods like Flex box and grid these are are used to lay out your elements in columns and rows and then responsive design is really important all of your projects should look good no matter what device they're being viewed on you know there's there's a few elements to responsive design but media queries are probably the most important uh this is where you can apply different Styles based on the size of the screen so you definitely want to be familiar with responsive design so next we have CSS Frameworks now at this point these are optional and you could just go right to JavaScript however these Frameworks can make things much easier when it comes to creating layouts they're also very popular and a lot of companies use them and they're pretty easy to learn when comparing it to other Technologies like a programming language so my personal advice would be to spend a week or two learning one of these Frameworks and there's uh there's a ton to choose from however these are the main four that I would suggest looking at and to be even more specific I'd say the first two but that's just my opinion so bootstrap is one of the original CSS Frameworks it's been around since I believe 2011 and it's a very widely used technology and has a large community which is always a plus its component based which means that there's a lot of pre-built classes that you can use for things like buttons cards nav bars Etc and the upside to this is that you can create uis and websites really quickly and you have less classes in your HTML the downside is that sometimes bootstrap websites can look pretty similar now it's fair to say that you can really customize bootstrap and make it look however you want but you will have to learn SAS which is a CSS pre-processor and I'll talk about that in a minute um bootstrap also has an easyto ous grid system that a lot of people like however I definitely wouldn't suggest using it just for that because you have CSS Grid or Flex box which are built into CSS so you don't need to use bootstrap just for the grid another plus to bootstrap is you get a set of JavaScript widgets like models carousels and dropdowns and this is great for people that don't have a lot of JavaScript experience and still want that functionality so I'd say bootstrap is one of the best tools for Freelancers because you can create websites and layouts very quickly now Tailwind CSS seems to be the most popular right now as far as you know content that you see out there and what people are talking about you see it everywhere in new projects a lot of startups are using it it's a utility first CSS framework that allows you to build custom designs without pretty much ever leaving your HTML and being utility first makes it a bit different than the rest of these because instead of having a class for let's say a button which would generally have mult multiple Styles you have a class for each style so you'll have a class for the background color for the text color for the padding so you almost never have to write any custom CSS because every CSS property has a class the downside to this is you end up with a ton of of classes in your HTML but the upside is that you can really customize your layout and they don't all look the same which can be an issue with a lot of these other options all right so next we have balma which is a newer framework that I really like it's it has some good-look components and it's really easy to use as far as class names go it's not as popular as bootstrap or Tailwind it's also not as customizable as Tailwind um but it is very fast and lightweight and I think it looks good then you have materialize which has been around for a while it uses Google's material design system and as far as component-based Frameworks go I think materialized is one of the best looking um obvious obviously that's just my opinion there's a ton of components to choose from and there's also JavaScript widgets like modals and dropdowns similar to what you would get with bootstrap um from what I from what I can tell its popularity has come down since the release of Tailwind but it's still a very viable option and some other Frameworks out there are semantic UI Foundation UI kit I'm not going to go over all them because they're they're all pretty similar once you learn one it's pretty easy to pick up another one so SAS is another option that you may want to learn around this time it's a CSS pre-processor that adds extra functionality to CSS so it allows you to write CSS with variables and functions mixins um Native CSS is catching up with SAS features for instance we have custom properties in CSS which are essentially variables they're not as clean looking as SAS variables but they basically do the same thing um there's still a lot that SAS can do that CSS can't though so you can nest and inherit Styles which is a very helpful feature I would say learn SAS if you're using a framework like bootstrap where you need to customize the Styles also it can make your CSS very modular so you can separate it into different files and then you can import them into one another and this makes it easier to maintain you basically create your own CSS framework and you have a separate file for things like button stop or navbar Styles it's been around for a while there are other CSS pre-processors like Les and stylus but they kind of just faded away SAS has a a really good ecosystem of both command line tools and guey tools to compile it because you can't use SAS files directly in the browser right you can't just include them like you can CSS you have to compile it down to regular CSS and there's different tools that allow you to to do that it's also great for theming so where you want to have different color options and things like that um it is optional but again it's something that's really easy to learn so why not learn it you could you could learn it in a weekend and I have a crash course that pretty much shows you all the features that you need to know so next we have a batch of really helpful tools that you'll most likely learn and use early on so git is a version control system for saving and versioning your code as well as collaboration and say you should learn it no matter what type of developer you are you don't have to learn it before you start coding like you don't have to learn it right the second but it should be on your list uh as something to learn pretty early on it's it's really not difficult to learn the basics at the very least just create a GitHub account and learn how to create a repository and push that push your code to that remote repository and you can do it through the terminal through commands or you can do it directly through your your text editor through the guei markdown is another thing that you should probably learn it's a markup language that's used to style text similar to HTML it's used in a lot of places such as GitHub it's used in readme files which you should have for every project that you create it's used for documentation and it's very simple to learn you can literally learn it in a weekend or even even in a day uh and the things that you don't know you can always just go and reference I forget the the exact URL to the markdown website but very simple stuff so next we have editor or IDE extensions so most text editors such as vs code Sublime Text adom they have extensions or plugins that you can install and EMT is something that anyone that writes HTML and CSS should be using it's it's not even extension for vs code it's built-in but with some text editors you do have to install it so it gives you really nice shortcuts to create all kinds of HTML tags with classes and IDs and content CSS Styles it saves a ton of time it saves you a lot of typing so definitely something you should learn early on live server is another great one that I use all the time it gives you uh a devel local development server that updates as soon as you save your files so you don't have to go and manually refresh the page uh prettier is something that I use a lot it's a code formatter that will help you keep your code clean you can make it so that it's it it formats your code when you save the file another thing that I would highly recommend is to learn the shortcuts of your editor because it makes you much more efficient and makes you code much faster all right so next we have some AI tools that can Aid in writing code and problem solving AI is getting bigger by the day obviously almost to the point where it's a little bit scary but I know a lot of people fear that AI will replace replace their jobs or replace developers and I think that may be true to an extent when it comes to basic tasks but for the most part I think it's just going to change the way that we write code it's going to change the landscape and what developer roles entail uh my suggestion would be not to worry about it too much and try to utilize the tools that are out there to your advantage to make you a better developer and the two AI tools that have been pretty much invaluable to me are GitHub co-pilot and chat GPT so co-pilot is an AI pair programmer that helps you write code and you can install it as an extension to vs code and many other editors uh it's not perfect but it is pretty amazing and it helps you be more efficient saves a lot of time um helps you solve problems I use it for even things like like generating sample data you can say give me you know 20 give me a Jason file with 20 users with these fields and it just generates it for you so really cool stuff there's others that are similar like tab9 kite there's a new AI tool that looks really interesting called Codi I haven't used it yet but it looks really powerful and not only can you use it for like Auto completion and suggestions but you also have a chat window where you can interact with it and ask it questions about your project and not just a single file the entire project even if it's you know hundreds of files so really cool and then chat gbt is obviously huge right now it's incredible for learning just about anything um there's a few things that you really have to understand though when it comes to using tools like this the first is that it can be wrong it can be very wrong in fact so you can't just rely on that uh I use it kind of as a starting point along with other resources and the other thing is to make sure that you don't rely on it too much if you're just using it to generate code and using that code without understanding it you're not doing yourself any favors so use it as a learning tool not as a crutch and if you find yourself doing that I'd say don't even use it for now um but if you use it correctly it can be a great tool so next we have design tools and this is another area that you may or may not need to know depending on your goals and I usually suggest that you learn the basics of design unless you're working strictly backend as a freelancer you're going to need to know some of this stuff I think one thing that a lot of people don't realize is if you plan on freelancing you have to kind of have an eye for design and be able to create good layouts and good-look websit unless you're Outsourcing that work which you probably can't afford to do when you're starting out so as far as tools go figma is a great tool for designing websites and uis that's probably what I would recommend most people it's free it's web-based uh it's very easy to use it's not something you need to rush to learn but it will help you in certain situations some others include sketch which I believe is still Mac OS only uh you also have adob Adobe products like XD Photoshop Invision seems to be really popular for mockups and prototypes and then you have canva balsamic as well as well which are both web- based now while we're on the topic of design and again unless you're a backend developer I usually suggest learning at least the basic principles and these are some of the ones that I suggest you keep in mind when you're building websites or uis so color and contrast is important which color paletes look good the difference in brightness between elements I see a lot of hero images where I can barely read the text uh that's against the background image so you want to make sure that your text is readable this is one of the the biggest and most obvious mistakes that I see so white space Also important uh it's another big mistake I see when people don't have enough space between their elements or they have too much space having the right amount of white space can make a huge difference and really improve readability and just the overall experience of the website scale is also important you want to make sure that your elements are sized correctly you don't want to have a huge button and then a tiny input field things like that everything should be proportionate and then visual hierarchy you want to make sure that the most important elements stand out and you can do this with size color contrast this helps users navigate your website or UI and it's not only important for how your website looks but it's also important for how it functions and how successful it is in terms of sales or signups or whatever the goal of of the website is so obviously there's other principles typography is another one you want to make sure that your fonts are readable and consistent things like that and I think these are skills that anyone that works in the front end can benefit from you don't have to be a designer but you should know the basics okay so everything we've covered so far has to do with creating static websites and layouts and not really any Dynamic functionality or interactivity so that's where JavaScript comes in JavaScript is the programming language of the browser now how much JavaScript you learn depends on your goals so if you plan on being a backend python developer then you probably don't need to learn much much but if you want to become a front-end developer you'll probably end up using a JavaScript framework like react so you need to learn quite a bit if you want to be a backend or full stack developer and use node.js then obviously you need to learn quite a bit of JavaScript as well so this brings me back to why your end goal is so important now people always ask me how much JavaScript should I learn before moving to a framework like react and Shameless plug here I do have a course called modern JavaScript from the beginning that'll teach you everything that I recommend plus more it's a a 37-hour course but as far as just you know an overview of what I would suggest I'd say learn the fundamentals first so variables functions conditionals Loops things like that then you want to learn about the document object model which is how JavaScript interacts with the HTML and CSS learn how to select elements and manipulate them this is what's going to allow you to create things like like uh dropdowns and models and menus you know icons you click on and the menu slides out cool things like that and then high order array methods are important for working with data so methods like for each map filter and you should also learn the fetch API so that you can make requests to either a backend or a public API and fetch some data so you want to learn about HTTP and methods like get post put and delete and learning about promises and asynchronous code in general is a must in with JavaScript and then learn about Json which is a data format that's used to send data back and forth between the client and server so as a front-end developer you'll be using the Json data that's sent from the server and if you're a back-end developer you'll be creating or generating that Json data so I'd say that that's the minimum that you should learn before moving on to a front-end framework you can learn more if you want such as object-oriented programming classes prototypes things like that but I think that this is a good starting point all right so WordPress is a CMS or content management system that's built on the PHP programming language and I always struggle with where to put WordPress in this guide because technically it is full stack but you don't need to be a full stack developer to use WordPress or any tool like it for that matter uh a very common learning path is to learn HTML and CSS then a little bit of JavaScript and then get into WordPress and possibly PHP that was actually my path back in the the late 2000s so WordPress is especially handy for Freelancers there's a few reasons for that it allows you to uh build Dynamic websites quickly with little to no coding skills it's great for clients because they can easily update their own content without having to create uh without you having to create a custom admin area which can take months to build there's tons and tons of of themes that you can use as well as PL plugins to give you certain functionality both free and paid uh I do always recommend that people that that want to use WordPress also learn PHP so that they can really customize and create their own themes and plugins it does make all the difference in the world if your client asks for something specific and you can build it on on your own because there's no Plug-In or theme for that does what they want um believe me when I started freelancing I didn't know much PHP and I was using Wordpress and there were a lot of times where I had to tell my client that I couldn't do that or I'd have to pay someone else to do it but once I learned PHP I was able to just go in and customize everything I should say PHP and JavaScript because there was was some front-end stuff there's also a huge Community for support and learning I think something like 35 to 40% of the web is still run on WordPress so many like small business websites things like that all right so once you're able to create a basic website or small application front-end application you need to know how to actually deploy it to a live server and this is something that a lot of people don't seem to think about until they're done with a project and they're like now what so websites or applications that are just front-end HTML CSS JavaScript can pretty much be hosted anywhere you don't need to have a server like Apache or engine X which we'll talk about later in the in the backend section there's literally hundreds of options out there some of the most popular services are static hosts like netlify versel GitHub Pages now you can use something like versell to host like a nextjs website which is server rendered in fact versell created nextjs but they're also great for just plain old HTML and CSS projects and those three services are extremely easy to use because all you really have to do is push your project to GitHub which you should already know how to do it this time and then link your account and choose the repository that you want to deploy they will give you a URL they'll assign you a URL but you're going to want to purchase your own domain for your website most likely and there's a lot of services for that I personally use name cheep but there's Google domains GoDaddy there's so many different domain name registrars out there that you can use and as far as SSL certificates go a lot of Hosting Services these days include SSL so you don't have to really do anything extra if they don't and you need to purchase an SSL certificate on your own you can purchase one from from name cheep um there are different types or you can get a free one from a service called let's encrypt so that might be something you need to look into now out of the the hosting Services here for simple static websites or simple front-end applications or even SSR projects I prefer net lefi and versel I think they're both very similar they both offer Sim similar features you get things like form submissions serverless functions logs and and so on if you're are running a business and you you need for instance business email for your domain name things like that then you might want to go with a company like hostinger or blue host and these companies offer shared hosting which is very very cheap usually under like $10 per month and these Services I'm recommending for for mostly front-end projects when you get into larger full stack or or or or apis you're going to need something a little more a little more advanced something like AWS or digital ocean and I'm going to get into those Services a bit later but I would just suggest taking a look at some of them and and seeing what works for you you know do your own research on on the services all right so let's see where we're up to at this point I'd say if you're familiar with most of what we've talked about then you're somewhat of a a foundational front-end developer or a web designer if you you lean more towards design as well and if you plan on being a backend developer a lot of this doesn't really apply to you however I usually do suggest learning the basics of HTML CSS and JavaScript even for backend devs it just gives you a better understanding of how the frontend works and how to work with it and that's just my personal suggestion but I know not everybody has enough time to learn everything so you should have a familiar development environment that you work with including a text editor or IDE a set of helpful extensions some kind of local development server like live server uh a terminal although at this point you probably don't need it much and then you should know the basics of git and GitHub so you should know HTML and CSS pretty well enough to create static websites with responsive layouts have a good understanding of the Box model knowing some design principles and stuff that also is very helpful you should know at least enough JavaScript to create some Dynamic elements like models dropdowns tabs form validation and just the ability to make Pages Dynamic and be able to add and remove CSS Styles dynamically with JavaScript and having knowledge uh about HTTP requests about the the request response cycle HTTP methods and using the fetch API understand asynchronous code and promises and then you should also be able to deploy a basic website or application to uh a live server using a service like netlify a versel or whatever it is that you choose now CSS Frameworks like I said are optional but in my opinion are recommended I would suggest either bootstrap or Tailwind they're easy enough to learn and they do help you you know style your websites much faster SAS is also optional but recommended as well because you can learn it really fast and I think I mentioned this but I I might not have but it's really important to to learn CSS before you jump into any kind of CSS framework just like with JavaScript you need to know fundamentals before you move to a JavaScript framework um some of you may choose to go the WordPress route especially if you're going to be freelancing if so you should know how to install and set up plugins themes widgets also work on learning how to create your own themes and plugins once you're ready to start learning PHP as far as Jobs go you could start applying with this knowledge but typically front-end positions are going to want you to know a framework like react or view so you might want to learn one of those first in my experience there are a lot of jobs that are willing to train you if you do know if you you know you're familiar with JavaScript but you just really haven't gotten deep into a framework yet some companies are willing to train you on that um you could also start freelancing at this point you could create websites for small businesses and individuals so it's really up to you on where you want to go next now from here it really depends on what you want to do and I think there's a few different paths you can take from this point so let's say that you want to be more of a web designer or or work for a small agency or freelance you might choose to learn more about design get better at CSS maybe get more into WordPress or even some no code tools like web flow you probably want to learn some SEO practices as well because that's something that a lot of clients will will need um this route usually is a mix of coding and business and you work really close with clients in other businesses you may even get into some marketing I did this for quite a few years myself um you could also go the the full-blown uiux designer route which is kind of out of the scope of of this guide um but maybe you find that you're better at design than coding I I've seen a lot of people do that they start off wanting to be a web developer but they end up um getting more into you know figma or uh Adobe XD and they they get more into the design side of things so that that could be an option as well and then the next option is to proceed with the front end and this this is probably the most common among my audience at least if you're more into the coding aspect and you want to work for a company as a front end or even full stack developer you can continue to learn more about JavaScript and learn a framework like react view or angular all right you can learn about UI components and state front-end workflows and and build tools like webpack and vit static site generators like Gatsby and SSR Frameworks like next JS you'll also learn about testing and performance this route is much more focused on coding and less on on design and again this could be for you whether you plan on being a front-end or a full stack developer and I want to stress that if you do plan on freelancing you can still proceed with this particular path it can be really beneficial to learn something like react and maybe a static site generator like Gatsby and use that along with a headless CMS that's that's a good stack for a freelancer because you can create things that are very Dynamic and you can create them really quickly and I'll talk more about that stuff soon next if you want to be a backend developer or a full stack developer and just start with the backend next you can take this approach so you can move to a server side programming language like python C PHP or stick with JavaScript and learn a runtime like node.js or even a newer runtime like bun JS or Dino so you'll also need to learn a backend framework like Express if you're using node D Jango for python larl for PHP uh maybe asp.net if you're getting into C so lots and lots of choices and we'll get into all of that and then you're also going to need to know about uh databases so either relational or nosql databases with this option you'll be creating apis for front-end developers to work with if you're going full stack then you'll be creating and consuming apis you may also want to learn a little a little bit about devops and how to deploy server side applications to and apis to production so I'm going to continue with what I see most people do and move further down the frontend developer path so we're going to take the the middle option here now before we look at front-end Frameworks and ecosystems I want to address a change that's that's happening where the front end is evolving quite a bit and this may seem complicated and overwhelming at first but I think we're headed in the right direction so website started off with a traditional multi-page server rendered approach so think of like a PHP website each distinct piece of content is presented on separate HTML Pages whether it's static whether you create those HTML Pages or they're generated by some kind of server side language like PHP and this is still a common approach it's great for SEO but the UI isn't as fast and dynamic as if you were to use a front-end framework like react which which for many projects is absolutely fine then these front-end Frameworks come along and change it up where we're building single page applications or spas and this is where the entire UI the entire application or front end is bundled into a JavaScript or or multiple JavaScript files and the browser loads a single HTML page so when you click on a link it doesn't actually go to a new page like it would for a traditional HTML or PHP site it just changes the URL and then JavaScript handles the rest and this makes the site very Dynamic it gives you a very fast and and interactive user interface on the client side but it's not great for SEO and it can lack performance in some areas so now we have what are called SSR or serers side rendered websites this is where the page is initially rendered on the server by default and then sent to the browser similar to traditional websites however we can still have that interactive fast user interface by using client side components in Frameworks like react and view so you really get the best of both both worlds and we do this through what are called met meta Frameworks or SSR Frameworks there's different names for them but some examples are nextjs which you can use react and you can have your pages server side rendered nujs for view you have spelt kit for spelt so I'll talk about those Technologies in a bit but that's kind of the approach that we're St stting to see more of now now in addition to that you have static site generators like Gatsby gridsum Astro nextjs is also a static site generator and these are Frameworks that allow you to build static websites with react view felt so you can have a static website with a dynamic UI and I know that sounds a bit confusing but it I think it's a good thing because it gives us more options and allows us to build better websites or more interactive websites and applications so instead of talking about front-end Frameworks and then talking about SSR and static site generators I'm going to talk about them all together as an ecosystem I think that makes more sense so if you're a react developer and you want to learn SSR then you're probably going to use something like nextjs or remix because you already know react you just need to learn the the the nextjs way of doing things now since this can be confusing especially for beginners I always say that I always say I always say start with a single page application if you're learning react just start with Spas using Create react app I'll talk about that in a minute and basically go with the whatever's in the framework's documentation then once you're comfortable with that you can move to a meta framework like nextjs so think of it as you're you're not just learning or getting into react or view but you're getting into that entire ecosystem and that can include SSR SSG State Management mobile Frameworks UI component libraries and more so you don't have to learn all these things but the more you learn the more types of projects you can build now there's a crap ton of Frameworks out there but these are the big four you have react view spelt and angular and I would suggest learning one of these because if you choose some obscure framework it could go away at any point you know and no longer be supported and there's probably not much of a community you may have a hard time finding a job so would stick to one of these and I'm going to go over each one and then after that we'll go over the ecosystems of each one so we'll start off with react which is a front-end framework that was created in 2013 By Facebook and I would say it's the most popular front-end framework it's been around for quite a few years now there's quite a few react jobs out there in many areas so if you're looking to work as a full-time developer then react is a good choice it's a component based framework work as are all of these and it uses jsx which is a syntax extension to JavaScript so it basically allows you to write HTML within your JavaScript and within your components it's not required with react but it's the most common way to use it and the most common way to write components now and when I say components I'm talking about pieces of the user interface so a search input uh a nav menu an article whatever you you you start to think of your website in terms of UI components now technically react is a UI library and not a framework however it's so popular and has such a huge ecosystem that I think it's fair to call it a framework and it's a direct competitor to Frameworks like angular and just know that react is a library so you'll most likely be installing a lot of other packages react does have one of the or I'd say the biggest ecosystem and that's not necessarily a good thing because it means that the framework itself is pretty bare bones and you'll need to install other packages to do things like routing Etc I'd say it's pretty middle of the road when it comes to the learning curve there are some things that might make you scratch your head and things that are a bit easier to do in other Frameworks especially when it comes to State however it's much easier than something like angular at least in my opinion it's also pretty quick to to get something up and running with now when it comes to Performance all the Frameworks are pretty impressive it's hard to really gauge this because it depends on the project and how you write your code react is generally more performant than angular um it's also much lighter but it's not as performing as something like spelt but again it depends on the project and how you write your code you can use things like memorization and lazy loading things like that to improve performance now there's also a lot of jobs in react in most areas at least in the US I'm not really familiar with other countries and this is definitely a good reason to get into react but it shouldn't be the only reason if you hate writing react you may be better off using something that you like even if there's less jobs and remember if there's less jobs there's probably less competition as well also remember when there's a lot of jobs with a certain technology that's really popular a lot of people know that technology so you have to weigh the pros and cons next we have vue.js which is a framework that was created by Evan u in 2014 and it gains more popularity every year a just the fact that it was created wasn't created by a tech giant like Facebook or Google and is still one of the most used Frameworks is pretty impressive and it shows that it's a great framework one of if not the main focus of vue.js or main focuses is Simplicity and performance and it is component based of course just like the rest of these and it uses a template syntax that's very similar to HTML and view components are very simple there's an area of the template for for the output or the HTML the logic or the JavaScript and the Styles and there's two different ways to write your JavaScript in view components now at least with uh since version three there's the options API where your component is an object with properties and methods and then the view version three introduced the composition API where it's uh you have a setup function and you return the data and methods from that function I'd say the options API is a bit easier to learn but the composition API is more powerful that's just my opinion though so like react view is also very lightweight and on its own it has a a pretty similar ecosystem to react when it comes to you know SSR and SSG Frameworks and so on and we'll take a look at those soon I would say that Vue is one of if not the easiest Frameworks to learn of course I'm saying that relative to the others uh it's also very powerful and it has a lot of the same features as react so as I said Vue has a focus on performance and it's very fast has a very small bundle size so next we have angular which was created by Google and there was a version back in the day called angularjs I believe around 2010 and the entire framework was revamped for version two which is just angular so if you hear angularjs and angular those they're usually two different Frameworks so if you just go by the cont content in things like YouTube and Twitter and you know things you read online you might think that angular is kind of dead however it's still very much alive and used by a lot of really large companies and Enterprise level projects so I don't think it's going anywhere anytime soon the others are more popular with startups smaller companies individuals and of course they're they're also used by really large companies um but you see mostly react and view if you're looking at YouTube tutorials and videos and stuff like that um but yeah angular is a true full-featured and opinionated framework meaning that there's certain ways to do things where with something like react you have much more freedom and you can there's a million ways to do the same thing now angular includes a router it has its own HTTP client it has its own Services animations and much more it also uses typescript by default which is a superet of JavaScript that lets you use types and you can use typescript with any framework however it's the norm it's the default for for angular applications and it also ships with the angular CLI which is a command line interface that allows you to create an angular application with virtually no configuration and it's used to build and deploy your app not only that but you can set your project up to be a spa so a single page application or an SSR or a pre-rendered static site so the ecosystem as far as third-party tools is much smaller than react or view because again so much is included in the framework itself I think angular has a pretty steep learning curve and I don't usually recommend it for beginners unless they're going to be working for a company that uses it um but that's that's just kind of my opinion and it seems to be the opinion of a lot of people the bundle size is larger than others which is expected because it's so full featured however it's still pretty fast for what it is um for most projects the bundle size isn't going to be an issue anyway so the last one we have is spelt which is a modern JavaScript framework for building web applications that takes a kind of a different approach in fact technically spelt is a compiler and it focuses on shifting a lot of the work that's traditionally done at runtime to compile time so other Frameworks like the ones we just talked about use what it's called a virtual Dom while spelt comp piles your components into highly optimized vanilla JavaScript code during the build process so this results in faster and more efficient applications and it's also the most lightweight of the four as far as writing codes felt offers a simple and intuitive component-based approach where components are written using a clean HTML like syntax with JavaScript logic embedded directly within them so when you write spelt code it it it feels a lot like vanilla JavaScript out of I'd say out of all the Frameworks it's almost like what you wish JavaScript would be on its own in terms of how you create events and dynamic interaction with with HTML uh spelt has a a pretty easy learning curve I'd say spelt and view are definitely the easiest to learn uh it has a very straightforward development experience which makes it an an attractive choice for building modern web applications the downside to felt is that it's it's fairly new so when it comes to finding jobs I just don't see a lot of them and I'm not saying that you can't find a job as a spelt developer but there's a lot more react View and angular jobs out there and it's a it's a great framework on its own though and I would suggest checking it out um now the ecosystem for spelt is really small because there's an official meta framework called spelt kit that pretty much includes everything you need to build a full stack application you can build Spas SSR static websites it handles all the routing the building the dev server and much more all right so now I want to talk about the ecosystems for each of the four Frameworks and instead of showing you a page with all the SSR Frameworks all the static site generators I'm keeping it within that particular framework ecosystem and some of this stuff is are tools that are built into the framework but most of it is is thirdparty tools to add function it and I'm going to start with react because it has the biggest ecosystem and then I'll talk about the others and you're going to see that most of what is available for react is also available for the others whether through native features or through thirdparty packages so we'll start with create react app that's probably what you're going to start with if you if you're just starting to learn react and this is more more of a traditional way to use react it's a CLI a command line interface that allows you to to spin up a project with no configuration it's great for beginners and it's what you would use to create a spa or single page application so you could install react manually if you wanted to but I wouldn't suggest it because create react app gives you additional features like Hut reloading gives you a Dev server service worker and more and it's built on top of the webpack build tool and you can eject from create react app if you want to customize the configuration and really dig into webpack but I wouldn't suggest just that unless you really know what you're doing now as I said react is referred to as a framework but it's technically a UI library and it doesn't have some of the essential things that you would find in a framework and a router is one of those things so with a single page application you need to manually Define your routes it's not like an SSR framework where you just put a file into a certain folder and then it's accessible you need to install the router and you need to create your routes and the most popular way to do this is with react router which is the official re router that you would use and you'll typically learn about this along with react it's very easy to use it has a lot of features and it's very well documented now when it comes to managing state or data in your application you have component level state which just pertains to that component which is pretty easy to handle but then you have app level or Global state where you need to share that data between multiple components now in my my opinion react isn't the best with State Management out of the box there is a built-in context API that you can use along with some hooks but it's fairly difficult for beginners to grasp also if you're building something with a lot of State you might have to reach for a third party solution so Redux has always been pretty popular um Redux also isn't the easiest thing to deal with I think Redux toolkit makes it a bit easier that's another a library you can use on top of Redux you also Al have mobx which is a popular state management tool there's some others like zo zustand zustand I'm not sure how to pronounce it but um that's gaining some traction recoil xstate there's a lot of different ways you can manage state within react but I would say learn the the native features first learn the context API learn the you know usate hook user reducer hook and so on now when we get into the server side rendered Frameworks I think that this is where react's ecosystem really shines nextjs is a great framework and just great platform to build react projects with it uses react server components so all of your components are actually rendered on the server by default and you can fetch and load data very easily from the server you can also make them client side components and make them Dynamic just by adding a single line at the top saying use client um next JS also is a static site generator so you can create static websites then you have remix which is another SSR framework that's built on top of it's actually built on top of react router and it's very similar to nextjs it's a bit more difficult to learn in my opinion but it does have some features that next doesn't and I do have a crash course on both if you want to check them out SSR websites are great for SEO and performance you really get the best of both worlds like like I said earlier and you can also use uh something called a headless content management system like content full or sanity and I'll talk more about those later but those pair really well with SSR Frameworks now Gatsby takes a different approach compared to traditional single page applications or or SSRS it's a static site generator so instead of rendering content on the client via JavaScript Gatsby generates static HTML files at build time so this approach results in really fast load times and improved SEO so it's built on top of react so if you already know react you can easily jump into Gatsby it has a data layer that uses graphql which is a query language for apis and I'll get a little bit more into that later um but yeah Gatsby and nextjs are both used to create really fast static websites and again you could use something like a headless CMS for your data and use the stat static website as your front end so of course you can write your own CSS and styles but you you might want to use a UI component library or UI kit these are pre-built components that you can use in your application and they're great for beginners because you don't have to worry about styling you can just import the component and you can use it so there's a bunch of these material UI is uh really popular one it uses Google's material design pattern and it's very customizable has a a ton of components to choose from some other popular ones are react bootstrap which has pre-built bootstrap components Shakra UI which I really like I think has some really goodlooking components and then you also have a library called styled components which is a CSS njs library that allows you to write CSS in your JavaScript so this is is it doesn't come with pre-built components like the other ones do but it allows you to essentially create your own pre-built components so another part of the ecosystem is react native which allows you to build native mobile applications using the react framework and what's great about react native is that you can use the same codebase for both IOS and Android usually when you build native mobile apps you have separate a separate Swift Code base for iOS either Swift or objective c and then you'll have a separate cotlin or Java code base for Android apps where with react native it's it you have just one app for both and it's also great for web developers because you can essentially use your JavaScript skills to build mobile applications so those are the main parts of the ecosystem but there's plenty of other smaller things you might find yourself using such as react query which is a library for fetching caching and synchronizing data you have libraries to work with forms like formic and react hook form react testing library and many other libraries to to test your react applications there's libraries for animation there's even even Frameworks and libraries for using react to build VR so virtual reality and augmented reality environments um you certainly don't need to learn all of this but if you learn react you can get into all this stuff pretty easily so the vue.js ecosystem almost seems to miror reacts it has a lot of the same features and tools so create view is similar to create react app but just for vue.js it's a CLI and Scaffolding tool to create a single page application and it's built on top of a build tool called vit so vit is a newer build tool that's much faster than webpack we used uh we used to use something called the Vue CLI which is still around but I don't think it's supported anymore I would just suggest using Create view uh if you're building a spa with VJs and then Vue router is the official router for VJs it's very similar to react router it allows you to create routes for your application it's very easy to use very well documented now State Management with the native vue.js is is pretty easy compared to react just by the way components are structured but there are tools if you need more advanced State Management so VX used to be the official state management tool for view but now it's called pinea which works in a very very similar way to VX and it allows you to share your state across components and pages and it works of course with view version two and version three you also have other options like xstate Harlem uh and there's a lot of other thirdparty tools you can look into if needed and then nujs is very similar to nextjs it's a server side rendered framework or meta framework for vue.js it's great for SEO and performance it's also a static site generator so it includes most of the features that nextjs does as far as filebase routing server components data fetching utilities um it uses the Nitro server engine if you're a view developer and you want to get into SSR you're probably going to be learning nujs and then gridsum is a popular static site generator built on top of you and it's very comparable to Gatsby and it's ideal for building fast and efficient static websites blogs documentation sites it's also um uh it also uses a graphql data layer just like Gatsby so you can kind of see the pattern here everything that react has view basically has in its own right and then as far as UI libraries go VY is probably the most popular it's similar to material UI for react it's based off of Google's material design pattern very customizable tons of components probably what I would recommend but there's others as well um if you want to use bootstrap components you have bootstrap view I believe believe there's also one called view strap you have quazar Buffy which is uses the balma framework so tons of of UI kits available and then as far as mobile development there's not really something that's directly comparable to react native um you do have native script or native script view but native script you can use any any um uh framework with you could even use react with it and it has access to Native API so you can essentially create uh a native mobile app with View and have a single code base for both IOS and Android and then some other things you might run into our view query or tan stack which is basically the react query for view it's a way to fetch and cache data you have view testing utilities you have native animations that you can use um that's built into the framework and then for virtual reality you have Vue VR so just some things that I figured I'd throw win that you might find uh find in the ecosystem now for angular the the ecosystem isn't as big or I should say a lot Mo a lot of the stuff is built into angular itself because it's a much more full-featured framework so you're not reaching for as many thirdparty solutions so the angular CLI is the official command line tool for angular it allows you to create build test and deploy angular applications and it's it's similar to create react app and create view it's built on top of webpack and it's pretty easy to use also very well documented um you can enable SSR with angular CLI which is pretty cool it was initially called angular Universal the SSR framework but that repo has been merged with the CLI there's also options to pre-render your app which is similar to static site generation now the angular router is the official router for angular and it's very similar to react router and view router except it's built built in you don't have to install it separately and it includes things like route guards it even has some animation options uh so very cool now as far as state goes one thing I really like about angular is the concept of services this gives you an easy way to manage your state because you can inject a service into your components and you can share data from that service across your entire application okay you also have ngrx which is the official state management tool for Ang it's similar to Redux um it's it's actually built on top of something called rxjs which is a library for reactive programming using observables so dealing with asynchronous code similar to promises and it's a bit more complex than other State Management tools but also very powerful and it's great for larger complex applications uh and again for SSR and static sites you can just use the CLI so there is no nextjs or njs for for angular U it's all included and bundled in the CLI for UI kits angular material is pretty popular you also have NG bootstrap Prime mg Clarity and a bunch of others as well with that you just kind of have to go through and see which ones you like what what components you like the look of and so on uh if you even want to use a UI kit and then for mobile apps you can use native script just as well as you can use it with any framework um you can also use ionic for hybrid apps which I'll talk about later and then as far as other tools you might find yourself using obviously typescript because that's the default with angular some other packages I've used are angular fire to work with Firebase um which we'll also talk about later formly for forms and angular testing library for testing um and testing is built in with the CLI as well so spelt is newer than the other framework it doesn't have as big of an ecosystem because it has an official meta framework called spel kit which is awesome I really like the way that spelt does things it's a full stack framework that allows you to build single page apps server side rendered apps and static websit so it's basically an all-in-one tool and it's great for SEO it's great for performance um it's similar to nextjs and knjs with some elements of Gatsby and gridsome so you can basically build whatever you want with spelt and it's built on top of the vit build tool um sapper was the original meta framework for spelt but it's no longer supported so spelt kit is basically the new version of sapper and State Management is is really well integrated you don't really need to reach for a third-party solution because spel kit has uh a context API and built in readable and writable stores that you can use to share data between components of course if you want you can use a thirdparty state manager but I think for most types of applications the built-in the built-in functionality is really all you need and there's also a bunch of UI kits like spelt strap which is a port of bootstrap for spelt there's U there's carbon components which is aort of IBM's carbon design system as well as flow bite and some others so the the way that spelt does it I think is is the way to do it just have everything bundled in a single official meta framework now you can see that a lot of these framework ecosystems basically all copy each other they all have the same features and tools so it really comes down to what which one you like best you can pretty much build the same stuff with any of them some are might be a little more performant than others but they're all pretty fast so those are the big front-end Frameworks and ecosystems and I know that it's a lot of information but I think it's important to know what's out there and what I suggest is is just trying each one out and seeing what kind of Vibes with you uh a lot of people on the internet like to say this one's great and this one sucks don't ever let that be the deciding factor try them out for yourself and see what you like I think they're all great and they all have their pros and cons all right so let's talk a little bit more about typescript I mentioned it a couple times but didn't really talk about what it really is um it's available for front end and backend if you're using something like node.js and typescript is a superet of JavaScript meaning that it is essentially JavaScript it is the JavaScript language but with some added features so anything you can do in JavaScript you can do in typescript but then in addition you have features um such as static typing that's kind of the main addition to it is that JavaScript by default is a dynamically typed language which means that you don't specify the types of your variables or function return values you don't say this variable is a string or this one's a number but typescript allows you to do that and you might say well why the hell would I want to do that why would I want to write more code when I don't have to and it's kind of hard to explain until you use it and really see the benefits it's not for everyone but I think it's worth learning I think that having types does require more code but it also makes your code more robust and less prone to errors it also makes your code more descriptive and readable and if you use something like vs code it will give you more intellisense and show you you know what properties and methods are available for or or what you're missing um so there are a lot of reasons to use typescript all right so headless content Management systems are becoming more and more popular and they allow you to create content in a user interface similar to what you would do in a WordPress admin area and then they generate an API from your content and you can use that API in whatever front end you'd like and these these can also be useful for Freelancers because clients can log in they can update their content easily and uh of course you could create your own custom admin area for them but that takes way more time and money and these are really popular with static site generators like Gatsby as well as SSR Frameworks like nextjs or njs so let's just take a a look at at a few of the popular ones there's tons of these out there so sanity or sanity.io is a headless CMS that can be used by projects of all sizes companies like Nike and figma use sanity there's a free option for personal projects but you can also pay for plans for for teams uh for really large projects so it can be good for really complex applications or something like a personal blog content full is another popular headless CMS that has a ton of features it's used by companies like Spotify and Urban Outfitters it's also free for personal projects and you can pay for plans for teams and there's also extensive Integrations available so strappy is a free and open source headless CMS that's built on top of node.js and it uses a mongodb database and it's great for small to mediumsized projects it's also very customizable I like strappy because it's open- source and you host and manage or you can host and manage everything yourself um the interface is pretty easy to use as well it can generate a rest API or a graphql API from your content I do have a crash course on strappy if you're interested uh I also have a crash course on the next one which is prismic and this is another headless CMS that uses a structured content model based on slices and it allows content creators to build Dynamic page layouts with reusable components and this is good for allowing non-technical users or your clients to create versatile content and and then High graph is a new uh new product that looks pretty cool it's it's not something I've used um it's a headless CMS with e-commerce capabilities so you can you can build an entire shopping platform API and it integrates seamlessly with payment gateways it also uses graphql again I'll talk about graphql in a little bit now if you haven't used WordPress in a while you may not know that in addition to the traditional WordPress CMS it also has headless capabilities and you can generate a rest API from your WordPress content and it's easy to get up and running um it's it gives you the the powerful WordPress admin interface without being bound to the front end without being bound to Wordpress themes so you can use anything you want react view spelt whatever um so this can be really good for free uh Freelancers as well now there's like I said there's a ton of these and I would just suggest taking a look look at a few of them and seeing if you like it see how you know how the API can can be generated and how you can integrate it into whatever it is you use in your front end now there are some other newer smaller Frameworks and other tools that I want to mention I'm not going to go into detail about them but I'll give you a brief overview if you're just starting out and learning one of the big Frameworks you don't need to worry about these just yet but if you're a more experienced developer you may want to check them out so solid is a declarative JavaScript library for creating user interfaces and it's built on top of jsx which is the syntax extension to JavaScript very similar to react in fast in fact the framework overall is very similar to react and solid js's reactive rendering is one of its standout features it uses um fine grained reactivity to update only the parts of the Dom that actually change resulting in high performance and minimal rendering so it's fairly easy to learn I still need to create a crash course on it it's not as popular as the other Frameworks but it's also much newer and it's growing in popularity so I won't be surprised if we see a lot more of solid JS Alpine JS is a minimal framework for composing JavaScript behavior in your mockup so in your HTML and it's quite different than the other ones we've talked about in fact I wouldn't even put it in the same category it's more of a utility Library it's very small and it's great for adding some Dynamic elements to your website without having to learn a full framework and you also don't have to write any JavaScript it almost makes HTML function as if it were a programming language so you can have conditionals and um loops and stuff like that within your HTML just by using special tags so if you have a basic website and you just want to add like a drop down or a modal you can do that easily with alpine JS and there's no need to learn learn a full framework it also pairs well with laravel templates or you can use it with d Jango and Frameworks like that and then HTM X is another really cool technology it's a a JavaScript library that allows you to create Dynamic front ends again without writing any JavaScript code and it does this by allowing you to use special attributes in your HTML to make HTTP requests and then update the Dom so it's actually similar to Alpine but it's more focused on making HTTP requests and it's great for adding some some um Dynamic elements to your website and making requests to an API or backend without having to learn a full framework and I think Alpine and HTM X are great technologies that work much differently than traditional framework so I would definitely suggest checking them out now Astro is one of my favorite new Frameworks it's actually a static site generator as well as an SSR framework and you can ALS also create a API endpoints with it I just did a quick start course that's available on YouTube and on my website what's really cool about Astro is that it builds zero JavaScript by default it actually renders the HTML pages on the server and uses an architecture called Islands also you can use Astro components which are very simple and straightforward or you can use react components views felt so it's it's sort of like a nextjs but it's not bound to react or any other framework uh it's also built on top of vit which again is a very fast build tool so definitely worth look stencil or stenciljs is something that I haven't used yet but it's a tool chain for building reusable scalable component libraries it's it was built by the ionic team and it's a compil compiler that generates web components so you can create your own components and you can basically use them in any framework you want or in just just JavaScript so JS Doc is something that has been around for a while I actually did a crash course on it years ago that I forgot about but I'm seeing a lot of it lately where people are using it in place of typescript and it's actually an API documentation generator for JavaScript but it can be used to add types to your JavaScript code it's not as robust as typescript but it's a lot easier to get into and I'd suggest looking into it and seeing if it's something that you might benefit from all right so in addition to tools languages and Frameworks you also have a lot of web apis available in the browser that you should be familiar with and I'm not going to go over all of them but I'll list some of the common ones here many of these are easy enough to learn I just suggest spending a little bit of time on them so the canvas API provides uh a means for drawing Graphics via JavaScript and the HTML canvas element uh among other things it can be used for animation game Gra Graphics data visualization photo manipulation realtime video processing and much more so canvas API probably something you you want to check out and then the geolocation API allows users to provide their location to a web application if they so desire uh for privacy reasons the user is asked for permission before they you know accept to show their location but this can be very useful for things like Maps weather apps um you can c tailor The Experience based on the user's location things like that the web storage API provides mechanisms for the browser to store key value pairs in uh a much more intuitive fashion than using cookies it also allows you to store more data than cookies and you can store data locally or session based so this is also called local storage and session storage now the web workers API makes it possible to run a script operation in the background thread separate from the main execution thread of a web application so this allows for long running scripts that are not interrupted by scripts that respond to clicks or other user interactions and allows long tasks to be executed without yielding to keep the the page responsive web the web sockets API makes it possible to open a two-way interactive communication session between the user's browser and a server and with this API you can send messages to a server and receive event driven responses without having to pull the server for a reply so this is great for chat applications and other real time applications um then you have the the web and video apis obviously these allow you to create and manipulate audio and video content you can create audio and video players record audio and video and even create audio visualizations so some others you might want to look into our web RTC for realtime communication and video streaming the Bluetooth API the web search API things like that um they're all fairly easy to get into once you learn the basics of JavaScript so I'd suggest learning about them and maybe building a small project with some of them all right now testing is something that you may or may not get into testing ensures the reliability functionality and security of your applications and I would suggest looking at your project load to see if testing would be beneficial uh I'm actually creating a video now that goes into all of that so it should be released by the time you watch this now if you're freelancing and you're using something like WordPress or building static websites you won't need to worry about testing but if you're building larger more complex applications it can be beneficial or if you're working for a company that requires you to write tests then obviously you need to learn it um but I think it's a good idea to at least see how testing Works check out some of the libraries and and some of the different types of testing as far as the different types there's a lot of them but I'd say the most common are these three you have unit testing this is where it pertains to individual units of code this is probably the most common type in web development then integration testing is the process of seeing how different elements of your application work together and then you also have endtoend testing which is the process of testing your entire application from start to finish and every programming language has testing tools I'm not going to go over all those but just some of the popular ones since we're talking about JavaScript just is very popular um it was built by Facebook and it's pretty easy to use it includes built-in assertion libraries mocking capabilities powerful features like snapshot testing mocha is another highly flexible testing framework for JavaScript uh if you're looking to run endtoend tests Cypress is is a good option it's it's JavaScript JavaScript based testing that allows you to write tests that run in the browser and then enzyme is a JavaScript testing utility for react you also have react testing Library there's just so many of these and I can't go over all of them for every language but um definitely something you want to look into if you're looking to build really complex applications all right so if you've learned most of what we've talked about then I'd say you're a pretty Advanced front-end developer so so if you're fluent with a frontend framework whether it's react view felt angular as well as their ecosystems um so have some frontend tooling skills so you should know how to use npm to install packages uh CLI tools module bundlers like vit and webpack and then server side rendering that's definitely something that a couple years ago I would say is optional but now I think that it's something that you need to get into so if you're becoming a react developer then you should be learning about nextjs or remix um spelt kit angular SSR njs whatever it is service side rendering I think is the future for um for you know a big part of web development and then static site generators also very useful if you want to build really fast performant websites uh headless cms's are obviously optional but they're really helpful again especially if you're freelancing and you want a way for your client to be able to update their own content but use whatever you want on the front end so uh really cool stuff and then some additional tools such as typescript uh Alpine HTM X some of the newer Technologies you might want to just mess with and get into web apis I would say you should understand a lot of the common uh apis that are available like canvas the speech API geolocation things like that so now that we've gone over the front end let's talk about the back end end and if you want to be a full stack developer or a backend developer that creates apis microservices you need to learn a servers side language or service ey technology and this is where you start to get a lot of options really you can use any language that you want that has HTTP capabilities but I'm going to go over some of the most popular choices and I'll give you some stats at the end of this section as well so the first option I have is Javascript right JavaScript was initially created for the browser but now we have these runtimes that allow us to use JavaScript as a server side language a very fast server side language no JS being the most common and definitely what I would suggest if you're just getting started there are some newer interesting options to play with if you already know node.js Doo is a a newer runtime that's built by the same person that created node it's very similar to node but it has some interesting features like built-in typescript support built-in package manager bung s is even newer and more interesting and I'm actually going to have a slide dedicated to to that towards the end but nodejs is very popular for building apis microservices as well as full stack applications it's non-blocking and event driven which makes it highly efficient for handling concurrent connections and IO intensitive tasks what it's not good for is CPU intensitive tasks so if you're building something that requires a lot of processing power you may want to look into something else um but node.js is is great for just about everything that has to do with web development so anything where we're just doing crud operations create read update and delete working with databases Etc it's built on the V8 JavaScript engine which is the same JavaScript engine that powers Google Chrome and it's also pretty easy to get started with now you'll need to learn about npm which is the node package manager and you can use it to install all types of packages and libraries um if you're familiar with a front-end framework then you already know how to use npm because it's used on the front end as well um you'll need to know about the node.js ecosystem there are a lot of tools and Frameworks that you can use with node I'll go over some of those soon node is pretty popular with startups as well as large companies and the biggest reason for me why I like node.js is because I like JavaScript and I like to have the same language on both the front end and backend so if I'm using react on the front end it's nice to be able to use the same language on the back end as well now python is another popular option it's a a general purpose programming language that's used for a lot of different things in fact I'd say Python's probably one of or the most diverse languages out there it's great for data science machine learning automation but it's also great for web development whether full stack application or apis in microservices and python has great readability um It's relatively easy to learn there's some phenomenal Frameworks that python offers such as D Jango and flask I'll talk about those soon and python is great for beginners it's uh like I said very readable it's easy to get into also at some point if you want to transition from web development to something like data science python is a great option it's just a fantastic general purpose language overall next we have PHP which is a server side scripting language designed for web development so unlike python where there you can use it for a lot of different things PHP isn't really used outside of web development at least on a large scale and its purpose is to build Dynamic web pages so there's some popular platforms that use PHP such as WordPress um I think PHP is great for Freelancers because again it's a tool that allows you to get things done quickly and it's Unique from other languages because you can actually go to a PHP page in the browser and load the page on the server and you can write HTML directly in your PHP files so it's essentially a template language and you can't really do that with any other languages the downside to PHP is that you you get so much Freedom that it's really easy to write bad code and I think that's why PHP does get a bad WAP sometimes but if you know what you're doing you can write clean code with PHP and Frameworks like laravel address that and pretty much don't allow you to write bad code or really bad code um so it's definitely a a good choice in my opinion now go or goang is a statically typed language developed by Google and it's known for its performance and efficiency which makes it suitable for building web services apis and Powerful applications um it's it's also great for building things like command line tools uh it's a fairly new language but it's growing in popularity it's among the top 10 primary languages for professional professional developers with a share of about 7% and it's used to it's used by some really big companies and um Power some really huge applications in apis it's not really something you'd use for like a personal blog it's more for large scale applications um one thing about goang is it has a very vast standard Library so you can build quite a bit without reaching for any kind of framework however there are some great Frameworks that you can use with go and I'll talk about those soon um it's also a very secure language it scales well making it suitable for large scale applications and it's used a lot in the the big business world so C is also a general purpose language it's a robust objectoriented langu language developed by Microsoft it's used for building desktop applications web apps mobile apps games and more and it's a very popular language and used by a lot of companies it's also used for game development with unity um it's a great language to learn and it's very similar to Java but better in my opinion it's also used with the Net Framework which is a software framework developed by Microsoft that's very very powerful and can be used with many different types of projects then you have asp.net which is a web framework for building web applications um very similar to something like Jango or laravel but it's a great language it has good performance it's very secure and definitely um definitely a candidate so Java is another general purpose objectoriented language that's actually really similar to C Java is used for again desktop apps Android apps backend web development and more and it's been around for a really long time and it's most popular in the Enterprise world it's used by a lot of big companies one stack that I see a lot of in big business is Java or C on the back end and angular on the front end so I may get some crap for this but I think Java is one of the best languages to learn programming in general uh it's very strict and it forces you to write clean code in an object-oriented way it was actually the first language that I've ever worked with so I may be a little biased on that um I wouldn't use it for freelancing or small projects but if you're looking to get into a big company it may be worth learning so Ruby is a dynamic object-oriented programming language that can be used for web applications and apis among other things its most popular web framework is Ruby on Rails and it's tough to talk about Ruby without talking about Ruby on Rails in the context of web development as far as the language goes I really like it I think it's one of the most readable languages there is um and it's it's almost like reading English and that was actually one of the goals of Matts the the creator of Ruby and it's a pretty forgiving language as well it's not a cyntax language and it has its own unique and expressive syntax it does draw inspiration from languages like Pearl small talk and lisp all of which I've never used to me I think it actually is is similar to python uh Ruby has a rich ecosystem of open source libraries and packages called gems which can be easily integrated into Ruby on Rails projects to extend the functionality so gems ruby gems it's kind of like npm if you're coming from the node.js world or pip if you're coming from Python and you can get things up and running really really quickly with Ruby it's great for Rapid development people like to say that Ruby is dead sure it's not as common as some other languages and it has fell a bit in the past 10 years but there's still a lot of companies using it now rust is a is actually a systems programming language so it's lower level um it can almost relate to something like C++ but it also incorporates highlevel language features so it's pretty unique and you don't have to worry about things like memory management like you would with C or C++ rust isn't typically associated with web development but it does have features that can make it a good choice and certain situations now rust is a popular choice for compiling to web assembly enabling the development of high performance web apps that can run in the browser and I'm going to talk more about web assembly later uh it's also a very safe language it's used by companies like Dropbox Discord Microsoft um web development probably isn't the most common case for us but it's still a great language to learn I think it will grow more popular in web development because it's commonly used with web assembly um so as web assembly gets more popular I think rust will as well um there's also web Frameworks that you can use that I'll mention in a little bit so Elixir is new to this guide and it's been gaining some popularity I've seen quite a bit about it it's a functional concurrent general based or general purpose language and runs on the erlang virtual machine and it can be used to build web applications and apis it it's very F tall an and can be used to create realtime applications like I said with goang you probably won't use Elixir for something like a personal blog or any small project it's more for large scale applications so not something I'd recommend if you're if you're just getting into web development now these definitely aren't all the languages you have to choose from some other options are Scala Pearl Swift and cotlin although those are really more on more for web app mobile apps sorry um I would suggest looking into a few and seeing one which ones you like best also look at what's popular in your area so this is a chart from jetb brains.com for 2017 to 2023 and it's the percentages for languages used by web developers and the percentages for likely to to adopt so you can see that the most used is Javascript then python HTML CSS SQL Java and so on so I wouldn't base everything on this chart but it's just interesting to see and you can pause it if you want I'll also have the link in the description um to this to this article so now that we've gone over some server side languages let's talk about some of the Frameworks that you can use with those languages and I'm not going to go over all of them there's no way I could do that but I'll list some of the more popular ones here now most of these Frameworks fit into either an an an opinionated or an unopinionated framework so an opinionated framework is is one that has a set way of doing things it's very high level and Abstract you kind of have to follow the the structure and follow the rules to use it however you get a ton of features right out of the box an unopinionated framework is you don't have as much freedom so what I've done is I've split the the Frameworks that I'm going to mention up into opinionated SL highlevel and unopinionated SL minimal all right we'll go in the same order as we went with the languages so node.js I should say JavaScript nodejs has a bunch of Frameworks there's way too many to list here so these are some of the the more popular ones now unlike the rest of these languages the most popular framework for node.js is actually a very min minimal unopinionated framework and that's Express so Express is great for building web applications and apis it has a great set of features it's well documented it's very popular you can find tons of content in tutorials and courses that use express is a great Community it's very fast and performant so that's probably what I would recommend if you're going with node.js then you have coo which is another minimal framework that was actually created by the same team as Express and it's very similar there's some more modern features but it's it's pretty much the same thing you can build a lot of the same stuff and same thing with fastify fastify is an even newer framework that is extremely fast it's faster than Express and H again has some more modern features but again I'd probably say learn Express just because it's so popular and that's probably what you'll end up using all right so those are the the the popular opinion uh unopinionated or minimal Frameworks as far as the highlevel opinionated Frameworks we have Nest or nestjs which is actually built on top of Express and it's a typescript first framework that's very similar to angular and I know that sounds weird because angular is a front-end framework but it actually has a really similar structure now it's very opinionated and you know you have to do things a certain way but it's great for building large scale applications it's very well documented I'd say if you're coming from angular and you're you're learning full stack and you're getting into node.js you might want to check nestjs out for your back end and then Adonis is the last node.js framework that I'll mention it's another very opinionated framework that's very similar to laravel I actually think that it's it's really underrated it's an MVC framework that has scaffolding authentication a template engine it's it has a lot of the features that you find with laravel so if you're coming from PHP laravel to node.js a Adonis might be something you want to check out all right so next we have Python and there's a lot of Frameworks that you can use with python but there's two that really stick out that are really phenomenal Frameworks and that's D Jango and flask and one of them is highlevel opinionated and one of them is is uh minimal and unopinionated so D Jango is very high level it's it includes everything that you need to build a web application it has a template engine an omm authentication a CLI uh like I said it's very opinionated so you have to do things a certain way but you also get a ton out of the box including an entire admin area to manage your content so basically you can create models for your content like let's say a Blog and you have a post model you'll have an admin area just right out of the box where you can add create read update and delete posts so really really cool um it's great for Freelancers as well because you have an admin area for your clients and then flask is another great python framework that's pretty much the polar opposite of D Jango flask is very minimal uh it's very similar to express it's great for building apis you can structure things how you want it's fast it's flexible it's a great option so next we have PHP and the two most popular Frameworks are laravel and Symphony and there's others like code igniter which was actually my first PHP or I should say my first MVC framework that I was introduced to and I really like it it's not used much anymore but I I I don't know code igniter has a special place in my heart I guess but laravel is in my opinion one of the best Frameworks period it's a highlevel opinionated framework it includes everything you need to build a web app it has database migrations has a really great om called eloquin and I'll get into ORS in a little bit built-in authentication uh with multiple drivers a CLI a template engine and much more I'd say it's pretty similar to Python's Django then you have Symphony which is another great PHP framework it's a bit more complex than larl and it's used by a lot of big companies laravel is actually built on top of symphony components because symphony is very modular I created a small course on Symphony along time ago but I haven't used it in years so a lot of it has kind of slipped my mind um but it might be something you want to check out now Slim PHP is another framework that I think is really underrated because you don't always need something as lock as laravel or Symphony sometimes you just need a simple framework to build an API or a small application and slim is great for that it's very similar to both Express and flask but for PHP so next we have goang one thing that I realized is with just about every language you need a web framework to build anything substantial with goang you really don't need a framework you can just use a lot from the standard Library so it's very powerful it has everything you need to build a web application um but there are some Frameworks so one is called Jin this is an includes a router template engine and more and it's more like laravel or Django so next we have C and C is a general purpose language that is used for all kinds of things web development mobile development game development and it's used a lot with the Net Framework which is a software framework developed by Microsoft then you have asp.net which is a web framework for building web applications so asp.net is probably what you're going to use if you do go into web development as a c developer it's part of the broader Donnet ecosystem and it provides a a flexible platform for developing web-based applications you can also use languages like FP and Visual Basic with asp.net so asp.net core is the latest version of asp.net and it's open source it's crossplatform it's a bit more lightweight than the original platform um but yeah so that's probably what you're going to go with with c now you also have Blazer which is a newer framework that actually fits more into a front-end framework believe it or not so it's part of asp.net core and it allows you to build interactive web uis using C instead of JavaScript so in many ways it's similar to something like reactor View and it can also be used with web assembly which I'll talk about soon so next we have Java the big web web framework for Java is spring and it's used by a lot of big companies it's a bit more complex than some of the other Frameworks and it has a lot of different parts to it so spring MVC is a web framework that simplifies the development of web applications and follows the model view controller design pattern and it provides features for building web controllers handling requests and rendering views there are some other web Frameworks for Java like hibernate uh Apache struts and play which you can also uh the play framework you can also use with the Scala programming language now if you're using Ruby for web development I'd say there's probably a 90 99% chance you're going to be using Ruby on Rails it's a very highlevel opinionated framework that just includes a ton of stuff out of the box and it's great for Rapid development because you basically have command line tools and Scaffolding that can pretty much generate a basic crud application in seconds and then you can kind of take it from there so it's great for large scale applications but you can also use it for smaller stuff I actually had a uh a knowledgebase app that I built with Ruby on Rails that served as documentation for my computer repair business a long long time ago uh rails is definitely I'd say in my top five if not top three favorite Frameworks and then Sinatra is another framework that uses Ruby that takes a more minimalistic approach so if you don't need something as in-depth as rails you could check out Sinatra now rust is often associated with systems program but it has gained popularity for web development due to its focus on safety performance uh modern programming practices while Russ doesn't have as many web Frameworks as some other languages it does offer some solid options for building web applications and apis so actic is a high performance web framework for rust it's known for Speed and scalability makes it suitable for real-time applications microservices uh actic leverages rust concurrency features and it can be a good choice to to handle many connections simultaneously and then rocket is an opinionated web framework for rust that prioritizes developer productivity so it aims to create kind of a a great outof thebox experience with strong type checking expressive syntax and a focus on safety now for Elixir you have Phoenix which is uh a framework that's inspired by Ruby on Rails it's a high level opinionated framework includes everything you need to build a web application uh it's great for building large scale applications but you can also use it for smaller projects and again it's very similar to Ruby on Rails and then plug is a minimal and composable library for building web apps in Elixir uh it's designed to be lightweight and unobtrusive all right so I mean there's other Frameworks as well but chances are if you're going with one of these languages you're probably going to use one of these Frameworks all right so you you learn a language you learn a framework at this point you should understand HTTP including the request response cycle methods status codes you should Al also understand the basics of rest which is which stands for representational State transfer and it's an architectural style for building apis it's not a standard or protocol it's just a set of guidelines for building apis and I have an older but still relevant crash course on rest apis if you want to check that out and learn more about what what it is no matter which type of developer you are you should definitely understand rest because even as a front-end developer you're going to interact with these apis and as a backend or full stack developer you'll be building these apis so something that you just need to know in web development now graphql is a newer alternative to rest and it's a query language for apis and a runtime for fulfilling those queries with your existing data it's a bit more complex than r rest and I wouldn't say that graphql is something that you absolutely need to know but it is helpful um it's a little bit more powerful because you can specify the data that you want to get back from the server where with rest you get all of the data that's available so for instance if you have a a rest uh endpoint that you hit maybe SL API posts it's going to give you all the fields for post you know you might get back 10 blog posts it's going to have the title the body all that stuff and you can't really say well I just want the title of the post you can't do that with a rest API with graphql you can you can actually send a query that says I want just the title and the category or whatever it might be so it's it's more powerful than uh than a rest API but again it's not a necessity um as a backend or full stack Dev you'll you may be creating graphql apis and you can do that with many different languages and Frameworks and as a front andev you may be interacting with these apis so you'll learn how to make graphql requests and parse the data using a client there's different graphql clients and one popular one is Apollo okay so if you're a frontend Dev dealing with graphql there's a good chance you might be using the Apollo client now as a backend or full stack Dev or even as a freelancer that works with WordPress you're going to need to learn about databases and a database is a collection of data that's stored in a computer system and the software that we use to work with that database is called the database management system or dbms and there's a few different types of databases so I'm just I just want to go over those real quick and talk about some of the the the database systems that are in those types so the first type is the most common and that that's a relational database and these have been around forever they're systems that hold structured data that can be related to each other and data stored in tables and rows so you can kind of picture an Excel spreadsheet just much more powerful and you can have multiple tables that are related to each other for example you can have a table for your users and then a table for let's say blog posts and each user can have multiple blog posts so you can relate the two tables together by putting a user ID field in your blog post table and we use something called SQ l or SQL uh which stands for structured query language we use that to interact with these databases so you can create tables insert data update delete data and more aggregate data and usually in your application you'll use something called an OM or an object relational mapper to interact with your database instead of writing raw SQL queries and we'll talk more about ORS uh in a few minutes now as far as relational databases go postgrads or postgresql is one of the most popular um for for all size projects really it's an object relational database so everything is looked at as an object with properties and it's very common with node.js and python but of course you can use it with any language as long as there's a driver that supports it so you're not really bound to a specific database system just by the language you use but some things are just more popular with others so my SQL or MySQL is very simil ilar to postgres they work in a very similar way and my SQL is very popular in the world of PHP so if you're learning PHP and you know you're learning con with content online tutorials courses chances are a lot of them are going to be using MySQL and then mssql or Microsoft SQL is used a lot with like cop and The NET Framework because it's part of that whole Microsoft ecosystem but you can still use like postgrads with C so you're not bound to any specific system as long as there's a driver available for it now you also have nosql databases these are non-relational databases which store data a bit differently they're more I'd say they're more for huge data sets that aren't as closely related so you can still have relationships but you don't get as many features as you do with relational databases in that aspect and what these are typically good for is performance and scalability they're also great for things like realtime web app applications you also have a subset of nosql databases like document databases or key value stores so instead of storing data in tables and rows with columns you store data in what are called documents in something called a collection you can kind of think of a collection as a table and a document as a row or a record in in you know a relational database and documents are formatted like Json objects so it really goes well with JavaScript script in fact mongodb which is the most common um nosql database is used a lot with nodejs now some other nosql databases include redis which is a key value store it's great for caching and storing session data it's also very fast then you have Cassandra which is a wide column store it's great for large scale applications neo4j which is actually a graph database but still considered no SQL it's great for storing Rel relationships between data so if you have a social network for instance you can use neo4j to store the relationships between users or whatever um you also have Coach DB Dynamo DB there's there's tons of of nosql databases but I would say mongodb is the most popular by far now Cloud databases are extremely popular now and it used to be that you would install the database on your server and set everything up yourself but now you can use a cloud service like a AWS or mongodb Atlas where your database is hosted separately so this is great for scaling and performance you can use a lot of the the ones we talked about um for instance you can set up a remote postgres database through Amazon web services or a mongodb database through Atlas but there's other Cloud databases such as Google's Firebase which is a realtime database and it includes everything you need from authentication to file St storage to hosting and it's an all-in-one solution for medium and and for small and mediumsized apps and then superbase is another uh another one that's similar to Firebase it's an open- Source alternative that's built on top of postgres and it's a great option if you want to host your own database but you want the features of something like Firebase because it also includes authentication and stuff like that so I prefer to use databases hosted in the cloud because it just takes so much work out of it you don't have to worry about backups or anything like that you don't have to worry about getting it set up you have full support in most cases um as long as you know you usually have to be on a paid plan mongodb Atlas does offer a free tier but if you have a serious project you're going to want a paid plan all right so it just it just lets you focus on your application and not have to worry about the database aspect of it and then fauna DB is another one that's starting to gain a lot of traction it's a serverless database that is used a lot in the JavaScript world and it has a typescript inspired developer experience with data stored in documents similar to mongodb so lastly we have file-based databases well markdown actually isn't a database but I'll explain in a minute so these have little to no setup and they're great for developing they're great for testing and for just small projects even if you want to use it in production for like a personal blog or something like like that so SQL light or SQL light it actually is a SQL database but it's file based so you don't have to install anything or anything like that you just create a file something. DB and you can just use SQL queries and there's different there's orms you can use with with it as well so I think it's great for of course just development if you don't want to set up a postgres database or something like that and you just want to temporarily use SQL light or if you just have like a simple blog and you you're not going to have a ton of data you just create a post every couple days sqlite is more than enough for something like that now markdown files are also good for um for personal websites for personal blogs things like that especially if you're using something like Gatsby or nextjs there's there's packages that you can use to work with markdown files so when you want to create a new blog post you would simply create a new markdown file in a specific folder and you would add the front matter which is the metadata at the top and then the post in the body and once you save that it'll automatically be put into your you know your your blog's front end so definitely something to to look into for smaller projects and then H2 is another file based database I've never used it so I I really can't say much about it um I would stick to SQL light or markdown for for development testing as well as small projects if you don't want to install or set up um postgres or mongodb or something like that okay so like I said SQL or SQL is used to create queries um to insert data select data all that stuff for relational databases but typically you don't write SQL queries raw SQL queries in your your application code uh it's more for the command line if you're using uh like the the MySQL shell or something like that or if you're using uh even a guey tool you can usually write SQL queries within your application you're usually usually going to use an OM which stands for object relational mapping and it's a tool so you can interact with your database through object-oriented programming within your application and it usually has its own syntax rather like I said rather than writing SQL queries and it's great for productivity it makes your code much neater um it they tend to prevent things like SQL injection attacks and a lot of the time you can easily swap out database systems and still use the same code so even if you if you use postgres and you you want to switch to mySQL you can do that just by changing a config and then keep the same code and it still works the same way so typically how they work is you create a model of your data in your application so you might have let's say um let's say you have a work workout app and you have a a database table or collection called workouts in your application you would create a model for workouts and you would Define the different fields and types that the workouts should have and then what you would do is bring that workout model into your file and you you'll be able to do things like workout. find and then pass in whatever you you're you know whatever you're looking for workout with the ID of of a certain number or whatever it might might be much better than writing select all from workouts where whatever um so it makes things much easier and some ORS are specific to the language Andor database so these are just some examples uh first we have which is an OM for mongod DB and node.js so if you're using those two things together node.js and there's a good chance you're going to be using SQ eyes is also an omm for node.js but it supports SQL datab bases like postres MySQL even even SQL light and uh and Ms SQL Server as well and it's very popular and easy to use it's very well documented um and then D Jango omm is used for obviously D Jango websites but you can use it as a standalone or without using D Jango as well SQL Alchemy is an orm for python that supports the same databases that SQ eyes does and it basically works the same way except it's for Python and you can use it with d Jango flask or any other python framework and Pongo as I I I don't know if I said this but most of these are for relational databases um except for Mongoose and then you also have P which is an omm for mongodb and python so similar to you know how Mongoose is to node.js then eloquent is an OM for PHP that's used with laravel and I really like eloquent I think it's very eloquent and it's very easy to use it has a very clean syntax well documented Doctrine is another or for PHP that supports SQL databases uh Dapper is an orm for CP and.net very popular used by a lot of big companies Prisma is a typescript omm with an intuitive data model it has automated migrations type safety it lets you declare your T database tables in a more human readable way and you can use it with JavaScript typescript rust and I believe you can use it with goang so drizzle orm is another typescript orm that you can use in in SQL like syntax or qu the queries API which is a more squiz or mongus like syntax and then mro or micro RM I'm not sure how it's pronounced I've never use this but it's another typescript RM that supports both mongodb as well as SQL databases and then nextjs is a query builder for node.js that supports SQL databases it's not an omm but it is similar it's a bit more lowlevel and it's great for building SQL queries in a programmatic way so you can imagine how many of these are when you think of how many languages and how many databases there are so there's no way I can go over all of them but I just wanted to give you guys a couple examples all right so another thing you'll need to learn pretty much no matter what route you take is is authentication authentication and authorization so authentication is the process of verifying the identity of a user it's a very important part of web development as a front-end Dev you need to know how to consume and use authentication services and as a backend or full stack Dev you're most likely going to need to know how to implement the entire system and there's a few different ways to do this these aren't all of them but these are some very common practices so one we have cookies and sessions this is a popular way to authenticate basically when a user logs in a session is created on the server and a cookie is created on the client and the cookie is sent with each request and then the server can verify that user based on the session so you should definitely learn about HTTP only cookies and secure cookies this will help you understand how to make your application more secure also you're going to be want to be aware of things like cross-site scripting and cross-site request forgeries these are attacks can be used to steal cookies and impersonate users next we have Json web tokens or jwt's and these are Json objects that are signed by the server and they're stored on the client in most cases and sent with each request and the server can verify the user based on that token and this is commonly used with rest apis and full stack Java uh full stack JavaScript applications and it's a good way to protect your API endpoints so so that just not just anybody can visit every endpoint then we have ooth which is an open standard for Access delegation and it's commonly used as a way for users to Grant websites or applications access to their information on other websites but without giving them password so for example when you see login with your Google account or login with your Facebook account that's usually ooth so that's another way that you can have users authenticate and you might have a mix of oaf and cookies and sessions or something like that now authentication libraries um you can use you can write your own middleware for authentication but there's a bunch of libraries you can use such as passport or Grant um also many framework such as larl and D Jango they have built-in authentication systems that you can use and extend and then password hashing that's also something you're going to need to look into um there's libraries like bcrypt that can do this for you you and um you know it'll it'll encrypt the password you never want to save plain text passwords in your database and then you can use the bcrypt library to compare a plain text password to the encrypted one in your database now traditionally we have front end and backend but as I've said those lines are really getting blurred and serverless architecture is becoming more popular now serverless is essentially it allows you to run serers side code without having to manage your own server so you can use a platform like netlify a versel that will give you serverless functions um you could also use something like AWS Lambda or Azure functions platforms like Firebase and superbase also considered serverless um you can use serverless functions to handle things like authentication sending emails protecting data and it also saves you money because you're not paying for an an all thetime server a server that's always running you're only paying for the time that your code is running and hits those functions okay it's event driven and your code is triggered by events like HTTP requests file uploads or database changes so if you have a small application this is a great option um serverless architecture is usually really scare uh scary scalable as well um it's also part of what we call the jamstack which is a modern web development architecture based on client side JavaScript reusable apis and pre-built markup okay so it's a a great option for static websites and small applications most of the technologies that are included in the jamstack we've already talked about so that would be static site generators like Gatsby and xjs apis like graph q and rest and then serverless functions so it's not really anything new it's just a new way of doing things so to learn more you can check out the jamstack website James Qui also has a great crash course on uh on this channel about more about what the jamstack is if you want to check that out now let's talk about deploying full stack applications and apis this is a bit more difficult than deploying a client side application or or like a static website because you typically need a web server like Apache or enginex and there can be a lot of configuration that goes into that now how you set that up depends on the type of hosting service that you're using uh you can use something called a platform as a service or a pass and then you also have infrastructure as a service or an IAS um so a pass or a platform as a service abstracts away the server and sometimes the database and you can just deploy your code you usually have a um a pretty in-depth user interface and you have access to the server through a terminal but you don't have to install and configure like a patchy and all that stuff and this is obviously easier and great for people that aren't too familiar with Linux and running servers then you have Cloud hosting and infrastructure as a service and this is where you have to manually set up and configure your server um you have full control over everything that's that's the nice part about this you can install and configure Apache you can install a database whatever you want it's basically like having your own Linux machine with root access and again it's great for people that know what they're doing but a lot of us don't right I'm I really am not that great with with devops I'm not great with setting up servers so I prefer to use a platform as a service um but there are some great infrastructure as a service uh hosting companies like digital ocean Len Noe um and then you have like of course AWS and aure which are the big boys really large companies tend to use them if they don't have their own infrastructure um but we're starting to get into devops territory here which is a whole another topic but I just want to mention that there are different typ YP of hosting and it depends on what you're building and your skill level as to what you should use and I should say that that cloud hosting like digital ocean and Len Noe I'd say they're they're semi-managed because they do have images you can use to set up an entire environment for you um you can even set up Docker and and I'll talk more about Docker in a little bit um but you can have some predefined um infrastructure with digital Ocean or Lode or vulture uh there's a lot of companies that do that now for individual developers I suggest render if it fits your need it's great for node.js python PHP rails and a bunch of other stuff it's very easy to use it's free for personal projects um you can also deploy databases and static sites Heroku is another option it's been around for a while it used to be what I used in tutorials because they had a great free tear so people could follow along however they did get rid of the free tear so if you're just learning and testing things out you'll probably want to go with render because they do have a pretty generous freet tear and all you really have to do is deploy to or push to GitHub and then log into render and select your repo much like you would with netlify or versel and and render does support full stack applications all right so I briefly mentioned bung JS but I wanted to have a dedicated section for it because it's another one of my favorite new tech technologies that I really hope takes off and I have a crash course on it if you want to go more in depth but it's essentially a JavaScript runtime like node.js but it also has a complete toolkit that includes a front-end bundler so you can easily build full stack applications it has a test Runner it has its own node.js compatible package manager so you can run bun install whatever whatever package you want um it's written in the zig programming language which is a newer language that's gaining some traction uh it's very fast it's similar to C but what I love about bnjs is that it's an all-in-one approach and you don't have to use webpack or parcel or anything like that it's all just built in um I think that javascript's biggest problem is there's just so many different damn things that you need to combine and use other languages aren't really like this if you have any experience with with other languages they have a very integrated close nit ecosystem where JavaScript is just all over the place so I think that bun really addresses this and it's still very new and it's not really ready for production yet at least I don't think I haven't checked in a in a little while but I think it will be soon and I I I'm hoping that it will gain a lot of traction all right so up to this point we've talked about everything that you need to know plus a lot of optional things to be a backend or full stack developer so obviously you need to know a server side language which one you choose is really up to you uh if you're building web apps or apis you'll need to know a framework it's very rare to create a substantial application without a web framework um there are some exceptions like if you're using a language like goang or rust but even then there are Frameworks that you can use now you'll need to know about databases this could be a relational or a a non- relational database you also need to know about ORS so that you can create models for your data and interact with your database and this could be a standalone or or one that's built into your framework and then authentication you should know how to implement um in your applications this is a very important part of web development whether you using sessions JWT ooth or something else or a combination and then you should know how to create rest apis from scratch you should know how to create endpoints and handle HTTP requests knowing graph fql is also a plus but I don't think it's a it's a it's mandatory um you also need to know how to make your applications or apis live on the internet so you need to know deployment and again this this is more difficult than client side stuff but you'll establish a process and it'll it'll start to become second nature once you have a a a workflow to deploy applications so the next batch of Technologies are things that you may want to get into but I wouldn't say are IAL to becoming a developer they're kind of extra um they may be essential for certain job positions though so the first one we'll look at is containerization and this is a way to package software into standardized units for development shipment and deployment and some people don't understand why this is valuable so let's say that you're working on a node.js application and you have it running on your local machine everything's working fine then you deploy it to a server and it doesn't work or you give it to uh another you know a coworker another developer and it doesn't work on their machine and you have to figure out why so it could be that the server is running a different version of node.js or maybe it's running uh a different operating system and something got messed up now imagine you have five people 10 people working on that project all having different machines and different operating systems and environments so that can be a nightmare and with containerization you can package your application into a container that includes everything it needs to run uh it's kind of like a virtual machine but it's much more lightweight and you can then deploy that container to any server and it will run the same way so all five or 10 plus team members can have the same container on their local machine and it will run the same way uh it's a great way to ensure that your application will run regardless of the environment because it includes the environment uh everything down to the operating system so Docker is the main tool that's used for containerization it's a platform for building running and shipping applications with containers uh it's very popular and used by a lot of big companies it's also very well documented if you plan on working for a large company as as anything that has to do with devops then you're going to need to know Docker and then kubernetes is another tool that's used for containerization it's it's an orchestra uh orchestration system for automating deployment scaling and management and it's not a a competitor to Docker it's actually used with Docker and it allows you to manage multiple containers across multiple servers all right and Aid driven automation is also enhancing the capability of kubernetes and the complexity is being kind of abstracted away more and more and developers will be able to um focus on application development and much less on infrastructure management and there's some other tools that you can use that are similar to Docker like vagrant and lxc but these are more like virtual machines Docker uses containers which are are process level virtualization so they're much more lightweight so next we have web assembly often abbreviated as wasm and this is a technology that allows us to run high performance code written in languages like C C++ and rust in web browsers and in simple terms think of web assembly as a way to bring fast and efficient software written in languages other than JavaScript to your browser and JavaScript has obviously been the programming language of the browser and just for the web in general and is great for many things most things when it comes to web development however it's not good for things like uh computationally intensive tasks so web assembly is great for that and you can Port existing code bases to the web so if you have like a C++ application you can compile it to web assembly and then run it in the browser so some things that web assembly would be good for are games video editing CAD software things like that and no web assembly will not replace JavaScript it's not meant to it's actually meant to work with JavaScript so you can use JavaScript to interact with web assembly and we're really not to the point where web assembly is just everywhere but it seems to to rise every year it seems to gain more popularity now next we have mobile development options and I know this is a web development guide however there there is a lot of crossover and you can use your web development skills to build mobile applications of course you can get into native development mobile development with cotlin or Java for Android apps as well as Swift or objective c for iOS apps but you can also use Frameworks that allow you to build crossplatform applications with web or web like Technologies so I'm going to go over some of those options now we did already talk about some of the stuff in the framework ecosystem section but I'm just going to quickly go over them again so the first choice is react native and obviously we've talked about this a little bit it's a framework that allows you to build native mobile applications with JavaScript and the react framework and what's great about not only react native but all of these really are that you can have a single code base for both IOS and Android as opposed to where you would do Native development you'd have to have two separate code bases and two separate languages so if you're a react developer you're probably going to gravitate toward react native it's it's very powerful it's used by a lot of big companies um next we have flutter which is another popular option and it's a framework that allows you to build native mobile apps with doart so doart we haven't talked about yet it's a it's a programming language that's similar to JavaScript um so if you already know JavaScript Dart is pretty easy to pick up flutter uses its own rendering engine written in C++ called skia and I know that they were working on a new rendering engine called uh impeller but I'm not positive if that's been released yet now flutter does have a slight performance advantage over react native because it doesn't use a bridge to communicate with the native components like react native does but these are are two of the most popular options uh of their kind now you also have native script which allows you to access native apis using JavaScript so you can technically use any framework you want to build uh Native mobile apps whether it's react view spelt angular um or or even just vanilla JavaScript so like I said it gives you a set of native apis to work with it's not as popular as react native or flutter but it could be a viable option especially if you want to stick to Vue or spelt or angular and then you also have ion IC which has been around for a while it's a mobile SDK software development kit that allows you to build hybrid mobile applications with web Technologies like HTML CSS and JavaScript so you can also use the framework of your choice with ionic now it's not going to be as fast as react native or flutter but it it can be a viable option I believe years ago you could only use angular but now you can use anything and it's great for Progressive web apps which I'm going to talk about next so Progressive web apps are web applications that have been designed to be to to run more like native mobile applications they're fast they work offline they can send push notifications they can even be installed on the home screen of your mobile device so it's not a native app it's a web app but it has it has to pass certain criteria to be considered a pwa or a progressive web app so first it has to be completely responsive no matter what screen size no matter what type of device it's being viewed on whether it's a a a cell phone or a a big screen TV it also has to be secure and served over https that should go without saying these days it has to be able to uh at least have some basic functionality offline even if that means just having a custom offline page it should be performant and discoverable by search engines and include a manifest file and a service worker so the Manifest file is a Json file that contains information about the app like the name description icon the service worker is a Javascript file that runs in the background and allows you to cash assets and data for offline use okay then you can also add push notifications make it installable so it's a great way to make your application more like a native mobile app than a regular web app and you can use a framework like ionic or you can use something like nextjs which has built-in support support for pwas there's many different uh Technologies and different ways to do it now you can also use a lot of the same technologies that you use for web development to create desktop applications for Windows Mac and Linux now my suggestion would be electron it allows you to use JavaScript to build really fast and Powerful desktop applications you can use any front-end framework react view angular whatever you want to use it works by bundling chromium which is the uh the the browser engine that Chrome uses that edge uses and a bunch of other browsers it bundles that with node.js into a single runtime and apps can be packaged from Mac windows and Linux uh so you have again a single code base for all three platforms and there's a ton of really popular desktop applications that use electron at least in some way including vs code which is probably the the desktop app that we use the most atom slack Discord and the postman HTP client so these are all things that I use all the time another option that I'm seeing more of is Tori and this is a newer framework that's similar to electron but it's actually more lightweight and it's actually built on Rust so it's very performant and secure it uses the os's native web renderer and the size of a Tori app can be less than 600 kilobytes and you can use front-end Frameworks of course there's also binding for python go C++ and other languages so it's definitely something that I plan on getting into this year so next we have neutralino Js and this is another option it's a lightweight and portable framework that allows you to build crossplatform desktop apps uh with web Technologies and it implements a secure websocket connection for Native operations and it embeds a static web ser server to serve the web content within the the desktop application also it offers a built-in JavaScript client library for developers now nwjs is another option it's similar to electron but not as popular it works in a similar Way by bundling chromium with node I do have a crash course on NW as well as electron if you're interested um I would say go with electron if you're going to get into this kind of thing and then you have other options for other languages for instance if you're a python developer you can look into tkinter to build desktop applications I do have a video on that um it's a standard python interface to the um the TK goey toolkit shipped with python it's not as popular as electron but it it can be an option if you're a python developer Ki excuse me Ki is another option for Python and then of course you have native uh you know other languages where you can use native tools whether it's Java um WPF for C Coco for Swift whatever it might be but that starts to get out of the range of web development Technologies all right so I don't often talk about Aesthetics in this guide it's based on software but I I do think it's important to keep up to date with design Trends so I just want to mention a couple here so trends for 2024 dark mode is obviously extremely popular it has been for a few years I think it's because it's it's easier on the eyes and it's also more energ efficient uh and it looks better in my opinion at least I personally use doc mode on everything because I get I actually get floaters in my eyes if I stare at light screens too long so um it's actually a health thing for me but I know a lot of people like it and it just seems to be everywhere whether it's just straight up dark mode or you have some kind of Toggler on your UI that will toggle dark and light and then we have ai generated designs so I think that we're going to see more of this this year um there's all kinds of tools that you can use such as mid Journey Sensei dream Studio you can use these tools to create unique designs for your projects now a lot of them do look kind of fake and and like super futuristic and sometimes they look a bit weird but I think it's a cool concept and I think it's going to be used more and more as as it improves so glass morphism is a newer design Trend that's become pretty popular it's a frosted glass effect that is used for many things like buttons cards and modals it's a bit more subtle than the previous Trend which was uh neuro new neumorphism I I don't know how to pronounce it uh I think it looks really cool and I think that it'll be around for a while and then Clay morphism is a web design Trend that is characterized by the use of soft rounded shapes and pastel colors and this trend is inspired by the look and feel of clation it's a popular choice especially for younger audiences and then ret rro futurism is a design Trend that's inspired by the future and I should say it is inspired by the future as imagined in the past so like what we used to think the future would look like and it's characterized by bright colors geometric shapes futuristic typography uh it's a great option for things like landing pages and portfolios all right so I just wanted to throw uh a little bit of that in there for you guys all right so next is iot so internet of things and the metaverse now Internet of Things refers to the connection of everyday objects to the internet and to to one another and it's a very broad term it's used in many Industries but iot is expected to have a pretty Major Impact on web development moving forward so we can expect to see more iot enabled websites uh and web applications and this will be you know as businesses take advantage of iot to improve their operations so it's something that you may want to look into and then the metaverse is a virtual world where people can interact with each other in a virtual environment and it's a concept that has been around for a while but it's really starting to gain traction so it's something that I think will be a big part of the future of the web so if this were a Trends video AI would definitely take the top spot it's something that's being used in many Industries and it's only going to become more popular so much so that a lot of people are actually terrified uh we talked about tools like co-pilot and chat GPT as well as design generation but there's many Tools in many categories so chatbots are another thing that are really becoming popular because of AI a chatbot is a a computer program that simulates human conversation through either voice commands or text chats or both and they're used for things like customer service Marketing sales so you can expect to to be integrating chatbots into a lot of your applications and and then open AI has some amazing apis that you can use to create your own tools including tools to create chat Bots uh text to speech things like that and there's a lot of AI powered no code tools and I know that that scares a lot of developers but my advice is to use those tools to your advantage to make you a stronger candidate for a job or just a stronger freelancer for clients and just because those tools are available doesn't mean every joeo is going to be able to use them or even want to take the time to use them and I I know it's just kind of my speculation but my My overall advice when it comes to AI is to use what is available to to better yourself as a developer rather than just saying poor me it's going to take my job try and use it to make yourself better um that's my advice I know some people kind of get mad at that some people might say I'm naive but I'd rather be I'd rather have that mind State than the Doom and Gloom state that is definitely not going to find you success all right so devops or developer operations is a set of practices that combine software development and it operations and it's a it's a pretty broad term it can mean different things to different people when you talk about application deployment and maintenance that's usually part of devops containerization with Docker and kubernetes and your environment that's all all devop stuff uh cicd stands for continuous integration and continuous deployment and this is using tools so that you can push code to a repository and it will automatically deploy to your server and there's tools like Travis CI Circle CI um terraform is what we call infrastructure as code or ioc you can specify the state of your infrastructure and then automate it um or automate the process of managing resources and this goes way beyond my scope of knowledge this is just from my own research now a lot of these tasks include positions of their own so a devops engineer is a specific role but as a software developer you may need to kind of peek into this world a little bit it really depends on where you work so just something to take note of now the web is getting much more interactive and animation is a big part of that so there's a lot of libraries that you can use to create animations so I'm just going to very quickly go over some of the the big ones so Gap is a JavaScript animation Library that's used by a lot of big companies it's widely used for creating really complex animations you have anime anime.js is a lightweight JavaScript animation library that offers simple and flexible animations with a focus on uh readability it supports CSS properties transforms and more and I do have a a crash course on anime and then velocity JS is known for its Speed and Performance it can be used for animating CSS SVG and Dom elements it has a very simple syntax and good documentation and then react spring is a physics-based animation library for react it provides a sample API for creating interactive animations in react there's other libraries animation libraries that you can use for react and other specific Frameworks as well uh 3js is a really really cool JavaScript library for creating 3D graphics and animations uh it provides a highlevel API for webg which is a JavaScript API for rendering interactive 2D and 3D graphics with any compatible browser so I've seen some really cool stuff built with 3js in fact if you go to the website um you'll see a bunch of really cool examples that you can look at and interact with and then typed JS I figured I'd throw that in there because it's a it's a cool little library for creating text space animations so things like typewriter effects and text transitions so it's a good choice for adding Dynamic text content so VR and AR which is virtual reality and augmented reality are getting bigger every year and I think it's only a matter of time until they're common in the world of web development because we're going to have websites that are virtual we're going to have um websites that have augmented reality which is basically a mix of virtual and the real world so if you want to start to get into that now you can it's definitely not something you have to by any means but if you want to just mess around there's some technologies like A-frame which is a web framework for building virtual reality experiences it's built on top of HTML and it's very easy to use you can also use react 360 virro react there's some other Frameworks as well that allow you to build virtual reality experiences in react and then arjs is an efficient and lightweight JavaScript library for creating augmented reality experiences on the web and it enables marker based AR directly from from the browser and even libraries like 3js allow developers to create 3D graphics and animations that are that are often used in combination with VR and AR Frameworks okay so lastly we have web 3 which is a bit tricky there's so many different things that fall under the web 3 umbrella it's a term that's used to describe the future of the web there's also many different opinions on it some people will say that it's the future of information and communication and finance and some say it's a campaign for marketing nfts honestly I don't like speaking too much on web 3 just because it's so early and it's such a a broad and and kind of uh controversial topic now the blockchain which is a huge part of web 3 has proven to be a powerful technology it's decent it's a decentralized and secure digital Ledger technology that records transactions across a network of computers and it consists of uh a chain of blocks each containing a list of transactions and once a block is added to the chain it becomes permanent and tamperproof so it enhances trust and transparency and that alone is incredibly powerful and I think will stick around uh I think learning about the blockchain and ethereum and smart contracts is a really good idea if that interests you so solidity is the language that is used to write what are called smart contracts uh solidity is a bit like JavaScript smart contracts are self executing contracts with the terms of of the agreement between the buyer and seller being directly written into the lines of code and I'm not going to pretend like I know a ton about it but being some of the first people to learn about this stuff I think could be a huge Advantage for the future so it's kind of like an investment of your time and of your your learning all right guys so that wraps up this year's guide I know that this was extremely long it's way longer than I wanted it to be but I don't want to just go through some slides and just read the bullet points I want to elaborate and just kind of let you know what I know about each part each section of this guide so hopefully you learn something from it the time stamps are in the Des uh in the description if you want to go back and look at a certain section uh again I have the page on my website that has a guide of my content including YouTube videos and courses that kind of coincide with this the topics in this in this presentation so thanks so much guys if you watch till the very end I really really appreciate that that's awesome uh if you could like the video I'd appreciate it because this this is basically my biggest video of the year every year um so thanks for watching and I will see you next time"
    },
    {
        "id": "c2bdc281-6f60-4b47-97fe-8cd6035795a0",
        "type": "video",
        "domaine": "technology",
        "titre": "100+ Web Development Things you Should Know",
        "url": "https://www.youtube.com/watch?v=erEgovG9WBs",
        "description": "WebDev 101 is a complete introduction into the world of ",
        "chaine": "Fireship",
        "durée": "13:18",
        "keywords": [
            "full stack web",
            "web developer JavaScript",
            "access web pages",
            "custom HTML element",
            "web user SSR",
            "encapsulate HTML CSS",
            "stack web developer",
            "web page open",
            "web page",
            "single page application"
        ],
        "transcription": "web development is the best job in the world you build on a platform with nearly 5 billion daily active users all connected together like the neurons of a global super intelligent brain A system that can cure disease eliminate poverty Advance science and stuff like that but mostly it's used to share memes create parasocial relationships amplify drama and most importantly make tons and tons of money if you want to get into it you're going to need to know some stuff like a lot of stuff in web development 101 we'll take a look at 10 101 different concepts that you'll need to know when building full stack web apps this is the Internet it's a network of billions of machines connected together what do you write to it like mail no a lot of people use it and communicate I guess they can communicate with NBC writers and producers Allison can you explain what internet is it was officially born on January 1st 1983 thanks to the establishment of the Internet Protocol Suite which standardized the way these computers communicate the Internet Protocol is used to identify different computers on the network by assigning each one of them a unique IP address these computers can then send data back and forth with the transmission control protocol it breaks data into a bunch of small packets kind of like puzzle pieces then sends them through a bunch of physical components like fiber optic cables and modems before they're put back together by the receiving computer you can think of the internet as Hardware but the internet is not the same thing as the web the worldwide web is like software that sits on top of the internet where people can access web pages with the hypertext transfer protocol what's special about it is that it gives every page of content a uniform resource locator or URL humans typically use a tool tool called a web browser to access a URL where it can be rendered visually on their screen the browser is called the client because it's consuming information but on the other end of that URL there's another computer called a server it received an HTTP request from the client then sent a response containing the webpage content these are called HTTP messages but more on that later what's interesting is that every web page has a unique domain name like fireship doio or example.com a domain name can be registered by anyone via a registar whose accredit by ican a nonprofit responsible for overseeing name spaces on the internet when you navigate to a domain in a browser it gets routed through the domain name system that Maps these names to an actual IP address on a server somewhere DNS is like the phone book of the internet now when you look at a web page the actual content you see is represented by hypertext markup language most browsers have Dev tools where you can inspect the structure of the HTML at any time to build your own web page you'll want a text editor like vs code an HTML document is just a collect of elements where an element is an opening and closing tag with some content in the middle like a paragraph and heading it also has elements that handle user input like the select and input Elements which are used to build forms in addition elements can have one or more attributes to change their behavior for example an input can have a type like text or number which the browser will render differently to collect the appropriate value but the element that puts the hyper text in HTML is the a tag or anchor it's a link that allows one page to navigate to to a different page based on its URL these elements are nested together in a hierarchy to form the document object model or Dom from the root element a web page is split into two parts the head contains invisible content like metadata and a title then we have the body for the main content that the end user actually sees the reason we wrap everything in tags is to give browsers and Bots hints about the semantic meaning of the web page this allows search engines to display results properly and also helps with accessibility for devices like screen readers that allow anybody regardless of disability to enjoy the content my computer reads me the text Bro smash that like button and subscribe one of the most common elements you'll come across is div or division to define a section of the web page on its own a div might not seem to do anything and currently produces this plain black and white website that begs the question how do we make this website look cool the second language you'll need to learn as a web developer is cascading stylesheets or css which allows you to change the appearance of the HTML elements one way to accomplish that is with an inline Style using the style attribute on an element the style itself contains a collection of properties and values that change the appearance of the element like we might make the background color black and the text color red what we've created here is an inline style that will only be applied to this one element however CSS Cascades which means it can be applied to multiple elements at the same time providing better code reusability another option is to move our code into a style tag but to make the code work we'll first need to define a selector so it knows which elements to Target a selector for example can Target all of the paragraph elements on the page but that's too broad we can be more granular by defining a class that style can then be applied to one or more elements with the class attribute what's interesting though is that we now have classes that apply different styles to the same element CSS contains a bunch of specificity rules that determine which styles are relevant to an element in a way that's self-evident and elegant like a benevolent elephant most often though we don't use style tags but instead use an external style sheet which is linked to the web page in the head of the document when it comes to CS by far the most difficult thing to learn is layout and positioning think of every element like a box the outside of that box is wrapped with padding border and margin the boxes then take up space on the page from top to bottom some elements like heading have a display of block by default which means they take up all available horizontal space other elements like image are displayed in line which means they can line up horizontally side by side the problem is that the default position is usually not desirable it can be changed by customizing the position property on an element relative positioning allows an element to move a certain number of pixels from its normal position absolute positioning is similar but the position values are relative to its nearest ancestor and then we have fixed positioning which will keep an element on the screen even as the user Scrolls away from it because it's fixed to the entire viewport changing the position of an element is one thing but one of the biggest challenges web developers face is creating responsive layouts users can access your web page from all kinds of different screens and it should look good on all of them CSS provides a bunch of different tools to to help make this happen one of which is Media queries a media query allows you to get information about the device that's rendering the web page and apply different styles accordingly but more importantly it provides layout tools like flexbox applying display Flex allows the parent to control the flow of the children to easily create rows and columns for more complex layouts display grid can be used to control multiple rows and columns at the same time now CSS is usually not considered a turing complete programming language on its own however it does have mechanisms like Cal to perform mathematical operations and custom properties which are like variables that you can reuse in multiple places vanilla CSS is rarely enough though and many developers choose to extend it with tools like SAS that add additional programmatic features on top of it and that brings us to the third language you'll need to know as a web developer JavaScript technically you don't need JavaScript to build a website however most developers choose to use it to make the user interface more interactive to run JavaScript code on a web page open up a script tag then write some JavaScript code inside of it the browser interprets the HTML from top to bottom and runs this code when it encounters it in the Dom in most cases JavaScript is written in a separate file then referenced as the source on the script tag usually it's preferred that this code runs after the Dom content has loaded which can be accomplished with the defer attribute JS is a big complicated programming language which is more formally known as ecmascript and is standardized in all major browsers there are several different ways to declare a variable a variable that might be reassigned in the future uses the let keyword while a variable that can't be reassigned uses con it's a dynamically typed language which means no type annotations are necessary that's not always ideal so many developers choose typescript as an alternative to add static typing on top of JavaScript now one of the most common reasons you would use JavaScript in the first place is to handle events whenever the user does something on a web page the browser emits an event that you can listen to like a click Mouse move form input change and so on we can tap into these events using browser apis like document which in this case provides a method called query selector that allows us to grab an element El with a CSS selector once we have that element set as a variable we can then assign an event listener to it an event listener is a function that will be called or re-executed anytime the button is clicked the language has a variety of built-in data structures like an array to represent a collection of values but the most fundamental data structure is the object also commonly called a dictionary or hashmap anything that's not a primitive type like a string or number inherits its base functionality from the object class it relies on a technique called prototypal inheritance where an object can be cloned multiple times to create a chain of ancestors where the child inherits the properties and methods of its ancestors this is different from class-based inheritance which is kind of confusing because JavaScript also supports classes however these classes are just syntactic sugar for prototypal inheritance but now we're getting a little too low level most developers don't ever want to have to touch the word prototype so what we do instead is use a front-end framework like react view spelt angular and so on all of these Frameworks do the same thing in a slightly different way which is represent the UI as a tree of components a component can encapsulate HTML CSS and JavaScript into a format that looks like its own custom HTML element most importantly they produce declarative code that describes exactly what the UI does and that's much easier to work with than imperative code that you would normally get with just plain vanilla JavaScript at this point we've taken a look at the front end stack but now we need to switch gears to the back end starting with node.js which is a serers side runtime based on JavaScript you can run serers side code for web applications and all kinds of different languages but node is the most popular because it relies on the same language as the browser it's also based on the same V8 engine that powers the Chromium browser to run code in a single-threaded non-blocking event Loop this allows node to handle many simultaneous connections quickly and efficiently in addition it allows developers to share work remotely thanks to the node package manager a package is also called a module which is just a file that contains some code with an export statement so it can be used in another file the file can consume a module with an import statement but now we need to think about how to deliver the actual website from the server to the client the classic option is serers side rendering in this approach the client will make a get request for a certain URL every request has an HTTP method and git means you want to retrieve data from a server as opposed to methods like post and Patch where the intent is to modify data the server receives the request and then generates all the HTML on the server and sends it back to the client as a response the response contains a status code like 200 for success or levels 4 and 500 for errors for example if the web page doesn't exist the server will return a 404 status code which you've likely seen before as a web user SSR is extremely popular but in some cases it may not be fast enough another approach is the single page application with this approach the server only renders a shell for the root URL then JavaScript handles the rendering for all other pages on the website the HTML is generated almost entirely client side in the browser making the website feel more like a native iOS or Android app when the app needs more data it still makes an HTTP request but only requests a minimal amount of data as Json which is called a data interchange format that can be understood by any programming language this can result in a great user experience however it can be very difficult for Bots like search engines and social media link previews to understand content on the page this led to another rendering strategy called Static site generation in this case every web page on the site is uploaded to a server in advance allowing Bots to get the information they need a frontend JavaScript framework usually takes over to hydrate the HTML to make it fully interactive and behave like a single page application performance is extremely important and you'll want to use tools like Lighthouse to optimize metrics like first contentful paint and time to interactive now to implement one of these patterns most developers will use a full stack framework like nextjs Ruby on Rails laravel and so on they abstract away many of the more tedious things developers don't want to deal with one of which is module bundlers which are tools like webpack and that take all of your JavaScript CSS and HTML and package it in a way that can actually work in a browser they might also provide a linter like es lint to warn you when your code doesn't follow the proper Style Guidelines oh and I almost forgot you are definitely going to need a database to build a full stack web application because you need somewhere to store your data like data about your users but in order to get that data you'll need to give users a way to log in Via a process called user authentication now before you deploy your code you'll need to test it with a web server there are tools like engine X and A pchy to create an HTTP server but your framework will likely do this for you by serving the files on Local Host which makes your own IP address behave like a remote web server when it comes time to deploy you'll likely use a big cloud provider like AWS most apps are containerized with Docker making them easy to scale Up and Down based on the amount of traffic that they receive there are many tools out there that function as a platform as a service to manage this infrastructure for you in exchange for your money or if you don't want to get locked in with a giant Tech Corporation you might host your app on a decent calized blockchain with web 3 and that's about 1% of what you'll need to know to call yourself a full stack web developer if that seems overwhelming don't worry too much almost nobody knows what the hell they're doing and we all just use Google to figure things out on the Fly congratulations you just passed web development 101 thanks for watching and I will see you in the next one"
    },
    {
        "id": "04d9354e-2242-4416-aec9-63e2f5a82115",
        "type": "video",
        "domaine": "technology",
        "titre": "The Complete Web Development Roadmap",
        "url": "https://www.youtube.com/watch?v=GxmfcnU3feo",
        "description": "Go from zero to a full stack ",
        "chaine": "Programming with Mosh",
        "durée": "15:15",
        "keywords": [
            "languages HTML CSS",
            "CSS framework provides",
            "frontend developer job",
            "python Ruby Java",
            "development Cycles Java",
            "SQL databases data",
            "JavaScript python Ruby",
            "backend Developer jobs",
            "development frontend development",
            "language called SQL"
        ],
        "transcription": "let's talk about the skills you need to become a web developer web development is generally broken down into two areas frontend development and backend development and then full stack development which is a combination of both frontend development is all about what the user sees and interacts with it's the website in your browser or the app on your mobile phone or tablet backend development handles everything behind the scenes like data processing storage and logic you can start on either end but if you're starting out and pursuing a career in web development I recommend you to start with the backand because it gives you a solid foundation in programming and problem solving plus when you transition from back end to front end you'll have a deep understanding of what happens under the hood in contrast if you start with the front end back end looks like a mystery and you'll have no idea what's really happening under the hood so in this video first we're going to cover the skills you need to become a backend developer and then we'll talk about front-end development to become a backend developer there are five essential skills let's go over them one by one the first step to learning backend development is to pick up a programming language here we have a few options like JavaScript python Ruby Java C and go just to name a few now which one is the best well it's almost impossible to pick one language as the best or the ultimate language because the choice of language depends on various factors like project requirements team expertise and performance needs for example JavaScript is used for full stack development because we can use it on both the front end and the back end in contrast Python and Ruby are often used for rapid prototyping and fast development Cycles Java and C are often used in building large scale Enterprise grade applications they're heavily used in large organizations and government systems and go is used for performance critical and concurrent applications now the common mistake I see among my students is that they try to learn many of these languages hoping that this would increase their job opportunities but it doesn't work that way because learning a language is only the first step you also need to learn the ecosystem of tools and libraries for that language to land a job so if you're starting out just stick to one language whichever you like but also do a bit of research and see how many job opportunities are available for that language where you live generally speaking there are often more job opportunities for python Java and JavaScript but again I want you to do your own research now assuming that there are more job opportunities is for these three languages in your town and you're not sure what language to start with I would recommend python because it's the easiest and has a simple readable syntax that's great for beginners my second choice is Java because it's a solid language and is often taught to computer science and software engineering students JavaScript has a ton of weird parts and baggage from the past because it wasn't originally built for building backends we can certainly use it to build great backends and I've done that many times but I still prefer Java or or C to JavaScript for building backends so don't overthink this pick a language and dedicate 2 months to learning it if you spend 3 to 5 hours every day studying and coding you can learn any of these languages in about 2 months now to help you on this journey I've created a free supplementary PDF that breaks down the specific Concepts you need to learn for each skill it also includes several project ideas to help you practice and apply what you have learned it's a great resource to review your progress find gaps in your knowledge and prepare for interviews you can find the link in the description Box by the way I have a bunch of tutorials on this channel and complete courses on my website if you're looking for structured learning again links are in the description box the next thing you need to learn is a version control system like git git is not a programming language it's a tool that we use to track changes to our code and collaborate with others git and GitHub which is a platform that hosts git repositories are essential for every developer git has a ton of features but you don't need to know them all for everyday use think of it like the 8020 rule 80% of the time you use 20% of gits features so one to two weeks of practice is enough to get up and running now building backends often involves working with data structures and implementing complex algorithms this is where a lot of self-taught programmers struggle because they try to skip ahead and learn more and more languages and tools without learning the fundamentals of computer science data structures and algorithms are critical subjects taught to computer science students and they're often covered in Tech interviews especially at Big tech companies like apple Google and Microsoft while you can skip this step and go to the next as someone who has had the privilege of teaching millions of people I highly recommend you not overlook this step otherwise you're going to feel the pain later in your career so spend 1 to two months studying classic computer science data structures and algorithms this will give you a strong foundation in programming and problem solving the next thing I'll recommend to learn which a lot of self-taught people Miss is design patterns design patterns are proven solutions to Common software design problems there are 23 classic design patterns that were documented in this classic book design patterns by the gang of four many of these patterns are used in web Frameworks particularly spring Django and as.net core which we will talk about in a few minutes so learning these design patterns will give you a deeper understanding of object-oriented design principles and how these Frameworks work under the hood now I got to tell you this book is pretty old and it's written in C++ honestly it's a difficult read because many of the examples in the book are dry and not quite relevant to Modern software that's why I've created a very handson and pragmatic course on this topic where I use Java and modern examples that you find in applications we use every day so you can see how these design patterns are used to solve problems in modern applications whether you want to take my course or a different resource I believe if you dedicate a few hours every day you can have a pretty solid understanding of design patterns in about 2 months the next thing you need to learn is understanding and designing databases there are two classes of database engines relational and non-relational also called No SQL databases in relational databases data is stored in tables with rows and columns that are related that's why we call them relational databases these databases are best for applications that require complex queries and transactions like banking systems and e-commerce applications especially any application that needs complex reporting examples of relational database engines are MySQL postgress SQL server and Oracle these are different products that despite some differences work more or less the same way with all these products we retrieve or store data using a language called SQL some people call it SQL which is short for structured query language it's a simple language that looks like plain English now you don't need to learn all these database engines because different projects and teams use different database engines when you're starting out you just need to learn one of them and you can easily pick up others on the job out of these I would recommend MySQL because it's the most popular database engine but you can pick any other database engine that you like one month is enough to learn the essence of SQL and working with a relational database now in no SQL databases data is stored without a predefined table structure so these databases are more flexible they're best for applications that require flexible data models and real-time analytics examples include mongod DB couch DB and Cassandra again these are several products out there and you don't have to learn all of them out of these I would recommend mongodb because it's the most popular and you can learn it in about a month you're not going to be an expert but you're going to have a decent practical knowledge the next thing you need to learn is a web framework which depends on your programming language for python you should learn Jango for Java you should learn spring boot for JavaScript you should learn express.js for C you should learn as. net core for Ruby you should learn Ruby on Rails and for go you should learn J all these Frameworks more or less do the same thing they provide a bunch of tools for building backends handling tasks like routing requests and response handling database interaction and Security in a nutshell with these Frameworks we can build and publish application programming interfaces or apis these apis are essentially communication points between front ends and backends allowing front ends to retrieve or post data to backends if you have a solid background in a programming language and databases you can learn any of these Frameworks in about 2 months so if you dedicate a few hours every day and follow this road map you'll have the necessary knowledge to apply for entrylevel backend Developer jobs in about 12 months now let's talk about the essential languages and Technologies you need for frontend development frontend development is built on Three core languages HTML CSS and JavaScript HTML or hypertext markup language is used for structuring web pages we can Define headings paragraphs images links and more it's quite simple and if you dedicate a few hours a day you can learn the basics in a week or two the next thing you need to learn is CSS or cascading stylesheets CSS is used for styling web pages it allows us to control colors fonts layouts and so on it helps create responsive designs that adapt to different screen sizes with a few hours of practice a day you can learn the essence of CSS in 2 to 4 weeks you won't be an expert but you'll have practical knowledge to apply in your projects as you work on different projects you will learn additional techniques along the way the next thing you need to learn is Javascript and this is where programming starts HTML and CSS are for structuring and styling pages but programming is about logic it's about algorithms and this is where JavaScript comes in with JavaScript we can make our web pages interactive we can handle user clicks validate form data show popups get data from the back end and basically bring our website to life now if you have never programmed before this might be the most challenging part of your journey because you have to learn how to think like a programmer it might feel weird at the beginning but with continuous study and consistent practice I'm sure you can get a reasonable grasp of it in about 2 months the next thing you need to learn is typescript it's a language that's built on top of JavaScript that adds static typing and additional features allowing us to write more robust code these days most companies prefer typescript for large scale applications so if you want to land a frontend developer job in 2024 and Beyond typescript is a must know it's relatively small compared to JavaScript and you can get up and running in about 2 to 3 weeks next on our list is a UI or user interface library or framework a UI framework is for building user interfaces using reusable components or building blocks examples include react angular View and so on react is the most popular and has a ton of job opportunities so if you're looking to land a frontend developer job react is your best bet now to learn react effectively you need to have a solid understanding of JavaScript and basic grasp of typescript because most react projects these days use typescript so make sure to build a strong foundation in JavaScript before diving into react otherwise you're going to face numerous challenges with a solid understanding of JavaScript you can get up and running with react in about 2 months then you can explore other options like angular or view to add to your resume focus on one framework at a time learn it properly do a few projects and once you have a solid understanding you can learn other Frameworks if you wish so that's the core of front and development these skills are listed on nearly every job description and with continuous learning and consistent practice you can learn them all in about 6 months but I got to be honest with you frontend development is competitive so to truly stand out there are additional skills you need to learn to increase your job opportunities so let's go over them one by one you learn that with CSS we can style web pages and make them beautiful now as our projects grow and get more complex styling Pages using plain CSS can become painful and messy so over time many solutions have been created to address this problem one of them is CSS pre-processors which allow us to write CSS in a more efficient syntax using additional features and then compile it down to plain CSS examples include SAS Les and stylus different projects use different tools and you don't need to learn all of these to apply for a front and developer job if you're familiar with one of them you can quickly learn others on the job out of these I would suggest SAS because it's the most popular and a good one to start with one to two weeks is enough to get up and running with SAS another approach to writing manageable CSS is using a CSS framework a CSS framework provides pre-written CSS that we can use in our applications some of the popular ones are bootstrap Tailwind Foundation skeleton and so on now as you can see here on npm Trends bootstrap used to be very popular and a lot of projects are still using it but over the past couple of years Tailwind has been emerging and overtaken bootstrap so a lot of newer projects particularly react projects use Tailwind so out of these I recommend learning Tailwind it's not that complicated and you can get a decent grasp of it in about 2 to 4 weeks another key skill that employeers are looking for especially in senior developers is automated testing with automated testing we can write code to test our code and make sure it functions correctly automated testing minimizes bugs and enhances the overall quality of our applications there are many testing Frameworks out there but the two most popular ones are just and V test which are pretty similar so once you learn one of them you can learn the other pretty quickly just is the most popular one but it has some baggage so newer projects often use vest again they're very similar and you can start with either of them I believe 3 to four weeks is enough to learn the essence of just and automated testing principles next on our list is meta Frameworks a meta framework is a higher level framework that sits on top of a core UI library or framework and enhances its cap abilities it's not something that all employers are looking for because it's only used in newer projects a lot of older projects don't use a meta framework but if you want to have a Competitive Edge if you're looking for a better position with a better salary I would recommend learning a meta framework for react applications we have nextjs which is the more popular option and remix I recommend learning nextjs which you can master in 4 to 6 weeks if you have a strong foundation in react so that really sums up the essential schem deals you need to become a frontend developer if you have any questions please let me know in the comments below and I will do my best to answer you right here or in my future videos if you enjoy this video please give it a like And subscribe for more useful content"
    },
    {
        "id": "f0ec51b1-25b4-4985-972c-3ec4906bcae3",
        "type": "video",
        "domaine": "technology",
        "titre": "Front-end web development is changing, quickly",
        "url": "https://www.youtube.com/watch?v=TBIjgBVFjVI",
        "description": "Let's take a first look at that latest release of shadcn/ui and combine it with Vercel's V0 tool - an AI tool for building front-end UIs on ...",
        "chaine": "Fireship",
        "durée": "3:43",
        "keywords": [
            "Shad Cen components",
            "recently Shad Cen",
            "run Shad Cen",
            "Facebook style Emoji",
            "front-end World recently",
            "make things easier",
            "Emoji reaction thing",
            "actual front-end developers",
            "World recently released",
            "chat GPT switch"
        ],
        "transcription": "the worst part about being a front-end developer is developing uis which also happens to be 100% of the job web developers have tried to make things easier with countless UI libraries like bootstrap material and so on but recently Shad Cen the hottest UI framework in the front-end World recently released a major update that makes it way overpowered and it's nothing like you've ever seen before the only way I can think to describe it is like if Ruby on Rails and Skynet had a baby who grew up and got jacked on steroids and then got into front-end web development when I started this channel back in 2017 my goal was to make tutorials like this Facebook style Emoji reaction thing the code for that video took the better part of a day but now I can build an even better one in like 30 seconds in today's video you'll learn how to build a custom front-end website faster than ever but with great power comes great trade-offs and we'll also look at the drawbacks of this approach it is September 5th 2024 and you're watching the code report last week I ran a pull about for sale and thousands of people agree that it's the best for an incloud this video is not sponsored by them nor have they sponsored any of my past videos and that's why I can tell you that yesterday versell took a pretty big L when it was revealed that chat GPT switch from nextjs to remix despite that versell did make a really good move by hiring the developer behind Shad CN and now as we'll see it's tightly integrated into the versel ecosystem the Shaden is a component or UI library but it's a lot different than most other libraries like bootstrap instead of installing a massive library of components into your node modules and importing them you copy and paste the code for each individual component into your own project which allows you to use things all a cart and makes it easier to customize the code it sounds chaotic but it's based on Primitives like radex and Tailwind which keep things looking consistent pretty cool but it's killer new feature landed in the CLI in the form of a component registry like you can run Shad Cen ad data table or Shaden ad Carousel to easily add those components to your project and it works with all the major Frameworks but here's where things get really crazy versell also runs this service called vzer which is an AI chat bot for building UI like all you do is ask for a button and it'll return something that looks just as good as any a16z funded startup with a $100 million valuation if we look at the code though what you'll notice it's doing is relying on the existing Shad CN button it then AI generates some extra Tailwind slot and the end result is pretty nice that's not the crazy part though if we click on this install button up here we'll have a command to Shad CN add this to our project it'll automatically copy that code into our project and bring in any necessary dependencies and now we have a cool custom button we can use anywhere and not just that but these URL can also be made public to be shared with anyone and you could even build up your own standard library of Shad Cen components if you drink the Shaden Kool-Aid and then combine it with other AI tools like co-pilot or cursor you can build uis 10 times faster than you could just a few months ago and they actually look halfway decent the end result might look exactly the same as all your friend side projects but at least it didn't take you 6 months to build but the AI haters out there will tell you to never touch any of these tools they'll make your programming skills go flaccid and their garbage code will eventually backfire on you the but the reality is that just a few years ago you'd have to solve many of these problems by going dumpster diving for code on blogs or humiliate yourself with a stack Overflow question but nowadays you have people building to-do apps in their Teslas in the Ikea parking lot the AI performance gains are real but they have to be used carefully and deliberately to avoid unnecessary complexity I don't think Tech like this will replace actual front-end developers but here's my prediction in the near future I think developers will care less about the ergonomics of a framework like the syntax differences between angular react View and spell and care about how quickly and reliably they can generate stuff like I wouldn't be surprised if we see a prompt-based UI framework oh wait a minute it actually looks like someone already built that this has been the code report thanks for watching and I will see you in the next one"
    },
    {
        "id": "160ba387-ea14-438d-af59-1cbc6ea17852",
        "type": "video",
        "domaine": "technology",
        "titre": "Understand the Next Phase of Web Development - Steve Sanderson - NDC London 2024",
        "url": "https://www.youtube.com/watch?v=p9taQkF24Fs",
        "description": "This talk was recorded at NDC London in London, England. #ndclondon #ndcconferences #",
        "chaine": "NDC Conferences",
        "durée": "57:49",
        "keywords": [
            "web assembly component",
            "server side rendering",
            "client side code",
            "web assembly",
            "client rendering Frameworks",
            "server side code",
            "web server",
            "rust web server",
            "streaming server side",
            "web assembly file"
        ],
        "transcription": "all right there's still a few more people coming in but that's fine I can just talk over them while they do that uh no problem all right so hello everybody Welcome to this talk thank you for coming yes uh I know You' just had your lunch so I'm sure that that will filled you up with loads of energy to ingest as many fast demos as you possibly can that's how it works I understand um so nice to meet you all my name is Steve and uh I am a developer architect type guy at Microsoft and I work on the net team uh particularly focusing on web related stuff and that's what we're going to talk about today now I imagine that this is largely a room full of web developers so let's find out give me a hands up if you do something related to the web in your job yeah it's like basically everyone all right um so that's not really surprising because the web is obviously a very dominant part of the software ecosystem there's a lot of hype around other areas of the software ecosystem at the moment but the web is still where a very large proportion of overall activity is taking place and because there's so many people working in this area people just keep inventing new stuff all the time like they're constantly incentivized to come up with the next new thing and in some ways that's a bit annoying because we keep having to learn new stuff but in another ways it's great because we get better and better ways to do stuff and obviously it keeps us in a job as we keep moving one from one framework to the next so that's really going to be the subject matter of this talk what's going on with the web industry at the moment where is it likely to head over the next few years so to set your expectations there's kind of two main parts to this talk we are going to start by talking about web applications and what I mean by that is something that has some kind of user interface that shows up in a browser and then after that we're going to change our Focus to stuff that's happening on the back end in the server and we'll look at ways that we technology like web assembly is changing the way that server programming is happening and I know that some of you will have already heard of things like wzy uh if you haven't that's fine we'll introduce that uh but what you might not know is that wzy is changing at the moment or it has just changed in the last couple of weeks Wazi Preview 2 has been standardized and that changes quite significantly what it is what it can do and so we're going to look at what new possibilities now emerge for us okay so let's get started by talking a bit about web applications and to understand really where we are in the whole sort of timeline of the web ecosystem let's look at a timeline specifically right back to where things started so the web was invented right at the start of the early '90s and if you wanted to create some kind of web UI at that time there was only one way to do it you had to write server rendered HTML so you would use a technology like CGI which is a way of connecting your web server to an arbitrary EX utable to produce some content and then you would use something like Pearl or PHP to actually script your server to emit some HTML and then later on people moved to things like web forms D Jango rails and other stuff like that and that was all we could do back then it was all we knew but eventually people started to outgrow this because there was this movement around 2005 for a few years which was called Web 2.0 at that time and this was a time when people were really strongly incentivized to produce better and better user interfaces in order to try and drive more engagement with their web applications and so at this point people really started to write some JavaScript and at that time it was a horrible language of course it's not now it's great now but it was an Abomination back then and so in order to try and cope with this people had to use libraries like jQuery that made the thing manageable and that was great for about 5 years until people started to outgrow it because they started to write so much code that their application just became an unmaintainable mess and that's when the first client rendering Frameworks came in they tried to bring some kind of structure to client side code structures like MVC mvvm running in the browser and we had names like backbone knockout angular this first wave of client rendering Technologies again it was great for a little while until people outgrew it by about 2015 people's client side applications were too big even for these early client side architectures and that brought us into the era of modern client side rendering and I think the biggest gamechanging thing there was react when that was introduced in about 2015 that showed people a whole different component oriented way of building their client side applications with a new kind of syntax and it was very popular and a lot of other Frameworks came along to try and follow on from that and refine that technique and again that's been great but we're starting to outgrow it again and this time it's because we've got so much code running in the browser now that it's starting to become a performance issue it's starting to become a usability issue for people with low-end devices as well and so there's an emerging collection of web Frameworks which are now starting to move things to the server as well so we went from server to the client and we're now trying to do server and client at the same time and that's going to be one of the main focuses for the first half an hour or so of this talk we'll look at several different Frameworks we'll see how they're similar to each other and we'll see some of the differences between them as well okay so I'm going to do a series of demos but the first thing to really understand about this is just this one very simple idea which is that most of these new Frameworks are favoring rendering on the server first and only enabling interactivity for small pieces that are let up to run on the client so the easiest way to see that is just to look at a demo so I'm going to show you a demo of that now and we're going to start with the one of the most popular Frameworks in this area which which is called nextjs a way of running JavaScript components on on the server and combine it with running on the client as well okay so I've got my I've got this next dashboard application here in fact I'm just going to start it in a browser so we can see what's in there okay and we're going to see how it's server rendered but we can enable parts of it to run on the client and how we can control that as well so when that comes up okay here we go we've got our Dev Team Management Hub because what we're building here is some sort of management portal for a software team where the engineering manager need to keep track of all the stuff that's going on we'll add more stuff later but right now just look at this little message that says too okay well where's that in the code that is here inside uh where is it inside app page. TSX all right so this is like I said a react component next is a framework for running react server and client side all right but this is not sending any code for this component down into the browser it's just server rendered so if we look at the HTML that's coming back in the browser here here bit hard to read obviously but if we search then we can just about make out that here's where that message is showing up in the HTTP response and there's no script related to that component going to the browser the only scripts that we do have are stuff to do with hot reload and things like that you can ignore that CU it wouldn't be there in production okay so since this allows us to use arbitrary react components let's have a go and put in one n and I've got this one over here called clock. TSX which is going to display the current time all right we'll look at that more in a second but let's just add clock in here all right save that back over here we now see the current time extremely precisely great very useful and like I said that is not sending any code for this component into the browser it's up to the developer to choose whether to do that now here's the source code for that component you can see that it knows whether or not it's running on the client if it's not well then it's just going to render statically just going to render this HTML and and then it's finished but if I want to I can have it run on the client as well and then it can use logic like this where it's going to use set interval to update the time in real time all right so if I want to change this over to run on the client I'm going to add this magic marker use client and then back over here you'll see that looks horrible there we go you can see it now is actually sending the code to the client which allows that to run interactively there so that's pretty easy for the developer okay that's pretty good so why would somebody want to do this why would you want to favor running stuff on the server when you could just run everything on the client like we used to in the past well a couple of advantages to do with performance so of course since we're sending less code over the wire we're not using as much bandwidth we should be able to load faster we should reduce our Network egress costs from cloud hosting or whatever you're using so that's clearly some sort of Advantage okay it also means that it's a lot more like likely to work even if the users on a very low-end device with a poor network connection because it's just doing some old school HTML rendering and it just has to light up small pieces interactively according to what you need it's got another Advantage which some people are really into some people don't quite get it but it means that as a developer you are mostly going to structure your application in terms of simple HTML Primitives Pages links forms and such like that rather than things that are specific to a particular client side technology so arguably you might count that as an advantage and then of course the fact that you're doing this doesn't stop you from enabling whatever client side interactivity you want uh we've had this term Progressive enhancement for quite a long time you could argue that's what I've just done when I caused one of my components to run client side okay right so that is just one framework nextjs but there's a lot of different Frameworks that are emerging that are sharing some of the same ideas next like I said is running react on the server no is running view on the server spel kit is running spelt on the server Blazer is Blazer on the server as well as on the client and and so on we're going to look at some of these other ones as we go on um but really what we've got now is a sort of like honeycomb of different Frameworks that are all following a similar pattern to each other even though they have slightly different characteristics among themselves okay and they are kind of all agreeing on what the main features would be that you would need if you want to productive following this kind of architecture uh we just looked at service side rendering uh just there uh that makes sense hopefully but there's a slightly more advanced version of this called streaming server side rendering what is that then well this is something that allows you to overcome one of the traditional limitations of server rendering so traditionally with server rendering if you want to show some kind of data in your page you have to fetch all the data before you can render the HTML obviously uh if you need to do an expensive database query or an expensive API call your user just has to wait for that to complete before you can render the HTML and return it to the browser and maybe that takes a little while and maybe it's not a great experience for the end user so streaming server side rendering is a way of overcoming that by rendering the page first without waiting for anything and then patching in different bits of content as it becomes available so I'll show you that in a couple of different Frameworks now and then we'll see how it actually works behind the scenes by implementing it ourselves from scratch so you can see it's not actually Magic all right so the first example of how that can be used is over here on this dashboard page so I'm going to click that and I want you to just try and pay attention to how long it takes to load so I'm clicking now and we wait we're waiting we're still waiting and eventually it shows up all right so it took about three seconds or so all right so what have we gotten there why did it take so long to load well this is showing information from a few different backend sources some of which take a while for example we're displaying our current Bild status and you know we see we've got some failures it's probably not a problem problem because as long as the executive Netflix thing is fine we'll be all right uh we've got a list of incoming issues um which uh you know again it's probably how to call out to GitHub or something like that and then finally my favorite bit we've got this team activity which shows us what each of the different employees are doing like exactly how many lines of code they've written today how much time they've unprofessionally wasted doing personal web browsing and then we got cameras that will show us you know what their current mood is and how we should manage them so anyway that's that's a separate thing that's an emerging field of Engineering Management called surveillance driven development and I think that's probably the future but you know I can't see any disadvantages anyway right so the the point behind all this is really that it takes a little while to get all this data and if we have a look in the code for that let's see why it takes a little while so here's our page which has got the build status team activity and things like that and if we look in team activity you'll see the way it gets its data is by doing this API call to a backend service there and that takes a few seconds to come back CU you know it's got a communicate with AI systems and things like that right so how about what if we just don't wait for that to load what if we show the page first even before it's loaded now traditionally you can't do that with server rendering you would need some sort of client rendering technology to do that but streaming server side rendering allows us to do it so what we can do is use this component which is built into react server components called suspense and what that means is don't wait for this subtree to actually load its content instead just initially render this fallback you u i which in this case I've set to be a spinner and then when it's loaded swap it in so let's see how that looks now if we move away from here and then I move back we still wait a minute for the other stuff to load but then you see we see a spinner around that slow loading part of the page and we're not limited to just a single suspense we could have a few of them if we want to so let's put one around build status there like that and we'll put another one around incoming issues okay and now if we zoom out a little bit and we reload you see we see a few different Spinners and all the different parts of the UI kind of pop into place as they become available all right so that's pretty nice let's now dig a little bit further into how that's working behind the scenes and let's see how that can be used in other Frameworks as well and we're going to switch over now to Blazer which I happen to work on so that's convenient to me uh but if you don't know about that it's just a net uh web UI framework which works in a similar way to many of these other ones all right so I've got uh actually we need a scenario don't we for our for our web application and I always like having a great business idea uh to back up my demos so I've got an amazing idea for this one right now which I think I'm going to make a lot of money out of uh but I I really hope that no one copies my idea please don't um because it's clearly uh pretty revolutionary so how many of you have heard of this okay Twin Peaks right it's a cult classic TV show from the 90s I see not many of you have heard of it like I heard of it I'm I'm a big fan uh you know I I even wear ' 90s shirts as you can see to to try and fit into the theme of this um it's it's an amazing TV show but if you haven't heard of it it doesn't matter all you need to know is that it's a TV show and in this TV show people quite often drink coffee now anyone heard of coffee yeah all right yeah now if you haven't heard of it don't worry it's just a drink all right and in this TV show people quite often drink coffee and loads of people are really obsessive about this they're really big fans of that and so I thought you know the next big business idea could be a web application that keeps track of when people drink coffee in Twin Peaks all right so here's my web app called Twin Peaks Coffee and I'm going to open this in my browser here and what you'll see is zoom in a bit yeah there we go right so it keeps track of all the different coffee moments starting from the very first heartwarming scene where Laura Palmer got killed there in the first episode right down to the very very final episode where Cooper gets attacked while drinking a coffee and all the other coffee moments that we know and love throughout the years it's quite emotional isn't it when you think about all of them okay and we can search through all these different coffee moments using whatever we want um but it can take a little bit of a while to load because you know there's a lot that our database has to query over and also because I've slowed it down on purpose to make the demo make sense all right so look how long it takes to load if I press that button we wait and then it loads it takes about 1 second if I do a search like let's see for all the cases where someone was having a donut and coffee at the same time and I click and I wait and then about 1 second later it swaps in and you can see it's basically all the law enforcement people that have donuts and coffee so you know some good cliches all right cool now we want to make this a better user experience by using some streaming server side rendering let's see how we can add that into our application right so this is Blazer on. net 8 and this is purely a serers side server rendered application right now if you've used Blazer in the past you probably know that used either web assembly or web sockets to create interactive UI as ofet 8 you can still use those and you will do for many things but you can also just do Straight server rendering with techniques like streaming rendering as I'm going to show you now so in this case when you click on that search button it's going to perform a query against the coffee database uh with your search options and get the results and that's initially going to be a null variable and in the UI rendering logic if the results are null then we'll display this loading message otherwise will display the actual results okay make sense we never actually saw it say loading and that's because it's not streaming yet it's waiting until all the tasks have resolved before it renders the HTML but we can turn on streaming really easily and we don't even have to use something like a suspense component because net has a really well understood system of using tasks for tracking all the different background work so we can just hook into that and we know when your application is ready to render so I'm going to add an attribute called stream rendering onto my P page like that and then when I go back and reload you'll see that we now see the word loading appears while we're waiting for that to happen and when I click on this button loading shows up there so it starts to feel a little bit more fluid to the user you don't have to wait as long for things to actually load all right that's nice but again how does this actually work is this some sort of dark magic that we've done is this a special browser feature that we're using or something like that given that it's not any client rendering technology well it's pretty simple browser technology that's been there since the very beginning of browsers even though people didn't really use it up until this point so let me show you an example of how we could create our own streaming rendering feature from scratch without using any framework features I'm going to do that inside this program CS file here right now and I'm going to add an endpoint onto my server which is called my streaming and it's going to work like this it's going to write a message to the console hello not to the console to the response then it's going to wait a little bit and then it's going to write it again and then it's keep going to keep doing that for 5 seconds okay so if that has now worked I should be able to go in my browser to my streaming and we'll see Hello 0 1 two 3 and so on right so you can see it's kind of updating the the display in the browser dynamically but it's not really all it's doing is a very slow HTTP response and the browser is just showing you everything that it's got up until the current moment in fact it's even easier to see that there's no magic if we do it inside curl on the command line like this okay so you can see again nothing magic it's just a slow HTTP response and that's fine if all you want to do is just add more and more content incrementally to the page that's not what we want to do we want to update content that's already there based on our loading state so how can we do that well not too hard actually what I'm going to do is I am going to add a little bit of extra code uh firstly what I'm going to do is set the response content type to HTML just so that we can use some formatted elements and I'm going to say hello the time is and then I'm going to say loading dot dot dot so that's our fake loading status and then back in the browser you can see it does indeed show that but I want to populate this part of the UI dynamically while the page is loading and we can do that by adding a little bit of extra content to the response so what I'm going to do is add a template element which won't show up in the UI it's completely invisible it's just a template and that's going to contain the content that we want to put in the UI there so it's going to uh contain a bold element with the current time and then where should that actually go in the UI well to Define that I've added this other element called ad streaming block which is just a madeup name the browser doesn't know about that and it says the destination is going to be an element called time which is this one up here now that won't make any difference initially because the template element is invisible and AD streaming block doesn't even exist so the browser will just do nothing if I reload you won't see any difference at all uh but you should be able to see in curl that it is in fact sending that content to the response string all right so now all I have to do is my make my own fake little bit of framework feature that is going to take these ad streaming blocks and use it as an instruction to add this template content into the Dom and that's not specific to my application it could be shared across all applications it's pretty simple it's defining a custom element called ad streaming block and it says when we see one of those elements we'll find the content which is the template element that immediately precedes it we'll find the destination by looking at that attribute and then we'll use this extremely naive technique for copying that content into the Dom a real implementation could be a little bit more sophisticated than that but anyway that should be enough for what we want so if I go back and reload now then we see it does in fact actually work so the clock is updating as the page is loading and we can use that technique to paste in arbitrary content to the response as part of our long running response uh and that's exactly how this is working here so when the response initially goes out it contains these empty placeholders and then as more and more data becomes available the server is sending more chunks of response and causing them to get patched in to different parts of the page all right so there's no real magic to it it's fairly simple you could Implement that yourself uh you might want a real implementation to be a bit more sophisticated like preserving other parts of the Dom that aren't affected things like that uh but you know you get the idea of it okay so let's move on to the next feature which is common to all these different Frameworks which is called enhanced navigation or enhanced form posts in some cases and this again is to overcome another one of the limitations of server side rendering so traditionally with server side rendering every page is completely independent of every other page if the user follows a link the browser will throw away the completely it'll throw away all the JavaScript State and create a new page from scratch potentially reload a load of static content and set up the new page and that can be quite a slow and jarring experience for the end user so enhanced nav is a way of getting the kind of fluidity that you have with a client side router even though you're doing server side page loading so let me show you that and I'm going to show you that from the point of view of a different framework called um selet selet I think is the one that introduced this termin enhan nav even though lots of others now use it so let me start up that one let's get out of here and go into spelt demo and I don't have a cute scenario for this one it's pretty much just what you get when you create the the project from their template all right so when you create a new spelt project you get something like this it's got a nice little counter example which I always love it's got an about page it's got a Wordle clone for some reason and it's got a to-do list which is important all Frameworks need to have a to-do list and this if we look at it is just a plain HTML form because once again this is just doing server rendering it's not actually doing client side stuff right now so this is the HTML form that you can see there and because there's nothing special about it when I submit that form the browser will throw the whole page away and create another one from scratch and reload all the stuff and to see that more clearly let's check out the network Tab and see how many files get requested all right so when I load the page you can see the browser's done 64 requests there uh it would be smaller if I made an optimized production Bild but that's not important the important thing is just that you remember that number 64 and see how it changes as we do this stuff all right so let's clear that out and I'm going to add a new thing let's put hey n DC and then I'm going to press enter and we see that the browser submits the form throws the page away and does another 63 requests to load the updated page so it cached one thing apparently but everything else had to be reloaded and all the other state will have been thrown away but with enhanced nav or enhanced form posts we can intercept that form post and resolve it without a full page load without really having to change very much of the developer code so let's add that in now I'm going to go over to the code for that which is in here that would be inside the to-do page okay here we go right so here's our HTML form that we just submitted there you can see there's nothing you know unusual or magic about it and we can can add this special attribute called use enhance which is built into spelit and that is going to tell it that we want it to upgrade this form when scripts are available to resolve it using client side code without having to you know change other aspects of our server side code all right so let's try that now so I've reloaded you'll see it's done 64 requests again if you can see the bottom left corner and then I'll add another thing and I'll hit enter and you can see now it only had to do two requests to resolve that form post this time a single request to send the data and then it does another request to get like the updated page St from the server okay and that creates a much more fluid user experience for the end user because you know they don't have to watch the browser sort of unload and reload a new page okay now we're going to look at how that works behind the scenes as well in a minute but I want to show you that from the Blazer point of view now because I want to show you that that's not just about performance it's also about changing the actual practical user experience as well so let me show you an example of why it's going to make a difference so notice that in my form here I've got this Advanced check box here and when I click that it's going to open up this extra part of the form where we can pick a location so let's look for I don't know a crime scene I always love coffee at crime scenes and there was two of those apparently or it was the same incident where two people were having coffee good to know all right but did you notice that the advanced checkbox became unchecked when I did that what's going on I didn't uncheck it let's just try that one more time I'll click it to open it and then I'll submit and notice it just becomes unchecked Again by itself so what's that about is that a bug well it's not really a bug this is just how server rendering works and has always worked because we're throwing the page away then we'll lose all the state of things like whether a checkbox is checked or not and of course as the developer you can do some work to manually preserve that state across page loads if you want you can store in local storage you can try and round trip it through the form post data or whatever you want but it's quite a pain to have to do that and with enhanced navigation and enhanced form posts it's much simpler B because you can just retain any part of the page you want when things like forms are posted so let's do that right now I'm going to go into the source code for that which is back here you saw that before okay and on our actual form element here I'm going to use Blaze's equivalent to use enhance which is data- enhance all right and that again is going to tell the framework to resolve that fo poost using client side code which is built into the framework so now when I open this check boox this uh this location area down here and then I click the button notice that it does not lose the state of the checkbox anymore and everything just works in the way that the user expects so now we've got the ability to retain parts of the page when we're doing things like form posts and we can do streaming rendering to update the UI during different loading phases it really starts to feel like quite a fluid user experience it feels basically identical to a client side Spa application even though we're not relying on any client side Spar technology uh this is Blazer and it's not using any web assembly it's not using any websockets in this case it's just using these techniques of streaming rendering and enhanced nav okay all right so let's now dig a little bit deeper into how this is really working behind this scenes now you probably don't really need to know this but you know you're an advanced bunch of people and I'm sure you want to know like what is going on here how does this actually work behind the scenes and you'll find out that it's not very difficult and in fact again you could implement this from scratch without needing the framework if you wanted to and to prove that we're really doing it from scratch I'm going to take Blazer's standard JavaScript library Blazer web.js and just delete it from my application completely which I very much don't recommend normally but we we're going to do that just now because we can then see that everything that happens is stuff that we've implemented ourselves all right so let's go over here onto this chat page and I want to show you um what happens when we navigate from one place to another okay so because I have just turned off the Blazer standard um enhanced navigation thing when I navigate from one page to another it's going to have to reload everything from scratch so if I load you'll see that it's done 13 requests to load that page just then and I'll clear that and then I'm going to navigate to another page like that and you will see now it's done 12 requests to resolve that so again one thing was cached but everything else had to be fetched again and it's thrown away the whole page State and created another one so let's Implement our own enhanced navigation to fix that right now it's not very difficult so we will add a little bit of standard script which is going to look like this a bit of JavaScript that's going to detect any click events in this document and we're going to check was that a click event on a link tag an a tag and if it was we're going to say hey don't do your normal thing don't follow that link don't update the URL just do nothing right apart from alert the fact that we know that this has happened right so it's just just a starting point for us so now when I click on this link to chat up here you'll see that it does not update the URL it's still where it was before and it just displays this alert box instead all right so next step I do want it to actually update the URL and I want affect the content dynamically using client side code so let's add a bit more JavaScript we are going to push the URL that you just click the link for into the history stack like that and then we're going to call perform enhanced nav which I haven't implemented yet that's going to do the main body of the work right and the initial perform and enhanced nav is going to look like this we're going to fetch the contents that come back from the server at that URL and read that as a string called HTML and we're going to display it in a minute but for for now let's just alert it onto the screen to check this is working right come back over here and I will click this now and you'll see this time the URL did update it did update to chat which is what I just clicked on uh but it doesn't display the do the content in the browser it's just alerting uh it onto the screen like that so finally all we have to do is simply update the Dom using the content that we've just fetched and there are many ways you could do that some of which are much more sophisticated than others uh this is an incredibly naive technique all we're doing is just pausing the HTML and just completely overriding the entire document body with it but you can imagine a more sophisticated way of doing it through some sort of diffing algorithm that retains the parts of the page that don't need to change and in fact that's exactly what Blazer does do behind the scenes but this will give you the idea of what's going on so now if I'm over here on chat and I click onto merchandise it updates the URL and the content like that and if we have a look in our Network tab uh I've done a Reload you'll see it's done 13 requests there and then I'm going to go and click on the merchandise page and you'll see it's only done one more request there uh because we intercepted everything and just implemented it ourselves okay so that really is pretty much all there is to enhanced navigation a little bit more is needed for a real implementation to do with like integrating with back and forwards and things like that but you've got the core idea of it right there okay so that's enough about enhanced navigation let's move move on to our last topic which is interactive Islands now you might think that we've already talked about that because you know that's where we started when we looked at that clock thing at the beginning um but I want to show you this a little bit more from the perspective of a couple of other Frameworks as well I'm going to finish off showing you Blazer and then we're going to move on to look at Astro which is a little bit different still and has got some interesting characteristics of its own so to complete the story for Blazer uh we've got a page over here called chat which uh it does work as a pure static server rendered page but it doesn't work very well and to show you what I mean by that let's say that we want to uh participate in this fascinating discussion about do they film with real coffee and can you see at the bottom it counts the number of characters left that you can type in let's say yes it's all LS like that uh it's not updating the number of characters at all as I type and I can submit that yeah and it does show up on the screen great but it doesn't work so well if there's multiple people on the site at once for example I'm going to open a sec second window here like this all right and then I'll say down here from Starbucks like that and then I'm going to send that and that last message that I've just added in this window does show up here but it doesn't show up to the other person why doesn't it show up to the other person because why would it like there's no live connection from this page to the server how would it even know that another message has come in if the user manually reloads like like that then they'll get to see the updated message but that's not really what you want for a chat experience so Blazer like many of these other Frameworks has got the ability to mark parts of your page as running interactively and if you've used Blazer before you'll know that it can work with either web assembly or with server rendering uh so I'll show you how we can add that quite straightforwardly right now here's my chat thread uh page which Loops over all the messages and displays then and I'm going to add a render mode directive here and I can mark it as being interactive on web assembly or server or even Auto which switches between the two depending on caching state but I'm going to pick server okay and then let's see if that actually works now so hopefully oh wait hold on I need to uh restart because of removing that script earlier let's see if this works now yeah so now can you see that the number of characters remaining is updating as I type that's good and what's more if we've got multiple people on the site at once let's reload uh then if I it's difficult to see isn't it but if I send that there then you'll see it's immediately on the other window behind the scenes as well because we do now have this live websocket connection between the browser and the server because that's what bler server does and it's smart enough to start and stop that connection as the user navigates around so when the user on this page the websocket connections there if they go over onto the search page then the framework will say hey I don't need that websocket connection anymore it'll shut it down or it would restart it if the user comes back so you only pay for that server connectivity at the time you're actually using that okay so let's now move on to another framework Astro and that's quite interesting because it's it's Unique among all these different Frameworks and that it's not tied to any particular client rendering technology Astro itself started as a simple static site generator and then over the years they added more and more functionality to integrate with client rendering Technologies let me show you what we can do with that and how it is a little bit different let's get rid of some of this and here's my Astro team portal which we're going to add some stuff into Let's uh start that up like so and once again I didn't really do any cool design on this this is just the standard project template that you get when you create a new astro project the only thing I've added is this link to exciting counters because I love counter based demos and um we're going to add some counters to that uh to that page there right let's see the code inside there inside uh Pages counters all right here's the code for that you'll recognize that message fam earliar and you might look at that and say okay so what is this syntax then is that react maybe it looks a lot like react um the answer is no it's not react it's not view it's not anything else it's just Astro's own builtin template syntax and this only does serve and static rendering this is not doing anything on the client it's just a way of constructing HTML using templates okay but I've also got this folder over here called components and inside there I've got a react counter and a view counter because Astro itself is not tied to any client framework it allows you to work with whichever ones you want or even multiple ones so here I've got a counter implemented in react which has got a button which you click it and it increases account and it uses use State and things like that okay and then I've also got a view counter which does the same thing using view as well and because Astro integrates with these things I can add a react counter to my page here and you can see the tooling automatically Imports that for me and then back in the browser we've now got our react counter in the page there and I could do the same thing with the view counter as well like that if I want to and now we've got react and View at the same time but that is not sending any code for these to the browser just like these other Frameworks that talked about it's server rendering first and if I click the button nothing happens at all if we want it to send the code for these into the browser we have to tell it to do that specifically so I'm going to tell it that I want it to load these component instances in the browser and if I do that then once I go over here now you'll see they do actually work and just to emphasize that this is a little bit different from what we would do with other Frameworks I'll show you a weird thing we can do so since in my react component I've given it the ability to render child content like that I can pass anything into it to render it inside that react component so if I wanted to for some reason I could take my react component and put a view component inside it as a child and it and it's there yeah so that's nice yeah what do you mean this is the the future I'm sure combining as many Frameworks as you can and in fact in fact you if you really crazy which of course you are we could put a react component inside that as well so now we've got react inside view inside react inside Astro and everything just works together okay right thank you okay so uh that just goes to show that we've got a lot of flexibility with these kinds of things and it's up to you the developer to choose what runs on the server what's runs on the client what technolog is used for what and you've got a lot of flexibility with all that so there we go that is what we're going to look at in terms of web applications today uh hopefully you can see there's a lot of commonality among these things in many ways it makes your life more difficult as a developer because there's just so many different ways of doing things now but it does also give you the power to tune that user experience to be as lightweight as you want uh while still having whatever level of interactivity you want okay so let's move on a little bit from web UI stuff and we'll change our Focus now to stuff that's happening on the server and I know that you'll have heard of web assembly before I'll introduce it in a second just in case you haven't um most of you will have heard of wazzy web assembly system interface which is a way of running web assembly code on a server in order to do servery things so why would anyone want to do that and why am I talking about this now the the reason I'm talking about this now is because stuff is changing in this space right now and I'm going to show you how it's changing all right so to understand the background of this let's do another timeline web assembly itself has been around for quite a long time now so it first sort of appeared around 2015 and it actually became available by Del by default in all the browsers in 2017 and that's the thing that if you've ever used Blazer web assembly is what's allowing net to run in the browser there and the core goal of this at that time was to make it possible to run arbitary code in a browser so in 2017 if you wanted to run JavaScript in a browser obviously you could because that was what it was designed to do but if you wanted to use C or rust or go or whatever else then web assembly was the way that that was possible you could compile from another language to web assembly a bite code that runs inside a browser that's great it's fast it's sandboxed lovely but then a few years later people started to say hey this stuff is really good wouldn't it be nice if we could use web assembly to do our server side code as well because then we could write our code in any language we want and it would work on any operating system on any CPU type it would still be like nearly native speed and it would be more secure because of all the sandboxing and people said yeah that would be kind of cool but what would it even be able to do anyway because web assembly doesn't have a way of interacting with the outside world in a browser all it can do is communic Comm unicate to JavaScript because it's inside that sandbox what can web assembly do when it's on the server nothing so that's why wazzy came along web assembly system interface gave web assembly on the server a way of doing useful stuff it was a set of standard apis for doing server type stuff like working with files network sockets clock clocks environment variables stuff like that okay and the design of this was inspired by posix uh that's a a standard set of operating system apis that's widely used in Linux it's also available on Windows and Mac and this design has been around for a long time so posix is like a 1970s technology pretty much and it made sense for wazzy to start with that because the goal was to be able to get existing code to run and it was successful but it's not the future of Wazi the reason why posx is not the future of Wazi is one it's a sort of many decades old view of computing it doesn't really represent the modern era of cloud programming you know it's just about file handles and not about things like distributed cues and blob stores and AI inference and stuff like that uh secondly because it's not extensible in any way uh all you could use is just the standard apis that were built in and there's no way of standardizing your own other apis on top of it but it wasn't the long-term Vision the longer term vision is something that we're just coming to now and this has just been standardized in the last couple of weeks wiy Preview 2 and that brings a new programming model that allows us to do some new things and the core idea in that is something called the comp component model so let me introduce that to you now this is how different pieces of web assembly can work together so the central thing behind this is a new interface definition language called wit web assembly interface types and here's an example of that so you can imagine this is part of some kind of e-commerce system and I've defined an interface called ordering and inside that we've got this type called Product with a few different fields on it and I've also defined a function called add to car which takes an item and it returns some kind of result okay now what language is that written in no language it's not rust it's not C it's just a language independent format for defining a set of functions and data types but you can use that with any language that you want for example you could take that wit file and you could have some go code and compile them together to produce a web assembly component that uses those apis you could also take some Rust code and compile it with that wit file to produce a different web assembly component or you can take some C code and again use the same wh file to produce another web assembly component and because all of these share the same API definitions we know for sure that they can actually work together at runtime so uh obviously that gives you cross language interrupt but it's not just about cross language interrupt that's been a solved problem for decades the main new innovation that this is bringing is that it's still taking advantage of all the benefits of web assembly so even though all the these components are working together they can still be independently sandboxed and they can only communicate through the channel defined in these wit files so when you take a dependency on a web assembly component you don't actually have to trust it really you don't have to trust that it won't read your memory space or mutate your data when you didn't expect it to you don't have to trust that it won't access the file system or the network or whatever else because you know that all the components are running in their own little sandboxes and all they can do is communicate across the API interfaces that are defined in the whip files that you know about so to understand that a bit more let's have a go at building something with it shall we and we're going to build uh a little web server now which uses components written in multiple different languages working together and the main language we're going to use is C because I know that most of you in here will see that as your main language uh but just before we get to that we're going to write a bit of rust code for our actual web server now don't worry if you don't know rust you never seen it or you hate it or whatever doesn't matter it's not going to be very much code it's just going to be a little web server and we're going to make it extensible and pluggable so that we can ball other functionality into it using other languages okay so let's find our starting point for this I'll close some things down and have a look over here all right okay so here is our rust web server it doesn't have very much code in it it's just a single function which takes an incoming request and it's going to read the current URL in that's coming in from the browser or whatever it's also going to determine the current Tim stamp or it will do later it's just hardcoded right now and it's going to print a message to the console and then it's going to determine what the response content should be and it's going to send that response back to the browser with a 200 status all right hopefully that makes sense even if you don't really know Russ syntax we're going to compile that now and rather than compiling to native code I'm going to compile it to a Wy preview2 component now this talk is not really about the build systems so I'm not really going to talk about how that works I'm just going to use a little script that I already prepared that builds stuff converts it into a preview2 component and starts it up inside this little runtime called spin which allows web assembly components to interact with a network listener okay so when I open this in a browser now you'll see it says to do call external component and that is not very surprising because that's exactly what we hardcoded into our source code all right makes sense but we want to make this into a pluggable web server now where you can add functionality using any other language as a web assembly component and to do that we are going to need to define a wit file to define the API contract that we're allowing people to use and in fact I've already written this whip file it's over here you can see web server. Whip and it's got this interface web app and it says that to be a plugin for a web app you need to do two things you need to be able to give a Tim stamp you also need to be able to give the current uh to give some response for a given request so a URL comes in and you need to return a string which is the HTML that you want to send back to the response and then this other stuff down here is quite a weird syntax I don't know why they use the word world but basically uh you can decide when you're consuming this do you want to work on the web app provider side which means you're going to export an implementation of this stuff so that people can call you or do you want to be the server which means you import this stuff so that you can call into it uh so that's what this is doing it just allows you to specify which side of the contract you want to be on okay so let's have a go actually using these functions from our rust code so I want to call into this get timestamp which I'll do there and I want to call into get response HTML which I'll do that now initially the rust tooling will display these R squigglies and it'll say like what on Earth are you talking about I don't know what get Tim stamp is that's not defined anywhere you obviously doing something wrong and that's because I haven't wired it up to this WID file in any way yet the way we do that in trust is using this markup sorry this macro called wit bind gen which allows us to point to a particular wit file which I've done in my build config file and say which side of the contract we want to be on okay so now I've done that i' still get squigglies but it's a little different this time it says hey I do know what that is actually because there's just been some code generated for that in the background do you want to import it so I'll say yeah I do want to import that and and this one as well and now the squigglies will go away because we are actually referencing this API okay now let's try and rebuild and restart and it's actually not going to work now it won't be able to start the server you see we'll get a build error and it will say hey you're trying to use this thing call get Tim stamp I went looking for that and I got nothing like what do you mean you're trying to reference something but you haven't provided an implementation for it so that makes sense hopefully we can't call something without having an implementation for it let's provide an implementation and we're going to do that using C so I'm going to switch over to visual studio now and I've got a project here it's kind of an unusual project because it doesn't contain any source code whatsoever there's no C files in there because I really want to do this from scratch so you can see everything and if we look in the Cs project file you'll see there's not a lot in there it's just a pretty standard UHA class Library project okay so first thing I want to do is compile this as a web assembly component uh we could do that in a few different ways but I'm going to use this experimental package called wasm component SDK and what that is going to do is it's not going to use the monor runtime which we Norm use uh for net and web assembly it's going to use native aot compilation instead to produce a fully aotd web assembly file just an experiment we're working through at the moment and then I'm also going to configure the fact that I want the output to be wazzy flavored wasm okay so once I've done that if I rebuild we should see that the build process goes through a few extra steps compared to what you'd normally see and it's gone through this llvm phase and it's eventually produced a file which is a web assembly file but it's not a traditional web assembly file it's a wazzy preview2 component which knows how to be linked up to other whip files okay so let's uh actually link it up with a wit file now how do we do that well with this tooling we can add a wit into one of our item groups and here you'll see that here's my reference to the web server. wit file and I've defined that I'm on the web app provider side of this contract which means that I'm going to implement stuff and if I try and build now we should now get some build errors because it'll say hey that contract says that you need to implement this thing but you haven't done so I can't build this anymore so let's Implement that I'm going to add a new C class and I'm going to call it uh web app impul you can actually call anything you want that doesn't matter and then I'll go into here and I'm going to drop in uh a starting point so because of this build tooling behind the scenes it's code generated an interface that matches the thing that we're supposed to implement it's the naming is a bit weird that it doesn't start with i but that's being fixed at the moment if I go in there you'll see this is the interface that's been generated and it looks just like that width file so if I come back here and do a control dot I can say right I need to implement this now generate the outline for that and let's put in an implementation this is going to be quite easy let's just have date time now ticks I don't need that that'll do okay and for get response HTML I'll say hey NDC from.net okay nice and I'm going to rebuild that now okay so hopefully because of the fact that my build script wires these two components together I shouldn't get a build error from this anymore it should now actually start up the web server and it does so open up in my browser and you can see we've now got our rust web server which is able to call into our C code to provide part of the response that's good but I don't just want to return a hard coder string I want to make this into a little static file server you'll see I've got a couple of markdown files right here uh such as this one here and I want it to serve whichever markdown file corresponds to the current request so I am going to paste in a little bit more implementation here which is going to take that URL and it will say if it ends with a slash we'll normalize it by adding index onto it because I want the homepage to serve index.md then we'll have a look and see if that file exists if it does we're going to return it to the response otherwise we'll say not found okay so we we'll start our web server again and we'll see if our updated logic now actually gets used let's find out come over here and reload and it does it's now serving our markdown to the response now of course it looks absolutely disgusting that's because I haven't formatted it as HTML yet it's just returning markdown string into the browser and I could implement the markdown formatting in C there are markdown formatters available for net it's not difficult but that's not really the point of this talk I want to show that we can work with yet another technology or another ecosystem so what I want to to do is Define the abstract notion of markdown formatting as yet another wit file and then I'm going to provide an implementation for that in go in this case right now you won't be surprised to hear that I've already done that uh that's over here and if we look in there you'll see here is the markdown format WID file it defines a single function format as HTML which takes the markdown as a string and returns another string which is the HTML and once again you can decide which side of the contract you want to be on and uh here's the actual implementation in go don't worry if you don't know go there's nothing clever about this this is just using an open source Library called go markdown which will do the formatting and then it's got all this block of code down here uh which is what's needed to actually instantiate that and push the incoming string through the markdown format okay now don't worry about reading that we want to consume that now from our C code so to do that we will go over here and add a reference to yet another WID file like that and we'll say this time we're going to be on the consumer side of it and one minor weird glitch at the moment which is a bug that should hopefully be fixed is that whenever you import something you have to manually add this weird definition uh in order for it to actually work but you can ignore that because hopefully that would just go away right so I can now compile my C code and I've got a reference to this markdown format even though I haven't called it there's no build error because you don't have to call something just because you've implemented it but it will be there and available for me to call now and I happen to know that the naming convention it uses uh for something like this uh markdown functions will look like this in C markdown uh what is it functions interop like that and as long as I've spilled that correctly then I should be able to import the name space for that and then I can call format as HTML like that and then hopefully everything will be wired up to call across uh into go like that all right let's see if this works we're going to shut down the server one more time and start it and then go back into our browser and reload and indeed it did actually work so we've successfully got our rust web server as a web assembly component calling into a net plugin another web assembly component calling into a go Library another web assembly component and we can serve multiple pages and things like that okay so obviously it's a kind of a a very basic and and small example there but it leads to you know potentially quite an interesting future for these kind of technology so the overall goal of something like this like the kind of dream you could imagine for it would be a sort of cross- language package ecosystem so right now we've got package managers called things like cargo and mpm and net and they're all tied to specific languages but you could imagine a future one which is based on web assembly and wit where you can consume those components from any language you want without needing to care what it's written in and if you want to contribute a component again you can do that from any language you want without having to uh you know align with what your consumers of that are doing and then at runtime this stuff can run in any operating system on any CPU type at high speed and with full sandboxing so will that be the future of server cloud programming don't know but that is what wazzy is trying to achieve at the moment and where it's just going right now okay so that is all we've got time for I hope that's been of some use to you I hope you've seen something new at least um I'm around if you want to come and ask me questions or whatever that's fine uh but other than that I hope you have a really good rest of the conference and I will see you all around"
    },
    {
        "id": "a4aaa06a-540f-4b07-aa71-2f7b549c008e",
        "type": "video",
        "domaine": "technology",
        "titre": "Blockchain Technology Explained (2 Hour Course)",
        "url": "https://www.youtube.com/watch?v=qOVAbKKSH10",
        "description": "Blockchain",
        "chaine": "Coding Tech",
        "durée": "1:54:54",
        "keywords": [
            "distributed ledger technology",
            "network distributed ledger",
            "distributed internet technology",
            "distributed token networks",
            "data distributed ledger",
            "IOT blockchain system",
            "blockchain technology enables",
            "contracts smart contracts",
            "blockchain based networks",
            "system enables networks"
        ],
        "transcription": "the blockchain is a term that has come to mean many things to many people for developers it is a set of protocols and encryption technologies for securely storing data on a distributed network for Business and Finance it is a distributed ledger and the technology underlying the explosion of new digital currencies for technologists it is the driving force behind the next generation of the Internet for others it is a tool for radically reshaping society and economy taking us into a more decentralized world whichever way you look at it blockchain has become a term that captures the imagination and fascinates many as the implications of such technology are truly profound for the first time in human history people anywhere can trust each other and transact with in large peer-to-peer networks without centralized management trust is established not by centralized institutions but by protocols cryptography and computer code this greatly strengthens our capacity for collaboration and cooperation between organisations and individuals within peer networks enabling us to potentially form global networks of collaboration without centralized formal institutions unprecedented but hugely relevant in an age of globalization and a new set of 21st century challenges that require mass collaboration Chane is a complex technological economic and social phenomenon it calls into question what might have seemed to be established parameters of the modern world like currency economics trust value and exchange to make sense of this one needs to understand it in a holistic context all the way from its technicalities to it's aspirational potential this course is designed to do exactly that by giving a 360-degree overview to the different dimensions of the technology its potential application within various industries and its far-reaching implications for society and economy in the first section of the course we give an overview to the blockchain both on a technical and non-technical level we also discuss the importance of the blockchain within the context of the emerging next-generation Internet in the second section we talk about the blockchain as a so-called trust machine and how it enables transparency and collaboration we will look at distributed ledger technology talking about smart contracts etherium and decentralized applications in the third section we introduce you to the workings of token economies illustrating how the blockchain and distributed Ledger's can work to build vibrant ecosystems through the use of tokens to incentivize behavior section of the course we will be looking at specific applications of the blockchain to economy society technology and environment looking at both existing practical applications and potential future applications the blockchain is a so-called emerging technology that is currently experiencing very rapid evolution within the space of just two or three years it has already gone through changes in its technical implementation and our understanding of what it is and can be as such our aim is to future-proof this course by not dwelling excessively on existing technical implementations but presenting a more conceptual understanding of the blockchain within the broader process of change of the emerging next-generation Internet is much more than a technology it is also a culture and community that is passionate about creating a more equitable world through decentralization it is a movement to disrupt the disruptors to redesign the Internet and in so doing shake up existing centralized incumbents throughout the course we will introduce you to this culture and its aspirations this course is non technical in nature it is an introductory course and thus all terms will be explained it should be accessible to anyone with a basic understanding of web technologies and economics in this video we're going to give a high-level overview looking at the primary dimensions of this technology that we call the blockchain will first talk about the underlining technology then the distributed edges that this technology supports then the token economies that can be built on top of that ledger system will only touch on these topics here to get an overview before going into them in more detail in future videos on its most basic level the blockchain is a new class of information technology that combines cryptography with distribute computing both of which existed for a number of decades it was the genius of Satoshi Nakamoto to combine them in new ways to create a model where a network of computers collaborate towards maintaining a shared and secure database as such we can say the blockchain as the technology is simply a distributed secure database this database consists of a string of blocks each one a record of data that has been encrypted and given a unique identifier called the hash mining computers on the network validate transactions add them to the block they're building and then broadcast the completed block to other nodes so that all have a copy of the database because there is no centralized component to verify the alterations to the database the blockchain depends upon a distributed consensus algorithm in order to make an entry onto the blockchain database all the computers have to agree about his state so that no one computer can make an alteration without the consensus of others once completed a block goes into the blockchain as a permanent record each time a block gets completed a new one is generated there is a countless number of such blocks in the blockchain all connected to each other by links in a chain in proper linear chronological order the blockchain was designed so that transactions are mutable meaning they cannot be deleted each block contains a hash value that is dependent upon the hash of the previous block so they're all linked together meaning if one is changed then all the other blocks linked to it going forwards will be altered this works to make the data entered tamper proof what we've described here is the workings of the first generation of block chains which function largely simply as databases but the technology is currently evolving to become much more than this as the second generation already provides the capacity to execute any computer code on the blockchain the system is evolving to become a globally distributed tile computing infrastructure and as we'll discuss in a future video it remains very much a work in progress when seen from this perspective blockchain technology works to create a permanent and secure database this makes blockchain suitable for the storage of a record or transaction that involves value or in some way it needs to be a secure and trusted source of information these secure distributed records are called distributed Ledger's a distributed ledger is a consensus of replicated shared and synchronized digital data geographically dispersed across multiple sites countries or institutions without centralized administration or centralized data storage being maintained instead by a distributed network of computers such Ledger's can be used for any form of asset registry such as inventory or monetary transactions this might include the recording of hard assets such as physical property cars homes etc or intangible assets such as currencies patents votes identity healthcare data or any other form of valuable information this distributed ledger technology enables us to replace a multiplicity of private databases within each organization with one shared database that is trusted and accessible by all parties involved in this respect the blockchain enables trust between parties that may otherwise not trust each other the results greatly strengthen our capacity for collaboration between organizations or between individuals peer to peer without dependency on third parties centralized institutions likewise their results in transparency and many other efficiencies this is of major significance as we currently have many centralized organizations that may be internally optimized but the inter organizational space in between them is really inefficient with huge amounts of border friction redundancy arbitrage and resources wasted on competition by enabling trusted into organizational networks these Ledger's enable the formation of organization and collaboration where previously there was none such as across whole supply chains or for different healthcare providers to collaborate around the patient's needs or for different transport providers to collaborate in delivering and integrated logistics network likewise second-generation blockchains offer the possibility to automate the workings of these networks through what we call smart contracts smart contracts are computer code that is stored inside a blockchain which encode contractual agreements these smart contracts are self executing contracts with the terms of the agreement or operation directly written into lines of code which are stored and executed on the blockchain like normal computer programs these containers hold algorithms that take an input of data and depending on the value of the input trigger certain events for example this might be a financial contract that takes as the input the amounts of money in a person's accounts if it is above a certain level then it increases the interest rate that they earn on their deposits such smart contracts can be used for automating and many basic operations on the network once again working to remove the need for intermediary third party institutions as smart contracts can be trusted a tamper-proof and executes automatically much of the current discussion surrounding blockchain remains at the level of the technology and the possibilities of distributed edges as he shared trusted database enabling the collaboration between organizations with the resulting disintermediation of centralized institutions and market exchanges however its implications go far beyond this as the blockchain concepts is more than just a database or ledger it is a new organizing paradigm for the discovery validation and transfer of all discrete units of value and the developments of distributed organizations via token market systems a token is a quantified unit of value that is recorded on the blockchain this value may be of any kinds it may be likes on social media it might be a currency it might be the integrity of an ecosystem or might be an electrical units token networks consists of a network of independent nodes that act autonomously but through incentive structures and the signaling system of the market self-organized to create emergent coordination and thus a distributed management system for example we might create a clean air token where anyone who provides a service that contra buttes to the maintenance and provision of clean air can earn tokens for example by planting a tree while those who pollutes by say operating a combustion engine have to pay in air tokens thus instead of having a centralized Authority and a Clean Air Act's we have a token market that works to create signals that align people's incentives with maintaining and growing the underlining resource likewise the same model could be applied to the management of technology infrastructure as an example we could think of traffic control we currently have traffic control systems in cities whose operations are monitored by centralized control centers but in a world of autonomous vehicles and the blockchain cars could signal to each other its appear bidding tokens to see which gets priority in such a way the system has dynamically allocated resources and self-organized via distributed token networks in short blockchain is not just an information technology but also an institutional technology in that it enables us to design incentive structures in the form of token economies and in such a way converts centralized organizations into distributed markets via token economics this is where things start to get quite complex as you move into the realm of designing economies and incentive systems for coordinating human activity in a decentralized fashion something that could potentially enable the coordination of human activity at a much larger scale than has been possible before the great design innovation of the blockchain is really its capacity to coordinate a network of autonomous nodes towards maintaining a shared infrastructure and this is done not just through innovations in information technology but also through the design of incentive systems which has traditionally been the domain of economics through adding a layer of trust and value exchange to the Internet the blockchain merges our newly developed information networks with the institutional structures that sit on top of them in so doing it greatly strengthens the capacity of those networks as a new mode for organizing society and economy by merging economics and technology it enables us to redesign institutional structures and ultimately reconceptualize how we organize virtually every aspect of society economy and even technology infrastructure based on networks of autonomous nodes that are incentivized to collaborate of course it does not do this alone such claims can only be realized in combination with other technologies and broader processes of change as such the blockchain has to be understood in the context of a broader set of technological transformations taking place with the current evolution of the internet most notably much what the blockchain promises will only be possible given parallel developments in the Internet of Things data fication and advanced analytics all of which are combining to form the next generation of Internet of which the blockchain will be a critical infrastructure in this video we're going to talk about the basics of the blockchain as the technology on its most basic level the blockchain can be understood as a new kind of database at least this was its original design what's different about this database is that it's distributed digital databases have been around for a while now but until recently they've been designed to centralize information on one computer or within one organization the blockchain though uses a distributed network of computers to maintain a shared database the blockchain is then a set of protocols and encryption methods than enable a network of computers to work together in securely recording data within a shared open database this database consists of a series of encrypted blocks that contain the data the blockchain is a continuously growing list of these blocks of data which are linked and secured using cryptography this makes it a trusted database with this trust being maintained by open secure computer code an encryption instead of any single institution the database stores information in blocks that are linked together through hash values with entries to this database being made by computers that all have a copy of the database and all must come to consensus about its state before they can update it so these are three central concepts to understanding the system's workings that of blocks and hashing mining and proof of work and distributed consensus we'll go over each of these separately in terms of its structure a block chain may be considered as a series of blocks of data that are securely chained together new blocks are formed as participants create new data or wish to update existing data these blocks are encrypted and given a hash value that represents a unique identifier of the data within that block this hashing works by a standard algorithm being run over the blocks data to compress it into a code which is called the hash which is unique to that documents no matter how large the file or what information is contained it is compressed into a 64 character secure hash this hash value can be recalculated from the underlining file confirming that the original contents have not changed but the reverse is not possible given just the hash value you cannot recreate the blocks data contained within it which is encrypted all blocks of data which are formed after the first block are securely chained to the previous one this means that the hash value of the next block in the chain is dependent upon the previous one thus once recorded the data in any given block cannot be altered afterwards without the alteration of all subsequent blocks as well as this hash pointer linking to the previous block each block typically contains as well a timestamp so that we know what happened and when it happens this hashing and linking of blocks makes them inherently resistant to the modification of their data making them immutable records you can only write data to the database and once it's there it's very hard to change almost impossible thus data is stored on the blockchain is generally considered incorruptible blockchain security methods include the use of what we call public key cryptography a public key which is a long random looking string of numbers is an address on the blockchain value tokens sent across the network are recorded as belonging to that address a private key is like a password that gives its owner access to their digital assets or the means to otherwise interact with the corresponding data a public key is associated with the private key so that anyone can make an encrypted transaction to the public key address but that encrypted message can only be deciphered with the private key that corresponds to that public key in such a way effective security only requires keeping the private key privates the public key can be openly distributed without compromising security for example on the Bitcoin blockchain to receive funds from another person you use a piece of software called the wallets which creates a public key that you give to someone else for them to send bitcoins to that address with your corresponding private key you can then access that address with those bitcoins on it the blockchain is a distributed system this means there is no centralized organization to maintain and verify the entries on the database this database is instead maintained by a large number of computers that are incentivized to provide computing resources by earning some form of tokens in exchange but these computer nodes in the network themselves cannot be trusted individually the city's required that the system provide a mechanism for creating consensus between scattered or distributed parties that do not need to trust each other but just need to trust the mechanism by which their consensus has been arrived down any computer that is connected to the blockchain network and using a client can perform the task of validating and relaying transactions each of these so-called minor computers gets a copy of the blockchain which gets downloaded automatically upon joining the network when new entries into the database are made these changes are automatically broadcast across the network mining nodes validate transactions add them to the block their building and then broadcast the state of the complete block to other nodes on the network in order to randomize the processing of blocks across the nodes and to avoid certain service abuses block chains use various time stamping schemas such as proof of work proof of work describes a system that requires a certain amount of resources or effort to complete an activity typically this resource is computing time as in the case of the Bitcoin blockchain this is realized on some form of challenge such that no one actor on the network is able to solve this challenge consistently more than everyone else on the network miners compete to add the next block in the chain by racing to solve a very difficult cryptographic puzzle the first to solve the puzzle wins the lottery as a reward for his or her efforts the miner receives the small amounts of newly minted bitcoins and a small transaction fee it can sense this algorithm like bitcoins proof-of-work functions to ensure that the next block in the blockchain is the one and only version of the truth and it keeps powerful adversaries from derating the system block chains are trying to create a secure trusted shared database and do this through encryption and hashing proof of work and network consensus the hashing and linking of blocks makes it difficult to go back and change a previous block once it's entered but this alone would not be suffice to ensure that the data is truly tamper proof so then the proof of work system intentionally makes it computationally more difficult to alter the database thus making it extremely difficult to alter all the blocks on top of this it places that distributed consensus mechanism so that even if someone did manage to do this their record would not match that of others and thus would not be accepted as a valid record so to successfully tamper with the block chain you would need to alter all the blocks on the chain redo the proof of work for each block and take control of more than 50% of the peer-to-peer network only then would your altar block become accepted by everyone else on a block chain of almost any size this would be almost impossible to do indeed the Bitcoin blockchain is very good proof of this given that it now secures hundreds of billions of dollars using this method without the network having yet been compromised at the end of the day what this technology enables is a database that is secured with automatic trusts that is enabled by open source code and encryption the data is tamper proof once information is put into the database it cannot be altered afterwards it is a shared database as many people across a network have a copy which is continuously being updated so that all have a single source of truth likewise it is transparent meaning that everyone can see all of the transactions and alterations made to the database if needed data quality and the resilience of the network is maintained by massive database replication across many different nodes on the network no centralized official copy exists and no user is trusted more than any other having started out life is simply a mechanism to enable Bitcoin it has become increasingly recognized that this system is secure enough to work as a ledger for the recording and exchange of any value what we now call a distribution there germ over the past years blockchain evolving fast from the original Bitcoin protocol to the second generation aetherium platform to today to where were in the process of building the third generation of block chains in this evolution we can see how the technology is evolving from its original form as essentially just a database to becoming a fully fledged globally distributed cloud computer in this video we're going to trace the past present and future of blockchain technology the first blockchain was conceptualized in 2008 by an anonymous person or group known as Toshi Nakamoto the concepts and technicalities are described in an accessible white paper termed Bitcoin a peer-to-peer electronic cash system these ideas were then first implemented in 2009 as a core component supporting Bitcoin where it served as the public ledger for all transactions the invention of the blockchain for Bitcoin made it the first digital currency to solve the double spending problem without the need of a trusted Authority or central server it was only later that we came to really separate the concept of the blockchain from that of its specific implementation as a currency in Bitcoin we came to see that the underlining technology had a more general application beyond digital currencies in its capacity to function as a distributed ledger tracking and recording the exchange of any forms of value the Bitcoin design has been the inspiration for other applications and has played an important role as a relatively large scale proof-of-concept within just a few years the second generation of blockchains emerged designed as a network on which developers could build applications essentially the beginning of its evolution into a distributed virtual computer this was made technically possible by the development of the etherium platform aetherium is an open-source public blockchain based distributed computer platform featuring smart contract functionality it provided a decentralized turing-complete virtual machine which can execute computer programs using a global network of nodes aetherium was initially described in a white paper by the italic Bertrand in late 2013 with a goal of building distributed applications the system went live almost two years later and has been very successful attracting a large and dedicated community of developers supporters and enterprises the important contribution of etherium as the second generation of blockchains is that it worked to extend the capacity of the technology from primarily being a database supporting Bitcoin to becoming more of a general platform for running decentralized applications and smart contracts both of which we'll discuss in coming videos as of 2018 aetherium is the largest and most popular platform for building distributors applications on many different types of applications have been built an app from social networks to identity systems to prediction markets and many types of financial applications aetherium has been a major step board and with its advent it has become ever more apparent where we're heading with the technology which is development of a global distributed computer a massive globally distributed cloud computing platform on which we can run any application at the scale and speed of today's major websites with the assurance that it has the security resilience and trustworthiness of today's block chains however the existing solutions that we have are like extremely inefficient Computers the existing blockchain infrastructure is like a really bad computer that is not able to do much except proof of concepts getting to the next level remains still a huge challenge that involves some original and difficult computer science game theory and mathematical challenges scalability remains at the hearts of the current stage in the journey that were on and this is what the third generation of blockchain technologies are trying to solve the mining required to support the Bitcoin network currently consumes more energy than many small nations being equal to that of Denmark and costing over 1.5 billion dollars a year in the lectures deem a lot of this is being fueled by cheap but dirty coal energy in China where almost 60% of the mining is currently being done this high energy consumption is simply not scalable to mass adoption etherium and Bitcoin use a combination of technical tricks and incentives to ensure that they accurately record who owns what without a centralized Authority the problem is it's difficult to preserve this balance was also growing the number of users currently blockchain requires global consensus on the order an outcome of all transfers in aetherium all smart contracts are stored publicly on every node of the blockchain which has its trade-offs the downside is that performance issues arise in that every node is calculating all the smart contracts in real time which results in those speeds this is clearly a cumbersome task especially since the total number of transactions is increasing approximately every 10 to 12 seconds with each new block added the volume of transactions is likewise an existing constraint with cryptocurrency speed is measured by TPS transaction per second the Bitcoin network theoretical maximum capacity is up to seven transactions per second while the ethereum blockchain as of 2018 can hand about 15 transactions per seconds by comparison a credit card network is capable of handling more than 20 thousand transactions per seconds equally Facebook may have about 900 thousand users on the site in any given minutes meaning that its handling about a hundred and seventy thousand requests per second another issue is that of cost the fact that it costs some small amount to run the network so as to pay the miners for maintaining the ledger what we have is okay for a limited number of large transactions such sending money but making a small transaction by purchasing a coffee could not be done by most block chains they simply can't in their existing form deal with a very large amount of micro transactions such as will be required to enable high-volume machine-to-machine exchanges it would prove too expensive to operate these kind of economies that involve many small exchanges but this is exactly what many people will want to use the blockchain for in the future in response to these constraints a third generation of blockchain networks are currently under developments many different organizations are currently working on building this next-generation blockchain infrastructure such projects include Definity Neo Geo's iota and a theorem itself they're each using different approaches to try and overcome existing constraints going into the details of how these different networks work is a bit advanced for this course so we'll just give a brief overview to two of them the Lightning Network is one such project that seeks to extend the capacities of existing block chains the main idea is that small and non significant transactions do not have to be stored on the main blockchain this is called an off chain approach because small transactions happen off of the main goal chain it works by creating small communities where in transactions can take place without each of those transactions being registered on the main blockchain a payment channel is opened between a group of people with the funds been frozen on the main blockchain those members can then transact between each other using their private key to validate the transactions this is a bit like having a tab or an IOU with the shop where you just mark down what you've exchanged so that you don't have to update the main record in the bank each time you make a purchase the record stays local between the members involved before at some time setting the finances and updating the main bank record this only requires two transactions on the main blockchain one to open the transaction channel and once closed here all other transactions happen just within the network without it being registered on the main blockchain this both reduces the workload on the main blockchain and makes it possible to run a very many very small transactions within the sub network as of the start of 2018 there is a proof-of-concept running live on the Bitcoin test net but the system will not be fully operational until later in the year as is the case with most of these projects IATA is another example where as existing block chains are sequential chains where blocks are added in a regular linear chronological order the data structure of the iota system is able to achieve high transactional throughput by having parallel operations the data structure is more like a network rather than a linear chain wherein processing and validation can take place alongside each other the other big difference is that there are no specialized minors in this network every node that uses the network functions as a minor in the i/o to network every node making a transaction also actively participates in forming the consensus that is to say everyone does the mining this means that there is no centralization of mining within the network which is what creates bottlenecks and demands lots of energy likewise with this network there are no transaction fees for validation and with iota because it is more user generated the more people that use the network the faster becomes which is the opposite of existing systems and obviously makes it very scaleable there are lots of other possible approaches to overcoming existing constraints but suffice to say the blockchain should be understood as an emerging technology whose existing implementation is like a large-scale proof-of-concept running on a very inefficient system but through lots of experimentation and iteration well hopefully in the coming years evolved into this global distributed computer as nan Lee Swan writes in her book first there was the mainframe PC personal computer paradigms and then the internet revolutionized everything mobile and social networking were the most recent paradigm the current emerging paradigm for this decade could be the connected worlds of computing relying on blockchain cryptography to understand this better in the next section we're going to talk about the blockchain in the context of the broader technological changes that are currently underway as we build the next generation of the Internet's what we call the decentralized web or web 3.0 how we understand the blockchain and where we are with it today is extremely transitory in this respect what we're talking about in this course when we talk about the blockchain is ready this emerging IT infrastructure of a distributed global cloud computer the next generation of block chains will take us a step further on that journey what we called the blockchain today is really just a very limited and often very inefficient version of this we still have many very difficult problems to solve before we'll get there possibly that end stage will look something like the blockchain of today but possibly it would look very different people will make big claims about the potential of the blockchain to revolutionize the foundations of social and economic organization but the blockchain can only have such potential as part of a broader ecosystem of technologies that are emerging as the next generation of the Internet's what may be called web 3.0 or the decentralized web today powerful technological changes are coalescing to take us into a new technology paradigm these include the rise of advanced analytics coupled with data fication and the Internet of Things the blockchain will have to work synergistically with these if it's true capacities are to be realized but to understand this next generation web we need to understand a bit about the history of the Internet going back to the early 90s web 1.0 was the first generation of the world wide web it was based primarily on the technology of HTTP which worked to link documents on different computers and make them accessible over the Internet HTML was then used to display these documents so that any connected computer with a browser could access and read a web page this first iteration of the web was all about information as it enabled us to exchange information much more efficiently and head Sagat the name information superhighway even though it was a revolution in information exchange content creators were few with the vast majority of users simply acting as consumers of contents it was really very static and lacked interactivity whereas in the web 1.0 era people were limited to pass a viewing of contents with web 2.0 websites allowed users to interact collaborates and become the creators of contents with web 2 people could not only read from the web but also write to it and thus it got the nickname the readwrite web by the early 2000s new server-side scripting technologies such as PHP enabled developers to easily build applications where people could write information to a database with that information then being dynamically updated every time they refresh the page almost all of the websites that dominate the web today are based on this server-side scripting technology it gave the social networking blogging video sharing obey YouTube Facebook and all the other large platforms the most people spend most of their internet time using the idea of web 3.0 has been around for a while but it's only very recently with the development of the blockchain that it is actually starts to become something real web 2.0 has evolved to become highly centralized around very large platforms running out of ever larger data centers creating many issues surrounding security privacy control and concentration of power in the hands of large enterprises it's only today that these issues are starting to enter into mainstream discourse web 3 is set to disrupt this whole technology paradigm as the critical change that is coming about is the word D centralizing the web the blockchain provides the protocols and cryptography for a globally distributed network of computers to collaborate on maintaining a public secure database and with a virtual machine like aetherium we can run code on this creating a new set of distributed applications these new technologies of the blockchain ipfs and the distributed web enabled us to reconfigure the internet into a distributed global computer so that we're no longer dependent upon the web platforms and data centers of web 2.0 to run the internet but now can build and run applications on this shared global computing infrastructure as might be polled of the Institute for the future noted it starts with the realization that the internet that we know today is only one possible interpretation of the original vision of an open clear to peer network independent of any centralized technology commercial entity or sovereign governments think of it as a first curved internet one that is increasingly vulnerable to abuse and even collapse to date we've largely taken the infrastructure of the internet for grants it's all of the innovation and action has been focused on the application layer that sits on top of it on web applications like social networking or e-commerce with the developments of blockchain and particularly with this third generation we're starting to innovate on the low level protocols asking not if we can build a better web application but if we can build a better internet the implications of the decentralized web are indeed radical in that it enables us to create automated services disintermediate existing incumbents and enable people to set up their own secure networks of exchange empowering them in new ways the blockchain will be a core part of web 3.0 but the next-generation internet would also see the convergence of the Internet of Things and big data analytics the ongoing fundamental process of data fication will be a key aspect to this next-generation Internet as we increase in the instrument our world's data will flow from all sources about everything data fication is the term given to our newly found ability to captures data many aspects of the world in our lives that have never been quantified before this process results in what we call big data vast amounts of unstructured data that can be mined by advanced analytical methods to gain new insight into the world around us this is important with respect to the blockchain because firstly it means we'll have a lot of sensitive data that we want to store secondly we will be quantifying accounting for and exchanging all sorts of value that we did not or could not in the past thirdly such a diversity of sources of data combined with advanced analytics which could find cross correlations and patterns within it can provide a new source to verify the data that is being inputted to the blockchain without depending on a centralized Authority for validation the next-generation internet will be much smarter whereas web 1 was dumb and web 2 was dynamic web 3 will incorporate various aspects of machine learning and cognitive computing as a service as it becomes infused into almost all applications making the web truly adaptive responsive and personalized whereas web 1 and web 2 were largely about people exchanging information in web 3 machines will come online and the internet will become something much more physical as billions of devices and actuators connected to all sorts of things from tractors to watches to factories and drones enabling them to interact and coordinate machine to machine the value of the Internet of Things IOT will not be in making one device or system smart it will be in enabling seamless processes across systems this will require open networks that can communicate and coordinate components on demand across domains organizations and systems the envision of IOT is not to have our lives populated with thousands of smart things but instead to change our world from discrete things to service processes to do this these technologies will have to communicate securely it appear dynamically allocating resources and this will require some kind of distributed secure infrastructure like the blockchain and likewise micro economies this ties in with the broader process of change which comes about as we move into a services economy called services ation which is the shift from products and the ownership of things to the access of services on demands for example instead of only a car you simply have access to a car sharing service this economy of temporary usage VA services requires the formation of frictionless markets and automated exchanges that the blockchain is well-suited to support as we'll discuss in a future video these components of the next generation internet the blockchain the Internet of Things and advanced analytics are each of them very powerful technologies that will have a profound effect on society they will take us much further into this new worlds of the information age as power shifts in a radical way from people in hierarchical institutions to automated networks and the algorithms that coordinate them in the coming decades more and more of our systems of organization will move to the Internet and it will become vastly more complex than today in web-one and web 2 we develop the internet from small to large through a client-server architecture the work decentralized the web around large data centers but the internet after data fication and all these IOT devices have come online will not be large it will be more like infinite you can get from small to large by centralizing but you get from large to infinity through distributing and that's what the blockchain can do for this next generation Internet technologies are just tools that enable us to do things the interesting part of the blockchain is really what it enables in terms of new forms of distributed organization as one commentator noted the blockchain is an institutional technology not an information technology there's an enormous difference between the two institutional revolutions are things that don't happen very often blockchain technology enables new forms of network distributes to organizations something that runs very much contrary to our existing organizational paradigm and that's what makes it somewhat difficult for us to understand the organizational model of the Industrial Age that we inherit today was one of centralization in order to achieve economies of scale through mass production thus reducing unit cost and providing for a mass society the technologies of the Industrial Age selectively favored centralization of production within closed hierarchical organizations manufacturing is in centralized factories transport systems are centralized around transport hubs education within schools and universities entertainment centralized within mass media organizations and governance centralized within state-run organizations and so on the information revolution is in the process of taking us into a new world of distributed networks as the organizational paradigm of the Information Age the combination of telecommunications networks and computerized coordination enables us to replace centralized management with enclosed hierarchies with open networks as the underlining technology matures were able to convert more and more systems that were previously closed and centralized and have them managed through automated networks and the blockchain is just one more stage in this process we saw this with the rise of the online platforms like eBay uber or Alibaba social networks blogging etc that built massive networks of uses exchanging goods and services but these platforms were still dependent upon the centralized organization to manage the shared database for the computing infrastructure for the algorithms for financial transactions and to enable trust and authentication in the network the decentralized web takes these platforms a step further by offering a shared open and secure database that can be trusted by all parties and a set of protocols for the secure exchange of value between organizations and individuals peer-to-peer the web platforms are open networks this means they do not just optimize within a given organization but can enable coordination across whole industries indeed this is why and how they're quickly supplanting the closed organizations what centralized organizations enabled was trust cooperation and coordination within organizations but what the blockchain enables is trust coordination and cooperation between organizations and between individuals if we look at how our society and economy is currently organized we'll see many closed organizations that are internally optimized but when we look at the inter organizational space it's extremely inefficient along many dimensions if we look at the way businesses coordinate along a supply chain or the way nation-states interoperate in the global political system we will see there is huge redundancy and friction caused by discontinuities a classical example of this is the border system between nation-states and the bureaucratic procedures for obtaining a visa for moving from one nation to another which creates a massive amount of friction at the inter organizational space and it's because those organizations don't have an effective into organizational infrastructure for collaboration and coordination this greatly reduces the overall effectiveness of these systems and the delivered outcome for the end user when we look internal to these organizations they look like efficient well-oiled machines but when we look between them the whole space is very inefficient the whole space is very ineffective at delivering overall outcomes and this is part of the significance of the blockchain because it provides a shared trusted database between organizations it has the potential to switch to dynamics within economy and society from competition between close centralized organizations to collaboration between organizations and greatly strengthened working capacities across organizational boundaries the results of this would be much more efficient overall societal and economic outcomes indeed we can note that achieving coordination across organizations could result in quantum leaps in delivering outcomes and our capacity to tackle major global challenges of today such as environmental degradation where weak existing into organizational institutional infrastructure has gained little traction in this respects the blockchain has the potential to give us not just incremental improvements but an order of magnitude greater capacities within society through collaboration within whole ecosystems it is precisely this coordination across organizations industries nations and people that is required to provide the resources needed to tackle some of today's most complex challenges and it's precisely this that is significantly absent within existing institutional structures because of the centralizing forces prevalent within the industrial age we live in societies that are operated by many different closed organizations many different companies all producing cars and competing for market share many different governments that all focus on the interests of their citizens over those of others many different health care providers transport providers at cetera the results of this is though a huge amount of inefficiency in redundancy when taken as a whole many different companies all recreating the wheel within their own organizations and expending huge amounts of time and energy on trying to get ahead of their peers we assume that this is the normal state of operations that it's just human nature in some way but in fact it's really just a function of the institutional structures we have built over the past centuries as game theory will tell us people respond to the incentives and the socio-economic forces acting on them in the absence of cooperative structures competition is often the optimal strategy for individuals and organizations but once there is the institutional structures to enable trust and coordination between members cooperation can become a much more viable strategy for the agents involved because the blockchain enables this shared and trusted database that doesn't belong to any single organization it makes it greatly more possible and viable for organizations to collaborate on a single solution or single source and achieve much better results for each organization and the economy as a whole as an example of this cooperation across different closed organizations we could think about the design and construction of a building there may be many different companies involved in this process or creating their own designs and diagrams for the building with each having to continuously contact each other to access exchange and cross-reference all this information given a single shared database they could though or collaborate on a single design of the building making for a greatly more efficient overall process while at the same time each organization would benefit and thus the overall results are more efficient likewise the same is true for identity we currently have many different copies of our identity spread across many different organizations governments social networks employees etc but each of these only has a partial understanding of us currently we're recreating the will for each organization while data and reputation does not move well between them instead a single identity could be created on the blockchain that belongs to the individual with each organization then contributing to this data as they work together to create a more complete record of identity and reputation in so doing we've moved from all those frictions between these closed organizations to collaboration and synergies between them creating something that is greater than any of the parts they had before the same for a supply chain instead of each participant holding their own documents and records during each stage in supply chain a single record for the item could be created on the blockchain with each organization then contributing their information to it to create a single source of truth that is accessible to always need it while at the same time being more secure than having separate records in each centralized database the end results of this new institutional technology is a much greater capacity for inter organizational collaboration and powerful ecosystems that are greater than the sum of their parts given that all our current systems of organization that are centralized could be decentralized in this fashion using blockchain technology we can see how it really could enable every organization of society and economy organizations within society rarely operate in isolation they function as parts of ecosystems and the value for society is not created by anyone but instead by the flow of value across the ecosystem it's not Apple that delivers our iPhones it's a massive global supply chain of hundreds of different organizations collaborating whereas our previous institutional structures optimized for individual organizations the blockchain optimizes for the value within the whole ecosystem and thus potentially a much greater value for society as a whole the information revolution is changing the world from disconnected to connected the genie of hyper-connectivity is out of the bottle and connectivity along virtually all dimensions is proliferating daily as a consequence our systems of organization will change from being based around fixed structures and boundaries to being coordinated via connections instead of the controller components through fixed higher structures organization would emerge out the interaction and the exchange of value along those interactions enabling that will require a massive build-out of secure frictionless information networks this global cloud computer of blockchain to understand better how this shared database that enables inter organizational collaboration works we'll talk about distributed ledger technology as we've been talking about the blockchain is like another layer to the Internet that enables secure trusted records and transactions between people who may not otherwise trust each other the trust is in the technology computer code in mathematics rather than people and centralized institutions in this respect people sometimes talk about the blockchain as a trust machine in its capacity to enable a network where Trust is created by design it's built into the system automatically because the blockchain creates a trusted database it can function as a record of value storage in exchange these records of value and transactions may be called Ledger's since ancient times Ledger's have formed the backbone to our economies to record contracts and payments for the buying and selling of goods or the exchange of assets like property these ledges started out as records in stone clay tablets and papyrus and later paper as they evolved into the ledger books supporting modern accounting these Ledger's enabled the formation of currencies trade lending and the evolution of banking over the last couple of decades though these records have moved into the digital realm as whole rooms of people working to maintain accounts have been replaced by digital computers which have made possible the complex global economic system we live in today this record-keeping system is once again being revolutionized as these Ledger's are shifting to a global network of computers which is cryptographically secure fast and decentralized what we call distributed ledger or distributed ledger technology DLT for shorts a distributed ledger can be described as a ledger of any transactions or records supported by a decentralized network from across different locations and people eliminating the need of a centralized Authority all the information on ledger is securely and accurately stored using cryptography and can be accessed using keys and cryptographic signatures any changes or additions made to ledger are reflected and copied to all participants in a matter of seconds or minutes the participants at each node of the network can access the recording shared across the network and can own an identical copy of it at the same time these networks make constantly available for examination a full audit trail of the information history which can be traced back to the moment when a piece of information was created and every participant in the network can get simultaneous access to a common few of the information these Ledger's can be used for the recording tracking monitoring and transacting of all forms of assets all asset registries inventories and exchanges including every area of economics finance and currencies physical assets such as cars and houses and intangible assets such as votes ideas health data reputation etc in this case the blockchain can serve as a public record repository for whole societies including the registration of all documents events identity and assets in this system all property could become smart property this is the notion of encoding every assets of the blockchain with the unique identifier such that the asset can be tracked controlled and exchanged on the blockchain for example distributed edges could be used to replace or supplement all existing intellectual property management systems as they can register the exact content of any digital asset such as a file image health record or code to the ledger and give it a unique identifier in the form of the hash values that we discussed earlier there are two main classes of distributed ledger public Ledger's and permission Ledger's the former type is maintained by public nodes and is accessible to anyone Bitcoin is a well-known example of a public blockchain where anyone can read the chain anyone can make legitimate changes and anyone can write a new block into the chain ripple is an example of a permission blockchain where the creators of the network determine who may act as transaction validators on that network distributed ledger platforms in each category have their own unique features some are designed for specific types of application and others for more general use for instance in the quarter DLC platform which is a consortium of more than 70 of the world's largest financial institutions the sharing of individual ledger data is limited to parties with the legitimate need to know which is not the case for public platforms DLT technology can have a powerful disintermediation effect as data can be put directly onto the shared database by the nodes in the network there is no longer need for a centralized organization to provide this service a developer can create a DLT on a blockchain and use public/private key cryptography to give people secure storage space on that ledger allowing people to own their own data which creates a very different scenario to the world we live in today currently centralized organizations like Google and Facebook suck up all of the little bits of data we need behind us and use it to serve us customized advertisements from which they create their revenue this results in a huge power imbalance within society where centralized organizations armed with teams of mathematicians and computer scientists use mountains of data to influence people's behavior towards purchasing with products of their appetizers data that is a very valuable asset and the information society and of critical importance to tackling major societal challenges is being used against us in many ways creating a stumbling the societies are becoming increasingly aware of in a world of distributed edges people have their own little databases on the blockchain and can own their own data giving it to organizations to use when and where needed fundamentally reversing the current dynamic and truly empowering individuals your health records reside in your health ledger and different health care providers can access and update that single record but only with the permission of the end-user as the data remains theirs and they choose who can have access to it likewise when people own their own data on a distributed their germ they can transact directly its appear as is the case with Bitcoin with the existing traditional system when you pay for a ride in a taxi with a credit card it looks like you're paying the driver directly when in fact what is happening is that a database record belonging to my bank is being debited and a database belonged to the bank of the company that the driver works for is being credited in this respect we can note that in our society value and data do not really belong to individuals all the time they're being held behind the walls of some centralized organization and we are dependent upon them to secure and validate it's creating huge power imbalances within society in contrast with the Bitcoin blockchain the individual has a ledger record and a secure key with which they can access their records when they send money they send it directly to the other person's record it simply gets debited from your record and added to theirs directly peer-to-peer no centralized organization holds that data distributed ledger technology can greatly improve transparency reduce corruption and improve security while reducing overhead costs of auditing accounting and legal issues currently records of value are hidden within the databases of centralized organizations where they're largely in excess for their many possible uses within other systems they are open to manipulation by members within those organizations which breeds corruption and because of that there has to be all sorts of regulation and legal requirements that create many overhead costs and it's this they are centralized points of failure for critical data sources as large concentrations of valued data proved very attractive for malicious actors likewise it is inefficient to be constantly updating and synchronizing data across many centralized databases by putting the information on a shared ledger it can be easily made accessible and visible on demand as needed because there is tamper proof we can remove many existing points of corruption and the associated need for regulation likewise it is made secure by distributed networks without a single point of failure and continuously synchronized across all nodes to create a single source of truth for all users one of the key technology innovations of second-generation blockchains has been the development of what are called smart contracts smart contracts are computer code that is stored inside of a blockchain which encode contractual agreements smart contracts are self executing with the terms of the agreement or operation directly written in two lines of code stored and executed on the blockchain computer a contract in the traditional sense is a binding agreement between two or more parties to do or not do something each party must trust the other parties to fill their side of the obligation they are a written or spoken agreement that is intended to be enforced by law a multiplicity of different contractual agreements form the institutional foundations to our modern society and economy which have evolved since ancient times if we think about something as seemingly simple as a cafe serving a cup of coffee we will see that this process is really enabled by a massive amount of contractual agreements between different parties that enable them to cooperate in delivering that outcome contracts between employees and employer of the coffee shop contracts that provide workers with health coverage contracts that ensure the coffee-shop contracts between suppliers along the supply chain contracts between property owner and tenant etc our economies are powered by a massively complex set of contractual agreements that are currently created and enforced by centralized organizations like insurance companies and banks which themselves are supported by the ultimate centralized authority in the system the nation-states institutions are societies and economies almost completely dependent upon third party organizations to maintain and enforce those contractual agreements smart contracts feature these same kind of agreements to act or not act but they removed the need for the trusted third party between members involved in the contracts this is because a smart contract is both defined by the computer code and executed or enforced by the code itself automatically without discretion at such blockchains as smart contract technology can remove the reliance on centralized systems and enable people to create their own contractual agreements that can be automatically enforced and executed by the computer code these smart contracts are decentralized in that they do not subsist on a single centralized server but are distributed and self executing across a network of nodes this means that untrusted parties can transact with each other in a much more fluid fashion without depending upon third parties to initiate and maintain the rules of the transaction likewise smart contracts enable autonomy between members meaning that after it is launched and running a contract in its initiating agents need not be in further contacts one illustration of this concept is offending machine unlike a person a vending machine operates algorithmically you provide the source input of money and product selection which the machine takes as input and simply execute on a rule automatically to produce the pre-specified output the same instruction set will be followed every time in every case when you deposit money and make a selection the item is released there is no possibility of the machine not wanting to or not feeling like complying with the contract or only partially complying as long as it's functional there's another example we can think about a situation where four people pool their money to make a joint investment that will return interests of them a smart contract could be programmed on the blockchain to take any interest that is created divided into four and sent each amount to the corresponding wallets of the different stakeholders a smart contract is then ready just an Accounts on the blockchain that is controlled by code instead of by user because it's on the blockchain it is immutable that means the code cannot be changed and thus all participants in this investment can be assured that they will get their fair share automatically the code dictates how the process will take place and no individual has the power to change it no individual no organization no government can censor alter or manipulate the contracts in this respect it's often said that code is law in the sense that the code will execute no matter what of course computer code has been for a while now acting as the law for example as services have gone online we're increasingly faced with web forms that strictly control what inputs are allowed if you want to buy an item on iTunes USA then you'll have to have a credit card with the US address the system will also enforce this by not letting you complete the purchase with an incorrect address as another example a logistics company could use smart contracts to execute code that says if I receive cash on delivery at this location then trigger a supplier request to stock a new item since the existing item was just delivered a combination of smart contracts with blockchain encoded property gives us the idea of smart property smart property is simply property whose ownership is controlled via blockchain encoded contractual agreements for example a pre-established smart contract could automatically transfer the ownership of a vehicle title from the holding company to the individual owner when all the loan installments have been cleared the key idea of smart property is controlling ownership and access to an asset by having it registered as a digital asset on the ledger and connecting that to a smart contract in some cases physical world hard assets could quite literally be controlled via the blockchain one example of such an IOT blockchain system is SLOC it a door lock that is connected to a smart contract on the blockchain which controls when and who can open the lock this enables anyone to rent sell or share their property without need of a middleman with such innovations parking spots can be subletted on-demand Airbnb accommodation could become fully automated or someone with twenty bikes in Bangladesh could rent them out with smart contract locks the bike could shut itself off if it is not been paid for or if it's stolen then there could be an automatic deposit system or likewise if the person wanted they could simply pay a certain price to purchase the bike at any time like all algorithms smart contracts require input values and only act if certain predefined conditions are met when a particular value is reached the smart contract changes its state and executes that programmatically predefined algorithms automatically triggering an event on the blockchain thus the workings of the overall contracts can only be as good as the inputted data if both data is imported to the system then false results will be outputted blockchains cannot access data outside of their network thus requires some form of trusted data feed as input to the system what may be called an Oracle an Oracle is a data feed provided by an external service and designed for use in smart contracts on the blockchain Oracle's provide external data and trigger smart contract executions when predefined conditions are met such conditions could be any data like weather temperature the quantity of items in stock the completion of a successful payments changes in the prices on the stock market etc an Oracle in the context of block chains and smart contracts is then an agent the finds and verifies real-world occurrences and provides this information to a blockchain to be used by smart contracts Oracle's are third-party services which are not part of the blockchain consensus mechanism thus whether it be a news feed website or a sensor the source of information needs to be trustworthy as an example we could think of an online betting platform based on the blockchain that uses smart contracts to automatically execute payouts to people who have placed bets on sports matches the smart contract system would then have to be connected to a trusted Oracle to provide it with the score of the matches as of present this Oracle would likely have to be associated with some trusted third party centralized organization like a sports channel or Bloomberg for stock prices however in the future through data fication an IOT pervasive sensing this might also be automated given the use of advanced analytics using automated Oracle's that draw data from a myriad of sources and complex analytics to find cross correlations that provide a statistical assurance that for example a given event occurred or did not occur the advantages of smart contracts are numerous firstly they are automatic which could remove the time and costs associated with managing and enforcing them making them more efficient as they can be cheaper and faster to run through this form of automation a much greater amount of exchange could take place that otherwise would have never happens in such a way we can see how distributive edges and smart contracts are key parts in enabling a true services economy where ownership is displaced by temporal usage through the on-demand provisioning of services secondly they could reduce corruption as code is both transparent in its workings and automatically executed this leaves the room for individuals or organizations to alter it to their advantage thirdly they can reduce dependency upon centralized organizations that people may be able to set up their own contractual agreements peer to peer thus limiting the arbitrary power of centralized organizations lastly they can also deliver certainty as smart contracts guarantee a very specific set of outcomes that are predetermined before hands enabling all parties know exactly what will happen but herein also lies some of their limitations by automating the execution of a contract they are dependent upon formal rules with well specified inputs and leave little room for a multiplicity of eventualities where the rules may need to be slightly altered because of unforeseen circumstances for example a car that's being used on demand that operates through a smart contract may simply shut the user out if they have not paid their bill and would take little accounts of the facts but it may be a life-or-death emergency usage in the real world many unpredictable and unforeseen events to occur and rules sometimes need to be flexible and adapt Sporto accommodates and this is one advantage of having human oversight as people are much more capable at judging such circumstances and responding appropriately to complex unforeseen eventualities so the degree to which we can automate contracts is relative the kind of environment that is being operated in and in more complex situations they will often need to be some form of governing body to intervene when needed and this creates new complications surrounding governance that are still yet to be figured out the advent of the etherion platform in 2015 has worked to provide a virtual computing infrastructure for running applications on the blockchain this new form of program is called a distributed application or DAP for short aetherium was the first developer platform for building distributed applications it was a foundational general-purpose blockchain based platform that is a turing-complete virtual machine meaning that it can run any computer code although etherium was the first and still the largest platform for building distributed applications there are now others such as block stack oreos all of which provided the underlining infrastructure for building DAB's our working definition of a DAP is an application that runs on a network in a distributed fashion with participant information securely protected and operations executed in a decentralized fashion across a network of nodes taps use open source code operate autonomously with data and records cryptographically stored on a blockchain on a technical level a tab is very much similar to a normal web application except unlike with the normal web app where the back-end code is running on a centralized server a dab has its code running on a distributed peer-to-peer network a tap can have front-end code and user interfaces written in any language just like a normal app as such taps will often look and feel very much like regular apps and people will soon be using them in the coming decade without even realizing him like all apps perform specific functions whereas bitcoin is the decentralized value exchange a decentralized application aims to achieve functionality beyond transactions the middie exchange value many types of decentralized apps are starting to emerge as the underlining technology continues to progress already we can see many tabs represent alternatives to the existing popular web applications probably the most successful DAP to date is steam it steam it is a blogging and social networking websites on top of the steam it blockchain database the general concept is very similar to other blogging websites or social news sites like Reddit but the text content is saved in a blockchain using a blockchain enables rewarding comments and posts with secure tokens value in this way users can earn currencies for their posts and comments likewise for existing marketplace applications like eBay and Craigslist we have the decentralized version open Bazaar open Bazaar is an open source project developing a protocol for e-commerce transactions in a fully decentralized marketplace because the application connects people directly via peer to peer network it cost nothing to download and use it unlike sites like eBay or Amazon there are no fees to list items and no fees when an item is sold open Bazaar is not a company like eBay but an open source projects each user contribution etwork equally and is in control of their own storage and private data another example is Storch which is the decentralized cloud storage application similar to job box storage is based on blockchain technology and peer-to-peer protocols to provide secure private and a-fishing cloud storage system the application incentivizes storage providers and connects them with those who require it each file saved on the application is free encrypted and spread across the network until you're ready to use it again the keys to the database remain with the owners meaning the data is not accessible by a centralized cloud provider there are many other examples of DAPs but the general concepts can be applied to any area that requires secure records and benefits from decentralization these applications are automated which means they can operate at very low or even zero cost because of their snaps may be used to disrupt the existing platform economy as whole platforms like uber or Airbnb may eventually be converted into dabs that run automatically without the need for the centralized platform the advantages of dabs is that they're fully automated have superior fault tolerance and trustless execution these decentralized apps potentially represent the next generation of computing because the blockchain is a secure system that enables a trusted network it's often described as a value exchange protocol in this respect people often say that what the web did for the exchange of information the blockchain will do for the exchange of value just as the web revolutionized the use an exchange of information within society disrupting whole industries based upon the centralization of information so to the blockchain is set to do the same for the recording and exchanging of all forms of quantifiable value this idea of value lies at the hearts of the blockchain if there is no value involved in the process then there is no need for trust and no need to use the blockchain the vision of the internet of value is for any quantum of value to be exchanged as quickly and as fluidly as multimedia is today on the web although multimedia can move around the world almost instantaneously a single payment from one country to another is slow expensive and unreliable often taking days and involving numerous intermediary third parties to validate and process transactions at a significant cost thus it is no accident that the first widespread use of the blockchain was for currencies because it is the most immediate and obvious source for quantified value within society however to truly understand the revolutionary potential of this technology is to appreciate how value and its exchange influences and regulates almost all aspects of human affairs as a consequence the control of how value gets defined measured and exchanged is the key source of power and control within society and has been since the origins civilization today value of almost any kind is defined quantified and regulated by centralized organizations whether this is a national government creating their own currency or one's role within a hierarchy defining one's economic status or the branded clothing that we wear to signal to others our social status and value in society however the move into the networked society shifts the locus of organization from closed institutions to individuals and networks but off chain technology is a key element enabling this process by creating a shared ledger where people can own their own data it also enables a shift in the locus of value within economy to the individual in networks in a world of limited connectivity limited transparency unlimited peer-to-peer trust it was necessary to have third party institutions to define quantify and authenticate sources of value within society and economy but in a world of pervasive peer-to-peer connectivity transparency and trusted low cost automated networks value can be defined through a negotiation between peers within distributed networks the rise of digital currencies about one such example of this the surprising thing for a lot of people is that most major currencies like the dollar yen and euro aren't backed by anything they're just pieces of metal paper and entries in a bank account that get their value from everyone simply believing that they have value and accepting them as a medium of exchange and that's all it's really necessary currencies and money work a little bit like languages they are subject to network effects to give them value the more people who agree to and understand the language the more valuable that that specific language has as a form of communications dollars remnant B euros and bitcoins have no intrinsic value they're all social protocols and they merely represent a way of supporting the value flows between individuals in the past because of low levels have trusted here connectivity we required centralized institutions like governments and banks to get these value exchange networks started to support them regulate them and maintain them and this gave those organizations a lot of power this is a critical aspect that the internet and the blockchain are changing the blockchain enables us to create trusted and automated peer networks of exchange which greatly strengthens the capacities of people to negotiate and define value via direct here to peer exchanges people can now set up their own currencies with the value of the currency depending simply on what others are willing to pay for it Veeran automated peer-to-peer network exchange but the internet of value is more than just currencies because value is of course a much broader concept than just pure economic utility in talking about the internet of value it's important to recognize that on a societal level were moving into a post-industrial services economy the traditional conception of what society values is being revisited as a new set of societal and environmental factors re-enter the equation people are less and less content with the traditional concept of GDP as the sole metric for how well they're doing and more and more demanding actual quality of life which of course engenders a broader spectrum of values beyond economic utility over the past decades we've increasingly begun the process of tracking and accounting for different forms of value whether this is green bonds social impact bonds company loyalty schemes carbon accounting or a multiplicity of other forms but simply the erosion and loss of social and environmental capital that occurred during the Industrial Age is generating a recognition and growing awareness to their value metrics for how well a society is doing increasingly take account of many more environmental and social parameters in combination with GDP along with this recognition to the importance of different forms of value comes also the technical means the quantify an exchange them through the process of data fication information technology lets us measure track and exchange evermore types of value at ever smaller increments likes on Facebook people's attention carbon emissions etc with the rise of big data and IOT will be quantifying an ascribed value to almost everything and the blockchain will provide the network infrastructure for tracking and exchanging all these micro and macro quanta of value this shift from the narrow form of economic value that dominated in the Industrial Age to a broader spectrum of values that emerges within a post-industrial society is enabled by the Tribute alleges system that supports what we call token economies wherein we can define a token as a measure of any form of value and then built an economy around that token economies and the internet of value built upon the current expansion of digital markets brought about by the rise of the platform economy over the past decades with web 2.0 we've begun the process of expanding markets to more and more spheres of life that were previously organized via centralized coordination after only ten years or so of this process the biggest accommodation service in the worlds is no longer a centralized organization like the Hilton it's now an online market the same is true for the taxi industry the same is true for commerce with 10 million merchants and 440 million active users the Alibaba network is now reported as the largest retailer in the worlds after just 19 years of existence markets are complex they typically require the aggregation of large amounts of information and peer-to-peer interactions without the technology it is much more viable to achieve coordination very centralized hierarchical model but has become to quantify an account for more and more areas of life blockchain based networks will expand the capacities of plug-and-play markets to all spheres of activity social economic technological and environments on the Internet of value will function as the infrastructure to the emergence of the services economy which is currently taking place within post-industrial economies the move into a services economy results in the conversion of industrial age products into services whereas the product based economic paradigm was about the production and consumption of more products as measured by GDP a services economy is about value delivered a service is an exchange of value you don't get the product you just get its function and the value that it delivers as such all spheres of economy become redefined away from the static conception of units of products towards the more fluid exchange of value you don't buy lift to put in your office building you get it as a service paying only for the functional value it delivers in some offices now they don't even buy the carpets on the floor the function of the carpet is delivered as a service and they pay only for the value that's exchanged the blockchain is a key infrastructure enabling this services economy as it requires a very fluid dynamic an automatic tracking an exchange of value smart property and smart contracts will form the technological infrastructure powering the services economy as they operate within large peer networks automatically allocating resources and processing the financial debits and credits of value exchanges behind the scenes this huge shift in our economy lets us reconceptualize every industry to really question what is the actual value that it delivers and then reconstructed by building token markets around that value where anyone can participate in the delivery of the service with web 2.0 and the platform economy we extended the capacities of markets so that many more people could participate as exemplified by uber enabling anyone to operate as a driver however these markets were centralized around the platform operators and they were dependent on traditional currency systems and the financial system for processing transactions in web 3.0 blockchain applications will function as distributed automatic plug-and-play markets were extremely small increments of value can be exchanged directly it appear with very high levels fluidity when this is coupled with IOT and data analytics we'll be able to track the real value that things deliver which will help us to make the much-needed move from our product based economies to an outcomes economy the better reflects the underlying value being created in exchange with the ongoing revolution in in technology our economic systems of organization are being transformed and disrupted by the rise of information networks it started with the advent of the personal computer World Wide Web and with the rise of online platforms the disruptive power of information networks to reshape economic organization became ever more apparent today this process of economic transformation continues with a new set of technologies as we are currently in the process of remaking the technology stack of the Internet building what is called web 3.0 a primary component of which is the blockchain the defining feature of this next stage of economic development is that it decentralizes our economy and shifts operations to global information based networks like never before this distributed internet technology stack that is currently being built enables a network of computers to maintain a collective database of value ownership and exchanges via internet protocols this bookkeeping is neither closed nor the control of one party rather it is public and available in one digital ledger which is distributed across the network the most mature example of this is what we call the blockchain in the blockchain all transactions are logged including information on the date time participants and amount of every single transaction on the basis of sophisticated mathematical principles the transactions are verified by the so called miners who run the computing infrastructure required to maintain the Ledger's the technology of web 3.0 enables a new form of decentralized economy as it removes the dependency on a centralized authority for managing the network instead replacing it with a distributed consensus model managed by many this shared securely encrypted database enables trustless peer-to-peer interactions via new internet protocols people can begin to set up their own networks for coordination and direct exchanges of value peer-to-peer and it enables the rules of these transactions to be automated in new ways at the heart of this system is the distributed ledger which records the exchanges of value these distributed Ledger's can account for and validate the exchange of any form of value it may be a currency it may be property it may be a kilowatt hour of energy the usage of a parking spot the number of followers a person has on social media these distributed Ledger's provide the infrastructure for building token economies a token is simply a quantified unit of value tokens are both generic and fungible it is generic in that it can be used to define any form of value and it is fungible meaning it is exchangeable between different specific forms of value traditional monetary currencies are not fully fungible as there are many circumstances when one cannot exchange a monetary currency for other forms of value for example likes on social media may have a certain value but typically cannot be directly exchanged for monetary currencies a token differs from our traditional monetary currency and that it is more generic our existing currencies define a particular type of monetary value what we call utility which is based upon the economic logic of the industrial economy while tokens because they are more generic can define a broader set of values social capital natural capital or cultural capital for example natural capital is the integrity of an ecosystem that enables it to function and provide ecosystems services to people in our traditional economic model we only quantify and account for the services that the ecosystem delivers such as food water materials etc however we do not account for the integrity of the ecosystem that enables it to function the generic nature of the token means it can be used to account for values such as this natural capital the capacity to differentiate between different forms of value is made possible by the programmability of token units because tokens are digital they are also programmable which enables one to specify certain rules for that token and have those rules executed when it is exchanged thus enabling certain constraints or possibilities in its usage one can specify that a certain token is only spendable under certain terms or specify how it can be converted for example one could program the token so that it cannot be exchanged for diamonds that are mined in a particular location of the world known for its use of slave labor in this way the token is not just a unit of utility but also expresses social values likewise one could create a health care allowance in dollars or Euros that could be programmed on the blockchain so that it can only be used to pay for health care at certified parties automating these measures leads to a considerable decrease in bureaucracy this programmable token system works to shift our economies from a single value model to a multi value model they create many different types of value and economies but still retain the possibility for exchange between them the distributed web is the convergence of the economic market system with information technology that enables us to convert traditional organizations into distributed markets based on tokens tokens define whatever is a value within that organization and the market system is used as a distributed coordination mechanism for managing and growing that resource by creating an expanded definition of value and converting closed organizations into open markets this means that we can vastly expand the scope and capacities of the economy the provisioning of services within the economy no longer becomes dependent upon a limited number of centralized organizations acting for profit but instead anyone can now provide the service via these open protocols this means we can harness the resources of the many in a distributed fashion instead of being dependent upon a few likewise the token economy can harness the motives of individuals not just for financial rewards but for a multiplicity of values to illustrate how this works let's think about the service of cloud data storage currently this is provided by a limited number of enterprises like Amazon and Microsoft these centralized organizations have huge data centers but still those data centers are only a very small fraction of the storage capacity in the world most of the storage is in the personal computing devices of end-users and most of that is not being used a file coin is one organization that works to create a distributed token economy for this storage file coin is a decentralized storage network that turns cloud storage into an algorithmic market the market runs on a blockchain with a native protocol token also called file coin which miners earned by providing storage to clients conversely clients spend file coins hiring miners to store or distribute data the sum of all these computers that are coordinated through an automatic market system on the blockchain can provide a much larger more resilient system than the centralized model while reducing redundancy and inefficiencies in the overall system it also pushes the provision of the service out to the location where it is demanded as people are connecting peer-to-peer locally instead of going to the centralized server that may be on the other side of the planet tokens such as file coins can be exchanged for other currencies or members can hold on to their tokens whose value may appreciate as the networks grow over time this illustrates a very interesting aspect to tokens anyone who uses the system is also an investor in the system thus tokens merge investment capital and liquid exchange capital in new ways in the traditional capitalist model we have a divide between owners of capital and workers a divide between a more fixed investment capital and liquid exchange currencies the shares in a company are not the same thing as what people get paid with for working in that enterprise and use for everyday exchanges in the market this creates the notorious divide within the industrial economy described by Karl Marx between the capitalists that make money off their investments in the workers that have to stay selling their labor for money without ownership tokens represent both the inherent value of the community which is its capital investment and they are also units of exchange within that ecosystem the founders of the project issue a number of tokens at inception and sell those for someone to use the system they have to buy the tokens in so doing they become part investors in the project but they also use those same tokens to make exchanges within the market thus the people creating the value in the ecosystem are also getting paid in tokens meaning the workers that are creating the value through their work also have ownership within the organization in the traditional utility-based exchange of cash people have no ownership in the organization they just try to make money and this can create divides between the owners and the users the token system works to better align the incentives of the individuals with the overall system because the value of the tokens they earn is also dependent upon the value of the whole when you are working for a token network you are both working for yourself and for the whole organization as the to become more aligned unlike the traditional divide between capitalist and worker the token system enables networks to overcome the chicken-and-egg problem if you are the first user of a network like eBay then the value would be very low thus it is difficult to get the network started because it has to reach a critical mass before it will be of value to the users this means that it may require a large investment to create a network the Silicon Valley model worked by having large initial venture capital backing that enables them to overcome this but it means that most networks don't get off the ground and that once a network reaches scale and has value it becomes dominant and very difficult to compete with resulting in a lock-in effect and making it easy for large incumbent organizations to become extractive over time it also means that those who founded the organization win big time if the network takes off it creates a winner-takes-all dynamic with most people losing because of the threshold the token system extends the benefits of being an early adopter of a new network to all the users and thus helps to solve this issue it does this by issuing tokens for anyone to purchase at the beginning of the project as the project grows the tokens come to have greater value for all of the holders this also works to make the users of the network promoters of that organization because as it grows the tokens that they hold become more valuable it incentivizes people to join networks early so as to gain the benefits of the increase in their token value as it grows which reduces the problem of thresholds with this technology companies no longer have to go to traditional capital markets through an initial public offering of shares in the company in exchange for money but instead they simply sell tokens directly on the Internet to raise initial capital for the project in what is called an initial coin offering or IC o---- this means that founders can monetize their networks directly by simply holding their tokens and making the network useful to date we have had an Internet patched onto the side of an economy operated through the many centralized organizations of the Industrial Age creating a strong contradiction between the underlying technology and the institutional arrangements the distributed web will work to transform this by merging information networks and economic organization as the flow of information an economic value becomes one this will greatly reduce our dependency on centralized organizations expanding markets as systems of organization the global market economy will become available to the many through small distributed peer-to-peer interactions running through web protocols as the decentralized internet takes us a step further into the networked economy [Music]"
    },
    {
        "id": "2371a47c-0079-44de-b55f-88e7713a3883",
        "type": "video",
        "domaine": "technology",
        "titre": "Blockchain In 7 Minutes | What Is Blockchain | Blockchain Explained|How Blockchain Works|Simplilearn",
        "url": "https://www.youtube.com/watch?v=yubzJw0uiE4",
        "description": "This video on ",
        "chaine": "Simplilearn",
        "durée": "7:03",
        "keywords": [
            "phil transaction jack",
            "jack public key",
            "public distributed ledger",
            "sam send jack",
            "bitcoins sam ted",
            "blockchain technology blockchain",
            "jack ted sam",
            "jack private key",
            "friends jack ted",
            "complex mathematical problem"
        ],
        "transcription": "ever wonder if there's an easier way to complete transactions without having to deal with online wallets banks and third-party applications well it's possible thanks to blockchain here's everything you need to know about blockchain imagine four friends jack ted sam and phil meet up for dinner after they're done jack pays the bill and all of them decide to split the expense amongst each other now on the next day when phil sends his share to jack via online money transfer the transaction goes through without a hitch then ted and sam send their respective shares to jack but their transactions don't go through the failed transaction cites some issues at the bank that's when jack comes to know about the many ways a bank transaction could fail it could be due to technical issues at the bank one of their accounts were hacked daily transfer limits being exceeded and sometimes additional charges like transfer charges associated with transferring money to solve these problems the concept of cryptocurrency came into existence cryptocurrencies are a form of digital or virtual currency that run on a technology known as blockchain thanks to blockchain cryptocurrencies are immune to counterfeiting don't require a central authority and are protected by strong and complex encryption algorithms and in a market of more than thousands of cryptocurrencies like litecoin ethereum z cash and so on one reign supreme bitcoin now let's go back to our previous example and have phil ted and sam send jack two bitcoins each as their contribution to the previous night's dinner let's assume phil ted and sam have three bitcoins in reserve while jack has five first phil sends two bitcoins to jack a record is created in the form of a block the transaction details between them is permanently inscribed in this block this record also holds the number of bitcoins each of the friends own so after phil's transaction jack has seven bitcoins while phil has one following this sam and ted send two bitcoins to jack a new block is created for each of these transactions these blocks hold the transaction details as well as how many bitcoins sam ted and jack have in reserve these blocks are linked to each other as each of them takes reference from the previous one for the number of bitcoins each brand owns this chain of records or blocks is called a ledger and this ledger is shared among all the friends which acts as a public distributed ledger this forms the basis of blockchain so what happens when phil has only one bitcoin left and he tries to send two more bitcoins to jack the transaction will not go through this is because all his friends have copies of the ledger and it's clear that phil has only one bitcoin left his friends will flag this transaction as invalid a hacker will not be able to alter the data in the blockchain because each user has a copy of the ledger the data within the blocks are encrypted by complex algorithms all of this is made possible with the help of blockchain technology blockchain can be described as a collection of records linked with each other strongly resistant to alteration and protected using cryptography now let's have a closer look at the bitcoin transaction between jack and phil and find out how it works every user in the bitcoin network has two keys a public key and a private key the public key is an address that everyone in the network knows of like an email address of a user the private key is a unique address that only the user has knowledge of something like a password first phil passes the number of bitcoins he wants to send to jack along with his and jack's unique wallet address through a hashing algorithm all of this is part of the transaction details these details are encrypted using encryption algorithms and using phil's unique private key this is done to digitally sign the transaction and to indicate that the transactions came from fill this output is now transmitted across the world using jack's public key with this the message or transaction can be decrypted only by jack's private key which only jack has knowledge of different cryptocurrencies use different hashing algorithms while bitcoin uses the sha-256 algorithm ethereum which is also a famous cryptocurrency uses one known as ethash this transaction and several other similar ones are taking place all around the world these transactions are validated and then added block by block the people who validate these blocks are called miners for a block to be validated and added to a blockchain miners need to solve a complex mathematical problem the miner who solves this first adds the block to the blockchain and is rewarded with 12.5 bitcoins the process of solving the complex mathematical problem is called proof of work and the process of adding a block to the blockchain is called mining with this phil and jack's wallets are updated just like every person in the network who has completed a transaction now that you know about blockchain and its important concepts time for a small quiz what is the concept of blockchain that ensures data cannot be altered by any of the users within the network a public distributed ledger b proof of work c proof of stake d hash encryption let us know what you think is the right answer in the comments below three lucky winners will get amazon gift vouchers details are mentioned in the description below let's have a look at how walmart uses blockchain to provide its customers with better service walmart was facing problems in delivering quality products to its customers they were facing a high return rate and large amounts of refunds due to their products bad quality they were unable to determine the point of failure in the supply chain which started from farm to storage to transportation to processing all the way to the customer then walmart adopted blockchain technology with blockchain the quality of the goods at each step was permanently inscribed within a block for example when a customer flags a product as damaged it can be correctly identified where the product got damaged in the entire supply chain thus helping walmart to identify the problem areas and fixing them and this is just one of several ways blockchain is used in real life applications can you think of any others let us know in the comments down below that's all for now thank you for watching and stay tuned for more"
    },
    {
        "id": "7bc5dc04-25ad-49c2-a66d-63ccca56ceae",
        "type": "video",
        "domaine": "technology",
        "titre": "How does a blockchain work - Simply Explained",
        "url": "https://www.youtube.com/watch?v=SSo_EIwHSd4",
        "description": "What is a ",
        "chaine": "Simply Explained",
        "durée": "6:00",
        "keywords": [
            "block",
            "blocks",
            "blockchain",
            "hash",
            "previous block",
            "incredibly popular nowadays",
            "tamper",
            "chain",
            "network",
            "previous"
        ],
        "transcription": "Blockchains are incredibly popular nowadays. But what is a blockchain? How do they work, what problems do they solve\nand how can they be used? Like the name indicates, a blockchain is a\nchain of blocks that contains information. This technique was originally described in\n1991 by a group of researchers and was originally intended to timestamp digital documents so\nthat it’s not possible to backdate them or to tamper with them. Almost like a notary. However it went by mostly unused until it\nwas adapted by Satoshi Nakamoto in 2009 to create the digital cryptocurrency Bitcoin. A blockchain is a distributed ledger that\nis completely open to anyone. They have an interesting property: once some\ndata has been recorded inside a blockchain, it becomes very difficult to change it. So how does that work? Well, let’s take a closer look at a block. Each block contains some data, the hash of\nthe block and the hash of the previous block. The data that is stored inside a block depends\non the type of blockchain. The Bitcoin blockchain for example stores\nthe details about a transaction in here, such as the sender, receiver and amount of coins. A block also has a hash. You can compare a hash to a fingerprint. It identifies a block and all of its contents\nand it's always unique, just as a fingerprint. Once a block is created, it’s hash is being\ncalculated. Changing something inside the block will cause\nthe hash to change. So in other words: hashes are very useful\nwhen you want to detect changes to blocks. If the fingerprint of a block changes, it\nno longer is the same block. The third element inside each block is the\nhash of the previous block. This effectively creates a chain of blocks\nand it’s this technique that makes a blockchain so secure. Let's take an example. Here we have a chain of 3 blocks. As you can see, each block has a hash and\nthe hash of the previous block. So block number 3 points to block number 2\nand number 2 points to number 1. Now the first block is a bit special, it cannot\npoint to previous blocks because it's the first one. We call this the genesis block. Now let's say that you tamper with the second\nblock. This causes the hash of the block to change\nas well. In turn that will make block 3 and all following\nblocks invalid because they no longer store a valid hash of the previous block. So changing a single block will make all following\nblocks invalid. But using hashes is not enough to prevent\ntampering. Computers these days are very fast and can\ncalculate hundreds of thousands of hashes per second. You could effectively tamper with a block\nand recalculate all the hashes of other blocks to make your blockchain valid again. So to mitigate this, blockchains have something\ncalled proof-of-work. It's a mechanism that slows down the creation\nof new blocks. In Bitcoins case: it takes about 10 minutes\nto calculate the required proof-of-work and add a new block to the chain. This mechanism makes it very hard to tamper\nwith the blocks, because if you tamper with 1 block, you'll need to recalculate the proof-of-work\nfor all the following blocks. So the security of a blockchain comes from\nits creative use of hashing and the proof-of-work mechanism. But there is one more way that blockchains\nsecure themselves and that's by being distributed. Instead of using a central entity to manage\nthe chain, blockchains use a peer-to-peer network and anyone is allowed to join. When someone joins this network, he gets the\nfull copy of the blockchain. The node can use this to verify that everything\nis still in order. Now let's see what happens when someone creates\na new block. That new block is send to everyone on the\nnetwork. Each node then verifies the block to make\nsure that it hasn't been tampered with. If everything checks out, each node adds this\nblock to their own blockchain. All the nodes in this network create consensus. They agree about what blocks are valid and\nwhich aren't. Blocks that are tampered with will be rejected\nby other nodes in the network. So to successfully tamper with a blockchain\nyou'll need to tamper with all blocks on the chain, redo the proof-of-work for each block\nand take control of more than 50% of the peer-to-peer network. Only then will your tampered block become\naccepted by everyone else. This is almost impossible to do! Blockchains are also constantly evolving. One of the more recent developments is the\ncreation of smart contracts. These contracts are simple programs that are\nstored on the blockchain and can be used to automatically exchange coins based on certain\nconditions. More on smart contracts in a later video. The creation of blockchain technology peaked\na lot of people’s interest. Soon, others realized that the technology\ncould be used for other things like storing medical records, creating a digital notary\nor even collecting taxes. So now you know what a blockchain is, how\nit works on basic level and what problems it solves. Want to learn how you can implement a simple\nblockchain with Javascript? Then checkout this video here. And as always: thank you very much for watching."
    },
    {
        "id": "8268976e-25cc-4e9d-84dd-89c9b63374b5",
        "type": "video",
        "domaine": "technology",
        "titre": "What is BLOCKCHAIN? The best explanation of blockchain technology",
        "url": "https://www.youtube.com/watch?v=3xGLc-zz9cA",
        "description": "Blockchain",
        "chaine": "Lucas Mostazo",
        "durée": "6:27",
        "keywords": [
            "land title information",
            "data block chain",
            "reason blockchain technology",
            "stores data block",
            "blockchain technology stands",
            "track data changes",
            "block chain stores",
            "public private blockchains",
            "chain stores information"
         
        ],
        "transcription": "[Music] many people think of blockchain as the technology that powers Bitcoin while this was its original purpose blockchain is capable of so much more despite the sound of the word there's not just one blockchain blockchain is shorthand for a whole suite of distributed ledger technologies that can be programmed to record and track anything of value from financial transactions to medical records or even land titles you might be thinking we already have processes in place to track data what's so special about blockchain let's break down the reasons why blockchain technology stands to revolutionize the way we interact with each other reason number one the way it tracks and stores data block chain stores information in batches called blocks that are linked together in a chronological fashion to form a continuous line metaphorically a chain of blocks if you make a change to the information recorded in a particular block you don't rewrite it instead the change is stored in a new block showing that X changed to Y at a particular date and time sound familiar that's because blockchain is based on the centuries-old method of the general financial ledger it's a non-destructive way to track data changes over time here's one example let's say there was a dispute between Ann and her brother Steve over who owns a piece of land that's been in the family for years because blockchain technology uses the ledger method there is an entry in the ledger showing that Adam first owned the property in 1900 when Adam sold the property to Dave in 1930 a new entry was made in the ledger and so on every change of ownership of this property is represented by a new entry in the ledger right up until Ann bought it from their father in 2007 and is the current owner and we can see that history in the ledger now here's where things get really interesting unlike the age old ledger method originally a book then a database files stored on a single system blockchain was designed to be decentralized and distributed across a large network of computers this decentralizing of information reduces the ability for data tampering and brings us to the second factor that makes blockchain unique it creates trust in the data before a block can be added to the chain a few things have to happen first a cryptographic puzzle must be solved thus creating the block the computer that solves the puzzle shares the solution to all of the other computers on the network this is called proof of work the network will then verify this proof of work and if correct the block will be added to the chain the combination of these complex math puzzles and verification by many computers ensures that we can trust each and every block on the chain because the network does the trust-building for us we now have the opportunity to interact directly with our data in real time and that brings us to the third reason blockchain technology is such a game-changer no more intermediaries currently when doing business with one another we don't show the other person our financial or business records instead we rely on trusted intermediaries such as a bank or lawyer to view our records and keep that information confidential these intermediaries build trust between the parties and are able to verify for example that yes and is the rightful owner of this land this approach limits exposure and risk but also adds another step to the exchange which means more time and money spent if anne's land title information was stored in a blockchain she could cut out the middleman her lawyer who would ordinarily confirm her information with Steve as we now know all blocks added to the chain have been verified to be true and can't be tampered with so an can simply show Steve her land title information secured on the blockchain and would save considerable time and money by cutting out the middleman this type of trusted peer-to-peer interaction with our data can revolutionize the way we access verify and transact with one another and because blockchain is a type of technology and not a single network it can be implemented in many different ways some block chains can be completely public and open to everyone to view and access others can be closed to a select group of authorized users such as your company a group of banks or government agencies and there are hybrid public private blockchains too in some those with private access can see all the data while the public can see only selections in others everyone can see all the data but only some people have access to add new data a government for example could use a hybrid system to record the boundaries of Anne's property and the fact that she owns it while keeping her personal information private or it could allow everyone to view property records but reserved to itself the exclusive right to update them it is the combination of all these factors decentralizing of the data building trust in the data and allowing us to interact directly with one another and the data that gives blockchain technology the potential to underpin many of the ways we interact with one another but much like the rise of the Internet this technology will bring with it all kinds of complex policy questions around governance international law security and economics here at the Center for international governance innovation we seek to bring trusted research that will equip policymakers with the information they need to advance blockchain innovations enabling economies to flourish in this new digital economy learn more about our work on blockchain technology by visiting our website and social media channels you"
    },
    {
        "id": "307574c7-e314-4451-a27d-337ed3dd3151",
        "type": "video",
        "domaine": "technology",
        "titre": "Blockchain Technology Simply Explained",
        "url": "https://www.youtube.com/watch?v=QJn28fFKUR0",
        "description": "Blockchain",
        "chaine": "AI Uncovered",
        "durée": "14:34",
        "keywords": [
            "blockchains blockchain technology",
            "secure transactions blockchain",
            "blockchain Works step",
            "blockchain quantum computers",
            "supply chain blockchain",
            "Finance Defy blockchain",
            "chain blockchain purpose",
            "chain transparency blockchain",
            "traditional Financial systems",
            "quantum resistant blockchains"
        ],
        "transcription": "in the digital age where information is power and security is Paramount a revolutionary technology has emerged to redefine how we perceive and manage data blockchain it's a groundbreaking Innovation that's much more than just the backbone of cryptocurrencies in this video we'll demystify this complex technology breaking it down into simple digestible terms whether you're a tech Enthusiast a curious beginner or a forward-thinking entrepreneur this video will provide you with a clear understanding of blockchain Technology its purpose capabilities workings types and its promising Future Let's Start what is a blockchain in simple terms imagine you're playing a game of Whispers where a message is passed from one person to another and by the end of the line the original message is often distorted now imagine if there was a way to ensure that the message remained the same no matter how many people it passed through that's the essence of blockchain in the simplest of terms a blockchain is like a digital diary that's shared among a group of people everyone in the group can write entries in this diary but once an entry is made it can't be changed or erased it's there for everyone to see Forever This diary isn't stored in one place like a library or a single computer instead it's distributed across many computers all over the world making it decentralized let's take an example suppose you and your friends decide to start a book club to keep track of who has which book you create a shared document every time a book changes hands the person who gives the book and the person who receives it both write an entry this way everyone in the club can see who has which book at any given time if someone tries to claim they returned a book when they didn't everyone else can check the document and see the truth that's a basic example of how a blockchain works in the world of technology this book club could be anything from a group of people making Financial transactions like Bitcoin to a network of computers sharing data the books could be anything of value like money property contracts or even votes in an election so in simple terms a blockchain is a transparent unchangeable decentralized digital diary that records transactions across many computers it's a way to ensure Trust accountability and Security in a world where these qualities are more important than ever what is the main purpose of a blockchain the main purpose of a blockchain is to enable secure transparent and tamperproof transactions in a decentralized manner it's about creating trust in a trustless environment let's break this down a bit Security in a blockchain each transaction is encrypted and linked to the previous one this chain of transactions is visible to everyone within the n network but altering any transaction requires changing all subsequent transactions which is computationally Impractical this makes the blockchain secure against fraud and tampering transparency every transaction on the blockchain is visible to all participants in the network this transparency ensures accountability and makes it nearly impossible for any participant to cheat the system decentralization unlike traditional databases that are controlled by a single entity like a bank or a government a blockchain is distributed across multiple nodes or computers this decentralization means that no single entity has complete control over the entire chain making it resistant to censorship and single points of failure in essence the main purpose of a blockchain is to provide a secure and transparent way for parties who may not necessarily trust each other to agree on the state of a database without needing a trusted intermediary whether it's transferring cryptocurrencies like Bitcoin recording property Deeds or tracking Goods in a supply chain blockchain's purpose is to enable secure transparent and efficient transactions what can a blockchain really do blockchain technology while often associated with cryptocurrencies has a wide range of applications that can benefit Everyday People in many ways here's what blockchain can really do one secure transactions blockchain can facilitate secure peer-to-peer transactions eliminating the need for intermediaries like Banks this could mean faster transactions with lower fees which is beneficial for remittances or when you're sending money overseas two supply chain transparency blockchain can provide transparency in Supply chains for consumers this means you can verify the authenticity of products track their Journey from source to store and make ethical purchasing decisions three digital identity blockchain can provide a secure way to manage digital identities this could simplify the process of verifying identities online making it easier and safer to access services like online banking e-commerce or even government services four voting blockchain could be used to create secure transparent voting systems reducing the risk of Fraud and making it easier for people to vote remotely which could increase voter turnout five health records blockchain could be used to create secure inter operable health records this would give individuals more control over their health data and could improve the quality of care six copyright protection for artists and creators blockchain could provide a way to register and protect intellectual property rights and ensure they are fairly compensated for their work seven decentralized Finance Defy blockchain is the backbone of defy which aims to recreate traditional Financial systems like loans or insurance in a decentralized transparent manner this could provide Financial Services to people who are currently unbanked or underbanked as you can see the possibilities are endless as blockchain continues to advance the applications of this incredible technology will only become more diverse and Powerful how blockchain Works step by step understanding how blockchain Works can seem complex but let's break it down into simple step-by-step terms step one transaction action initiation a user initiates a transaction this could be anything from sending cryptocurrencies like Bitcoin to another user recording a contract or even casting a vote in an election step two transaction verification once a transaction is initiated it needs to be verified in a blockchain network this verification is done by a network of computers also known as nodes these nodes confirm the details of the transaction including the validity of the transaction action details and the status of the participants step three transaction added to a block once verified the transaction is grouped with other verified transactions into a block each block has a certain capacity and once that capacity is reached a new block is created step four block added to the chain before the block can be added to the chain it needs to be given a unique identifier known as a cryptographic hash this hash is created from the transaction data in the block and is unique to that block the block also contains the hash of the previous Block in the chain creating a link between the blocks this is where the term blockchain comes from step five consensus the block is now added to the chain but before it can be accepted the nodes in the network need to reach a consensus that the block is valid this is done through a process known as mining in some blockchains like Bitcoin where nodes solve complex mathematical problems other blockchains use different consensus mechanisms like proof of stake step six completion once consensus is reached the block is added to the chain and the transaction is complete the blockchain has now been updated and everyone in the network can see the new block and the transactions it contains can a blockchain be hacked while blockchain technology is designed to be secure and tamper resistant it's not entirely immune to hacking however successfully hacking a blockchain is extremely difficult and requires significant resources one potential vulnerability in blockchain is the 51% attack this occurs when a single entity gains control of more than half of the Network's mining power allowing them to manipulate the recording and verification of new blocks they could potentially double spend coins spend the same digital currency more than once or prevent other miners from validating new transactions however executing a 51% attack on a large well-established blockchain like Bitcoin would require an enormous amount of computational power and is therefore highly unlikely another potential vulnerability is in the smart contracts that run on some blockchains if there's a bug in the code of a smart contract it could be exploited by hackers this was the case in the infamous Dao hack on the ethereum blockchain in 201 16 it's also important to note that while the blockchain itself may be secure applications and digital wallets that interact with the blockchain can be vulnerable to hacking many reported blockchain hacks are actually hacks of these peripheral systems not the underlying blockchain the different types of blockchains blockchain technology has evolved into several different types each with its own characteristics and use cases here are the four main types of blockchains one public blockchains these are open to anyone who wants to participate they are decentralized and transparent meaning any person can join the network validate transactions and create new blocks Bitcoin and ethereum are examples of public blockchains the main advantage of public blockchains is their strong security and transparency but they can be slower and require more computational power due to their consensus mechanisms two private blockchains these are restricted to specific members by the network administrators they are often used by businesses for internal purposes as they offer more control over who can validate transactions and create new blocks this control allows for faster transaction times and less computational power but at the cost of some decentralization an example of a private blockchain platform is hyperledger fabric three Consortium blockchains also known as Federated blockchains these are controlled by a group of organizations rather than a single one they strike a balance between the openness of public blockchains and the control of private blockchains they are often used in the banking sector where several Banks May maintain a shared blockchain four hybrid blockchains these combine elements of public and private blockchains they allow for control over who can see and access the information on the blockchain while still allowing for verification from a decentralized network an example of a hybrid blockchain is Dragon chain each type of blockchain has its own advantages and disadvantages and the choice between them depends on the specific needs and goals of the users or organizations involved the future of blockchains and their true potential the future of blockchain appears both promising and provocative the potential of this technology extends far beyond its current applications and it's poised to disrupt traditional systems in ways we may not even fully comprehend yet one decentralized internet imagine an internet free from the control of tech Giants where data privacy is a given not a luxury blockchain could lay the foundation for a decentralized internet or web 3.0 where users control their own data and digital identities this could fundamentally shift the power dynamics of the digital world but it also raises questions about governance and regulation in a truly decentralized internet two token economy as blockchain and cryptocurrencies continue to evolve we could see the rise of a global token economy in this economy tokens representing real world assets like real estate art or even time could be traded on blockchain platforms this could democratize access to investment opportunities and create a more inclusive global economy however if could also disrupt traditional Financial systems and require new regulatory Frameworks three Ai and blockchain the convergence of blockchain and artificial intelligence could lead to more transparent efficient and secure AI systems blockchain could provide a tamperproof record of AI decisions which could be crucial in fields like autonomous driving or Healthcare but it also raises ethical questions about the control and use of AI in a decentralized context four Quantum threat on the controversial side the Advent of quantum Computing could pose a threat to blockchain quantum computers could potentially break the cryptographic algorithms that secure blockchains leading to a Quantum apocalypse however this also drives the development of quantum resistant blockchains and cryptographic techniques in conclusion the future of blockchain is a thrilling journey into the unknown it holds the promise of a more decentral ized transparent and Equitable world but it also presents new challenges and controversies as we navigate this Uncharted Territory it's crucial to foster a dialogue about the ethical legal and societal implications of this revolutionary technology if you have made it this far comment down below with the word 100% to confirm that you have received the knowledge from this video for more interesting topics make sure you watch the recommended videos that you see on the screen right now thanks for watching"
    }
]